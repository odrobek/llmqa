"file_name","processed_text"
"""CNotes.pdf""","notes: c variables and functions c syntax vs java variables - similar java types - int, short, long, char, float, double, signed vs unsigned const - constant sizeof - determine the size in bytes of a variable or type initialized vs uninitialized variables scope - global vs local variables note: java does not have unsigned types operators - similar java ( intro.c ) arithmetic operators: +, /, -, *, % unary operators: + +, – boolean operators: = =, <, < =, >, > =, & &, ||,! bitwise operators: ~, |, &, ^ ternary operator:?: shift: < <, > > literals - similar java decimal - no modifier needed ( e.g. 134 ) binary - 0b ( e.g. 0b1010 ) hex - 0x ( e.g. 0x1b ) - case does not matter control flow - similar java if / else do / while switch / case break / return arrays there is no new operator in c arrays are declared with [ ] symbols a number in the [ ] indicates the array size arrays do not know size accessing outside array bounds can cause memory violation ( segmentation fault ) functions c does not have classes functions must be declared with return type and 0 or more parameters ( similar java ) void indicates no return type functions must be declared before they are used functions may be declared without a body ( forward declaration ) special function - program entry point - main main may be void or return an int common practice - main returns 0 on success or other value indicate an error main has 2 parameters representing the command line arguments compilation gcc -"
"""CNotes.pdf""","there is no new operator in c arrays are declared with [ ] symbols a number in the [ ] indicates the array size arrays do not know size accessing outside array bounds can cause memory violation ( segmentation fault ) functions c does not have classes functions must be declared with return type and 0 or more parameters ( similar java ) void indicates no return type functions must be declared before they are used functions may be declared without a body ( forward declaration ) special function - program entry point - main main may be void or return an int common practice - main returns 0 on success or other value indicate an error main has 2 parameters representing the command line arguments compilation gcc - the gnu compiler collection 4 phases of compilation preprocessor text replacement of preprocessor macros ( defined using # ) output of this phase is text force the compiler stop after this phase with the -e flag compiler translates text source file assembly output of this phase is assembly language force the compiler stop after this phase with the -s flag assembler translates assembly language source machine language ( binary ) output of this phase is binary object code force the compiler stop after this phase with the -c flag linker builds an executable from all object code files searches for and links together library functions ( e.g. printf ) output of this phase is a binary executable using multiple files gcc will combine multiple source files into a single executable syntax requires all files be included on the command line e.g. gcc main.c otherfile.c problem: functions must be declared before they are used functions defined in another source file must have declarations accessable all files that use them solution: header files (.h files ) define function prototypes ( not implementation ) use preprocessor # include macro include header files in source files (.c files ) including a header file using # include requires name of the file as a string ( within quotes ). for example: 1 # include "" myheader.h "" the compiler will look for header files by name in the local directory directory paths can be used inside # include statements indicate other directory locations for header files. for example: 1 # include "" mydirector / myheader.h "" note: # include preprocessor macro includes the exact content of the target file and then runs the preprocessor on that file. problem: using # include can result in infinite recursive includes solution: use “ include guards ”. in other words, # ifdef, # define, and endif note: # include statements should be reserved for declarations contained within header files doing so can cause duplication definitions for variables, functions, or types also considered bad practice in general solution: put all source files on the command gcc."
"""CNotes.pdf""","for example: 1 # include "" mydirector / myheader.h "" note: # include preprocessor macro includes the exact content of the target file and then runs the preprocessor on that file. problem: using # include can result in infinite recursive includes solution: use “ include guards ”. in other words, # ifdef, # define, and endif note: # include statements should be reserved for declarations contained within header files doing so can cause duplication definitions for variables, functions, or types also considered bad practice in general solution: put all source files on the command gcc. for example: gcc file1.c file2.c file3.c using library functions the c standard library contains hundreds of different functions using c standard library functions requires # include statements for header files these header files are included by name using braces < and >. for example: 1 # include < stdio.h > braces tell the compiler search for header files in the system stored locations rather than the current directory. list of c standard library header files: https://en.cppreference.com/w/c/header links an external site. tutorialspoint - c standard library: https://www.tutorialspoint.com/c_standard_library/index.htm links an external site. notes: c pointers and structures arrays a variable representing multiple elements of the same time ( a sequence of integers ) stored as sequence of elements in memory arrays must be declared with size - note: there is no new operator in c array values are accessed by index ( similar java ) array indices are zero based for example: 1 int myarray [ 5 ]; // declare an array of 5 integers 2 printf ( "" % d\n "", myarra [ 2 ] ); // access 3rd element in the array note: arrays are not initialized by default arrays can be declared and assigned a literal value for example: 1 int myarray [ ] = { 10, 20, 30, 40, 50 }; the compiler will automatically determine the size allocate for the array arrays can be declared as function parameters without needing specify size for example: 1 void handle_array ( int array [ ], unsigned int length ) { 2 // code handle the array 3 } arrays do not know size myarray.length does not exist compiler can determine size of an array using sizeof operator if array is declared in same scope for example: 1 int myarray [ ] = { 10, 20, 30, 40 }; 2 printf ( "" % d\n "", sizeof ( myarray ) /sizeof"
"""CNotes.pdf""","[ ] = { 10, 20, 30, 40, 50 }; the compiler will automatically determine the size allocate for the array arrays can be declared as function parameters without needing specify size for example: 1 void handle_array ( int array [ ], unsigned int length ) { 2 // code handle the array 3 } arrays do not know size myarray.length does not exist compiler can determine size of an array using sizeof operator if array is declared in same scope for example: 1 int myarray [ ] = { 10, 20, 30, 40 }; 2 printf ( "" % d\n "", sizeof ( myarray ) /sizeof ( int ) ); note: does not work if array is declared in a different scope ( e.g. when passing an array a function ) useful convention follow - always pass array size as a separate parameter functions when passing an array strings there is no string class in c strings are represented as an array of characters ( char type ) strings, like other arrays, do not know length strings are null terminated ( i.e. end in a character that contains the value zero ) string functions and formatted output ( printf ) use the null terminator determine where strings end for example: 1 char mystring [ ] = "" hello ""; // compiler allocates 6 bytes - 5 for characters + 1 for null terminator 2 printf ( "" % lu \n "", sizeof ( mystring ) ); // prints 6 - assuming each character is 1 byte 3 printf ( "" % s\n "", mystring ); since strings are arrays, there is no plus ( + ) operator for concatenating strings the c standard library contains string functions for copying, concatenating, parsing, tokenizing, etc. strings: https://cplusplus.com/reference/cstring/ links an external site. pointers a variable representing a location in memory stored as a number useful assign the address of an existing variable for example: 1 int value = 10; // declare a variable 2 int * value_ptr = & value; // declare a pointer the variable 3 printf ( "" % d % p\n "", value, value_ptr ); // print the value and the address address of a variable can be retrieved using the “ address of ” operator ( & ) value stored at a pointer can be retrieved using the “ dereference ” operator ( * )"
"""CNotes.pdf""","pointers a variable representing a location in memory stored as a number useful assign the address of an existing variable for example: 1 int value = 10; // declare a variable 2 int * value_ptr = & value; // declare a pointer the variable 3 printf ( "" % d % p\n "", value, value_ptr ); // print the value and the address address of a variable can be retrieved using the “ address of ” operator ( & ) value stored at a pointer can be retrieved using the “ dereference ” operator ( * ) for example: 1 int value = 10; // declare a variable 2 int * value_ptr = & value; // declare a pointer the variable 3 printf ( "" % d\n "", * value_ptr ); // print the value stored at the pointer literal values can also be assigned a pointer, but not as useful allows passing variables by address a function ( also called “ by pointer ” or “ by reference ” ) instead of passing a value as a function parameter, the pointer ( address ) can be passed the function can then directly store in the memory location using the “ dereference ” perator allows functions return values ( through return ) but also return values through parameters for example: 1 int do_operation ( int input, int * output ) { 2 if(intput < = 0 ) { 3 return -1; 4 } 5 * out = input * 10; // store result directly into memory of the caller 6 return 0; 7 } 8 9 int main ( int argc, char * argv [ ] ) { 10 // initialize variables 11 int input_value = 20; 12 int output_value = 0; 13 14 // call the operation and check for success or failure 15 int success_failure = do_operation ( input_value, & output_value ); 16 if(success_failure = = -1 ) { 17 printf ( "" failed \n "" ); 18 return -1; 19 } else { 20 printf ( "" result: % d\n "", output_value ); 21 } 22 return 0; 23 } const disallows storing a dereferenced pointer for example: 1 int my_function ( int input, const int * other_input ) { 2 if(intput < = 0 ) { 3 return -1; 4 } 5 * other_input = input * 10; // de -reference operation is not allowed 6 return 0; 7 } note: function local variables are declared on the stack the stack entry for a function ( including all variables ) is removed when a function returns do not return a pointer ( address of ) a local variable - later access the variable value ( dereference ) can cause unpredictable results for example: 1 int * my_function ( ) {"
"""CNotes.pdf""","for example: 1 int my_function ( int input, const int * other_input ) { 2 if(intput < = 0 ) { 3 return -1; 4 } 5 * other_input = input * 10; // de -reference operation is not allowed 6 return 0; 7 } note: function local variables are declared on the stack the stack entry for a function ( including all variables ) is removed when a function returns do not return a pointer ( address of ) a local variable - later access the variable value ( dereference ) can cause unpredictable results for example: 1 int * my_function ( ) { 2 int i = 100; // storage for i is removed when the function returns 3 return & i; 4 } 5 6 int main ( int argc, char * argv [ ] ) { 7 int * function_result_ptr = my_function ( ); 8 printf ( "" % d\n "", * function_result_ptr ); // dereferenced value is unpredictable 9 return 0; 10 } pointers and arrays arrays can be represented as pointers the value of the pointer is the address of the first ( index 0 ) element in the array arrays represented as pointers can be accessed using index brackets ( [ ] ) for example: 1 int * myarray = { 10, 20, 30, 40, 50 }; 2 printf ( "" % d\n "", myarray [ 2 ] ); note: arrays in c do not know length using sizeof for arrays declared as a pointer returns the size of a pointer not the size of the entire array for example: 1 int * myarray = { 10, 20, 30, 40, 50 }; 2 printf ( "" % lu \n "", sizeof ( myarray ) ); // prints the size of an integer pointer not 5 * sizeof(int ) arrays when passed functions are passed as a pointer the first element, even if parameter is defined with array braces ( [ ] ); strings, like other arrays, can be represented as a character pointer. for example: 1 char * mystring = "" hello ""; 2 printf ( "" % s\n "", mystring ); note: strings declared as a char * use data declared in read only memory not on the stack for example: 1 char mystring1 [ ] = "" hello ""; 2 char * mystring2 = "" hello ""; 3 printf ( "" % s % s\n "", mystring1, mystring2 ); // prints the same string 4 mystring1 [ 0 ] =' h'; // this is allowed - 5 // data for mystring1 is stored on the stack 6 // and is writable 7 mystring2"
"""CNotes.pdf""","for example: 1 char * mystring = "" hello ""; 2 printf ( "" % s\n "", mystring ); note: strings declared as a char * use data declared in read only memory not on the stack for example: 1 char mystring1 [ ] = "" hello ""; 2 char * mystring2 = "" hello ""; 3 printf ( "" % s % s\n "", mystring1, mystring2 ); // prints the same string 4 mystring1 [ 0 ] =' h'; // this is allowed - 5 // data for mystring1 is stored on the stack 6 // and is writable 7 mystring2 [ 0 ] =' h'; // this is not allowed - 8 // data for mystring2 is stored in read only 9 // memory and mystring2 contains the address 10 // of this memory pointers functions data pointers - e.g. pointers int, float, long, double, char * function pointers, also known as code pointers, represent the address of a function in the text section of memory address of a function can be retrieved using the “ address of ” operator for example: 1 int my_function ( int a, int b ) { 2 return a + b; 3 } 4 5 int main ( int argc, char * argv [ ] ) { 6 printf ( "" % p\n "", & my_function ) 7 return 0; 8 } can be used create an “ alias ” ( e.g. another name ) for a function requires a multi -part declaration the return type of the function the name of the pointer ( do n’t forget the star in the declaration ) the types for the function parameters once assigned, pointer function can be invoked in the same way as the original function for example: 1 int my_function ( int a, int b ) { 2 return a + b; 3 } 4 5 int main ( int argc, char * argv [ ] ) { 6 int ( * my_function_ptr ) ( int, int ) = & my_function; 7 printf ( "" % p\n "", my_function_ptr ); // print address of the function 8 printf ( "" % d\n "", my_function_ptr ( 10, 20 ) ); // invoke the function and print the result 9 return 0; 10 } can be useful for providing custom functions for operations for example - c standard library for quick sort qsort requires a function pointer for comparing array elements: https://cplusplus.com/reference/cstdlib/qsort/ links an external site. structures mechanism for grouping multiple variables into a custom type similar classes in java note: structures do not have methods or functions note:"
"""CNotes.pdf""","[ ] ) { 6 int ( * my_function_ptr ) ( int, int ) = & my_function; 7 printf ( "" % p\n "", my_function_ptr ); // print address of the function 8 printf ( "" % d\n "", my_function_ptr ( 10, 20 ) ); // invoke the function and print the result 9 return 0; 10 } can be useful for providing custom functions for operations for example - c standard library for quick sort qsort requires a function pointer for comparing array elements: https://cplusplus.com/reference/cstdlib/qsort/ links an external site. structures mechanism for grouping multiple variables into a custom type similar classes in java note: structures do not have methods or functions note: no private keywords in c, all data elements in a structure are public declared using the struct keyword requires a type name for example: 1 struct rectangle_t { 2 int base; 3 int height; 4 }; types within a structure ( struct ) can be any valid data type char, short, int, long, float, double pointer another structure using a structure “ instance ” requires declaration of structure type structure types must be declared before they are used access structure elements uses the dot (. ) operator for example: 1 struct rectangle_t { 2 int base; 3 int height; 4 }; 5 6 int main ( int argc, char * argv [ ] ) { 7 struct rectangle_t myrectangle; // note: struct keyword required in declaration 8 myrectangle.base = 10; 9 myrectangle.height = 20; 10 return 0; 11 } structures declared within scope know size ( e.g. sizeof results in expected value works for both structure instances by variable name and by type name note: sizeof by structure type requires the struct keyword for example: 1 struct rectangle_t { 2 int base; 3 int height; 4 }; 5 6 int main ( int argc, char * argv [ ] ) { 7 struct rectangle_t myrectangle; // note: struct keyword required in declaration 8 myrectangle.base = 10; 9 myrectangle.height = 20; 10 printf ( "" % lu \n "", sizeof ( myrectangle ) ); // prints sizeof(int ) + sizeof(int ) 11 printf ( "" % lu \n "", sizeof ( struct rectangle_t ) ) // also prints sizeof(int ) + sizeof(int ) 12 return 0; 13 } useful declare structures in header files, so they can be used in multiple source files allows organization of data into a single type - useful for data structures can be declared literally “ inline ” like arrays and strings for example: 1 int main ( int argc, char * argv"
"""CNotes.pdf""","= 20; 10 printf ( "" % lu \n "", sizeof ( myrectangle ) ); // prints sizeof(int ) + sizeof(int ) 11 printf ( "" % lu \n "", sizeof ( struct rectangle_t ) ) // also prints sizeof(int ) + sizeof(int ) 12 return 0; 13 } useful declare structures in header files, so they can be used in multiple source files allows organization of data into a single type - useful for data structures can be declared literally “ inline ” like arrays and strings for example: 1 int main ( int argc, char * argv [ ] ) { 2 struct { // note inline structures do not require a type name 3 int amount; 4 double other_amount; 5 } my_structure; // this is the variable name not the type name 6 my_structure.amount = 10; 7 my_sructure.other_amount = 10.123; 8 return 0; 9 } structures can be declared and assigned values at the same time, similar arrays and strings element values must be set in the order in they are declared for example: 1 struct rectangle_t { 2 int base; 3 int height; 4 }; 5 6 int main ( int argc, char * argv [ ] ) { 7 struct rectangle_t myrectangle = { 10, 20 }; 8 printf ( "" % d % d\n "", myrectangle.base, myrectangle.height ); 9 return 0; 10 } declaration and assignment of structure values works for mixed types for example: 1 struct rectangle_t { 2 int base; 3 int height; 4 char name [ 10 ]; 5 }; 6 7 int main ( int argc, char * argv [ ] ) { 8 struct rectangle_t myrectangle = { 10, 20, "" john "" }; 9 printf ( "" % d % d % s\n "", myrectangle.base, myrectangle.height, myrectangle.name ); 10 return 0; 11 } structures can be passed as parameters functions structure type must be declared before they are used as parameters compiler will copy all structure variables when passed a function structures can be declared inside a function and used as a return type pointers structure instances can be set using “ address of ” operator pointers structure instances can be passed as a parameter a function access elements in a pointer a structure can be made using the “ dereference perator ” ( * ) followed by a dot (. ) or with the “ pointer ” operator ( - > ) for example: 1 struct rectangle_t { 2 int base; 3 int height; 4 }; 5 6 int main ( int argc, char * argv"
"""CNotes.pdf""","d % d % s\n "", myrectangle.base, myrectangle.height, myrectangle.name ); 10 return 0; 11 } structures can be passed as parameters functions structure type must be declared before they are used as parameters compiler will copy all structure variables when passed a function structures can be declared inside a function and used as a return type pointers structure instances can be set using “ address of ” operator pointers structure instances can be passed as a parameter a function access elements in a pointer a structure can be made using the “ dereference perator ” ( * ) followed by a dot (. ) or with the “ pointer ” operator ( - > ) for example: 1 struct rectangle_t { 2 int base; 3 int height; 4 }; 5 6 int main ( int argc, char * argv [ ] ) { 7 struct rectangle_t myrectangle = { 10, 20, "" john "" }; 8 struct rectangle_t * myrectangle_ptr = & myrectangle; 9 ( * myrectangle_ptr ).height = 200; // dereference first 10 myrectangle_ptr ->base = 10; // using the pointer operator 11 return 0; 12 } note: the “ pointer ” operator ( - > ) is only used on pointers unions similar structures ( struct ) but storage for variables is shared declared using the union keyword instead of the struct keyword other syntax for declaration is the same as structures for example: 1 union my_data_t { 2 int value1; 3 int value2; 4 }; note: storage is shared changing one value, changes the other 1 union my_data_t { 2 int value1; 3 int value2; 4 }; 5 6 int main ( int argc, char * argv [ ] ) { 7 union my_data_t data; 8 data.value1 = 10; 9 data.value2 = 20; // changes the value1 also 10 printf ( "" % d % d\n "", data.value1, data.value2 ); // prints the same value 11 return 0; 12 } mixing data types is allowed with unions semantics for unions still applies changing one value may change one or more other values for example: 1 union my_data_t { 2 int value; 3 char string [ 4 ]; 4 }; 5 6 int main ( int argc, char * argv"
"""CNotes.pdf""","[ ] ) { 7 union my_data_t data; 8 data.value1 = 10; 9 data.value2 = 20; // changes the value1 also 10 printf ( "" % d % d\n "", data.value1, data.value2 ); // prints the same value 11 return 0; 12 } mixing data types is allowed with unions semantics for unions still applies changing one value may change one or more other values for example: 1 union my_data_t { 2 int value; 3 char string [ 4 ]; 4 }; 5 6 int main ( int argc, char * argv [ ] ) { 7 union my_data_t data; 8 data.value = 0x00636261;; 9 printf ( "" % d % s\n "", data.value, data.string ); 10 return 0; 11 } declaration and assignment of values with unions causes a warning when extra values are assigned for example: 1 union my_data_t { 2 int value; 3 char string [ 4 ]; 4 }; 5 6 int main ( int argc, char * argv [ ] ) { 7 union my_data_t data = { 10, "" abc "" }; // causes a compiler warning 8 // the value of 10 is overridden 9 return 0; 10 } the sizeof operator works with unions but the results reflect the shared storage structures and unions can be used concurrently bit fields method of declaration declare a set number of bits declared using type and variable name but also an indicator of the bit width ( number of bits ) compiler will most likely ( but not required ) allocate storage for the entire type, but only allow code access the bits declared for example: 1 struct my_bits_t { 2 unsigned int value:3; // declares 3 bits 3 }; 4 5 int main ( int argc, char * argv [ ] ) { 6 struct my_bits_t bits = { 3 }; 7 printf ( "" % d\n "", bits.value ); 8 return 0; 9 } assigning a value larger than what will fit in the bits declared results in a compiler warning compiler will truncate the value fit for example: 1 struct my_bits_t { 2 unsigned int value:3; // declares 3 bits 3 }; 4 5 int main ( int argc, char * argv [ ] ) { 6 struct my_bits_t bits = { 100 }; 7 printf ( "" % d\n "", bits.value ); // should print 4 8 // 100 in base 10 is 0b01100100 ( in binary ) 9 //"
"""CNotes.pdf""","[ ] ) { 6 struct my_bits_t bits = { 3 }; 7 printf ( "" % d\n "", bits.value ); 8 return 0; 9 } assigning a value larger than what will fit in the bits declared results in a compiler warning compiler will truncate the value fit for example: 1 struct my_bits_t { 2 unsigned int value:3; // declares 3 bits 3 }; 4 5 int main ( int argc, char * argv [ ] ) { 6 struct my_bits_t bits = { 100 }; 7 printf ( "" % d\n "", bits.value ); // should print 4 8 // 100 in base 10 is 0b01100100 ( in binary ) 9 // the lower 3 bits of 0b01100100 is 0b100 10 // 0b100 ( in binary ) is 4 in base 10 11 return 0; 12 } notes: c user defined types user defined types primitive data types have a given keyword name e.g., int, short, float, double, etc. motivation - it is often useful assign a user readable name a type e.g., size_t, length_t, voltage_t, etc. structures and unions are examples of user defined types type definitions ( typedef ) the typedef keyword allows assigning a name a known type syntax: 1 typedef < known type > < custom name >; 1 typedef unsigned int size_t; when the compiler ‘ sees ’ size_t it replaces it with an unsigned int typically written in global scope, but also can be used in other scopes examples: bool in stdbool.h is a typedef uint8_t, int8_t, uint64_t, etc. in stdint.h are typedefs can use typedef simplify declaration of structures ( i.e., do not required the user use the struct keyword ) 1 struct my_structure_t { 2 int var1; 3 char var2; 4 }; 5 6 typedef struct my_structure_t my_structure_t; 7 8 int main ( int argc, char * argv [ ] ) { 9 my_structure_t myvar = { 10,' c' }; 10 } structure typedefs can be declared at the same time as the structure 1 typedef struct my_structure_t { 2 int var1; 3 char var2; 4 } my_structure_t; 5 6 int main ( int argc, char * argv [ ] ) { 7 my_structure_t myvar = { 10,' c' }; 8 } enumerated types ( enum ) enumeration - noun, “ the action of mentioning a number of things one by one. ” oxford languages: https://languages.oup.com/google -dictionary -en / links an external site. the enum keyword defines a data type containing a set of values values are defined as variable names compiler automatically assigns numeric values each name note:"
"""CNotes.pdf""","[ ] ) { 9 my_structure_t myvar = { 10,' c' }; 10 } structure typedefs can be declared at the same time as the structure 1 typedef struct my_structure_t { 2 int var1; 3 char var2; 4 } my_structure_t; 5 6 int main ( int argc, char * argv [ ] ) { 7 my_structure_t myvar = { 10,' c' }; 8 } enumerated types ( enum ) enumeration - noun, “ the action of mentioning a number of things one by one. ” oxford languages: https://languages.oup.com/google -dictionary -en / links an external site. the enum keyword defines a data type containing a set of values values are defined as variable names compiler automatically assigns numeric values each name note: values must be numeric syntax: 1 enum < name > { 2 < value name >, 3 < value name >, 4 < value name >, 5 < value name >, 6 etc. 7 }; 1 enum weekday_t { 2 monday, 3 tuesday, 4 wednesday, 5 thursday, 6 friday 7 }; declaring an instance of the type requires the enum keyword 1 enum weekday_t my_day = monday; note: can be useful combine with typedef 1 enum weekday_t { 2 monday, 3 tuesday, 4 wednesday, 5 thursday, 6 friday 7 }; 8 typedef enum weekday_t weekday_t; values in the enumeration can be directly assigned 1 enum orientation_t { 2 up = 0, 3 upright = 1, 4 right = 2, 5 downright = 3, 6 down = 4, 7 downleft = 5, 8 left = 6, 9 upleft = 7 10 }; directly assigning values can be useful for bit masks 1 enum pin_enable_t { 2 dc_3_3v = 1 < < 0, 3 dc_5v = 1 < < 1, 4 ground = 1 < < 2, 5 reset = 1 < < 3, 6 rx_01 = 1 < < 4, 7 rx_02 = 1 < < 5, 8 tx_01 = 1 < < 6, 9 tx_02 = 1 < < 7, 10 }; notes: c dynamic memory heap memory in a process address space that can be dynamically allocated as needed remains in existence until explicitly freed by the program freed by the operating system when a process terminates allocated using the malloc ( memory allocate ) function call allocates a number of bytes and returns the address ( pointer ) the location processes are limited in allowed dynamic memory - malloc will fail when process is ut of memory check return value verify that memory was actually allocated freed using the free function call takes an address ( pointer ) a dynamically allocated location in memory and frees the storage attempting free memory that was not allocated with malloc results in runtime error malloc and free ( along with other variations ) manual: https://man7.org/linux/man - pages / man3 / malloc.3.html links an external site."
"""CNotes.pdf""","values must be numeric syntax: 1 enum < name > { 2 < value name >, 3 < value name >, 4 < value name >, 5 < value name >, 6 etc. 7 }; 1 enum weekday_t { 2 monday, 3 tuesday, 4 wednesday, 5 thursday, 6 friday 7 }; declaring an instance of the type requires the enum keyword 1 enum weekday_t my_day = monday; note: can be useful combine with typedef 1 enum weekday_t { 2 monday, 3 tuesday, 4 wednesday, 5 thursday, 6 friday 7 }; 8 typedef enum weekday_t weekday_t; values in the enumeration can be directly assigned 1 enum orientation_t { 2 up = 0, 3 upright = 1, 4 right = 2, 5 downright = 3, 6 down = 4, 7 downleft = 5, 8 left = 6, 9 upleft = 7 10 }; directly assigning values can be useful for bit masks 1 enum pin_enable_t { 2 dc_3_3v = 1 < < 0, 3 dc_5v = 1 < < 1, 4 ground = 1 < < 2, 5 reset = 1 < < 3, 6 rx_01 = 1 < < 4, 7 rx_02 = 1 < < 5, 8 tx_01 = 1 < < 6, 9 tx_02 = 1 < < 7, 10 }; notes: c dynamic memory heap memory in a process address space that can be dynamically allocated as needed remains in existence until explicitly freed by the program freed by the operating system when a process terminates allocated using the malloc ( memory allocate ) function call allocates a number of bytes and returns the address ( pointer ) the location processes are limited in allowed dynamic memory - malloc will fail when process is ut of memory check return value verify that memory was actually allocated freed using the free function call takes an address ( pointer ) a dynamically allocated location in memory and frees the storage attempting free memory that was not allocated with malloc results in runtime error malloc and free ( along with other variations ) manual: https://man7.org/linux/man - pages / man3 / malloc.3.html links an external site. concerns: allocating with malloc requires the caller specify requested memory in bytes how determine exact size when allocating a specific data type? use the sizeof operator for example: 1 int main ( int argc, char * argv [ ] ) { 2 int length = 0; 3 printf ( "" how many ints should i allocate? "" ); 4 scanf ( "" % d "", & length ); 5 int * my_numbers = malloc ( length * sizeof ( int ) ); //"
"""CNotes.pdf""","values must be numeric syntax: 1 enum < name > { 2 < value name >, 3 < value name >, 4 < value name >, 5 < value name >, 6 etc. 7 }; 1 enum weekday_t { 2 monday, 3 tuesday, 4 wednesday, 5 thursday, 6 friday 7 }; declaring an instance of the type requires the enum keyword 1 enum weekday_t my_day = monday; note: can be useful combine with typedef 1 enum weekday_t { 2 monday, 3 tuesday, 4 wednesday, 5 thursday, 6 friday 7 }; 8 typedef enum weekday_t weekday_t; values in the enumeration can be directly assigned 1 enum orientation_t { 2 up = 0, 3 upright = 1, 4 right = 2, 5 downright = 3, 6 down = 4, 7 downleft = 5, 8 left = 6, 9 upleft = 7 10 }; directly assigning values can be useful for bit masks 1 enum pin_enable_t { 2 dc_3_3v = 1 < < 0, 3 dc_5v = 1 < < 1, 4 ground = 1 < < 2, 5 reset = 1 < < 3, 6 rx_01 = 1 < < 4, 7 rx_02 = 1 < < 5, 8 tx_01 = 1 < < 6, 9 tx_02 = 1 < < 7, 10 }; notes: c dynamic memory heap memory in a process address space that can be dynamically allocated as needed remains in existence until explicitly freed by the program freed by the operating system when a process terminates allocated using the malloc ( memory allocate ) function call allocates a number of bytes and returns the address ( pointer ) the location processes are limited in allowed dynamic memory - malloc will fail when process is ut of memory check return value verify that memory was actually allocated freed using the free function call takes an address ( pointer ) a dynamically allocated location in memory and frees the storage attempting free memory that was not allocated with malloc results in runtime error malloc and free ( along with other variations ) manual: https://man7.org/linux/man - pages / man3 / malloc.3.html links an external site. concerns: allocating with malloc requires the caller specify requested memory in bytes how determine exact size when allocating a specific data type? use the sizeof operator for example: 1 int main ( int argc, char * argv [ ] ) { 2 int length = 0; 3 printf ( "" how many ints should i allocate? "" ); 4 scanf ( "" % d "", & length ); 5 int * my_numbers = malloc ( length * sizeof ( int ) ); // correctly allocates enough bytes 6 7 // use my_numbers here 8 9 free ( my_numbers ); 10 return 0; 11 } memory must be freed after it is no longer needed memory should not be freed after it has already been freed doing so results in runtime error note:"
"""CNotes.pdf""","[ ] ) { 2 int length = 0; 3 printf ( "" how many ints should i allocate? "" ); 4 scanf ( "" % d "", & length ); 5 int * my_numbers = malloc ( length * sizeof ( int ) ); // correctly allocates enough bytes 6 7 // use my_numbers here 8 9 free ( my_numbers ); 10 return 0; 11 } memory must be freed after it is no longer needed memory should not be freed after it has already been freed doing so results in runtime error note: pointers are just numbers the address stored in a pointer dynamically allocated memory retains its value after being freed dereferencing freed memory results in unpredictable behavior for example: 1 int main ( int argc, char * argv [ ] ) { 2 int * my_numbers = malloc ( 10 * sizeof ( int ) ); // allocate 10 integers 3 4 // use my_numbers here 5 6 free ( my_numbers ); 7 8 printf ( "" % d\n "", * my_numbers ); // access freed memory - 9 // may work or 10 // may result in error - segmentation fault 11 return 0; 12 } useful when combined with structures for linked data structures linked list nodes tree nodes etc. forgetting free allocated memory results in memory waste - also known as a memory leak automatic memory release memory can be dynamically allocated on the stack alloca - https://man7.org/linux/man -pages / man3 / alloca.3.html links an external site. similar semantics malloc - requires size in bytes of allocation compiler typically allocates memory with alloca on the stack can cause stack overflow if requested allocation is too large does not have a corresponding free storage is automatically freed when function returns note: do not return the address ( pointer ) memory allocated with alloca"
"""csc3210-01-OSIntroAndMotivation.pdf""","introduction and motivation csc3210 – operating systemswhy are we here? 1940s – 1950s: how can computers be built? special purpose processing mathematical equations 1960s: what are the best abstractions use? instruction set architecture – general purpose hardware late 1960s and 1970s: researchers investigate operating systems 1980s – move from analog digital – personal computer age of information 1990s – 2000s -computing accessibility moore ’s “ law ” 2010s and on -information age internet of things artificial intelligencewhat can we learn from this? the gap between hardware and users is huge hardware is complicated abstractions are beautiful everything is connected data centers desktops smart phones devices sensorswhat can we learn from this? we are generating lots of datawhat can we learn from this? memory and storage is getting cheaperwhat is a computer? memory cpu keyboard monitor mouse disk drive peripheralswhat is a computer? abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. pieces of a computer processor controls the operation of the computer main memory stores the data used by a computer and the programs that execute. typically, losses all values when the computer is shut down i / o modules moves data between the computer and the external environment system bus allows for communication between processors, main memory, and io moduleswhat is memory? abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. how a computer works abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. fetch execute loop abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. what is software? “ software is a set of instructions, data or programs used operate computers and execute specific tasks. it is the opposite of hardware, describes the physical aspects of a computer. software is a generic term used refer applications, scripts and programs that run on a device. it can be thought of as the variable part of a computer, while hardware is the invariable part. ” https://www.techtarget.com/searchapparchitecture/definition/softwarewhat is an operating system? “ an operating system ( os ) is the program that, after being initially loaded into the computer by a boot program, manages all of the other application programs in a computer. the application programs make use of the operating system by making requests for services through a defined application program interface ( api )."
"""csc3210-01-OSIntroAndMotivation.pdf""","software is a generic term used refer applications, scripts and programs that run on a device. it can be thought of as the variable part of a computer, while hardware is the invariable part. ” https://www.techtarget.com/searchapparchitecture/definition/softwarewhat is an operating system? “ an operating system ( os ) is the program that, after being initially loaded into the computer by a boot program, manages all of the other application programs in a computer. the application programs make use of the operating system by making requests for services through a defined application program interface ( api ). in addition, users can interact directly with the operating system through a user interface, such as a command -line interface ( cli ) or a graphical ui ( gui ). ” https://www.techtarget.com/whatis/definition/operating -system -oswhat is an operating system? “ software that provides services users and applications. ” dr lembkecomputer hardware and software william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishing why do we need an operating system? questions is arm different than x86? is it desirable have the same software work on different computers? is it desirable for all software developers know how access hardware? is it desirable run multiple programs concurrently? is it desirable allow multiple programs access all the cpu hardware?why do we need an operating system? software that provides services users and applications advantages convenience efficiency security flexibility -ability evolve disadvantage -overhead what does an operating system provide? program development program execution io device access file access system access error detection and handling•accounting / bookkeeping instruction set architecture support application binary interface application programming interface isolation and protectionwhat is multiprogramming? “ multiprogramming is a rudimentary form of parallel processing in several programs run at the same time on a uniprocessor system. however, because there is only one processor, there is no true simultaneous execution of different programs. instead, the operating system ( os ) executes part of one program, then part of another, and so n. in this sense, multiprogramming can be thought of as pseudo - parallelism. the user, it appears that multiple programs are executing at the same time, but that is not what is happening. ” https://www.techtarget.com/whatis/definition/multiprogrammingwhat is multiprogramming? “ the appearance that more than one program is running at the same time ” dr. lembkewhy is multiprogramming good? a cpu “ core ” can execute a single instruction stream at a time cpus are orders of magnitude faster than memory cpus spend a lot of time waiting reading / writing from / memory reading / writing from / disks reading / writing from / other i / o devices waiting for user input idle cpus do n’t get any work donewhy is multiprogramming good?"
"""csc3210-01-OSIntroAndMotivation.pdf""","the user, it appears that multiple programs are executing at the same time, but that is not what is happening. ” https://www.techtarget.com/whatis/definition/multiprogrammingwhat is multiprogramming? “ the appearance that more than one program is running at the same time ” dr. lembkewhy is multiprogramming good? a cpu “ core ” can execute a single instruction stream at a time cpus are orders of magnitude faster than memory cpus spend a lot of time waiting reading / writing from / memory reading / writing from / disks reading / writing from / other i / o devices waiting for user input idle cpus do n’t get any work donewhy is multiprogramming good? https://verizon5gedgeblog.medium.com/why -cpu - utilization -doesnt -tell - the - whole -story -89239b07a7f6multiprogramming william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingperating system vs kernel operating system software that provides services users and applications kernel software that “ bridges ” hardware and software figurative sense of "" core or central part of anything “ ( https://www.etymonline.com/word/kernel ) questions is a kernel an operating system? is there more an operating system than just the kernel? can an operating system have more than one kernel? does the kernel run on its own? how do we create a kernel?program vs process program static representation of operations and data compiled code process instance of active execution"
"""csc3210-02-SystemCalls.pdf""","system calls csc3210 – operating systemsperating system vs kernel operating system software that provides services users and applications kernel a piece of software that “ bridges ” hardware and software figurative sense of "" core or central part of anything “ https://www.etymonline.com/word/kernel questions is a kernel an operating system? is there more an operating system than just the kernel? can an operating system have more than one kernel? does the kernel run on its own? how do we create a kernel?system calls system calls provide a set of “ functions ” for applications use perating system services os specific portable operating system interface ( posix ) c or c++ library interface typically involve some “ trap ” the operating systemdual mode operation modern operating systems use at least two modes of operation user mode a restricted mode of operation only allows certain instructions be executed by the program prevents errant processes from crashing the system kernel mode also referred as supervisor mode, system mode, or privileged mode allows the system full access the microprocessor intended be used only by the operating systemsystem calls trap, system call, supervisor call: user mode - > kernel mode transfers control from user program kernel function sets mode from user kernel abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. why do we need system calls? isolation and protection kernel is running in privileged mode user process is not can processes share anything? we will see this later as a method of inter -process communication can processes share information with the kernel? in addition sharing information, we also want kernel take actions, perhaps immediatelysystem call categories file management creating, accessing, modifying files, directories, and/or other files information maintenance retrieval of information stored in the operating system specific communication between operating system and a process process control creating, ending, waiting for processes communication sending information between processes may be processes within the same system or processes between different systems device management direct access and management of system devices behavior on success -data is returned, filled in via pointer, and operation is performed on errors -typically -1 is returned and specific error is set in errnosystem calls example -file input / output what ’s a file? abstract representation of data on “ disk ” how do we access a file? open, read / write, close file descriptor lab1 pen read write closesystem call table system calls are invoked by number kernel finds code process the system call by indexing in a table linux system call table: 32 bit -https://chromium.googlesource.com/chromiumos/docs/+/master/constants/syscalls.md#x86 -32_bit 64 bit -https://chromium.googlesource.com/chromiumos/docs/+/master/constants/syscalls.md#x86_64 -64_bit windows system call table: 32 bit -https://j00ru.vexillium.org/syscalls/nt/32/ 64 bit -https://j00ru.vexillium.org/syscalls/nt/64/system call -hello world https://en.wikibooks.org/wiki/x86_assembly/interfacing_with_linuxhow"
"""csc3210-02-SystemCalls.pdf""","in addition sharing information, we also want kernel take actions, perhaps immediatelysystem call categories file management creating, accessing, modifying files, directories, and/or other files information maintenance retrieval of information stored in the operating system specific communication between operating system and a process process control creating, ending, waiting for processes communication sending information between processes may be processes within the same system or processes between different systems device management direct access and management of system devices behavior on success -data is returned, filled in via pointer, and operation is performed on errors -typically -1 is returned and specific error is set in errnosystem calls example -file input / output what ’s a file? abstract representation of data on “ disk ” how do we access a file? open, read / write, close file descriptor lab1 pen read write closesystem call table system calls are invoked by number kernel finds code process the system call by indexing in a table linux system call table: 32 bit -https://chromium.googlesource.com/chromiumos/docs/+/master/constants/syscalls.md#x86 -32_bit 64 bit -https://chromium.googlesource.com/chromiumos/docs/+/master/constants/syscalls.md#x86_64 -64_bit windows system call table: 32 bit -https://j00ru.vexillium.org/syscalls/nt/32/ 64 bit -https://j00ru.vexillium.org/syscalls/nt/64/system call -hello world https://en.wikibooks.org/wiki/x86_assembly/interfacing_with_linuxhow do we invoke a system call? can a system call be a function call? most system calls are wrapped with user -callable functions available via the standard library linux -libc/ glibc windows – nativeapi ( ntdll.dll ) https://linuxhandbook.com/system -calls / linux system calls https://lwn.net/articles/604515/system calls -questions how do we pass data a system call? how many system calls do we need? what should the system calls do? what process executes a system call?"
"""csc3210-03-Processes.pdf""","processes csc3210 – operating systemsdual mode operation modern operating systems use at least two modes of operation user mode a restricted mode of operation only allows certain instructions be executed by the program prevents errant processes from crashing the system kernel mode also referred as supervisor mode, system mode, or privileged mode allows the system full access the microprocessor intended be used only by the operating systemprogram vs process program static representation of operations and data compiled code process instance of active execution william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingwhy do we need processes? concurrent processing real concurrency achieved by hardware i / o devices operate at same time as processor multiple processors / cores each operate at the same time apparent concurrency achieved with multitasking ( multiprogramming ) multiple programs appear operate simultaneously operating system provides the illusion isolation and protection ca n’t let one process affect another without permissionprogram structure a program has multiple pieces – here are some examples text the instructions execute data sections static data ( numbers, strings, etc. ) linking information what software libraries does this program use? ( math library, crypto library, etc. ) symbol table information about the symbols ( variable names ) this program usesprocess structure a process has multiple pieces text section the executable code that is running data section the global variables of the program bss ( block started by symbol ) – uninitialized global variables heap dynamically allocated memory when a process executes ( i.e. new ) stack temporary data for the process function parameters, return addresses, local variables, etc. program vs process program – elf executable and linkable formatprocessmultiprogramming william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingstack int foo2(int k ) { int i = 5 return i + k; } int foo1(int k ) { int i = 5; int j = k + i + foo2(k ); return j; } int main ( ) { int i = foo1(20 ); int j = i + 10; return j; } i and j return address -?? parameter k i and j return address - mainparameter k i return address – foo1foo2 foo1 mainwhat is a computer? abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. processes os abstraction created by os system call managed entirely by os; unknown hardware operates “ concurrently ” with other processes processes have “ state ” the status of the process – what is currently doing cpu can only do one thing at a time not all processes can be executing at onceprocess"
"""csc3210-03-Processes.pdf""","parameter k i and j return address - mainparameter k i return address – foo1foo2 foo1 mainwhat is a computer? abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. processes os abstraction created by os system call managed entirely by os; unknown hardware operates “ concurrently ” with other processes processes have “ state ” the status of the process – what is currently doing cpu can only do one thing at a time not all processes can be executing at onceprocess state – 2 state model two state model running and ready is this all we need? what about i / o? how do we decide state transitions? round robin scheduling: each process in the queue is given a certain amount of time execute and then returned the queue, unless it completes period is known as a quantum efficiency -can we do better?ready running start exitprocess state – 5 state model new the process has just been created but has not yet executed ready the process is waiting be assigned a cpu waiting ( blocked ) the process is waiting for some event occur running the process is executing on the cpu terminated ( exit ) the process has finished executionprocess state – 5 state model abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. processes – more things think about how many processes do we want allow? what if we run out of memory? what about process priority? how do we handle run -away processes? how do we schedule processes? fairness? what does the os need keep track of for a process? cpu can only do one thing at a time not all processes can be executing at onceprocess scheduler objective of multiprogramming the cpu must always be doing something process scheduler enforces scheduling policy selects an available process is ready and determines that it will be the next process execute send the process the dispatcher process dispatchers responsible for causing the cpu start executing the desired processprocess control block ( pcb ) what does the os need keep track of? process state process identifier owning user contents of registers program counter memory references others? abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. process table how do we track multiple processes? os keeps a table of all pcbs for all processes indexed by process identifierprocess"
"""csc3210-03-Processes.pdf""","what does the os need keep track of for a process? cpu can only do one thing at a time not all processes can be executing at onceprocess scheduler objective of multiprogramming the cpu must always be doing something process scheduler enforces scheduling policy selects an available process is ready and determines that it will be the next process execute send the process the dispatcher process dispatchers responsible for causing the cpu start executing the desired processprocess control block ( pcb ) what does the os need keep track of? process state process identifier owning user contents of registers program counter memory references others? abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. process table how do we track multiple processes? os keeps a table of all pcbs for all processes indexed by process identifierprocess table process hierarchy systemd system loggershell shell chrome ls gvimparent child child childviewing process information -linux listing processes and information ps – by default only shows the processes for the current user use “ psaux ” show all information a = show processes for all users u = display the process's user / owner x = also show processes that are running in the background listing the process hierarchy ( tree ) use the “ pstree ” commandviewing process information -windows listing processes and information accessed through the “ task manager ” listing the process hierarchy ( tree ) viewed through the windows process explorer utility https://learn.microsoft.com/en -us / sysinternals / downloads / process -explorercreating a process fork ( ) system call that “ splits ” a processes into two new process begins executing at the return from fork parent keeps executing after calling fork programmer can tell the difference based on fork return value return value in parent process – child process identifier ( pid ) return value in the child process – 0 questions: how can the child figure out its pid? how can the child process figure out the parent ’s pid? is there a use having multiple processes in a single program?about fork “ man fork ” for all the details parent and child processes execute the same source code do not share memory locations do share file descriptors can we communicate easily between parent and child? file system: named files, fifos, pipes shared memory is there a better way?executing a new program exec ( ) the fork ( ) system call duplicates a parent parent and child execute the same code problem: how do other programs get executed?"
"""csc3210-03-Processes.pdf""","system call that “ splits ” a processes into two new process begins executing at the return from fork parent keeps executing after calling fork programmer can tell the difference based on fork return value return value in parent process – child process identifier ( pid ) return value in the child process – 0 questions: how can the child figure out its pid? how can the child process figure out the parent ’s pid? is there a use having multiple processes in a single program?about fork “ man fork ” for all the details parent and child processes execute the same source code do not share memory locations do share file descriptors can we communicate easily between parent and child? file system: named files, fifos, pipes shared memory is there a better way?executing a new program exec ( ) the fork ( ) system call duplicates a parent parent and child execute the same code problem: how do other programs get executed? solution: the exec ( ) system call the exec ( ) system call replaces the current address space of a process with the address space for the given program determines the program entry procedure ( e.g., main ) and runs the process text, global memory, and stack are replaced with new programabout exec “ man exec ” for all the details on failure exec ( ) returns -1 and sets errno on success exec ( ) does not return the new program just starts executing at entry procedure process identifier remains the same old address space is destroyed old malloc ’s are free’ed open file descriptors are not closed by default"
"""csc3210-04-IPC.pdf""","inter -process communication csc3210 – operating systemsmotivation problem parent and child process do not share address spaces question how can parent and child communicate?parent child fork()file input / output what ’s a file? abstract representation of data on “ disk ” how do we access a file? open, read / write, close file descriptor lab1 pen read write closefile descriptors posix requires access file via a file descriptor ( fd ) file descriptor: stored as a number reference access file information in the file table in kernel space file table entry: open mode ( reading or writing ) position pointer reference the file system -access permissions, file type, reading, and writing every process is given 3 file descriptors standard in -fd 0 standard out -fd 1 standard error -fd 2file descriptors and fd table file descriptor ( number ) - > reference an entry in the fd table file descriptor table is referenced in the process control block managed by the kernel as files are opened and closed by the process parent and child share entries in the file descriptor table inter -process communication ( ipc ) mechanism provided by the operating system from one process communicate with another how? shared file pipes anonymous named message passing signals•shared memory memory -mapped file sockets ip unix domainfile system memory is not shared between parent and child open file descriptors are shared shared file myfileparent childfork ( ) create ( ) read ( ) write()read ( ) write()file system shared named file file descriptors are shared file position pointers are also shared problem parent opens file file position pointer is at location 0 child writes “ hello ” file – file position pointers is at location 5 parent reads from the file parent gets no data returned•solution? parent opens file file position pointer is at location 0 child writes “ hello ” file – file position pointers is at location 5 parent seeks beginning of file file position pointers is at location 0 parent reads from the file parent gets “ hello”file system -pipes provides an anonymous communication mechanism between parent and child pipe ( ) system call creates 2 file descriptors – one for each end kernel maintains position pointers named – fifo ( first in first out ) note: pipes and fifos are streams of data data has no structure ( format ) sender / receiver must know how data is formatted write end read endmessage passing messages are sent and received from queues can contain arbitrary binary data ( int, struct, etc. ) parent child queuesend recvmessage passing operate like a pipe / fifo write a message ( send ) read a message ( receive )"
"""csc3210-04-IPC.pdf""","child writes “ hello ” file – file position pointers is at location 5 parent seeks beginning of file file position pointers is at location 0 parent reads from the file parent gets “ hello”file system -pipes provides an anonymous communication mechanism between parent and child pipe ( ) system call creates 2 file descriptors – one for each end kernel maintains position pointers named – fifo ( first in first out ) note: pipes and fifos are streams of data data has no structure ( format ) sender / receiver must know how data is formatted write end read endmessage passing messages are sent and received from queues can contain arbitrary binary data ( int, struct, etc. ) parent child queuesend recvmessage passing operate like a pipe / fifo write a message ( send ) read a message ( receive ) messages have a set size ( structure ) message queues are limited in size ( number of messages ) message queues live beyond the life of the processes that use them options on how send and receive synchronous or asynchronous ( blocking or non -blocking )? blocking send – sending process is blocked until the receiving process reads message non -blocking send – sending process sends message and continues blocking receive – receiver blocks until a message is available non -blocking receive – receiver retrieves either a valid message or a null message https://man7.org/linux/man -pages / man7 / mq_overview.7.htmlsignals asynchronous mechanism for communication no data associated with the signal sent via the kill ( ) system call handler is a function given the os using the signal ( ) system call signals have numerical identifiers representing a type default behavior ( when no handler is set ) – terminate the receiving process signal list: https://man7.org/linux/man -pages / man7 / signal.7.htmlsignals and signal handlers shared memory memory is not shared between parent and child by default shared memory – special memory map between parent and child parent child shared shared sharedshared memory pros can share variables between parent and child -treat like global data cons takes up address space from other variables how much shared memory should we allocate? synchronization what happens if multiple processes try write the same variable at the same time?memory mapped file memory is not shared between parent and child by default memory mapped file – the contents of a file is mapped into process address space parent child shared shared myfilesockets like pipes can be used for network communication by binding a network interface ipc across physical machines unix domain sockets like sockets but optimized for ipc"
"""csc3210-05-ThreadsAndConcurrency.pdf""","threads and concurrency csc3210 – operating systemsmotivation problem parent and child process do not share address spaces question how can parent and child communicate? inter process communication is there an easier way?parent child fork()inter -process sharing sharing variables is easier than sharing via handles or descriptors unstructured load / store how much do we want processes share? text? heap? data? stack? threads “ processes ” that share by default text data heap each have own stack why? function calls local variablestext data heap stack 1 stack 2 stack 3 thread 1 thread 2 thread 3processes vs threads a process represents: address space that holds process image access resources ( i / o, file systems, etc. ) a process possesses one or more threads, each with: thread execution state, saved context if not running execution stack per - thread static storage access shared, process -owned memory and resources implicit ipc through shared text, data, and heap bad news – data racesthread implementation -kernel processes are an os concept does it make sense implement threads in os? os is already managing memory os is already managing scheduling blocking only stops active thread william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingthread implementation – user level does it make sense implement threads in user space? user program may have more knowledge of how threads are used ( scheduling ) runs without os awareness single process space manage blocking stops all threads william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingpthreads – posix threads user level functions built on kernel level threads function calls like those for processes pthread_create - > fork ( ) pthread_join - > wait ( ) pthread_exit - > exit ( ) pthreads share process identifier, but have own thread identifier pthreads share everything parent and child processes share + text, data, and heapconcurrency -motivation problem race condition – two processes / threads are manipulating the same data at the same time with the potential of having different outcomes critical section -a segment of code that accesses a shared resource that must not be concurrently accessed by more than one thread of execution. solutions? multiple processes that do n’t share address spaces modify values using pipes, messages, etc. atomic cpu operations can help ( fetch and add, fetch and subtract )"
"""csc3210-05-ThreadsAndConcurrency.pdf""","pearson publishingpthreads – posix threads user level functions built on kernel level threads function calls like those for processes pthread_create - > fork ( ) pthread_join - > wait ( ) pthread_exit - > exit ( ) pthreads share process identifier, but have own thread identifier pthreads share everything parent and child processes share + text, data, and heapconcurrency -motivation problem race condition – two processes / threads are manipulating the same data at the same time with the potential of having different outcomes critical section -a segment of code that accesses a shared resource that must not be concurrently accessed by more than one thread of execution. solutions? multiple processes that do n’t share address spaces modify values using pipes, messages, etc. atomic cpu operations can help ( fetch and add, fetch and subtract ) atomic cpu operations are not always portable does not work for multiple variables ( can only atomically change one at a time)concurrency – desires / guarantees mutual exclusion if a process is executing in its critical section, then no other processes can be executing in critical sections progress if no process is executing in its critical section and there exist some processes that wish enter critical section, then the selection of the processes that will enter the critical section next can not be postponed indefinitely bounded waiting ( starvation freedom / fairness ) a bound must exist on the number of times that other processes are allowed enter critical sections after a process has made a request enter its critical section and before that request is grantedprogress progress if no process is executing in its critical section and there exist some processes that wish enter critical section, then the selection of the processes that will enter the critical section next can not be postponed indefinitely deadlock ( aggressive holding of resources ) process ‘ a ’ is executing in its critical section while waiting for process ‘ b ’ at the same time, process ‘ b ’ is executing in its critical section while waiting for process ‘ a ’ can either continue? livelock ( passive ‘ holding ’ of resources ) process ‘ a ’ releases a resource so process ‘ b ’ can continue, but must wait for ‘ b ’ be done once the resource is received, process ‘ b ’ releases the resource so process ‘ a ’ can continue can either continue?mutual exclusion mechanisms signaling – semaphores locking – mutex locks conditions – condition variablessemaphore signaling mechanism from one process /thread"
"""csc3210-05-ThreadsAndConcurrency.pdf""","process ‘ a ’ is executing in its critical section while waiting for process ‘ b ’ at the same time, process ‘ b ’ is executing in its critical section while waiting for process ‘ a ’ can either continue? livelock ( passive ‘ holding ’ of resources ) process ‘ a ’ releases a resource so process ‘ b ’ can continue, but must wait for ‘ b ’ be done once the resource is received, process ‘ b ’ releases the resource so process ‘ a ’ can continue can either continue?mutual exclusion mechanisms signaling – semaphores locking – mutex locks conditions – condition variablessemaphore signaling mechanism from one process /thread another keeps a current value count operations: signal and wait signal atomically increments the value by 1 - > releases a process if value was < 0 wait atomically decrements the value by 1 - > forces the process wait if new value < 0 special case – binary semaphore – has a max value of 1 semaphore concerns: if more than 1 process is waiting, one will be released after a signal? linux uses a fifo wait queue; first process forced wait is the first process be released semaphore do no enforce ownership – not a lock there is no max value on a semaphore – multiple ‘ signals ’ will continue increment the count mutex lock like a binary semaphore can be locked or unlocked maintains ownership operations: lock and unlock lock locks the mutex if it is unlocked ( recording ownership ) if mutex is locked by someone else the locker is forced wait unlock unlocks the mutex if it is locked if someone is waiting for the lock, it locks the mutex under ownership and lets them continue only the owner of a mutex can unlock it mutex concerns: what if the owner locks the mutex more than once?"
"""csc3210-05-ThreadsAndConcurrency.pdf""","there is no max value on a semaphore – multiple ‘ signals ’ will continue increment the count mutex lock like a binary semaphore can be locked or unlocked maintains ownership operations: lock and unlock lock locks the mutex if it is unlocked ( recording ownership ) if mutex is locked by someone else the locker is forced wait unlock unlocks the mutex if it is locked if someone is waiting for the lock, it locks the mutex under ownership and lets them continue only the owner of a mutex can unlock it mutex concerns: what if the owner locks the mutex more than once? what if the owner unlocks the mutex more than once? mutex lock vs semaphore mutex lock can only be used synchronize threads binary only can only be unlocked by the wner locking mechanismsemaphore can synchronize across processes and threads can be binary or counting any process or thread can signal a semaphore signaling mechanismconditions concurrency mechanisms ( tools ) semaphores -allow a signaling mechanism allow 1 or more threads proceed locks -allow exclusive access resources problem operations with concurrency tools are not atomic between mechanism it is not possible receive a signal from a semaphore and acquire a lock at the same time why is this useful? producer / consumerproducer consumer one or more threads is / are writing a shared array one or more threads is / are reading from the shared array how do you control access? writers: more than one writer should not write the array at once writers might write multiple elements the array writers should finish all writing before being required wait for other writers readers: more than one reader should not read the array at once readers might read multiple elements from the array readers should finish all reading before being required wait for other readersproducer consumer"
"""csc3210-06-Deadlock.pdf""","deadlock csc3210 – operating systemsdeadlock situation: there are lots of resources on the system that we ’d like share access: memory cpu i / o devices files the operating system provides several mechanisms mutually exclusive access these resources semaphores mutexes condition variablesdeadlock problem what if a process tries get exclusive access a resource held by another process and vice versa? deadlock exists among a set of processes if every process is waiting for an event that can be caused only by another process in the setvoid * thread1(void * ) { pthread_mutex_lock ( & lock1 ); // do work, wait pthread_mutex_lock ( & lock2 ); // do work, wait pthread_mutex_unlock ( & lock2 ); pthread_mutex_unlock ( & lock1 ); return null; } void * thread2(void * ) { pthread_mutex_lock ( & lock2 ); // do work, wait pthread_mutex_lock ( & lock1 ); // do work, wait pthread_mutex_unlock ( & lock1 ); pthread_mutex_unlock ( & lock2 ); return null; } deadlock problem what if multiple process estryto allocate resources when not enough are availabl e? given 200 resources – assume request blocks if resources are not available deadlock exists among a set of processes if every process is waiting for an event that can be caused only by another process in the setvoid * thread1(void * ) { request(80 ); // do work, wait request(60 ); // do work, wait release_resources ( ); return null; } void * thread2(void * ) { request(70 ); // do work, wait request(80 ); // do work, wait release_resources ( ); return null; } conditions for deadlock all the following must happen for deadlock occur: mutual exclusion only one process may use a resource at a time no process may access a resource unit that has been allocated another process hold and wait a process may hold allocated resources while awaiting assignment of other resources no preemption no resource can be forcibly removed from a process holding it circular wait a closed chain of processes exists, such that each process holds at least one resource needed by the next process in the chaindeadlock mitigation strategies deadlock detection – have the system monitor locked resources determine when deadlock occurs deadlock prevention – never let the system be in a situation where all 4 conditions for deadlock occur deadlock avoidance – define a system state of safe or unsafe – never let the system enter an unsafe state deadlock recovery – when deadlock occurs and is detected, find a way remove itdeadlock detection resource allocation graph processes ( p ) and resources ( r )"
"""csc3210-06-Deadlock.pdf""","no resource can be forcibly removed from a process holding it circular wait a closed chain of processes exists, such that each process holds at least one resource needed by the next process in the chaindeadlock mitigation strategies deadlock detection – have the system monitor locked resources determine when deadlock occurs deadlock prevention – never let the system be in a situation where all 4 conditions for deadlock occur deadlock avoidance – define a system state of safe or unsafe – never let the system enter an unsafe state deadlock recovery – when deadlock occurs and is detected, find a way remove itdeadlock detection resource allocation graph processes ( p ) and resources ( r ) an arrow pointing from p r indicates a request for the resource an arrow pointing from r p indicates the resources is held create a graphs for all resources held and requested by all processes deadlock may exist if there is a cyclep1 r1 p1 r1requests held byresource allocation graphs deadlock? no p1 r1requestsp2requests deadlock? no p1 r1requestsp2held by p1r1 p2 r2deadlock? yes p1 is requests r1 is held by p2 requests r2 is held by p1resource allocation graphs what if you have more than one instance of a resource? does a cycle detect deadlock in that case? consider a semaphore where the value > 1 there are two instances of r1 r1is requested by p1 one instance is held by p2 there is a cycle but no deadlockp1r1 * * p2 r2deadlock prevention conditions for deadlock mutual exclusion hold and wait no preemption circular wait eliminate any of the conditions and deadlock ca n’t happen how do you do this safely?deadlock avoidance do n’t let a process request a resource if it could cause deadlock system state safety safe state – deadlock is not possible unsafe state – deadlock is possible ( although might not be happening ) goal of deadlock avoidance -never let the system get into an unsafe state what is safe and unsafe?safe state unsafe statedeadlock statedeadlock recovery what do you do when you have deadlock? three main approaches terminate the processes terminate all terminate one by one -priority based termination problem: how do you pick a process ( or set of processes ) terminate preempt the resources rollback execution a safe state problems how do you find a safe state? starvation -how do you ensure progress? do nothing"
"""csc3210-07-Scheduling.pdf""","process scheduling csc3210 – operating systemsscheduling situation: multiple processes ( instruction streams ) need be executed these processes have different cpu needs i / o intensive cpu intensive processes have different amounts of needed run -time ( burst time ) there are limited cpu resources ( cpu can only do one thing at a time ) switching between processes takes time ( overhead ) store old process context clear out sensitive values from old process set new process contextfairness situation: want schedule processes so that all make forward progress in a fair way. do n’t want ‘ starve ’ a process of cpu access i / o intensive – processes that take more time waiting for input / output than using the cpu for computation – e.g. a shell cpu intensive – processes that need lots of cpu cycles and do n’t spend much time ( if any ) waiting for i / o – e.g. matrix math what ’s fair scheduling when there are a mixture of i / o intensive and cpu intensive processes?queueing cpu blocked queueready, suspended queueready queuetimeout wait event suspendsuspend blocked, suspended queuei / o completeresume i / o completesuspend i / o waitdispatchqueuing with priority cpuready queue p1 dispatch ready queue p2 ready queue p3timeoutscheduling no preemption – os lets processes run completion without interruption first come / first served ( fcfs ) processes are executed in the order in they are submitted shorted job next ( sjn ) / shortest job first ( sjf ) of all processes in the ready queue, pick the one that needs the least time preemption – os interrupts processes running for some reason shorted remaining time ( srt )"
"""csc3210-07-Scheduling.pdf""","do n’t want ‘ starve ’ a process of cpu access i / o intensive – processes that take more time waiting for input / output than using the cpu for computation – e.g. a shell cpu intensive – processes that need lots of cpu cycles and do n’t spend much time ( if any ) waiting for i / o – e.g. matrix math what ’s fair scheduling when there are a mixture of i / o intensive and cpu intensive processes?queueing cpu blocked queueready, suspended queueready queuetimeout wait event suspendsuspend blocked, suspended queuei / o completeresume i / o completesuspend i / o waitdispatchqueuing with priority cpuready queue p1 dispatch ready queue p2 ready queue p3timeoutscheduling no preemption – os lets processes run completion without interruption first come / first served ( fcfs ) processes are executed in the order in they are submitted shorted job next ( sjn ) / shortest job first ( sjf ) of all processes in the ready queue, pick the one that needs the least time preemption – os interrupts processes running for some reason shorted remaining time ( srt ) at any point in time swap the process in the ready queue that has the least amount of time remaining round robin processes are given a time quantum removed from cpu after quantum has expiredevaluation criteria fairness turnaround time – elapsed time from the time of submission the time of completion wait time – the amount of time spent in the ready queue note: time spent in the suspended or blocked queue is not recorded response ratio – turnaround time / service time how many times longer did it take for the process complete than what was required? cpu utilization – amount of time the cpu spends executing ‘ useful ’ work throughput – number of processes completed per unit time deadline – did process complete on or before it needed toexample – no preemptionprocess arrival time service time a 0 3 b 2 6 c 4 4 d 6 5 e 8 2 fcfs a b c d e 012345678910111213141516171819 sjn a b c d e 012345678910111213141516171819example – no preemptionprocess arrival time service time a 0 3 b 2 6 c 4 4 d 6 5 e 8 2 fcfs a b c d e 012345678910111213141516171819 sjn a b c d e 012345678910111213141516171819fcfs a b c d e avg finish time 3 9 13 18 20 turnaround time 3 7 9 12 12 8.6 response ratio 1 1.17 2.25 2.4 6 2.56 sjn a b c d e avg finish time 3 9 15 20 11 turnaround time 3 7 11 14 3 7.6 response ratio 1 1.17 2.75 2.8 1.5 1.84example"
"""csc3210-07-Scheduling.pdf""","at any point in time swap the process in the ready queue that has the least amount of time remaining round robin processes are given a time quantum removed from cpu after quantum has expiredevaluation criteria fairness turnaround time – elapsed time from the time of submission the time of completion wait time – the amount of time spent in the ready queue note: time spent in the suspended or blocked queue is not recorded response ratio – turnaround time / service time how many times longer did it take for the process complete than what was required? cpu utilization – amount of time the cpu spends executing ‘ useful ’ work throughput – number of processes completed per unit time deadline – did process complete on or before it needed toexample – no preemptionprocess arrival time service time a 0 3 b 2 6 c 4 4 d 6 5 e 8 2 fcfs a b c d e 012345678910111213141516171819 sjn a b c d e 012345678910111213141516171819example – no preemptionprocess arrival time service time a 0 3 b 2 6 c 4 4 d 6 5 e 8 2 fcfs a b c d e 012345678910111213141516171819 sjn a b c d e 012345678910111213141516171819fcfs a b c d e avg finish time 3 9 13 18 20 turnaround time 3 7 9 12 12 8.6 response ratio 1 1.17 2.25 2.4 6 2.56 sjn a b c d e avg finish time 3 9 15 20 11 turnaround time 3 7 11 14 3 7.6 response ratio 1 1.17 2.75 2.8 1.5 1.84example – preemptionprocess arrival time service time a 0 3 b 2 6 c 4 4 d 6 5 e 8 2 round robin ( q = 1 ) a b c d e 012345678910111213141516171819 srt a b c d e 012345678910111213141516171819example – preemptionprocess arrival time service time a 0 3 b 2 6 c 4 4 d 6 5 e 8 2 round robin ( q = 1 ) a b c d e 012345678910111213141516171819 srt a b c d e 012345678910111213141516171819round robin a b c d e avg finish time 4 18 17 20 15 turnaround time 4 16 13 14 7 10.8 response ratio 1 2.67 3.25 2.8 3.5 2.71 srt a b c d e avg finish time 3 15 8 20 10 turnaround time 3 13 4 14 2 7.2 response ratio 1 2.17 1 2.8 1 1.59preemption vs non -preemption fcfs and sjn / sjf attempts minimize turn around time works well for cpu intensive processes round robin gives appearance of multiprogramming large time quantum > low overhead > poor response for multiprogramming low time quantum > high overhead > better response for multiprogramming optimal? enough for user interaction•srt provably optimal if service time is known sjn / sjf and srt often not possible know service time"
"""csc3210-08-MemoryManagement.pdf""","memory management csc3210 – operating systemsmemory management situation: multiple processes ( instruction streams ) need be executed these processes have different memory needs there is a finite amount of memory processes should not be allowed access other process ’s memory processes might want share memory problem: how do you allocate memory efficiently? not all processes need the same amount of memory processes do n’t know exactly how much memory they need process addresses spaces need be contiguous gaps in memory allocation are a wastetext data heap stackprocess address space 0 bssmemory allocation when processes start, memory needs be allocated process control block text data processes want dynamically allocate and free memory stack heap memory is finite - not all processes will fit in memory at the same timememory allocation – fixed partitions every process gets the same size memory partition problems: internal fragmentation extra space within the block that is allocated but is not needed some processes need more memory than others william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishing memory allocation – dynamic partitions processes get memory partition that is the exact size for what they need where do we put the process allocation? first fit next fit best fit worst fit problems: external fragmentation wasted space outside allocations that ca n’t be used because they are too small may not know how much memory a process will need when it starts william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishing memory allocation fixed allocation – equal or unequal partitions good - easy manage bad internal fragmentation ( if process does n’t need as much as is allocated ) unable run a process ( if process needs more than any partition size ) dynamic allocation good – variable in terms of memory allocation bad external fragmentation management requires finding an open fragment of free memory management requires freeing and coalescing free memory when processes endprocess – relocation and protection a process for a program is not always located in the same location in memory a process should not be allowed access another process ’s memory a process should be allowed allocate and free memory over the course of its “ life ” memory is finitememory access – a perfect world remember memory 0 1 2 3result 0 1 2 3accessthe world is not perfect remember memory 0 1 2 3result 0 1 2 3access? remember memory 0 1 2 3result 0 1 2 3notepaging0 1 2 3noteaccesspagingpaging 0 1 2 3noteaccess? paging - swapping 0 1 2 3noteaccesspaging - swapping 0 1 2 3noteaccesspaging - swapping 0 1 2 3noteaccesspaging - swapping 0 1 2 3noteaccessprocess management paging - problem a process expects data always be in the same place what happens when there are multiple processes?"
"""csc3210-08-MemoryManagement.pdf""","unable run a process ( if process needs more than any partition size ) dynamic allocation good – variable in terms of memory allocation bad external fragmentation management requires finding an open fragment of free memory management requires freeing and coalescing free memory when processes endprocess – relocation and protection a process for a program is not always located in the same location in memory a process should not be allowed access another process ’s memory a process should be allowed allocate and free memory over the course of its “ life ” memory is finitememory access – a perfect world remember memory 0 1 2 3result 0 1 2 3accessthe world is not perfect remember memory 0 1 2 3result 0 1 2 3access? remember memory 0 1 2 3result 0 1 2 3notepaging0 1 2 3noteaccesspagingpaging 0 1 2 3noteaccess? paging - swapping 0 1 2 3noteaccesspaging - swapping 0 1 2 3noteaccesspaging - swapping 0 1 2 3noteaccesspaging - swapping 0 1 2 3noteaccessprocess management paging - problem a process expects data always be in the same place what happens when there are multiple processes? memory management should not have be done by the processconsider: void foo ( ) { int i = 0; int green = 0; for(i = 0; i < 10; i++ ) { printf(""%p \n "" ), & green ); } } expected result: 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0 0x7ffe4fcbe6d0perating system managed paging requirement - allow processes access the same location for data even when the data is moved around in memory terms virtual address – va – location process accesses physical address – pa – actual location of data idea divide program memory into a series of equal sized pieces - pages divide physical memory into pieces ( same size as pages ) - frames copy pages from disk memory as they are needed copy pages from memory disk when there are no free frames record frame the page is located or that it is n’t in memory when a program accesses data at a virtual address, translate the access the correct physical address. address translation...... physical memory virtual memory ffset ffset fact: page size = = frame size page offset = = frame offset computation: offset = virtual address % page size physical address = k * page size + offset0 k n-10 1page number frame numberaddress translation – page table the ‘ notebook ’ for storing where ( frame ) pages are located indexed by page number stores frame number fact: page size = = frame size page offset = = frame offset computation: page number = virtual address / page size offset = virtual address % page size frame number = page table[page number ] physical address = frame number *"
"""csc3210-08-MemoryManagement.pdf""","physical memory virtual memory ffset ffset fact: page size = = frame size page offset = = frame offset computation: offset = virtual address % page size physical address = k * page size + offset0 k n-10 1page number frame numberaddress translation – page table the ‘ notebook ’ for storing where ( frame ) pages are located indexed by page number stores frame number fact: page size = = frame size page offset = = frame offset computation: page number = virtual address / page size offset = virtual address % page size frame number = page table[page number ] physical address = frame number * page size + offset6 9... 0 1 2 3 4 5 m-1address translation math is hard - hardware is easy ensure page size is a power of 2 - address translation becomes routing bits page size = 4096 = 212 address size = 64 bits max addresses = 264 page number offset0 11 12 63 page tableva frame number offset0 11 12 63 paaddress translation - hardware memory management unit ( mmu ) translates virtual addresses physical address problem: mmu needs page table translate va pa page table is in memory mmu requires additional memory access get page table entry solution: translation lookaside buffer ( tlb ) cache within the mmu that stores page table entriespage table entry page table entry size = address size present / valid - is the page in memory? yes / no ( 1 bit ) protection are the contents of the page readable? yes / no ( 1 bit ) are the contents of the page writable? yes / no ( 1 bit ) accessed - was the page access recently? yes / no ( 1 bit ) dirty - has the page been modified since it ’s been in memory? yes / no ( 1 bit ) page / frame number offset0 11 12 63 address structure: virtual memory / demand paging paging and address translation advantages process pages can be put anywhere in memory process can only access own pages – isolation and protection optimization how much of a process address space does a process access ( read / write )?"
"""csc3210-08-MemoryManagement.pdf""","yes / no ( 1 bit ) accessed - was the page access recently? yes / no ( 1 bit ) dirty - has the page been modified since it ’s been in memory? yes / no ( 1 bit ) page / frame number offset0 11 12 63 address structure: virtual memory / demand paging paging and address translation advantages process pages can be put anywhere in memory process can only access own pages – isolation and protection optimization how much of a process address space does a process access ( read / write )? only put the pages a process needs in memory problems what if a page that a process needs is not in memory? memory is finite – what if there is not enough memory for all executing processes memory?page replacement / page fault triggered by mmu when requested page is not in a frame mmu sends page fault interrupt ( like a trap ) operating system services interrupt determines frame for page free frame if available chose a victim page send disk populates the frame with new page updates the page table what happens if present bit in page table is not set and page does not exist?page replacement find the location of the desired page on disk find a free frame: if there is a free frame, use it if there is no free frame, use a page replacement algorithm select a victim frame write victim frame disk if dirty bring the desired page into the ( newly ) free frame; update the page and frame tables continue the process by restarting the instruction that caused the trap note: now potentially 2 page transfers for page faultpage replacement abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. virtual memory advantages isolation allows multiple processes memory without interfering with each other abstraction allows a process use all the memory they ‘ want ’ efficiency locality - a process typically only uses a subset of pages ( working set ) sharing - read only page ( e.g., code ) can be shared between multiple processes copy on write – “ copied ” ( e.g., fork ) pages can be shared until one process modifies a pagecopy on write ( cow ) allows both parent and child processes initially share the same pages in memory if either process modifies a shared page, only then is the page copied allows more efficient process creation as only modified pages are copied in general, free pages are allocated from a pool of zero -fill - on - demand pages why zero -out a page before allocating it?virtual memory concerns what happens when a process is context switched? how is a victim page chosen? what happens when a process working set is large?"
"""csc3210-08-MemoryManagement.pdf""","virtual memory advantages isolation allows multiple processes memory without interfering with each other abstraction allows a process use all the memory they ‘ want ’ efficiency locality - a process typically only uses a subset of pages ( working set ) sharing - read only page ( e.g., code ) can be shared between multiple processes copy on write – “ copied ” ( e.g., fork ) pages can be shared until one process modifies a pagecopy on write ( cow ) allows both parent and child processes initially share the same pages in memory if either process modifies a shared page, only then is the page copied allows more efficient process creation as only modified pages are copied in general, free pages are allocated from a pool of zero -fill - on - demand pages why zero -out a page before allocating it?virtual memory concerns what happens when a process is context switched? how is a victim page chosen? what happens when a process working set is large? thrashing what happens when the page table gets big 32 - bit address space and 4096 -byte pages / frames = > 220 ( 1048576 ) page table entries 4 bytes per entry = > 4 mib for page table 64 - bit address space and 4096 -byte pages / frames = > 252 page table entries 8 bytes per entry = > 36 tib for page tablecontext switching os needs context switch process p1 for process p2 tlb contains page table entry cache for p1 process p2 has its own page table os needs clear the tlb and ensure that p2 ’s page table is used for all future accesses result: context switching is costly cpu mmu memoryvirtual address physical address datapage table p1 tlbpage table p2frame allocation / page replacement frame allocation - how many frames give each process? page replacement algorithm first in / first out ( fifo ) least recently used optimal want lowest page -fault rate on both first access and re -accesspage replacement - first in / first out the first page brought into memory is the first victim page fast choose a victim treat frames like a linked list and keep track of the head pointer example: 7,0,1,2,0,3,0,4,2,3,0,3,0,3,2,1,2,0,1,7,0,1 3 frames ( 3 pages can be in memory at a time per process ) 15 page faults abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. page replacement – least recently used the victim page is the ‘ oldest ’ page idea take advantage of temporal and spatial locality temporal – if a process accesses a page, it ’s going access it again soon spatial -"
"""csc3210-08-MemoryManagement.pdf""","the first page brought into memory is the first victim page fast choose a victim treat frames like a linked list and keep track of the head pointer example: 7,0,1,2,0,3,0,4,2,3,0,3,0,3,2,1,2,0,1,7,0,1 3 frames ( 3 pages can be in memory at a time per process ) 15 page faults abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. page replacement – least recently used the victim page is the ‘ oldest ’ page idea take advantage of temporal and spatial locality temporal – if a process accesses a page, it ’s going access it again soon spatial - if a process accesses a page, it ’s going access a location close it soon requires lots of bookkeeping keep track of access time example: 12 page faults abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing.ptimal – needed farthest in the future the victim page is the page that will not be used for longest period idea take advantage of temporal and spatial locality temporal – if a process accesses a page, it ’s going access it again soon spatial - if a process accesses a page, it ’s going access a location close it soon not possible – ca n’t predict the future example: 9 page faults abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. virtual memory tradeoffs increasing page size decreases size of the page table, increasing performance but a smaller page result s in less fragmentation and thus better performance but a smaller page size may result in less total io, therefore giving better performance all in all, it depends on both spatial and temporal locality relationships of the executing program general trend is toward larger page sizes what works best? benchmark process behaviorthrashing more processes is not always good if a process does not have “ enough ” pages, the page -fault rate is very high. this leads: low cpu utilization – process spends more time waiting for i / o read / write pages high number of context switches – waiting processes are n’t ready abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing."
"""csc3210-09-FileSystems.pdf""","file systems csc3210 – operating systemsfile systems situation: user needs a mechanism organize persistent data problem: disk represents data a contiguous array of blocks solution: os establishes a structure and abstraction of directories and files ( file system ) os drivers translates user request ( system calls ) access directories and files into i / o requests external mediadisk drive media – block i / o hard disk drive ( hdd ) magnetic storage spinning platters read heads i.e., moving parts slow access time compared memory solid state disk ( ssd ) nand flash -no moving parts no magnetic storage can wear out -https://www.dell.com/support/kbdoc/en -us/000137999 / hard -drive - why - do - solid -state -devices -ssd - wear -out slow access time compared memorydisk drive media – block i / o disk drive ( hdd or ssd ) is a contiguous array of blocks ( typically 512 bytes although 4096 bytes becoming more common ) must be read / written via an i / o request slow access time hdd on the order of milliseconds ssd on the order of microseconds memory access time on the order of nanosecondsfile what is a file? what information do we want store for a file? what operations do we want do a file?file what is a file? data what information do we want store for a file? file name type size permissions location data other?file -operations what operations do we want do a file? create find read write delete manage permissions rename move others?file – access patterns processes access files for different reasons single file patterns sequential – access from start end random – access at random points in the file multiple file patterns different files in the same directory / folder files across multiple directories / folders meta data only access file size, time of last access, etc. goal – need be efficient for all access typesfile allocation data for multiple files needs be stored on disk problem files are not the same size files can grow or shrink during “ life ” files can be deleted files should be organizable in folders / directories potential solutions contiguous allocation chained allocation indexed allocationfile allocation -contiguous sectors on disk are treated like an array files are placed in contiguous free blocks file allocation table records starting block and length in blocks advantage fast for reading files – next block is always in next sector disadvantage ca n’t increase file size prone fragmentation william stallings. 2018. operating systems: internals and design principles ( 9th ed. )."
"""csc3210-09-FileSystems.pdf""","goal – need be efficient for all access typesfile allocation data for multiple files needs be stored on disk problem files are not the same size files can grow or shrink during “ life ” files can be deleted files should be organizable in folders / directories potential solutions contiguous allocation chained allocation indexed allocationfile allocation -contiguous sectors on disk are treated like an array files are placed in contiguous free blocks file allocation table records starting block and length in blocks advantage fast for reading files – next block is always in next sector disadvantage ca n’t increase file size prone fragmentation william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingfile allocation - chained file sectors are treated like a large linked list files are allocated in any free blocks a file block points the next block in the file file allocation table records starting block and length in blocks advantages no fragmentation, any block can be used for the file can add / remove from beginning, middle, r end of file by just updating pointers disadvantage must read the previous block before knowing the next block william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingfile allocation - chained consolidation / defragmentation file sectors are reorganized so they are contiguous advantages sectors are right next each ther so reads and writes are faster disadvantage ca n’t access the files while they are being reorganized william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingfile allocation - indexed a single block is used record all the blocks for the file files are allocated in any free blocks file allocation table records the block of the index block advantages no fragmentation, any block can be used for the file can add / remove from beginning, middle, r end of file by just updating pointers only need read the index block find file data blocks disadvantage file size is limited what fits in an index block william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingfile allocation – extents accessing contiguous blocks can be faster than non -contiguous access extents – map 1 or more contiguous blocks per allocation can be used for any file allocation mechanism must store the start of each extent and the length file - location typically, a folder / directory structure directory / folder contains no data contains entries items contained in the directory may contain other directories may contain “ pointers ” items in other directories ( e.g., links / shortcuts ) william stallings. 2018. operating systems: internals and design principles ( 9th ed. )."
"""csc3210-09-FileSystems.pdf""","pearson publishingfile allocation – extents accessing contiguous blocks can be faster than non -contiguous access extents – map 1 or more contiguous blocks per allocation can be used for any file allocation mechanism must store the start of each extent and the length file - location typically, a folder / directory structure directory / folder contains no data contains entries items contained in the directory may contain other directories may contain “ pointers ” items in other directories ( e.g., links / shortcuts ) william stallings. 2018. operating systems: internals and design principles ( 9th ed. ). pearson publishingfile system - operations problem finding the location of a file is costly requires searching the directory tree requires disk access do n’t always need read / write the entire file access may be in multiple places in the file files should n’t be deleted in the middle of access solution search for the file meta data once and store the reference the file use a reference count prevent file deletion e.g., openfile systems – free space management situation file allocation mechanisms manage allocated space for files meta data for files is loaded in memory when a file is open meta data for files is cleared when a file is closed problem how does the operating system efficiently manage free space? solutions bitmap/ bitvector free blocks - > 0, allocated blocks - > 1 linked list store link first free block, each free block links the nextfile systems – bitmap/ bitvector each block in the drive gets a bit a value of 0 indicates free a value of 1 indicates used by some file, directory, etc. advantage fast find free block find a free block = find first zero bit disadvantage needs be stored in memory be efficient 512 - byte blocks - > 1 tb drive = approx. 2 * 109 bits = 250 mb of memory for bit mapfile systems – linked list store pointer first free block each block points the next free block advantage fast find free block use the first entry in the list disadvantage takes time traverse the list of free blocks if a block breaks, the chain is lost abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing."
"""csc3210-09-FileSystems.pdf""","advantage fast find free block find a free block = find first zero bit disadvantage needs be stored in memory be efficient 512 - byte blocks - > 1 tb drive = approx. 2 * 109 bits = 250 mb of memory for bit mapfile systems – linked list store pointer first free block each block points the next free block advantage fast find free block use the first entry in the list disadvantage takes time traverse the list of free blocks if a block breaks, the chain is lost abraham silberschatz, peter b. galvin, and greg gagne. 2013. operating system concepts essentials ( 2nd ed. ). wiley publishing. file systems - performance situation disk i / o operations take a long time processes needs access potentially lots of files files are located all over the disk drive problem how access files quickly solution prefetching and caching concern – what happens if data is in the cache when the system fails?file system – consistency modifying a file may require multiple writes write meta data – directory entry write file allocation table ( blocks in the file ) write free space tracking system crash during modification can cause inconsistency blocks may fail how recover from failures? duplicate file allocation and free space file / block consistency checkingfile system – meta duplication keep two ( or more ) copies of the file allocation information advantage – if one copy goes bad, the second copy can be used disadvantages single file update requires two ( or more ) updates requires additional disk space system may crash in the middle of update if both copies are usable but not identical, one is correct? versioning set a version number on the table highest version is the correct versionfile system – block consistency build block tables scan file system for all allocated blocks scan file system for all free blocks check block table an allocated block should not be in more than 1 file a block should not be allocated and free at the same time update file system date be consistent add unallocated blocks free list remove allocated blocks from free list mark files corrupt if blocks are allocated more than oncefile system – block consistency block allocation countis free? 0 1 0 1 1 0 2 1 0 3 0 1 4 0 1 5 1 0 6 0 1 7 1 0consistent:"
"""csc3210-09-FileSystems.pdf""","if both copies are usable but not identical, one is correct? versioning set a version number on the table highest version is the correct versionfile system – block consistency build block tables scan file system for all allocated blocks scan file system for all free blocks check block table an allocated block should not be in more than 1 file a block should not be allocated and free at the same time update file system date be consistent add unallocated blocks free list remove allocated blocks from free list mark files corrupt if blocks are allocated more than oncefile system – block consistency block allocation countis free? 0 1 0 1 1 0 2 1 0 3 0 1 4 0 1 5 1 0 6 0 1 7 1 0consistent: block allocation countis free? 0 1 0 1 1 0 2 1 0 3 0 1 4 0 0 5 1 0 6 0 1 7 1 0inconsistent block 4 not allocated and not in free list block allocation countis free? 0 1 0 1 1 0 2 1 0 3 0 1 4 1 1 5 1 0 6 0 1 7 1 0inconsistent block 4 allocated and in free list block allocation countis free? 0 1 0 1 1 0 2 1 0 3 0 1 4 2 0 5 1 0 6 0 1 7 1 0inconsistent block 4 allocated 2 files fix add block 4 free listfix remove block 4 from free listfix allocate a free block copy block 4 allocated block update file allocation for one of the files use the new blockfile systems – case study – fat16 file allocation table ( fat ) file system uses chained and indexed allocation method data blocks are divided into clusters a cluster is a fixed # sectors, with a sector typically being 512 bytes disk region reserved region ( incl. boot sector ) file allocation table ( fat ) * x root directory data regionfat reserved region ffset description size 00h jump code + nop 3 bytes 03h oem name 8 bytes 0bh bytes per sector 1 word 0dh sectors per cluster 1 byte 0eh reserved sectors 1 word 10h number of copies of fat 1 byte 11h maximum root directory entries 1 word 13h number of sectors in partition smaller than 32 mb 1 word 15h media descriptor ( f8h for hard disks ) 1 byte 16h sectors per fat 1 word 18h sectors per track 1 word 1ah number of heads 1 word 1ch number of hidden sectors in partition 1 double word 20h number of sectors in partition 1 double word 24h logical drive number of partition 1 word 26h extended signature ( 29h ) 1 byte 27h serial number of partition 1 double word 2bh volume name of partition 11 bytes 36h fat name ( fat16 ) 8 bytes 3eh executable code 448 bytes 1feh executable marker ( 55h aah ) 2"
"""csc3210-09-FileSystems.pdf""","nop 3 bytes 03h oem name 8 bytes 0bh bytes per sector 1 word 0dh sectors per cluster 1 byte 0eh reserved sectors 1 word 10h number of copies of fat 1 byte 11h maximum root directory entries 1 word 13h number of sectors in partition smaller than 32 mb 1 word 15h media descriptor ( f8h for hard disks ) 1 byte 16h sectors per fat 1 word 18h sectors per track 1 word 1ah number of heads 1 word 1ch number of hidden sectors in partition 1 double word 20h number of sectors in partition 1 double word 24h logical drive number of partition 1 word 26h extended signature ( 29h ) 1 byte 27h serial number of partition 1 double word 2bh volume name of partition 11 bytes 36h fat name ( fat16 ) 8 bytes 3eh executable code 448 bytes 1feh executable marker ( 55h aah ) 2 bytesfile allocation table – fat16 fat # 1 follows reserved section, fat # 2 follows fat # 1, etc. each fat occupies sectors_per_fat each fat entry corresponds a cluster in the volume and denotes: the cluster number of the next cluster in a chain a special end of cluster -chain ( eoc ) entry that indicates the end of a chain a special entry mark a bad cluster a zero note that the cluster is unused fat 16 = 2 bytes per fat entry ( cluster ) fat cluster entries 0 and 1 are special … cluster 0 ’s entry = fat id cluster 1 ’s entry = eoc marker ( usually all 1s ) cluster # 2 starts right after root directoryfile allocation table – directory entry ffset length value 0 8 bytes name 8 3 bytes extension 11 byteattribute ( 00arshdv ) 0: unused bit a: archive bit, r: read -only bit s: system bit d: directory bit v: volume bit 22 word time 24 word date 26 word starting cluster 28 dword file sizefile allocation table - directory entry ffset length value 0 8 bytes name 8 3 bytes extension 11 byteattribute ( 00arshdv ) 0: unused bit a: archive bit, r: read -only bit s: system bit d: directory bit v: volume bit 22 word time 24 word date 26 word starting cluster 28 dword file size 46 49 4c 45 31 20 20 20 54 58 54 20 00 13 7c 7b |file1 txt.. |{| 64 51 64 51 00 00 7c 7b64 510b 0006 00 00 00 |dqdq.. |{dq......"
"""csc3210-09-FileSystems.pdf""","cluster # 2 starts right after root directoryfile allocation table – directory entry ffset length value 0 8 bytes name 8 3 bytes extension 11 byteattribute ( 00arshdv ) 0: unused bit a: archive bit, r: read -only bit s: system bit d: directory bit v: volume bit 22 word time 24 word date 26 word starting cluster 28 dword file sizefile allocation table - directory entry ffset length value 0 8 bytes name 8 3 bytes extension 11 byteattribute ( 00arshdv ) 0: unused bit a: archive bit, r: read -only bit s: system bit d: directory bit v: volume bit 22 word time 24 word date 26 word starting cluster 28 dword file size 46 49 4c 45 31 20 20 20 54 58 54 20 00 13 7c 7b |file1 txt.. |{| 64 51 64 51 00 00 7c 7b64 510b 0006 00 00 00 |dqdq.. |{dq...... |file allocation table file allocation table entry indicates the next cluster in the file or an indicator fat entry special values: 0x0000 – available cluster 0x0001 – reserved / not used 0x0002 0xffef – valid cluster next in chain value 0xfff0 – 0xfff7 – various reserved and/or non - standard usages 0xfff8 – 0xffff – end of cluster -chain file starts at cluster 0x0002 cluster chain is 0x0006, 0x0007, 0x0008, 0x0009, 0x00142 3 4 cluster number:"
"""PageReplacementExampleFIFO.pdf""","page fault example using first in / first out ( fifo ) replacement policy. there is a single process in the system. the system has 3 frames of memory. access number accessed page read or write page fault? ( yes or no ) victim page write back? ( yes or no ) 1 0 read y n / a n 2 1 read y n /a n 3 2 read y n / a n 4 3 read y 0 n 5 4 write y 1 n 6 5 write y 2 n 7 2 read y 3 n 8 0 write y 4 y 9 2 write n n /a n 10 5 write n n / a n 11 5 read n n / a n 12 6 read y 5 y 13 1 read y 2 y"
"""PageReplacementExampleLRU.pdf""","page fault example using least recently used ( lru ) replacement policy. there is a single process in the system. the system has 3 frames of memory. access number accessed page read or write page fault? ( yes or no ) victim page write back? ( yes or no ) 1 0 read y n / a n 2 1 read y n /a n 3 2 read y n / a n 4 3 read y 0 n 5 4 write y 1 n 6 5 write y 2 n 7 2 read y 3 n 8 0 write y 4 y 9 2 write n n /a n 10 5 write n n / a n 11 5 read n n / a n 12 6 read y 0 y 13 1 read y 2 y"
"""csc3210syllabus.pdf""","csc3210: operating systems spring 2024 instructor: dr jim lembke ( 002 and 004 ) ffice: dh419 student hours: see schedule posted in canvas email: lembke@msoe.edu microsoft teams: james lembke course meetings: 002 - mrf 01:00 - 01:50pm 004 - twf 02:00 -02:50pm course description: this course introduces the design and implementation of modern operating systems. topics covered include the history of operating systems, process creation and management, scheduling, resource sharing, concurrency, deadlock detection and avoidance, memory management, file systems, protection and security, and input / output systems. students wil l be exposed the posix interface, the construction of an operating system executing on a small microprocessor, and will construct shell scripts and “ make ” files. ( prereq: csc 2210 or cpe 2600 ) ( quarter system prereq: cs 2040 ) course learning outcomes: upon successful completion of this course, the student will be able: identify computer hardware components and relationship the operating system describe the process for accessing operating system services via system calls apply posix system calls identify the components of operating system process management identify and use operating system services for inter process communication recognize and resolve issues related concurrent processes and synchronization techniques discuss and illustrate several approaches operating system memory management discuss and illustrate commonly used process scheduling algorithms describe input / output handling in operating systems illustrate file system interfaces and implementation construct and execute simple shell scripts course materials: there is no required textbook for this course. we will utilize online and print resources where appropriate. course material used will be made available on canvas as needed. ptional books for reference: operating systems: internals and design principles ( 9th edition ), william stallings, pearson, 2018 operating system concepts essentials ( 2nd edition ), silberschatz & galvin & gagne, wiley, 2013 unix systems programming: communication, concurrency and threads: communication, concurrency and threads ( 2nd edition ), robbins & robbins, pearson, 2015 grading: course outcomes will be assessed through exams, quizzes /homework, and programming projects using the following weighting: attendance / participation 5 % programming projects 50 % quizzes /homework 25 % final exam 20 % total 100 % grading scale: grading will be based off the official msoe grading scale: a 93 - 100 ab 89 - 92 b 85 - 88 bc 81 - 84 c 77 - 80 cd 74 - 76 d 70 - 73 f < 70 class: all class meetings will be held in person in the room reserved by the university ( see above ). they will consist of a mixture of instruction, discussion, examples, and exercises. programming projects: programming projects will be assigned periodically during the semester."
"""csc3210syllabus.pdf""","ptional books for reference: operating systems: internals and design principles ( 9th edition ), william stallings, pearson, 2018 operating system concepts essentials ( 2nd edition ), silberschatz & galvin & gagne, wiley, 2013 unix systems programming: communication, concurrency and threads: communication, concurrency and threads ( 2nd edition ), robbins & robbins, pearson, 2015 grading: course outcomes will be assessed through exams, quizzes /homework, and programming projects using the following weighting: attendance / participation 5 % programming projects 50 % quizzes /homework 25 % final exam 20 % total 100 % grading scale: grading will be based off the official msoe grading scale: a 93 - 100 ab 89 - 92 b 85 - 88 bc 81 - 84 c 77 - 80 cd 74 - 76 d 70 - 73 f < 70 class: all class meetings will be held in person in the room reserved by the university ( see above ). they will consist of a mixture of instruction, discussion, examples, and exercises. programming projects: programming projects will be assigned periodically during the semester. unless otherwise noted with the assignment, projects must be completed individually and will be due on the specified due date. programming projects are due on the posted due date and are subject the grading penalty for late work ( see “ late work policy ” below ). github classroom: all programming projects will be made available through github classroom. links the associated assignment will be published in canvas. a link join the github classroom will be included in canvas. unless otherwise stated in the assignment, submissi ons will be made by submitting a link your repository in canvas. for group assignments, only a single submission is needed for the entire group. quizzes: quizzes will be given in class will be announced at least one class period prior the quiz date. failure take a quiz on the announced date will result in no credit. no makeup quizzes will be given without advanced reason excepting documented medical, family emergencies, or official university business. if you are unable take a quiz on the quiz date for any reason please contact the course instructor, beforehand. homework: homework will be assigned and submitted online through canvas. homework assignments turned in late are subject the grading penalty for late work ( see “ late work policy ” below ). exams: exams will be held during class meetings unless other arrangements are made prior the exam. no makeup exams will be given without advanced reason excepting documented medical or family emergencies. if you are unable take an exam on the exam date for any reason please contact the course instructor, beforehand."
"""csc3210syllabus.pdf""","if you are unable take a quiz on the quiz date for any reason please contact the course instructor, beforehand. homework: homework will be assigned and submitted online through canvas. homework assignments turned in late are subject the grading penalty for late work ( see “ late work policy ” below ). exams: exams will be held during class meetings unless other arrangements are made prior the exam. no makeup exams will be given without advanced reason excepting documented medical or family emergencies. if you are unable take an exam on the exam date for any reason please contact the course instructor, beforehand. per university policy, “ a culminating assessment is required in every course. the type of culminating assessment should correspond with what is specified in the departmental course outline and be announced the class at the beginning of the term. final examinations must occur i n the two -hour block that has been assigned by the registrar ’s office. for specific courses, a final presentation, project, or other summative assessment may be substituted for a final examination, as determined by the program, and approved by the chair. the chair will notify the registrar ’s office courses will not be utilizing a final examination period. undergraduate culminating assessments may not count for more than 40 percent of the final grade. ” this course will have a ﬁnal exam during week 1 6 of the term. the exact date and time will be released by the registrar during the semester. class participation and attendance: class will consist of a mixture of instruction, discussion, and examples. participation in class is expected. if you are unable attend class, please inform the course instructor as soon as possib le. late work policy: all course work is due on the announced due date. for each day an assignment is turned in late, 5 % will be deducted from the score ( rounded down ). for example, an assignment that is out of 100 points turned in 1 day late would instead receive a 5 -point p enalty. the same assignment turned in 2 days late would receive a 10 -point penalty, etc. this penalty will continue until a maximum of 50 % of the available credit is reached. for example, the max grade for an assignment turned in 10 or more days late will be 50 % of the possible credit. exams and quizzes are be completed during the class in they are given. no late exams or quizzes will be accepted. in addition the above late policy, any assignment submitted after friday of week 1 5 will receive no credit. tentative schedule week"
"""csc3210syllabus.pdf""","the same assignment turned in 2 days late would receive a 10 -point penalty, etc. this penalty will continue until a maximum of 50 % of the available credit is reached. for example, the max grade for an assignment turned in 10 or more days late will be 50 % of the possible credit. exams and quizzes are be completed during the class in they are given. no late exams or quizzes will be accepted. in addition the above late policy, any assignment submitted after friday of week 1 5 will receive no credit. tentative schedule week topic programming assignment 1 course introduction & unix environment linux setup 2 c programming review c programming 3 computer architecture review 4 operating system motivation 5 system calls making system calls 6 processes and process creation multi -process application 7 inter process communication writing your own shell 8 threads multi -threaded data management 9 concurrency 10 deadlock / livelock 11 scheduling working with the linux scheduler 12 memory management memory manager 13 paging and virtual memory virtual memory manager 14 input / output section 4.6 15 file systems fun with file systems 16 final exam institutional policies: nondiscrimination statement: milwaukee school of engineering admits students of any race, color, national and ethnic origin all the rights, privileges, programs and activities generally accorded, or made available, students at the university. it does not discriminate on the basis of race, color, national and ethnic origin, religion, age, gender, sexual orientation, marital status or disability in administration of its educational policies, admission policies, scholarship and loan programs, and athletic and other institutionally administered programs. msoe also maintains its long -standing p olicy as an equal opportunity / affirmative action employer of male and female personnel for its faculty and administrative staff. student accessibility services ( sas ): for students with documented disabilities, chronic medical conditions or mental health concerns; msoe provides services make reasonable accommodations available. if you are a student who requires or anticipates the need for accommodations, please conta ct student accessibility services ffice at 414 -277 - 7281, by email at moureau@msoe.edu, or in person at k250 discuss appropriate accommodations and eligibility requirements. policy on student integrity ( academic integrity ) sexual misconduct policy research with human participants ( responsible conduct of research ) link the 202 3 - 24 undergraduate catalog policy page link the 2023 -24 graduate catalog policy page raider center for academic success: student support: raider success coaches are professional staff who assist students one -on - one with emotional, personal, and academic support develop a plan, establish goals, and identify the habits help achieve success."
"""csc3210syllabus.pdf""","if you are a student who requires or anticipates the need for accommodations, please conta ct student accessibility services ffice at 414 -277 - 7281, by email at moureau@msoe.edu, or in person at k250 discuss appropriate accommodations and eligibility requirements. policy on student integrity ( academic integrity ) sexual misconduct policy research with human participants ( responsible conduct of research ) link the 202 3 - 24 undergraduate catalog policy page link the 2023 -24 graduate catalog policy page raider center for academic success: student support: raider success coaches are professional staff who assist students one -on - one with emotional, personal, and academic support develop a plan, establish goals, and identify the habits help achieve success. schedule a meeting, contact rcas ( rcas@msoe. edu ) or email the coach listed on your class schedule. raider success allies are upperclassmen peers who assist students in pursuit of success in and out of the classroom. an ally serves in a variety of ways - mentorship, accountability, study partner. students looking enhance academic skills c an stop by the rcas hype desk in the library m -f | 830am -430pm. academic support: tutoring offers free peer and professional academic support through one -on - one, group, and online sessions. tutoring is located on the 2nd floor of the library and online via teams. schedule a one -on - one, group, or nline session please go https://tutoring.msoe.edu or writing assistance request form | msoe course -specific academic support is coordinated with the instructor or department for individual classes. support comes in a variety of offerings: high impact review sessions, learning assistants, interactive study sessions. identify course -specific ac ademic support, inquire with your instructor or visit the rcas calendar: help with classes | msoe"
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","meeting in _ general_-20240122_130158 - meeting recording january 22, 2024, 7:02pm 48 m 11s lembke, james started transcription lembke, james 0:11 hello. hello right. alright, so for announcements, announcements, announcements, uh, canvas, canvas canvas, this one here notes that we've been going through. i posted them. they were already posted. i did send out an announcement through canvas, but i'm an announcing it now as well. the first is that really a programming project, but the first project is out. it walks you through setting up windows subsystem for linux. if i did n't mention it, i'll mention it now. we're going be learning the posix system calls the portable operating system interface xi do n't want x stands for what i can worry about that i will. i'll tell you when we get there, but it linux is one such operating system that is posix compliant and supports these portable interfaces. so we're gon na be using linux. and instead of having everybody install a vm or have you contact it and ask them unlock your your bios, you can install linux on metal. we're gon na use windows subsystem for linux. i had a couple of students ask can i use if i have a linux computer at home? can i use that for this class? yes, i've no problem with that. i will tell you, though, my grading when i grade the assignments will be using windows subsystem for linux and if there's some weird quirky thing that you're metal install. if you're using arch or something that is not installed properly or not properly, but it's installed in some configured way or using gen 2 or something like that and it does n't work the same way on windows subsystem for linux, i'm just be aware that that's where i'm gon na be doing grading. but that being said, that project that's out there if you log in and you accept the project in github classroom, you'll get something that looks like this and you're given essentially a set of steps go through and install windows subsystem for linux. it's due on friday. so you have some time. it is hoping it should be fairly small. this step follow that step below that step. if you've already done this and already have windows subsystem for linux setup, you can skip the installation steps and jump right down the questions, but there's a little bit of background on unix and linux. we'll cover that in class as well."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","but that being said, that project that's out there if you log in and you accept the project in github classroom, you'll get something that looks like this and you're given essentially a set of steps go through and install windows subsystem for linux. it's due on friday. so you have some time. it is hoping it should be fairly small. this step follow that step below that step. if you've already done this and already have windows subsystem for linux setup, you can skip the installation steps and jump right down the questions, but there's a little bit of background on unix and linux. we'll cover that in class as well. one thing that somebody had asked me, i mentioned me is that this is now not correct. 100 % correct two install double windows subsystem for linux. i say run wsl, dash, dash install but they updated it and the more recent version that you have specifically specify or have the option at least of specifying what linux distribution you want use, and there's a whole bunch that are supported. but for this class my examples all come using ubuntu and the instructions here say use ubuntu. if you feel comfortable with a different linux distribution, feel free use that, but i will be doing everything with ubuntu. if you do n't know the difference between ubuntu and arch and gentoo and debian, and man, all of the hundreds of different linux distributions out there, no big deal. do n't worry, just pick up buntu and you will be fine. i'm good. thumbs up. alright, so that's the first programming project that really programming, but it does do a first project. ok, keep me informed if you have any questions. so where were we? we were here. we were talking about computers and we were here and trying find a way focus this. that's a little bit better. yeah, that might be as best as we get. trying go through this idea of all of this stuff needs get hooked together in such a way that allows us write a program or download a program, or run a program. whatever you wanna say and turn that into, well, we're not gon na be turning that into the hardware, but having the hardware interpret that and do useful stuff, plain and simple, right? we want use our computer do useful stuff. microsoft word do data mining do machine learning? do elden, ring, whatever we wanna do, i got ta come up with a different game for my example."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","trying go through this idea of all of this stuff needs get hooked together in such a way that allows us write a program or download a program, or run a program. whatever you wanna say and turn that into, well, we're not gon na be turning that into the hardware, but having the hardware interpret that and do useful stuff, plain and simple, right? we want use our computer do useful stuff. microsoft word do data mining do machine learning? do elden, ring, whatever we wanna do, i got ta come up with a different game for my example. but you get the idea. something that we want our computer do, and we have logic that we need execute. we have algebraic instructions that we have execute. we have graphics that we need process. ultimately, graphics really is computing a bunch of numbers, but still we have graphics we wanna process. we have peripherals that we want interact with, right. i wanna play mega man. i do n't wanna use the keyboard, i wanna use my my my controller. it's just easier for me do that, but i'm playing a first person shooter. i wanna use my keyboard on my mouse. that's what i grew up with, right? all these different peripherals that we have deal with, all they get hooked up and they all have go through this, this is what was given and you might say again, why did they do it that way? well, that was, you know, looking through the lens of history. that was just the decision that was made given the constraints that we have money being one of them. the limit on the number of transistors we have. how small we can make things the materials that were available for making processors. all that stuff filters in how things are made, and then we have the world of backwards compatibility where if we have a program that we wrote in the 1980s, we'd still like be able let it run on our computers of today. so intel and amd and this instruction set architecture, is essentially the set of things that the cpu can do for the most part, is maintain backwards compatibility up until it's and it's sort of genesis so that we can run old programs without having rebuild them. we just still pretty cool. now there are some compatibility issues. i know that you probably have. i know i've run into them."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","all that stuff filters in how things are made, and then we have the world of backwards compatibility where if we have a program that we wrote in the 1980s, we'd still like be able let it run on our computers of today. so intel and amd and this instruction set architecture, is essentially the set of things that the cpu can do for the most part, is maintain backwards compatibility up until it's and it's sort of genesis so that we can run old programs without having rebuild them. we just still pretty cool. now there are some compatibility issues. i know that you probably have. i know i've run into them. if i try run some of my games or programs from back in the day, it does n't work in the same way, but certainly if i were try and take a software off of my old apple 2e, it would not run on windows because apple 2e has a different instruction set architecture than intel. right. ok, so where do we stop from here? we we are, we're talking about memory, talking about pieces of a computer and how things were hooked together. and ultimately, my goal here and i i mentioned this idea of this like io and data and interrupt request lines on this picture, what i want you do is like look at this and see how this stuff is hooked together. but i'm not going test you on it just yet. we will come back talk about io and we're gon na talk about interrupts specifically when we talk about system calls. but the big pieces of this hardware thing is we have execution on the cpu by reading registers, writing values registers, sending values through the all group, and modifying our control registers. and this control unit that's telling the rest of the cpu what do, right? so do that, i mentioned over here in my picture we have this idea of the program counter and i i call it isr. but at the notes call it ir and i got that confused. so i wanna replace this ir for the instruction register. now when it comes time for the cpu do something. here is sort of a philosophical question and there is no right answer, but i'm gon na ask you guys give me an answer. does the cpu know what we've known? what we've been looking at right now does it know what it's doing. so who says no, but the super you does n't really know what it's doing. ok, who says yes?"
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","and i got that confused. so i wanna replace this ir for the instruction register. now when it comes time for the cpu do something. here is sort of a philosophical question and there is no right answer, but i'm gon na ask you guys give me an answer. does the cpu know what we've known? what we've been looking at right now does it know what it's doing. so who says no, but the super you does n't really know what it's doing. ok, who says yes? no one says yes, i might say yes, ok. so for those who tell you know why? why not? ok, i'm big. why? so you know, i want you throw. why at me? i'm not throw at you. why does if you not know what it's doing? because if they if it's making a mistake, it has no way of actually realizing it's making a mistake unless we unless we specify eds that a certain point is a type of mistake and same way as the other way, it ca n't really do the correct thing on its own. it's just does whatever instructions be given. it's ok. couple of things there mistakes. what does the cpu do when it screws up right? it does n't necessarily know what is right from wrong. i like that idea. i put words in your mouth so it's it's ok. good for you, right? and it just does what we tell it. ok, i like that. who says yes, that the cpu does know what it's doing? yeah. why? i was just thinking like, you know, it's able like forecast ahead and like you kind of have like some like planning you know, ok, so you're getting in a little bit more complicated complex instruction set are can not complex instruction set architecture but more complex computer organization what we're talking about speculation and instruction level parallelism. yes. and so i will agree with you there. i would say yes and no. there is no right answer this question. i said that i had a time in that the cpu. only does what we tell it, but i like think of it as. yes, it does know what it's doing. you could say, well, how does? of course, the cps that know what it's doing, i tell it do an ad and the cpu know it's do it knows that it's doing an add 2 numbers."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","and so i will agree with you there. i would say yes and no. there is no right answer this question. i said that i had a time in that the cpu. only does what we tell it, but i like think of it as. yes, it does know what it's doing. you could say, well, how does? of course, the cps that know what it's doing, i tell it do an ad and the cpu know it's do it knows that it's doing an add 2 numbers. let's knows what it's doing right? this instruction gets starting the instruction register. it gets decoded in the control unit. the proper signals electrical signals are sent out the rest of the processor and it performs the ad of the two numbers and stores the result in the right place. so it knows what it's doing there. the thing that it does n't know is what is the purpose of that app? right. and what if we do a divide by zero, right? he does n't know that it's screwed up. it just said. not all that's not right. right. so i like look at it as is. if i looking if i was looking at a program that i wrote in c or java or python or whatever and all i could do was look at it one line of the code, one line of code at a time. if i look at that one line of code, i might say yeah, i know what that one line of code is doing, but the big picture of what's going on, i do n't really know what's going on. and all i do is look at one line of code and so yes and no. ok, so why am i? why we why we spending so much time covering this right. that's the big picture. let's zoom out and say doctor lemke, you get on with it. what is the big deal here? the big deal here is this. the cpu is executing a fetch execute loop. it is given an instruction stream. ok, that's what i'm getting at. it only sees what it's currently doing and then it gets the next thing do. ok. and ultimately ok, is it know what it's doing, it does not know that it's computing, you know the the a particular frame be displayed on my screen for some game it does not know that it's training a model right."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","the big deal here is this. the cpu is executing a fetch execute loop. it is given an instruction stream. ok, that's what i'm getting at. it only sees what it's currently doing and then it gets the next thing do. ok. and ultimately ok, is it know what it's doing, it does not know that it's computing, you know the the a particular frame be displayed on my screen for some game it does not know that it's training a model right. there might be special purpose processors out there that actually know what a model is and how train them. something like that as far as well, it's hardware is built, but all it does is it starts it, executes an instruction, and then it goes on, fetches the next instruction and executes it. have nausea, ok. unless something goes wrong and it's interrupted, we'll worry about that right? thanks. so what does this mean? i got a couple of questions here and i got some sources here from target from tuck target. ok, what is software? i do n't. not gon na read this, but this is a relatively detailed thing. it's a software. it's a set of instructions data programs used operate computers execute specific tasks, blah blah blah, right? this is that instruction stream. this is software. ok. later on, we'll talk about the difference between a program and a process. you know i'm word sensitive and you might see doctor lengthy, are n't they the same thing? no, they are not. sorry, programming process are different things. we'll talk about the difference there. ohh but ultimately i like this definition. specifically, the first sentence, and we did n't really could n't really look at this idea until. we understood what our set of instructions were, right or what this idea of instruction stream is. so the active executing us executing software yields this idea of an instruction stream. so what does this look like? let's take a look. so i've got sea lion i like use sea lion. it's where i use all of my examples for i do n't use sea lion for its built - in like build things. i just use sea line because it's a pretty cool editor and does some type checking and some neat text highlighting. i probably should transfer over vs code, but that's not a topic of this class right now, but let's just talk about this."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","so what does this look like? let's take a look. so i've got sea lion i like use sea lion. it's where i use all of my examples for i do n't use sea lion for its built - in like build things. i just use sea line because it's a pretty cool editor and does some type checking and some neat text highlighting. i probably should transfer over vs code, but that's not a topic of this class right now, but let's just talk about this. so let's make a new file here. i'm just call it add dc. now we're programming and see here, so i'm gon na make a main here and we'll just call it, you know. all right. looking so far, ok, this is a c program be honest with you, it looks very similar java as well, although i'm not using public static void in the string. argue there. it's not in a class or whatever, but anyway we all know. see. right. alright, so now i'm going compile this here. ok, stop quiz. pop quiz. who are members from your cn c++ class? what the four phases of compilation are? who knows? one of the four phases of compilation? yeah, the linker. ok, great. i like that. that's the 4th step. ok, who knows another one where we can build this? yeah. so the assembler. ok. that's the second last step. ok, what else we got? the free the preprocessor. what happens during preprocessing? i love preprocessors. i love them. it's pre, it's it's before processing. ok. no, in c we have the ability find a whole bunch of preprocessor macros, right? begin with the pound sign and the preprocessor runs and it translates all of the preprocessor macros into what they what they are. they evaluates them so you can actually make preprocessor macros that look like functions. they look like constants. you can use them include or import other files for other definitions and declarations we do our c programming review, probably starting tomorrow. we'll cover all that. no. next that tomorrow but wednesday. but we do n't meet that. yeah, but anyone? what's the other one that i'm missing? doing what? yeah, the compilation's there step step. so first the preprocessor runs. it takes my text file and converts it the text file by running all the preprocessor stuff."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","they look like constants. you can use them include or import other files for other definitions and declarations we do our c programming review, probably starting tomorrow. we'll cover all that. no. next that tomorrow but wednesday. but we do n't meet that. yeah, but anyone? what's the other one that i'm missing? doing what? yeah, the compilation's there step step. so first the preprocessor runs. it takes my text file and converts it the text file by running all the preprocessor stuff. then the compiler runs and it converts all of the code from a high level language like c or c into assembly language for my appropriate architecture for my target machine. while that be x86 or or arm or whatever you name it all the different things risk 5 or there's a whole bunch of different ones out there. mips you name it, there's a whole bunch of different cpu architectures out there, and then it runs the assembler, converts all of the assembly language instructions from something that a human can read. although it's debatable whether a human can really breathe assembly, but you know that used be the way things have be programmed into binary code creates an object file, and then the linker runs connect all the dots in a single file like this. the linker does n't have nearly as much do because it's just one file. but if i have lots of other files, it's got ta do all the symbol searching and matching up and then ultimately builds this executable and it finds all the references the external libraries that we use. if we want do something like printf or something like that, so what i wanna do is look at an instruction stream. so what i'm going do here is if i just did gcc add dot c, that's gon na run all four stages and it's gon na give me an 8 dot out. i'm not actually really doing anything here, so if i run a dot out i get. i get nothing because i'm not really printing anything the screen on doing is adding some numbers together and throwing out, throwing the result back. but if i run the compiler and have it stop at the after the assembler with the s flag i've ever do this. ok. well, we'll do it. we'll do it now and you'll do it in, in, in class, we get an ad dot s, is kind of cool. what does that look like?"
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","i'm not actually really doing anything here, so if i run a dot out i get. i get nothing because i'm not really printing anything the screen on doing is adding some numbers together and throwing out, throwing the result back. but if i run the compiler and have it stop at the after the assembler with the s flag i've ever do this. ok. well, we'll do it. we'll do it now and you'll do it in, in, in class, we get an ad dot s, is kind of cool. what does that look like? it looks like this and it looks like a bunch of garbage and you could say, well, doctor olympia, are you showing this us? well, this is the assembly language. my computer is an intel architecture running umm. it's actually six. are something like preferred as a different name? it's gotten the names have changed over a while, but it's and actually six, i'll call it x86 instruction set and these are the individual operations that the cpu can do. each line of code in here is 1 operation the cpu. so what do we see in here? we see a couple of things that start with dot. ok. you might say, well, what is dot? well, dot is actually more kind of like a declaration, and so it's not really a cpu instruction, but these things here are the cpu instructions so. if i looked over here, remember i had said i had this load instruction where we're loading something from memory. i got an add instruction where it says add the contents of two things together. if we look at my instruction stream, that's what these are. i've got a move. the queue is a separate instruction. stands for move. ohh what's new standpoint, move ours. move along. move q might be moved quad no sd with how many bytes are being moved. so you can move one bite in from memory. you can move two. you can move four. you can move eight because my computer is a 16 bit machine, a 64 bit machine, so i can move up 8 bytes, but ultimately we got a bunch of stuff down here. what is the dollar sign? it's a literal value. ok, so it says essentially move the value of 10 into this. this evaluation here, is essentially the contents of a register minus 8in memory."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","move q might be moved quad no sd with how many bytes are being moved. so you can move one bite in from memory. you can move two. you can move four. you can move eight because my computer is a 16 bit machine, a 64 bit machine, so i can move up 8 bytes, but ultimately we got a bunch of stuff down here. what is the dollar sign? it's a literal value. ok, so it says essentially move the value of 10 into this. this evaluation here, is essentially the contents of a register minus 8in memory. i'm going have it fast because i'm not gon na expect you know x86 architecture, but i will expect you know that these are the steps that the cpu is executing. one line of code is 1 cpu instruction. one thing that's doing, if i look at this in isolation, you could say, oh yeah, the cpu knows what it's doing. it's moving the literal 100 into sub location in memory. but in reality is the really know that it's adding this eventually? no, that happens later on and if i put these side by side, i do n't know that i could do this split right. ah, there we go. bam, there we go. we see that in a way this kind of makes sense, so i have take a and assign it the value 10. ok, that's a high level statement over here. this says take 10 and start at some location in memory. well, this location in memory is the contents of aid. i have store 100 and me. well, that was that. air place is memory is morbius. then i need add the two the two contents of those two variables together. well, the compiler knows that a&b are in memory. it just assign them that. so in order get them into a register, it does n't load, so it moves. because it's an a into this register, it moves the cadence b into this other register. this is a register domains and then it does an add of those two values. where does it put the result? will have look at what the add ellen struction is, but i believe if we do n't specify 3 parameters it puts the result in. uh, i do n't know. we'll work it out somewhere, but if it's it's something again, i do n't know, like 86. all that well, either. i know that there's an add instruction here."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","because it's an a into this register, it moves the cadence b into this other register. this is a register domains and then it does an add of those two values. where does it put the result? will have look at what the add ellen struction is, but i believe if we do n't specify 3 parameters it puts the result in. uh, i do n't know. we'll work it out somewhere, but if it's it's something again, i do n't know, like 86. all that well, either. i know that there's an add instruction here. and then finally, i'm doing the return return from the procedure. ok, instruction stream. ok, let's move on format. ok, good. so that's software all right. now let's motivate this a little bit more. what is an operating system? what is an operating system? we all know that windows is an operating system, right? ok. what makes windows and operating system as opposed something like hello microsoft word is microsoft word an operating system? i do n't think so. it could be i used have a a friend of mine that said that emacs these an editor that wants be an operating system or that chrome is a web browser that wants be an operating system. ok, we'll come back that later on, but none of them are actually operating systems. why is windows different? what is windows compared something like microsoft word but? ok, coordinating hardware things together. i like that. other thoughts about an operating system? yeah, it starts soon as your computer turns on. it starts as soon as your computer turns on. ok, i like that definition. uh, i could say that i could write something that's not an operating system that starts as soon as my computer turns on. a lot of embedded systems are written without operating systems that that that run a software. but yeah, that's a wishy washy way. that's a layman's or me say that a lame comment, but ok, we'll go there. runs when your computer turns on interfaces between software and hardware other things. inner inner interacts between the user and software ok. yeah, that's weird in a way. it's hard say that because as a user, what do i interact with? i do n't interact directly with the software doing what do i have interact with as a user? do anything with my computer, what do i have do? teams of peripheral. yeah, i have use a peripheral."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","that's a layman's or me say that a lame comment, but ok, we'll go there. runs when your computer turns on interfaces between software and hardware other things. inner inner interacts between the user and software ok. yeah, that's weird in a way. it's hard say that because as a user, what do i interact with? i do n't interact directly with the software doing what do i have interact with as a user? do anything with my computer, what do i have do? teams of peripheral. yeah, i have use a peripheral. i am an analog device. ok, it's true. i operate on signals of light and sound and touch my senses right? i ca n't. i do n't execute cpu instructions, so for me interact with my computer, the only way that i can do it is do hardware. it is inductive be why you going so slow? it's because this is the things that the operating system is use is doing so that we can use our computer. it is really be honest with you, providing that bridge between hardware and software and you could say, ok, well, what else? well, it's providing services applications, the software allow them utilize that hardware. ok, so this is a sort of a long winded explanation of what an operating system is. it's a program. ok, it's software ok that after being loaded into the computer's computer by a boot program, we have talked about boot program, but that's fine. manages all of the other applications on the computer. manages all applications. provides interfaces applications and i'm talks about this application programming interface, a command line interface is actually really nothing that different than just a program and a gui. ok, these are things that could be provided by an operating system. ok. but ultimately it is. this is ok. this is text definition. here's doctor lemke's definition. you wo n't find this in a book. i've not written operating system book, but here is my definition software that provides services users and applications done. and so now we say, well, why do we need an operating system, but we need an operating system because of. this. because we have all this hardware, ok, we could. we could why do n't program find away? we have n't talked about how boot orders work, but get it into memory and then run the thing and be done. ok."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","you wo n't find this in a book. i've not written operating system book, but here is my definition software that provides services users and applications done. and so now we say, well, why do we need an operating system, but we need an operating system because of. this. because we have all this hardware, ok, we could. we could why do n't program find away? we have n't talked about how boot orders work, but get it into memory and then run the thing and be done. ok. if we go back into history right now, looking through the lens of history here, and we say, ok, how do computers work earlier? well, that's essentially what they did scheduling. i was under the mobile later on talking about process scheduling in operating systems. for what processes get run max and things like that? multiprogramming scheduling back in the day was there was a piece of paper outside of the door and you signed up say when you were gon na run your program that was scheduling. there was a machine inside the room and you got sign up for when you're gon na use it. so between 1:00 and 2:00 o'clock, instead of coming operating systems class, you would go down the machine room with your deck of cards and that you've punched and you've set them on the machine and you'd run your program. this system would be off. you put your cards on there you turn the switch turn it on. it would feed them into the machine and well, that was the compiler. or actually individual assembly instructions that would get read in the machine loaded into memory executed and outcome would be your print your print out, and then you take your print out back your desk and you would say uh, now i need go on my program. my colleagues ibm that said, that's what we had do. we had walk down the machine room on our program and then we have go over it with a pen. schedule. ok. so operating systems, ok, they're nice because it allows us not have do that anymore. because of this. this interface between iron devices and programs. this looks complicated. i do n't think it is. once you break it down, but it bridges the scap we talked about instruction center architecture. we talked about hardware, we talked about the execution hardware. they're a little bit about how things are connected and made them right. when you talk about iron devices yet, but we'll get there."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","so operating systems, ok, they're nice because it allows us not have do that anymore. because of this. this interface between iron devices and programs. this looks complicated. i do n't think it is. once you break it down, but it bridges the scap we talked about instruction center architecture. we talked about hardware, we talked about the execution hardware. they're a little bit about how things are connected and made them right. when you talk about iron devices yet, but we'll get there. but we've got multiple programs that we want execute. that's the key, is that? well, it might be kind of fun for me have a sign up outside my door, outside your door, outside someone's door, and say who's gon na run program next. i want be able right they say that, uh, that for what it's worth, as we get more and more access technology and social media, our our attention spans are dropping, apparently like 10 years ago, a human's attention span, we could do something for two minutes before we got bored. now it's more like 45 seconds. so you see a lot of like commercials are a lot shorter, things like that, right. and so i do n't quite have the attention span as i used. and so i wanna be able flip flop back and forth between microsoft word and my email and my game and my social media and everything all at once as quickly as i possibly can because that's the kind of person i am. if my computer could only ever do one thing at a time, ca n't do that. i have reboot it every single time. i would wanna check social media or reboot it every time i want go on a different program. not something i believe willing do. other things that we're that we have for an operating system or why we have an operating system. any other thoughts? ok, let's let's look at this right now. we know, we know. about computer hardware. we know that we've got my program instructions in there, but we also know that we're gon na do multiprogramming. we have this ability, right? i have n't got it right here. i've got my visualizer from my camera running. i've got powerpoint running. i've got teams running. i've got my email running. i've got, you know, sea lion running. i've got all this stuff running and so i've got another programming here."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","we know, we know. about computer hardware. we know that we've got my program instructions in there, but we also know that we're gon na do multiprogramming. we have this ability, right? i have n't got it right here. i've got my visualizer from my camera running. i've got powerpoint running. i've got teams running. i've got my email running. i've got, you know, sea lion running. i've got all this stuff running and so i've got another programming here. and i got more. what's the problem with this? what's the concern? not really a problem. yeah, when karim might access the memory of the security problems. yeah, one program might run the now that we have the cpu allowing the cpu run multiple in multiple programs at a time, we have this problem. what happens if chrome is running down here and i am my own program up here? i think i mentioned this. i mentioned this last time, mike, but inside chrome i'm gon na go amazon. i'm gon na take my credit card number in right because i wanna buy lots of stuff from amazon. ok, that's in memory. i'm typing something on the computer we have going about device drivers for how that information comes from the keyboard into memory. but ultimately it does go into memory in a variable. ok. that's great for chrome. it's not good if i have my program that wants access that attempts access that mounting location. so this idea of isolation and protection, i think i said that i said that earlier, right. isolation and protection, isolation and protection. we wanna isolate processes from each other, ok? so security. alright, let's move on here. i'm jumping ahead here. why do we need an operating system? we get into something like this, right? so an operating system is software that provides services applications, right? this is doctor luke's definition. i'm not gon na necessarily ask you regurgitate this on a quiz or test, but just on it keep in mind as we go, why do we need these? that's something provide services applications. well, we wanna have convenience. ok, first thing right, i do not wanna write software that knows how access every single device that i could ever possibly connect my computer because it gets them. you might say, well, no you could, right?"
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","so an operating system is software that provides services applications, right? this is doctor luke's definition. i'm not gon na necessarily ask you regurgitate this on a quiz or test, but just on it keep in mind as we go, why do we need these? that's something provide services applications. well, we wanna have convenience. ok, first thing right, i do not wanna write software that knows how access every single device that i could ever possibly connect my computer because it gets them. you might say, well, no you could, right? because we have a keyboard, you could probably list the majority of the devices that we have. we have a keyboard. we have a mouse, we have a display. maybe we have a game controller? maybe we have speakers, right? well, yes, we do have that. but there might be a different hardware interface for every single manufacturer of hard drive belt there. so now if i wanna access a hard drive made by seagate, it might be slightly different as far as what the features are supported. then the hard drive is created by western digital or the hard drive that's created by corsair. they still make it makes all sleep this right. yeah. ok, right. so that's a problem and i like have a common way of accessing all this stuff. i wanna just say read this device please, right and more even more higher level than that. even if i did have a common interface. devices are devices are often either character or block special. i can either read a byte or a set of bytes. i do n't wanna read a set of bytes. i wanna read a file right? so this idea of wright chrome is gon na access a web page. ok, that could be a file. i wanna i wanna be able know what that is. i want that i do n't wanna read this light and that bite and this so i need a file system. i want somebody abstract that away thing. that's that's convenience efficiency. ok, i've got 16 processes that i wanna run for 16 programs that i want run all at the same time, right? most likely they're different chrome tabs cause i usually have lots of chrome tabs open. as it turns out, we'll find out later on that chrome actually creates every single separate, every single tab as a separate process running on the system. ok, i do n't want manage that because well, i could probably do a pretty good job at it."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","that's that's convenience efficiency. ok, i've got 16 processes that i wanna run for 16 programs that i want run all at the same time, right? most likely they're different chrome tabs cause i usually have lots of chrome tabs open. as it turns out, we'll find out later on that chrome actually creates every single separate, every single tab as a separate process running on the system. ok, i do n't want manage that because well, i could probably do a pretty good job at it. i i i i know that i'm not as good as as other people are. so efficiency and then this idea of security, i do n't want somebody else grab my credit card numbers. isolation and protection, right? and then flexibility, the ability evolve, this is specifically things like puppets and i wanted be able add memory my computer and i'll be able handle all that stuff. we'll find that the disadvantages overhead. this is one thing that when i worked for ibm, i always would hate having answer this question and ibm i worked as an operating system developer, specifically in the realm of memory management. so i'd have customers ideal charge people crazy amounts of money for memory and they would say ok jim cuz i was n't doctor at that point. i would say, jim, why is n't that? i just spent x number of dollars multiply large numbers of figures for 32 gigs of memory and when i boot up my computer it says i only have 30. i paid for all of those 32 gigs of memory. come on. and i would say this is me by my my wife is like you should not be passive aggressive. you're always passing. you could say something the the customer and say well then fine, just do n't install the operating system and see what happens, right? the average of them is gon na consume some system resources, processor memory specifically allow it do its job in order be able provide all of this stuff, yeah. questions. thoughts. ok, let's finish up here. maybe we'll get done early. so what else are we going do? we'll talk about all of these things in turn, but not all necessarily today. so program development program execution, we mentioned this, it's going provide a service that allows us run programs. ok, it'd be kind of silly if we booted up our computer, and the only thing we do is sit there, right?"
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","the average of them is gon na consume some system resources, processor memory specifically allow it do its job in order be able provide all of this stuff, yeah. questions. thoughts. ok, let's finish up here. maybe we'll get done early. so what else are we going do? we'll talk about all of these things in turn, but not all necessarily today. so program development program execution, we mentioned this, it's going provide a service that allows us run programs. ok, it'd be kind of silly if we booted up our computer, and the only thing we do is sit there, right? well, it provides interfaces allow us execute programs right io device access. i mentioned that too. a common interface for us access devices in linux. we'll find that that is through the file system. in linux it says everything is a file. that's not the best statement in the world, but a lot of things that abstracts away through a file. so once we learn how read and write a file, we'll be able do almost anything we want in the linux environment in the windows environment. i'll talk a little bit about that too. in windows uses the handle, so you have ask the. the operating system. may i have a handle for this io device and it will say here you go and then if you wanna access that i own device you make a special call into one of the operating system services and you pass that handle. they say i would like manipulate this device, you know, and honestly, it's very similar working with the file. it's just reading and writing bytes. while access system access, what does it mean access the system? well, we will find that the operating system does a lot of bookkeeping for us. and i say bookkeeping in that like just statistics, stats tracking, tracking processes, tracking who has access what. so in the world of security, yes we have permissions, but we do n't necessarily just wanna say we do n't want anybody else access anything. maybe we do wanna share some stuff. maybe do wanna allow processes access different things together for collaborations right? might makes sense. so system access is away for an operating system allow us do things like that. we can access information about other processes we can tweak around and make the permissions just right. we can limit the amount of memory we wanna process have."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","so in the world of security, yes we have permissions, but we do n't necessarily just wanna say we do n't want anybody else access anything. maybe we do wanna share some stuff. maybe do wanna allow processes access different things together for collaborations right? might makes sense. so system access is away for an operating system allow us do things like that. we can access information about other processes we can tweak around and make the permissions just right. we can limit the amount of memory we wanna process have. we can change that we can maybe even limit the amount of cpu usage that a processor process is allowed have. all that that is done via system access, these features, be honest with you, things that i never knew that i wanted until i learned operating systems would say ohh i guess i i it does make sense limit that processes. cpu usage because if that process is executing an infinite loop and i give it lots and lots of sleep and you access, it's not gon na do a whole lot of work and it's gon na prevent other things from doing a lot of work i mentioned here. this is a single core. it can do one thing at a time. computers. when i first learned it, and be honest with you for this particular class, we're just gon na assume that all of our computers have just one core in them. if we want make it appear like we're doing more than one thing at a time, let's tricky because like i said, that question does the cpu know what is know what it's doing? ohh yes and no right? yes, and that it knows that it's executing a bad instruction, but the next instruction does n't know what it does. maybe, maybe not. but it does n't know the grand scheme of things. so if i wanna make this appear like mall of the one thing is happening at a time the cpu is going execute something and then the next thing it executes might be a completely different process. that's weird, right? could you imagine? it's gon na do a fetch that's going load an add instruction for chrome because chrome has got ta add 2 numbers together add like speed some javascript or something and then the very next instruction that it's gon na fetch is something from microsoft word. well, how do you think about that? i feel like that is that concern you. i'm concerned a little bit, but anyway it's something that's that we need be able handle. all right."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","that's weird, right? could you imagine? it's gon na do a fetch that's going load an add instruction for chrome because chrome has got ta add 2 numbers together add like speed some javascript or something and then the very next instruction that it's gon na fetch is something from microsoft word. well, how do you think about that? i feel like that is that concern you. i'm concerned a little bit, but anyway it's something that's that we need be able handle. all right. accounting and bookkeeping and mentioned that too error detection handling. alright, back alan's comment about error detection. ok, the cpu when it executes something right when i run my java program ok and i say a / 0, what happens? what? what does java do if you tried divide by zero? yeah, you there? what? what is the error again? yeah, they get a divide by zero exception. you know what? i should stop relating this java. let's do it this way. i have floating point exception and see when i try divide by zero. ok. well, and that's true because the realm of dividing by zero addiction. just listened podcasts about this, the theoretical world, the divide by zero, how they invented i right, is sqrt -, 1 and also of the world still continues work in mathematics with this level of high. but if we were invent this other thing, like jay or p or z or something else, that represents a value of the number divided by zero, like all of mathematics breaks down. so we ca n't divide by zero. it's a big no no. so what does that mean? well. remember, the cpu is what's executed, right? so when we're executing something on our on our cpu, it is the only thing that it's. that's that's running our program. our computer is n't doing anything else. this is weird because you might say no. the graphical user interface is running and chrome is running and everything. let's see if you can do one thing at a time. so we'll find that we're talking about processes. this idea of a context switch and see if you're doing one thing so big divides by zero, right? what's gon na happen is the cpu has hardware in there that will detect that you're trying divide by zero. the all you will say hey user dude, one of your inputs is 0."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","this is weird because you might say no. the graphical user interface is running and chrome is running and everything. let's see if you can do one thing at a time. so we'll find that we're talking about processes. this idea of a context switch and see if you're doing one thing so big divides by zero, right? what's gon na happen is the cpu has hardware in there that will detect that you're trying divide by zero. the all you will say hey user dude, one of your inputs is 0. you ca n't do that and so it sends an exception. a hardware exception into the cpu say something went wrong. notice my computer did n't crash when i tried divide by zero, right? that's the operating system getting involved. ok, when i worked for ibm and i was an operating system developer. if i did happen divide by zero, the computer literally would crash because there's nothing. there's nobody else controlling this. nobody else is providing errors checking when you are the operating system. when you are in control, right? with great power comes great responsibility. thank you, uncle ben's. right, it's true. we're great. power comes great responsibility, so as a result we have an operating system that's providing error checking. that's kind of being hooked into the cpu say, hey, if somebody divides by zero, let me know because i'm in control of this system and so the cpu then will change all the operating system execute. so it can terminate that process without crashing the computer. there's a whole bunch of different exceptions that the cpu can have divided by zero is 1. there's accessing memory that you're not allowed accessing a memory address that does n't exist, right? if i have 16 gigs of memory and my computer, there's only so many addresses that i can access. if i try access outside of those bounds, that's a problem. we'll talk about several of them, but there's a whole bunch of different errors that can happen, and the cpu does not know well, yes and no does not know what it's doing, but when it comes an error message, it says something went wrong. i do n't know how fix this so i could n't crash, but i do n't want. i'd rather not. i'd rather involved the operating this thing ok."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","if i try access outside of those bounds, that's a problem. we'll talk about several of them, but there's a whole bunch of different errors that can happen, and the cpu does not know well, yes and no does not know what it's doing, but when it comes an error message, it says something went wrong. i do n't know how fix this so i could n't crash, but i do n't want. i'd rather not. i'd rather involved the operating this thing ok. as richard said, architecture support there are certain features that certain instruction sets provide that are special software that allows us do different things that is supported by operating system. we're not still gon na give me that too much detail, but i do want mention that it exists. uh, this idea of an application, binary and application programming interface. this is how we can access operating system services and then i highlighted this in big bold isolation and protection, isolation and protection abstractions are cool. ok, i know this is still a lot of hand waviness, but we'll get something concrete eventually. alright. under the deal of multiprogramming. ok, so here's another definition. i'm not gon na ask you regurgitate this this techtarget.com really cool. i got a lot of neat definitions and things, but it talks about idea of what is multiprogramming. it's a rudimentary form of parallel processing with several programs around the same time in here, but it's essentially the appearance of doing multiple things at the time. and so i like equate this something like a basketball game, right? you have multiple players on your team, but there's only one basketball right? only one person can be on the can be using the ball at a time and the goal is can we get multiple things done at a time when only one person gets have the ball at once? how do we do that? you're on the playground playing with the basketball. how do we allow everybody enjoy the basketball? was that you pass it right? what is that another way of saying that, right? you ever see this? like the teacher on the playground would come over the students. that are like arguing about the ball and they'll say i hope you're nice and share and take turns right. sherry take turns so both the programming ultimately will get inside, at least essentially. the processor and processes taking turns. it's my turn use the process. it's somebody else's turn use the processor in early stages of multiprogramming processes."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","was that you pass it right? what is that another way of saying that, right? you ever see this? like the teacher on the playground would come over the students. that are like arguing about the ball and they'll say i hope you're nice and share and take turns right. sherry take turns so both the programming ultimately will get inside, at least essentially. the processor and processes taking turns. it's my turn use the process. it's somebody else's turn use the processor in early stages of multiprogramming processes. had be nice and they had say, ah, i've had my turn. i mean, let somebody else use it. that worked ok. so long as everybody was collaborating with each other later on skype kind of realized that, you know, processes can be hogs. and so we'll alternately it was added into the operating system that you know what i am gon na be the one i'm gon na be that teacher on the playground say, hey, chrome, you're done. take a take a step back. it's somebody else's turn because i do n't necessarily trust you release the cpu. now process could still do that. they could still yield if they want, and they might be situations where you wanna do that, but for the most part all the targeting is done by the operating system and it says they're gon na take turns. here's my definition of multiprogramming taking turns of a nice, quick, short definition. but it's the appearance that one the one programmings ring at the same time, we ca n't do that on a single core cpu, but we can, with the help of the operating system. what's the cost of this overhead? so what does that mean? we're gon na take turns. we have a bunch of programs that all want run. only one gets run, so we might be something like that. this is referred as round robin, where each one gets take the turn and we kind of pass this ball around the room. ok. so combined, this is where it's really cool. this is what the cpu seems. this is what i see multiple programs on you, but the cpu just sees a stream of instructions running. they would say, well, normally we would expect that stream be 1 program, but it could be a bridge between more than one program we a and b it says abc. it does n't know one it's executing when. ok, this is important."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","this is referred as round robin, where each one gets take the turn and we kind of pass this ball around the room. ok. so combined, this is where it's really cool. this is what the cpu seems. this is what i see multiple programs on you, but the cpu just sees a stream of instructions running. they would say, well, normally we would expect that stream be 1 program, but it could be a bridge between more than one program we a and b it says abc. it does n't know one it's executing when. ok, this is important. the cpu just sees an instruction stream. ok, it does not know what the process is. it does not know what a program is. it knows what the program counter has set and what the instruction register has, and it executes that stream. one thing that's not in this picture, that kind of frustrates you about this, but i'm not going email the authors and have them update this. i really wish this is the way it looked like. lot of virtually it is not. we're not able run one process and then immediately run another. why not? yeah, context switching context switching. ok. that's a. that's a. that's a big word for for, yes, for for what the problem is, or the solution for this. but yes, let's think about it this way. think of the cpu as my desk or your desk or at home. ok, if you're an artist and you're drawing pictures, i'm i'm doing this relating this my daughter like we just did our and paint this morning. ok. we were in the middle of our kitchen and on our kitchen table. we had all the paints, we had everything out, all the canvases and everything like that. we're all working, right? that's essentially like one process, the painting process, and then she looked at me and said papa, i'm thirsty. i would like have a snack and i said ok, hold on. you stay right there. do n't go anywhere. i had get up. i had clean all of our artwork off the table. i had get a rag, wipe out the table and i said. all your hands. she looked at me and i'm like, well, it's that i wiped off her hands. and then i got out of snack and we had a stand right. that process right then."
"""OpSys_An_Intro_To_Operating_Systems_Transcript.txt""","that's essentially like one process, the painting process, and then she looked at me and said papa, i'm thirsty. i would like have a snack and i said ok, hold on. you stay right there. do n't go anywhere. i had get up. i had clean all of our artwork off the table. i had get a rag, wipe out the table and i said. all your hands. she looked at me and i'm like, well, it's that i wiped off her hands. and then i got out of snack and we had a stand right. that process right then. finally, when she was eating, that was the 2nd process running right? that downtime in between me cleaning off the table and getting out the snack. that's a context switch. this idea of overhead that has be involved for us switch tasks, so in reality, while it says run a run b run c, there's actually a non zero amount of priming here where the operating system will be running actually switch these processes. this is part of that cpu overhead, something we take for granted. we do n't even see that we open the windows task manager. we do n't see the operating system being involved as in switching processes around, but it is there. the cpu receives one stream of things involving multiple processes and operating system code, but it does n't even know the difference. ok, where am i out of time? pretty much, ok. yeah, we'll talk about that for us that next time. so anyway, we'll stop there. thanks for coming. lembke, james stopped transcription"
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","meeting in _ general_-20240405_130159 - meeting recording april 5, 2024, 6:02pm 47 m 39s lembke, james 0:08 all right. hello. hello. welcome class. welcome operating systems. i like this class man. alright, it's great. so what are we doing today? we're making my paper straight alright? so what do we got on canvas? i updated this week because this week is not just processed scheduling. this is process scheduling and memory management. next week we'll also be memory management. if you look at the notes slides, whatever. for memory management, they're pretty locked. that's because memory management is a pretty big topic. not that the topics we've covered so far have n't been big, but this is like seriously a meaty big topic. so that's there's a lot there. so we're gon na be at it for a while. but that being said, it is my favorite topic. why is n't my favorite topic? and remember, i always said, you know, ask me why? because i finally get make good on a bunch of other things that i told you that were n't 100 % true, and i know that i've been doing that a lot in this class, but now we're finally gon na get there. so memory management is awesome for that. for that reason, it also is when it comes abstractions, this it's a big, huge abstraction. and remember, the idea of like faking outer process. or were doing pipes and like file input redirection. that file descriptor fake out thing we're gon na be doing a lot of fake outs for processes now, is pretty awesome because that that's really in a way the way the system works. so it's on. so anyway, we'll get there. so other things linker had do today, right? so flagger had hopefully that's going well, dude. tonight, several of you have already submitted it, is awesome. thank you. thank you. but that's there, and the next programming project is out there. so for those of you that started it like this morning, i realized that i did not set a template repository. so for those of you that did, you probably got a blank repository, created it, or probably like once this assignment i have since pushed the actual assignment, so if you already started it, just do a fresh pull get the the the right stuff from your assignment. otherwise, we have n't started yet. no worries."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","but that's there, and the next programming project is out there. so for those of you that started it like this morning, i realized that i did not set a template repository. so for those of you that did, you probably got a blank repository, created it, or probably like once this assignment i have since pushed the actual assignment, so if you already started it, just do a fresh pull get the the the right stuff from your assignment. otherwise, we have n't started yet. no worries. it's not due for a while. you'll get the right stuff now. so why do wanna know it takes some time talk about this assignment before we start in the memory management. so that's all do now. so if you clone the repo or you accept the assignment, you'll get something like this hopefully, has a readme and what you're gon na be doing in this assignment is we're going put threads on the table for a while, so threads and concurrency, we're going just keep that in our back pocket for the final exam. but for now, we're just gon na hold on it. and you're going be writing a simulator very similar in idea the flag or i had simulator just you wo n't be using threads. well, you're gon na be simulating processes instead of using real time, is kind of what threads have where you run them and they just go for simulating processes, is what you're gon na be doing. you're gon na be using time units, and so events are gon na start at particular time, and you're gon na simulate those events happening. the events that will be happening are things like process enters the system with a particular priority process, leaves the system a process, waits for io for a particular io device identifier, io device identifier. io completes those types of things and your job will be write a process simulator that schedules the next process run on our theoretical single cpu system that can execute one instruction stream. so you have one major rule in your processor, is the processor schedules the when it comes time schedule it will schedule the highest priority process that is ready run. it will do that either be a preemption or non preemption that is going be set via parameter in your input parameter file and some ordering roles. ok. the rules are specified here. we have a single cpu we have up 10 io devices with id's and zero through nine. we have 10 priorities id's are zero through 9a. higher number means higher priority."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","so you have one major rule in your processor, is the processor schedules the when it comes time schedule it will schedule the highest priority process that is ready run. it will do that either be a preemption or non preemption that is going be set via parameter in your input parameter file and some ordering roles. ok. the rules are specified here. we have a single cpu we have up 10 io devices with id's and zero through nine. we have 10 priorities id's are zero through 9a. higher number means higher priority. your system needs schedule the highest priority process that's ready run. ok, a process can be running ready, eligible run or blocked on some io resource. you're gon na be giving, you know, the parameter files via an input file, so your process is gon na be run like this. very similar the flagger, the file will consist of a single line initially that will consist of zero or one, whether or not you're schedule should preempt the process that's running or not. if a higher priority process comes along, if preemption is not turned on and you assign a process run, it will run, and if a higher priority process becomes ready, either by entering the system or it's io that it was waiting on completes, it will not preempt the existing process. it will only schedule a new process run if the existing one gives up the cpu because it was waiting for some io or because it terminated like that's cream versus non preamp. the rest of the lines in the file indicate events that will happen on the system. it will get a live that will contain at least two numbers and it might contain more than that. the first number will always be the time the event happened in event time, so you're simulation begins at event zero and it ends when all the processes leave the system right. the line will start with the event time. it will next indicate some sort of event type, some sort of operation code, some sort of thing that happened. what does this event that happened and then the rest of the line this dependent based on what that event is? so here are your events. you're gon na event operation type one will be start a process. the additional values will be one value will indicate the priority of that process. operation two is io request. the current running process on the cpu requests some io operation. the identifier of the io device will be specified there. that io device will be the between zero and nine inclusive priorities."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","it will next indicate some sort of event type, some sort of operation code, some sort of thing that happened. what does this event that happened and then the rest of the line this dependent based on what that event is? so here are your events. you're gon na event operation type one will be start a process. the additional values will be one value will indicate the priority of that process. operation two is io request. the current running process on the cpu requests some io operation. the identifier of the io device will be specified there. that io device will be the between zero and nine inclusive priorities. same idea, zero 9 inclusive. we have operation 3 is an io n for particular device and operation 4 is process and has no additional parameters. it is just the current process that's running on. the cpu ends. i mean, look at these events. there's no way for a process that's waiting for io end. we do n't have any sort of extra way for assistive administrator or user terminate a process. that's not running, so the only way for a process end is for it just end while it's running, ok. there's some additional things about here. you can assume that everything is coherent. i'm not gon na give you a file in i create 2 processes and only end one of them. all the processes will end inside the simulation file and sometime you might run into a situation where more than one process requests io for the same device that io is grouped together. so if i have two processes, one process runs and it requests io, then another process gets scheduled run and then it requests io later on that io may complete and that io completes for both processes, so they are both released and ready run. right. makes sense. you have keep track of that. that's in there. priority is important, so if you have multiple processes that are ready run, always pick the highest priority process. if you have two processes that are the same priority, when you want run them, you can, i believe. prices will negative never have negative priority. they'll have a priority greater than mine. don primitive, ok. if the process of the same priority, the process should be ordered in time of arrival. thank so here is an example input file. you have and it explains it that you have a non preemptive scheduler and then at time too you know an operation one so process arrives of priority one at time 3a process arrives of priority two."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","if you have two processes that are the same priority, when you want run them, you can, i believe. prices will negative never have negative priority. they'll have a priority greater than mine. don primitive, ok. if the process of the same priority, the process should be ordered in time of arrival. thank so here is an example input file. you have and it explains it that you have a non preemptive scheduler and then at time too you know an operation one so process arrives of priority one at time 3a process arrives of priority two. at time four, we have a process that requests io and that the current process that's running requests io and that io device is 1. given what i've said about the priorities, what should be the process that's running? it's a non preemptive scheduler, so at the time of this guy arriving, this guy gets run. even though this guy arrived the later because we're non preempting and this is a higher priority, this guy gets keep running. ok, so the process that waited on io is going be this one. you are required as part of this assignment that every time a process runs that it should be given a process identifier starting with one and going up from there. do n't reuse process id's. if you've got a process that terminates, do n't reuse it. i will guarantee that the number of processes that i create as part of my test files will not be greater than what will fit in an integer. ok, so we can just use the regular integer alright. and then at time six, we have a process that ends because the process here waited on i / o. the cpu will schedule this guy run, and so at time six this process terminates and now between time six and seven, we have nothing that we can do. so our cpu is idle ok, so no process will be scheduled because we have no process that's ready run at time 7. the ioke that completed for that was requested for device one, so this process that was waiting on it, should have been this guy, gets run again and then at time 10 this process terminates. ok, so the simulation runs for 10 units of time, and i want you print out information about what's happening with each event that happens, right? i want you use queues for this, so find some mechanism that lets you use cues where they want you."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","so our cpu is idle ok, so no process will be scheduled because we have no process that's ready run at time 7. the ioke that completed for that was requested for device one, so this process that was waiting on it, should have been this guy, gets run again and then at time 10 this process terminates. ok, so the simulation runs for 10 units of time, and i want you print out information about what's happening with each event that happens, right? i want you use queues for this, so find some mechanism that lets you use cues where they want you. it's up you your implementation if you want use an array or a linked list or whatever is necessary. something do the queuing. consider the notes for how queue things and then statistics tracking. i want you keep track of two statistics for each process. that's wrong. i got ta erase that. i only watched keep track of two, not three. sorry about that. i want you keep track of the ready wait time and the io wait time, the ready wait time is the amount of time a process is not waiting for io, but it's in some ready queue. ok. whether it be all ready queue or you have multiple, it's up you for a moment. station you want time? that it wants the cpu but ca n't get it because it has wait. i oh, wait. time is the amount of time of process waits for io. i have turned around in time in here, but it's not because you're keeping track of these wait times. i'm not gon na bother having you keep track of that. i'm sitting raised that, but sorry about that. that's the title. ok, i do want you though keep track of the total time that the system was idle, where nothing was running, ok. all right, you are not required use threads. if you can find a way do it with threads, it's up you. i i did n't. so i do n't have much explain about that one, so here is an output for the example file that you're given. do n't starting process with pen. i signed a pin it, priority one scheduling that process times two with this other guy comes around. it does not get run because it's a non preemptive. we preemption as false if preemption was true, this guy would get run because it would preempt the lower priority process. here the process waits for io."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","if you can find a way do it with threads, it's up you. i i did n't. so i do n't have much explain about that one, so here is an output for the example file that you're given. do n't starting process with pen. i signed a pin it, priority one scheduling that process times two with this other guy comes around. it does not get run because it's a non preemptive. we preemption as false if preemption was true, this guy would get run because it would preempt the lower priority process. here the process waits for io. we're going schedule the other guy run, and we're gon na end that guy. we're gon na wait for iota complete and then this. i'm printing out the time unit of what the current time is so the io completes and we scheduled the next process run within the same time get it we end it system ends at time 10 was idle for three units should make sense. umm. alison, that makes sense. uh, i think. i think that makes sense. let's see. we were idle for two units initially because we had no process in the thing and then we were also idle in between 6:00 and 7:00. so that's 2 + 1 should be 3 good there. umm. and then the process information, i do n't care what order you print out the processes at the end, but i do want you print out the summary of information for how long each processes waited for io or ready time. so in this case i'm putting them all in the order in they terminated, but you can print them out in any order. ok. questions. right. you're given a bunch of sample input and output files, so i tried kind of explain what they are. this one up here is the given sample. i've got an example of multiple processes that a different priority where the preemptive scheduler and then one where i combine that with some io waiting. so the big things that i could n't get tricky on this one is if we have multiple processes of different priorities and they all are waiting for an io device, making sure you reorder them in the proper order based on priority when the io for that device completes is the highest priority process should get run next."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","you're given a bunch of sample input and output files, so i tried kind of explain what they are. this one up here is the given sample. i've got an example of multiple processes that a different priority where the preemptive scheduler and then one where i combine that with some io waiting. so the big things that i could n't get tricky on this one is if we have multiple processes of different priorities and they all are waiting for an io device, making sure you reorder them in the proper order based on priority when the io for that device completes is the highest priority process should get run next. so that's gon na be a tricky thing as well as keeping track of if you're using preemption or not, wanna process comes ready, making sure that you preempt the existing process if it is a higher priority and process that arrives or has the io complete. that is the same priority as the existing process running on the cpu should not preempt the existing process, only preempt for a greater priority. ok. right. make sure you submit a make file. i got some hints and tips on here as well as some stuff with scan if what i did for for this is i gave you this code for how you can use scanner read stuff in and then use scan after for reading and each event and grabbing any additional parameters inside your main dot c that's in your people. i've put this code in here. feel free change it. you do not need write. this is not like that. i know in cs1 and even some other classes it was like you have do it this way and you ca n't change it. this is an offer, not an obligation. you are welcome use this code, but if you find a better way or a different way do it, do it whichever way makes the most sense you. say otherwise. testing and debugging, just like with the flagger. had i do want you send it some additional script script, additional text files for input test different configurations, i gave you some, umm and then the deliverables are pretty much the same as the other stuff so. questions. one thing i do need do, and i'm going do this right now before i forget. i should be able edit this file. there we go is i want. umm. excuse me. there it is. you do not need print out the turn around time. done. ok, good. so that's that next thing."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","had i do want you send it some additional script script, additional text files for input test different configurations, i gave you some, umm and then the deliverables are pretty much the same as the other stuff so. questions. one thing i do need do, and i'm going do this right now before i forget. i should be able edit this file. there we go is i want. umm. excuse me. there it is. you do not need print out the turn around time. done. ok, good. so that's that next thing. no quiz today, although that it's not really a thing. it's like an anti thing. so the next thing i wanna talk about is for the rest of the day is talk about memory management. so what we got new new topic. so what's the simulator? that's part of scheduling. we finish scheduling. here we are memory management. this is kind of. alright, the next logical piece, process management and scheduling is kind of like cpu management. if you consider it that way, i did n't really call it back, but it's kind of what it is, right? memory management gets into a couple of things that like a lot of things be honest with you, fill in the rest of the gaps, here is the situation and i accept this a bunch of times, but maybe it makes more sense draw picture. you know, this picture is just as good as any better one i could draw. we're doing multiprogramming. we have an operating system that's juggling a lot of stuff right specifically the processes. what are processes? it's the abstraction that the operating system created. so in one way you could say the operating system kind of did this itself. it created this idea of processes, the schedule, the instruction stream that the cpu exits. but now, as a result, the operating system has be able figure out how juggle everything that a process needs. so i all resources, memory, cpu, resources. those are the big ones, right? and so we talked about. so if your resources in scheduling io, we kind of talked about it a little bit. we're doing file descriptors and stuff, but we'll come back that later on. so now we're on the memory management, so. process address space. you're talking about processes. we said the operating system gives us a process address space that a process gets its address space."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","so i all resources, memory, cpu, resources. those are the big ones, right? and so we talked about. so if your resources in scheduling io, we kind of talked about it a little bit. we're doing file descriptors and stuff, but we'll come back that later on. so now we're on the memory management, so. process address space. you're talking about processes. we said the operating system gives us a process address space that a process gets its address space. now that we know right one system calls and pork we call fork, we duplicate a parent that creates the child processes address space we call exec. now it gets replaced with some program run, and that's essentially how the the process gets its memory. ok. it's then scheduled on the cpu and that's how it gets cpu resources when the operating system then chooses it run it, but as part of the exec we have n't system will take the program and create this address space, right? text data keep and stack no problem. ok, we have multiple processes. we have a lot of these, right. if you look at our system, we look at the windows task manager or we run the ps command or whatever. in linux we see we might have 5 - 6, ten, 105,000 of these spaces that we have manage for an operating system, right? we do n't. the operating system has manage that. ok. so that's one thing we have lots of things that need happen. everybody gets own address space. ok, you can throw tomatoes at me and say, well, threads kind of share. ohh yes ok, so great threads do share ok, but if we abstract that away and say we just have processes worry about threads later. yes, we have many of these no sharing right now. each process is different. memory needs. ok. ok. that's that's if all me there that that makes sense, right. ok. right. i will speculate that a hello world program probably needs less memory than chrome. just a guess, i'm not sure, but i can do the math but anyway so different number he needs there is a finite amount of memory. ok, that's kind of a need say it's a no brainer, but it is. but you know, it's good mention, right? i my computer i think as like 16 gigs of memory my computer at home has less than that"
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","that's that's if all me there that that makes sense, right. ok. right. i will speculate that a hello world program probably needs less memory than chrome. just a guess, i'm not sure, but i can do the math but anyway so different number he needs there is a finite amount of memory. ok, that's kind of a need say it's a no brainer, but it is. but you know, it's good mention, right? i my computer i think as like 16 gigs of memory my computer at home has less than that and so we have different amounts of memory on different computers, but they all can run windows. now i guess there's minimal memory requirements, but eight gigs. i think it's enough run migos even though different computers are different amounts of memory, that number is fine. i ca n't create a computer with an infinite amount of memory. if you guys do that, please let me know because i kind of like have one of those, right? processes should not be allowed access each other's memory. isolation, protection, right and processes might want share memory, so we got ta keep that in mind because we have the shared memory thing. what you could just restrict that say sorry process. you wanna share something? create multiple threads, but we might wanna do shared memory segment, so that's in a way our situation and so the problem is how do we do this and how do we do it efficiently and what is efficiency? right. not all processes need the same amount of memory. that's another caveat. they do n't know exactly how much memory they need all the time, like a hello world program, we can probably guess, but like chrome, we do n't really know how much memory chrome is gon na need because we do n't know what web page it's going load. ok. and again, they're all these, the same amount of memory, process address spaces need be contiguous. ok, this is kind of a weird one in that if i'm a process and i'm running and i've got memory address 0 1,000,000 or whatever my limit is for how much memory i'm using. i do n't want have holes in here. i should n't, as an operating system, put another processes heap right in the middle of my texts. ok, my memory should be a block ok. and the last thing is gaps in memory are ways. ok, so let's take a look at this, alright."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","ok, this is kind of a weird one in that if i'm a process and i'm running and i've got memory address 0 1,000,000 or whatever my limit is for how much memory i'm using. i do n't want have holes in here. i should n't, as an operating system, put another processes heap right in the middle of my texts. ok, my memory should be a block ok. and the last thing is gaps in memory are ways. ok, so let's take a look at this, alright. so what does that mean? let's start with just simple memory allocation, ok and i call it simple. it's not necessarily simple, but let's talk about memory allocation, right? what is memory? now hardware wise is probably built on a capacitors or some sort of logic or, but conceptually logically what is memory? sure. it's ones and zeros. i like that one. let's go a little bit higher. it's an array of bytes. ok, right. so if i have an array of bytes and i wanna use that or something, i guess that's really what you say. even a java or c if i have an array of bytes and i wanna use a section of that array for something, i can just access it by its array index, right? i can do a look up in there if memory is an array of bytes, i can essentially carve out chunks of that for different purposes. they for process. a process needs added start. i control block text and spot for the data. it also needs dynamically allocated stuff. here's what's cool about them, right? this stuff, the process control block the text and the data. yeah, i'm ready. system knows exactly how much memory it needs for this. at the process get go the process control block is the stuff with inside of the operating system for doing the bookkeeping of the process. that's essentially a fixed size. it consists of all the stuff that the operating system needs keep track of, right? even like the file descriptor table, you can say, well, the process might open only one file with scriptor or 10 file descriptors, but ultimately the reference that file descriptor table, there's a limit the number of files i can open, right? so that's sad. so when the process starts or when i call exec start this, i can read the program and know how much text it's there."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","that's essentially a fixed size. it consists of all the stuff that the operating system needs keep track of, right? even like the file descriptor table, you can say, well, the process might open only one file with scriptor or 10 file descriptors, but ultimately the reference that file descriptor table, there's a limit the number of files i can open, right? so that's sad. so when the process starts or when i call exec start this, i can read the program and know how much text it's there. the program is static, it's compliant, and how much global data it needs because the compiler tells that now different programs might have a different value here. but at the program start this is known. this is the stuff that, be honest with you, that's kind of tricky. this is what makes a process as usage dynamic and that this i can go when the process starts, but this even stack i do n't really know. the process allocates that through the course of its lifetime, so i just got rid of people stack. maybe a lot easier for doing memory allocation, but fortunately we got this so. let's now move on. move on here and talk about memory allocation. so let's let's do simple right physics right? i remember in physics i took mechanics the very first thing we said was let's talk about force and motion and we'll just do a refraction and then they'll add friction later on. right? so let's just make it simple and get rid of friction in allocation, and we'll say what if we just this dynamic piece? we'll just say every process is going get asked tell us how much memory it needs when it starts, ok? now let's look at allocation for that. how do we can do that? one option here is use. oops, is do what's called block allocation. and with block allocation we have sort of two options. here we have fixed size. and we have variable size. what do i mean by fixed size? i mean the operating system is going do this. this is pretty awesome. ok, because it seems so simple but it works. we take all of memory. but fixed size we take all of memory and we say we're going divide this up into chunks. so the operating system will say everybody, let's do, let's say 8 meg. so this is 0 8 meg. this is 8 meg plus one 16 meg saw."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","and we have variable size. what do i mean by fixed size? i mean the operating system is going do this. this is pretty awesome. ok, because it seems so simple but it works. we take all of memory. but fixed size we take all of memory and we say we're going divide this up into chunks. so the operating system will say everybody, let's do, let's say 8 meg. so this is 0 8 meg. this is 8 meg plus one 16 meg saw. so every distance here size is 8 megabytes megabytes. and so on. ok. or actually we should probably use the word nibba bytes because mega is actually 10 the 9th versus miba is 2 the whatever right memory is actually computer and powers of two. so because we use binary, so whatever the closest power is but anyway, so i should use mid instead of mv, but just bear with me. ok, so we need thanks. and so the operating system, is that gon na do is it's gon na say, you know what? i need some memory for doing my own bookkeeping, right? i need memory for my own text. i need memory for process control blocks and things like that, so i'm gon na take a piece of this and if i need more than that, maybe i'll take more than one piece. maybe i'll an os gets two pieces that that'll be honest with you. if it was windows, it probably needs like 20 of these pieces, but we'll just, you know, let's not worry about that. so the operating system reserves some space, so the rest of the space it reserves roses and it says every process gets a block in memory. and so if a process comes along and it needs run, i'm gon na put p1 here. i'm gon na put p2 here and i'm going put p3 here and so on. if p2 terminates, i'm going consume its memory and i have an empty hole. but then when another process comes along, because everybody's using the same size, p4 would get that spot. ok, everybody just gets a chunk of memory. and that that works and there is actually some operating systems out there that do that. it's pretty simple. what can we do? how do we manage this? how do we know ones are free? that's pretty cool. we can create a bitmask for a bitmap."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","if p2 terminates, i'm going consume its memory and i have an empty hole. but then when another process comes along, because everybody's using the same size, p4 would get that spot. ok, everybody just gets a chunk of memory. and that that works and there is actually some operating systems out there that do that. it's pretty simple. what can we do? how do we manage this? how do we know ones are free? that's pretty cool. we can create a bitmask for a bitmap. maybe learn that in in data structures, right? we just done a bitmap and we have a bit for every single 8 meg chunk and then if it's being used by something we flip the bit be one or zero depending on how you wanna run it. wanna keep track of it? and then when the process enters the system, we scan that bitmap for the first zero, find its corresponding value by multiplying by the multiple of eight, and we allocate that for the process. we create the text data you've been sat there, flip the bit one, and then we know we're not gon na use it when a process terminates, we take our global bit, bask, we flip it 0 for that corresponding processes memory region. and we let another process use that spot for security reasons. we should probably 0 this out so that another process does n't get the another previous processes values, but depending on what our system is doing, maybe we do n't need do that, but ultimately would you the best. and it's pretty simple. now let's let's look at this friction thing. what do you guys, what do you guys think about this? the good symbol. what? what do n't you like about it? or is there anything you do n't like about it? i will say this is not the windows or linux does, so there must be a reason why they do n't do it. yeah, it feels kind of limited because. each chunk because of the process needs a more than it has and it tries reserve the more like the chunks will be like further down and then when it's like removed. it kind of messes up the. in order it, yeah. so couple of things with that, right. yeah, it's. i like that a process does n't know how much memory it needs. so while eight megs makes sense, a process in this case is limited 8 megs. i like your next statement as well."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","each chunk because of the process needs a more than it has and it tries reserve the more like the chunks will be like further down and then when it's like removed. it kind of messes up the. in order it, yeah. so couple of things with that, right. yeah, it's. i like that a process does n't know how much memory it needs. so while eight megs makes sense, a process in this case is limited 8 megs. i like your next statement as well. if i need more than 8 megs, why do n't i give a process chunks the operating system took two chunks, right? the problem there now is well. what if, if i do that and i put process q1 here and then later on it needs more space? i ca n't make it space any bigger because it would overlap with another process. i could say, well, let me find you another one down here. well, now my process address space is not contiguous and other processes stuff in the middle and so then you could say well alright, why do n't i try and find another spot and then move this process another spot. moving processes around in memory is not advisable because the process expects its data stick in the same spot once it runs right. could you imagine it in the middle of? i wanna load right cause i'm gon na load from my memory address and if i load from a spot and then six instructions later i try load from that spot but i'm move i'm gon na not get the right value potentially. so i do n't wanna move things around in that right. and so it's limiting in that process will only get the amount of memory that's in that block, and if it's if it needs more memory, it's stuck. the other thing is, and this is something that i often kind of take for granted. this it's kind of wasteful if i have a hello world program that does n't need nearly eight mags. it's gon na get 8 megs whether it needs it or not. so this is what it's called that. so what else can we do? variable size? in variable sized we have the os we have memory. and the os might take a spot, say the os needs 8 meg. and then what it can do is this. it can be like, well, you know, i've got some process that do n't need much memory."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","this it's kind of wasteful if i have a hello world program that does n't need nearly eight mags. it's gon na get 8 megs whether it needs it or not. so this is what it's called that. so what else can we do? variable size? in variable sized we have the os we have memory. and the os might take a spot, say the os needs 8 meg. and then what it can do is this. it can be like, well, you know, i've got some process that do n't need much memory. so i'm gon na create a couple of blocks that are only four meg, you know, create four of those. i'm going create some that are 8 meg. and then maybe a couple that are 16 meg. and so on. and that way, when a process starts, if it could tell me that it needs more memory, then i'll just put it in a in a the smallest block where it fits that. that lets me have bigger ones. the managing of this is a little bit more tricky because i ca n't just use the bitmask say i do. i mean i can use the bitmask for a bitmap for some of it, but now i also have keep track of how big each block is. so i can just do the bitmap board, unless of course i know that i'm allocating the same number of sam. always gon na allocate 16 blocks of each size. then i can use the index into the block know how big it is, right? that's one way kind of avoid that. what would all of a sudden done? this runs into the same problems. he is really a process, does not know how big it is. ok, how knowledge memory it needs. so where do you put it? would, if it needs more than that. but this does allow a process can use more than this 18 meg cache. so this fixed block allocation is nice. it's quick. it does n't take a whole lot of bookkeeping. one of variable or fixed in size but still is limiting because i ca n't always fit every process in there and process. do n't know much memory they need. ok. and that is what? this slide is attempting show, so this is the picture from the william songs operating systems book where they show essentially fixed blocks, default size or fixed blocks of unequal size. but that's the idea is that we have blocks that are set in size, ok?"
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","it does n't take a whole lot of bookkeeping. one of variable or fixed in size but still is limiting because i ca n't always fit every process in there and process. do n't know much memory they need. ok. and that is what? this slide is attempting show, so this is the picture from the william songs operating systems book where they show essentially fixed blocks, default size or fixed blocks of unequal size. but that's the idea is that we have blocks that are set in size, ok? and the problems here is some processes people memory than others, and we do n't always know how much memory that is, and this other word called internal fragmentation, i'm gon na talk about fragmentation more later when i talk about external fragmentation. but it's this idea of a waste in that if i have a process that needs a certain amount of memory. even if i did know exactly how much memory it needed, these blocks do n't always fit. if i have a process that does n't mean exactly mags. well, there's going be a waste in the amount of memory i allocate. i'm giving it more memory than it needed, right? if if i have 8 meg chunks and divide by memory like this and this is how much memory i have. i have 1234567 blocks. let me take it on 7 processes, ok. if i have 20 processes that all need 2 k, why i can really could have brought all twenty of those at a time, but because of this idea of a waste in internal fragmentation and allocating more memory the processes than what they need. limits my system on what it can do, and that's a problem i'd like avoid. efficiency can. so what are we left with the rest of the topic for today, is if we ca n't use fixed locks efficiently, let's use dynamic blocks. so part of dynamic blocks work ok, we still got ta get around this idea that processes do n't always know how much memory they need, so bear with me there. ok. so we we can worry about that. we're about that next week, but for now, again under the assumption that we have processes that know how much memory they need, dynamic block allocation just says you know what, i'm gon na reserve spots for me because i'm the operating system because i need some memory and the rest of memory. it's gon na be one big open array. ok, winter process comes along."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","so part of dynamic blocks work ok, we still got ta get around this idea that processes do n't always know how much memory they need, so bear with me there. ok. so we we can worry about that. we're about that next week, but for now, again under the assumption that we have processes that know how much memory they need, dynamic block allocation just says you know what, i'm gon na reserve spots for me because i'm the operating system because i need some memory and the rest of memory. it's gon na be one big open array. ok, winter process comes along. it's gon na say how much time are you needs, right? and what i'm going do is just start at the beginning and say, ok, process one, you can 29, i'll put you there. process too. you need 14 meg. that's there process three, you need at 18 meg, of there and no other process can be run. if it does n't, if it needs more than format, right? but that makes for very i feel like that can make sense. we just fill in as we go. i do this all the time at home when i'm stacking blocks, i'm putting dishes away and whatever right, i just stack them up next each other, right? before we get the rest of the infection, so do n't look at the slides. just go anybody see any problems with this? mixes adams concerns about the process needing more memory than others. ok. go ahead. yeah. we ca n't grow, ok? we're fixed in our amount of memory that we have in the way. so i mean, i mean you could say what can i add a memory dip? yes, i could add a memory dim. usually that involves me rebooting the system and i'm gon na get rid of all the processes at that point. some systems allow you dynamically add memory, but ok, but assumed that that is n't the case. yes, we're we're fixed. that's a problem, but we have finite amount of memory. so, ok, yeah, the that is the problem. so we'll worry about that actually next week. ok, so table that other problems with this? yeah, programs be ready and they can settle on the morning. ok. programs could be greedy. and i agree with you there. and so again, we will fix also back next week. i will fix these problems."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","some systems allow you dynamically add memory, but ok, but assumed that that is n't the case. yes, we're we're fixed. that's a problem, but we have finite amount of memory. so, ok, yeah, the that is the problem. so we'll worry about that actually next week. ok, so table that other problems with this? yeah, programs be ready and they can settle on the morning. ok. programs could be greedy. and i agree with you there. and so again, we will fix also back next week. i will fix these problems. i loved it, though. yeah, other things though. ok. we'll keep it. we'll keep it is a problem with that. it's a little bit of a concern for here because with fixed block allocation, fixed size blocks, i can just use the bitmask determine if a block is used. now when i allocate this, i need keep track of more than that. i have keep track of the start and the end for each process and i can do that in the process control block. that's just two numbers right for the start of the memory address, but along the lines of bookkeeping when poses a start, i get as jam them in there in the memory, and i can then keep track of like a running tally at where the free space starts. the say initially the free space starts after the operating system. i'm going allocate a process, figure out it started, end store those numbers in the process control block, and then advance the free space pointer down for the next process. ok, kind of like a stack, but the problem with the bookkeeping comes when anyone of these processes end. i've got a whole. so now i have manage holes. i do have manage holes before before it was just a bitmask. so not only now do i have this free space where the free space starts and ends. anytime i have an additional free space, i have keep track of that start and end. and they are false. so managing the holes now increases by bookkeeping requirements. yeah. and in this situation i've got a process that starts. where do i put it? i have processing that needs 8 meg. i have essentially iterate through all of my holes find the spot that fits before with a bit."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","i do have manage holes before before it was just a bitmask. so not only now do i have this free space where the free space starts and ends. anytime i have an additional free space, i have keep track of that start and end. and they are false. so managing the holes now increases by bookkeeping requirements. yeah. and in this situation i've got a process that starts. where do i put it? i have processing that needs 8 meg. i have essentially iterate through all of my holes find the spot that fits before with a bit. a bit sad, i could just find the first bit, but here i got ta find not only the next three spots, but the next three spot where this process fits and it fits here. some great i'll put it there and then make this all smaller. if i have another process that comes around that needs 6 meg, i can put it here and then get rid of that whole altogether, right? but now this guy ends. i've got another 20 meg of free space. i got a new hole keep track of and then the hole here and here is ultimately the ticker. you'll notice that as this runs, how many holes am i do i have? i'm getting more and more holes as i go the point of if i have a process now that needs 10 megs over here, can i run it? no, i'm gon na spot for it, but had i maybe like, move things around or find a way compress my holes, i could have. this is a waste. this type of fragmentation is called fragmentation. all these little holes or referred as fragments and this referred as external fragmentation. it's fragmentation or holes. wasted memory outside of a process's memory allocation, internal fragmentation is waste of space inside of a process of memory allocation, or essentially allocate more memory a process than what it needed, and inside it it has wasted space. this is external fragmentation. we have holes in memory that, had we managed it slightly different, we might have been able run more processes, but because we did n't manage correctly or efficiently, we have holes and so we ca n't. thanks. so that's one thing. external fragmentation. what is the other thing? we have a choice. we make comes time fill in the whole say right here, right. i've got a hole that's 20 meg. a hole that's 6 meg and a hole that's 4 meg."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","we have holes in memory that, had we managed it slightly different, we might have been able run more processes, but because we did n't manage correctly or efficiently, we have holes and so we ca n't. thanks. so that's one thing. external fragmentation. what is the other thing? we have a choice. we make comes time fill in the whole say right here, right. i've got a hole that's 20 meg. a hole that's 6 meg and a hole that's 4 meg. if i have a process that comes along that is 4 megs in size requirement, where do you put? what's efficient? sure. we completed here. right, that's called first fit first fit is you stand all of memory. all of your holes and find the first one that fits works fits. that's one way do it. that's what this example is doing, ok. next fit. what does that next bit is kind of like first fit only. after we allocate a process, when we find a place put it, the next one we look at is the next space. so we do n't always start at the beginning every time. we just start with the next one, so here. although it here would be if i have a process that is 4 mags, i heard with that spend if i start here allocated there and then the next bit, let's say skip this guy and go on the next one or the next process. the idea here is that by iterating through all the holes, we try keep the holes distributed as terms of size, but not expected first met says in the 1st place that fits. what do i like about first fit? yeah, i'm going three simple and does n't take a whole lot of time. i just stand in the first thing. it's still order n because it might have stand do a whole bunch of places, but that's that. best bet? best fits pretty cool. what is best fit do is it scans every single hole and finds the hole would result in the fewest remaining spots remaining memory. so in this case, if i wanted create a process that needed formative space and it was here, what i would do is i would stand all of memory, all the holes, and i would allocate it down here because this would create a hole of eventually too many. this would create a hole of 0, so i put it there test text. thank you."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","best fits pretty cool. what is best fit do is it scans every single hole and finds the hole would result in the fewest remaining spots remaining memory. so in this case, if i wanted create a process that needed formative space and it was here, what i would do is i would stand all of memory, all the holes, and i would allocate it down here because this would create a hole of eventually too many. this would create a hole of 0, so i put it there test text. thank you. and then worse, fixed says doing the opposite, find the spot where i would essentially be creating new the largest empty space of new, wasting potentially the largest amount of space and put it there. so in that case, if i needed for right, i would put it here or in this case, if i needed format, the best bet would put it here. worst fit put it up here in the 20 meg, they might say. why would you ever want do that? yeah, the idea there is that we want keep the the holes all about the same size. so if we fill in the hole that's biggest, we'll keep them all about the same size as we go under the assumption that most processes need the same amount of memory. if we can keep all the holes about the same size, that's what we're fits attempting do. best fit is so try make it so that we have the fewest number of holes or so. just trying keep all the holes in the same size. first, find the next bit. well, that's more like the first come. first serve. it's just intended make the algorithm easier, right? because when you get into best at worst fit we the amount of time we have iterate through all the holes is we got ta go through all of them make a decision with best person. the next bit we can stop as soon as we find one that works. ok. questions. that's the next but worst fit first fit. all right. so problems, though external fragmentation, you can actually do the do the math and you say right with with like the schedulers we kind of had this evaluation criteria of one is better than the other, right. and i said that theoretically shortest remaining time is the most efficient in terms of ohh response ratio. the problem there is we do n't always know or we not always very rarely do we ever know how much cpu will process needs. so the shortest remaining time."
"""OpSys_Balancing_Efficiency_and_Fairness_Transcript.txt""","that's the next but worst fit first fit. all right. so problems, though external fragmentation, you can actually do the do the math and you say right with with like the schedulers we kind of had this evaluation criteria of one is better than the other, right. and i said that theoretically shortest remaining time is the most efficient in terms of ohh response ratio. the problem there is we do n't always know or we not always very rarely do we ever know how much cpu will process needs. so the shortest remaining time. is it practical when it comes the fit algorithms? umm, there is also no optimal solution. here it is. you can always probably always can come up with umm in ordering of process arrival and process sizes, requirements that make any of these algorithms better than the other. so then all of a sudden, donna just kind of knows what it is. and so i'm in the world of memory allocation. often you see first fitted, next fit used just because they're simple implement and they have this sort of escape situation that as soon as you find something that works, you just use it. and that's just about it is what it is. ok is what i'm getting. other things? algorithms, but we're still stuck with this external fragmentation, right? we always will have that problem. ok. and of course, we still have how much memory of process needs, so we got ta fix that, that a process might not, we do n't know how much memory process needs. uh, we got ta fix the memory hogs that suck up all of them. like, ok, they'll be with that and we got ta deal with the fact that we have a limited amount of memory. ok. so those three things we're hopefully solved next week, but for now, let's stop there. questions, right. lembke, james stopped transcription"
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","meeting in _ general_-20240502_130510 - meeting recording may 2, 2024, 6:05pm 45 m 28s lembke, james started transcription lembke, james 0:08 i do n't really have a big plan, so anyway for the recording. the question was what is review gon na be like tomorrow? and it is going be a i'm gon na go through the topics that are sort of fair game for the final exam and then give you the opportunity ask the questions about me do problems or whatever from that point on. so a little bit of me talking a little bit of you talking, hopefully no. ah, but hello. hello. good morning. afternoon rather operating systems maybe for one last time isolation and protection abstractions are cool. that's been the topic of this semester. what do i got in canvas? not a whole lot new because we're gon na finish up file systems today and just i got this stuff that i've been building up for the final exam review. i'm gon na update the summaries and the recordings summaries for from the the ai model. so you can use that for studying. there's the information there about the note sheet. no blank quizzes are out and i posted the solution for the memory manager quiz and the notes for file systems i went through and updated the notes for file systems include the little bits about extents and that we talked about so that there was n't a slide in there and so then we'll finish going through those today and then i want do an example of an actual honest goodness file system that uses some of these concepts. some of the better points and the worst points, and fortunately of a lot of these concepts, and then we'll be done. so, umm, one of the things that i wanted talk about one more time here, just a quick review because i do n't know that i did a great job of it. but just reiterate, it is this idea of, umm, motivating. why we have have this open and close sort of contract with our drive and with our with our file system and that stemmed from this idea of the fact that in the world of file allocation. regardless of what you use for your file allocation, you're going the file system is requiring have some sort of bookkeeping that keep track of where the data blocks are for that file by name, right?"
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","so, umm, one of the things that i wanted talk about one more time here, just a quick review because i do n't know that i did a great job of it. but just reiterate, it is this idea of, umm, motivating. why we have have this open and close sort of contract with our drive and with our with our file system and that stemmed from this idea of the fact that in the world of file allocation. regardless of what you use for your file allocation, you're going the file system is requiring have some sort of bookkeeping that keep track of where the data blocks are for that file by name, right? so if some identifier for the file and then we also have other metadata that we did n't really talk about, but i'm gon na get him and show you the example today, things like permissions, biotype, data, blast modification, all that kind of all stuff associated with the file. is this the other case? the example just show the identifier, the name and then some way find the data blocks, but this shows it from an entire file system perspective and in reality this is not the way we wanna do this. we wanna actually group files together by category. so file abcd and e yeah, that's great, but they're all there. but they're all categorized in the same sort of grouping. and so later on in the slides, i showed this idea of a grouping where we could have this master starting point, and underneath there we have other sub categories or directories or folders that we can classify additional files in an additional directories that contain additional directories can contain files and so on. this structure essentially brings about the idea of breaking apart the file allocation table into multiple pieces, and all of these small pieces are distributed directory itself is really a file, but the data associated with that file is. the is the files that are contained within it. the file allocation table that's always the result that we wanna find the data blocks for a file, right? our goal, right? my goal as a programmer or as a user of the system is i just want save my microsoft word document and i want write the data the blocks for that file. ok, well, that requires the operating system find the blocks for that file. so in order find that the blocks for a file, it's got ta do something like this. it's got ta say user this is called file name resolution."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","the file allocation table that's always the result that we wanna find the data blocks for a file, right? our goal, right? my goal as a programmer or as a user of the system is i just want save my microsoft word document and i want write the data the blocks for that file. ok, well, that requires the operating system find the blocks for that file. so in order find that the blocks for a file, it's got ta do something like this. it's got ta say user this is called file name resolution. where we take the file path and resolve it its data blocks. so i might have a some a file like c colon slash docs slash lists slash power backslash. grocery dot txt ok. what i have do is i want find the data blocks for the grocery dot txt grocery dot txt is the in the directory or folder lists is inside the directory or folder docs is inside the file system for drive c so the operating system needs go the root directory for drive c read the data blocks for that and that's going consist of a file allocation table. but inside that file allocation table is going be the stuff that's immediately within it. so that in case it's gon na contain docs. and perhaps other stuff that's in there. i'm assuming they've got other stuff in my c drive, probably windows program files and a bunch of other stuff, but they're all inside the file allocation table. grocery dot txt is not in there, so i got ta look in the next stage in the path and say ok, where is the data blocks? from our docs, they're in here and the data blocks for docs maps another. while allocation table because this happens be. directory and inside there i will have an entry for lists as well as perhaps other stuff. maybe saved games or images or whatever other stuff in here, but then i got ta go the next stage in the directory path and say, ok, i got ta go where the data blocks for lists are and what's in there? well, lists is another directory, so i have another file allocation table. then will contain grocery dot txt and now with this i can get the data four grocery dot txt. and this name resolution. if you look about that look at this. i got ta read the the data blocks for c then i got ta read the data blocks for docs. then i got ta read the data blocks for lists."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","maybe saved games or images or whatever other stuff in here, but then i got ta go the next stage in the directory path and say, ok, i got ta go where the data blocks for lists are and what's in there? well, lists is another directory, so i have another file allocation table. then will contain grocery dot txt and now with this i can get the data four grocery dot txt. and this name resolution. if you look about that look at this. i got ta read the the data blocks for c then i got ta read the data blocks for docs. then i got ta read the data blocks for lists. all of those require additional io operations, so this name resolution find the data blocks could take a while and once i do that once i find the data for the sorcery dot txt. i do n't wanna have do that every single time the user does n't read or write, so as a result, instead of our system calls. so if you remember, our system calls it, it is not right see colon slash docs slash lists slash grocery dot txt and then the data. this is not the way the system call works. the way the system call works is you first do an open of the path. and that returns a handle. that you can then later use write the file. this handle is a reference your file descriptor table, in turn soars the location of where all the data blocks are so that you do n't have do name resolution every single time you do want do an operation a file. and that is this contract, because if i'm another user, comes around and says, you know what, i do n't need lists anymore. i'm gon na get rid of it now. the operating system is crashing these data blocks inside this file descriptor handle for a file that does n't exist, and that's a problem. so this is why when the operating system processes an open now only does n't do name resolution cache the data blocks, but it also keeps a reference count on that file make sure that it's not deleted until whoever is using it closes it, not only whoever is using it, but all of the users that use it close it. questions makes sense. this is why we end up in the right history, so speak. why we end up with open and this working cause in one perspective, from my perspective, is it just easier say operating system right this file? i'm done right? that'll be easier."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","so this is why when the operating system processes an open now only does n't do name resolution cache the data blocks, but it also keeps a reference count on that file make sure that it's not deleted until whoever is using it closes it, not only whoever is using it, but all of the users that use it close it. questions makes sense. this is why we end up in the right history, so speak. why we end up with open and this working cause in one perspective, from my perspective, is it just easier say operating system right this file? i'm done right? that'll be easier. this is open, closed things. a lot of stuff like the correct me drag up, but it's because of this. ok, stop name resolution. open and i tried reflect that in words in the slides, but this picture perhaps makes it a little bit more sense. alright, so next topic. let's move on here. we talked about file allocation, directories and name resolution talked about free space management, bitmaps and links. what i want do now is talk about consistency. bring up the c word and we i talked about this a bunch of times in the past that i just kind of hand what you did said. we're gon na talk about this later. well, now is our chance talk about it. ok. so couple of problems and i mentioned this before, but now let's get them in more detail. yes, we have. ok, lots of stuff that our file system is now keeping track of. we have correctores we have file metadata. we have file data. we have free space, right? and whenever we want write a file, ok, we might have update any number of locations, but inside our file system. so i'll give you an example. i want make a file bigger. ok, what do i need do? i wanna make it 1 block larger. yeah, i got ta find a free block, right? i have resolve the file. ok, so assuming i did all that and read all the directories, but once i know where the blocks are for that file, i have find a free block i can do using our free list bitmap or free list linked list."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","and whenever we want write a file, ok, we might have update any number of locations, but inside our file system. so i'll give you an example. i want make a file bigger. ok, what do i need do? i wanna make it 1 block larger. yeah, i got ta find a free block, right? i have resolve the file. ok, so assuming i did all that and read all the directories, but once i know where the blocks are for that file, i have find a free block i can do using our free list bitmap or free list linked list. i need allocate that block that file, so i need update the files entry in the file allocation table or the directory that contains that file so that i know that that file has an additional data block and not have update the free space mapping or the free space bookkeeping say that there's one less free block and that is being blocked is being used by that fire, right? all those required disk isles different locations on the disk potential. what happens if my system right? i wish. i wish i could. i really do. i wish i could make sure that my system does n't crash, right my battery could go dead and happens. what happens if the system crashes in the middle of updating one of these structures but not the other? i have an inconsistency i'd like fix that i'd like be able detect inconsistencies. i'd like be able fix up other thing is blocks may fail. how do i protect against that entire drives made mail? how do i protect against that? entire computers could fail. well, not a whole lot i can do about that, right? it's kind of get a new computer, but it things happen. things break. processors break memory breaks, memory gets corrupted. we're really focusing on this drives here, but how do we recover from failures? i've got a couple of strategies here. there are probably others, but these are the two that i think are most worthwhile talking about, at least today. one is block duplication and file and block consistency checking, right? do n't talk about block duplication. this is perhaps the simpler 1. so block duplication. the idea behind block duplication is if i have some critical block."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","processors break memory breaks, memory gets corrupted. we're really focusing on this drives here, but how do we recover from failures? i've got a couple of strategies here. there are probably others, but these are the two that i think are most worthwhile talking about, at least today. one is block duplication and file and block consistency checking, right? do n't talk about block duplication. this is perhaps the simpler 1. so block duplication. the idea behind block duplication is if i have some critical block. on my file system that is maintaining something important like say, i've got a file allocation table there, right? or a set of directory entries, whatever you want, refer it as right the information that says where the data blocks are for the files that are contained within a directory. this is important. if i lose this. i just lost every file in that directory, and if that directory is like the master directory or root directory or something like that, i've lost all of the files of my entire file system gone right? i ca n't find the data blocks for them. so1 solution is this block. is maybe block 0. we're gon na pick another block that we know exists on the drive. maybe block? i do n't know. who knows? who cares? they can put put block one and put another copy of that file allocation table there. that way, if block 0 fails, now we got another confident. is apple like right question though? yeah, go ahead. how do you know? ok. how do you know where the second one is? ok. that's important. i like that questions here. where is the other copy? i like that. ok. we'll keep that on in our brain other questions. ok, primary backup. i'm going twist your words a little bit and say if i have update this right add a new file or modify what the file data blocks are, or the files in here i have write it here and here. ok, that takes 2 disk ions. that kind of stinks because it makes the whole world slower, but that's a performance thing for protection. it might be worthwhile pay a little bit of performance penalty, but the words i'll twist around for is what happens right? this call idea of system crashing. i ca n't get it right away from it if i have issue a disk io write this lock and a this guy out write this lock."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","i'm going twist your words a little bit and say if i have update this right add a new file or modify what the file data blocks are, or the files in here i have write it here and here. ok, that takes 2 disk ions. that kind of stinks because it makes the whole world slower, but that's a performance thing for protection. it might be worthwhile pay a little bit of performance penalty, but the words i'll twist around for is what happens right? this call idea of system crashing. i ca n't get it right away from it if i have issue a disk io write this lock and a this guy out write this lock. what if i get this one written and then the system crashes on? i never get write the second one. one is the correct one? they're not the same. so do i always trust this one, or do i always trust this one if they're different? but what if this is the definitive one? or if this, what if i'm always trying trust this one and this one breaks? right, so what do we do? ok. 1st on the carson's question, where are they? well, some file systems just say the first one is block 0, the second one is block one and then just preprogram that in there know where they are. others will have another block in front called the master or the super block says information about the rest of the file system. the same where is you know how many copies of this file allocation table are they and where are they? well, then you could say what happens at the super block fails. ok. it's kind of a chicken and egg problem, right? kind of unwinding the on peeling the onion, but you could have multiple copies of the superblock in known locations. there's really not a great solution that, but that's kind of what's typically done. on the riots question. now, how do we know one is the master? is a version value. and we'll say every time we write the file allocation table, we will suck some of the file allocation table out of as overhead store a number. and if we store that number wide enough so that it's enough bits, it's never gon na wrap, so speak. and just every time we write it, we just increment that number by one, and whichever one is the highest number, that's the one that we wrote most recently. fair enough. the works duplication blocks."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","is a version value. and we'll say every time we write the file allocation table, we will suck some of the file allocation table out of as overhead store a number. and if we store that number wide enough so that it's enough bits, it's never gon na wrap, so speak. and just every time we write it, we just increment that number by one, and whichever one is the highest number, that's the one that we wrote most recently. fair enough. the works duplication blocks. we suck up a little bit more overhead by having copies of blocks. we use this versioning idea, takes a little bit more overhead, but it allows us duplicate blocks. the case blocks fail. buildings are protectors though for a system crash, because if i have write multiple file allocation tables when you, even if i have multiple copies of them, i still have this potential problem where the free space does n't map what actual files are. and that's a problem. do n't enter the world of consistency checking windows used do this. i think it's still might used be or. i remember back in the day when my first computers i get a blue screen of death. maybe probably did n't really find them. they're not as common anymore, but still it was. it was a thing and it windows would say something catastrophic happened. you can try hit any key let the system continue or reboot your computer, and if you rebooted your computer, windows had them. it just kind of felt like it was just so frustrating because it was windows that crashed and it would boot back up again and said user you did n't properly shut down your computer. maybe you should do that next time, and so i'm gon na have run consistency checking because you know it was n't shut down properly and that's it. there be going. you're the one that crashed. whatever. sorry, frustrations from my past, but i'll get over it, but consistency checking it's a thing. so what do we do with that? well, here's the idea of consistency checking is we have. file allocation. whether we're using contiguous or chained or indexed or extends, or a combination of any of these, we have some mechanism that records the data blocks for files, and blocks are allocated files. right. comes up ok, we also have. a free space. i will call it a free space map."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","sorry, frustrations from my past, but i'll get over it, but consistency checking it's a thing. so what do we do with that? well, here's the idea of consistency checking is we have. file allocation. whether we're using contiguous or chained or indexed or extends, or a combination of any of these, we have some mechanism that records the data blocks for files, and blocks are allocated files. right. comes up ok, we also have. a free space. i will call it a free space map. that's probably not necessarily the most generic term, but it's some mechanism that we are using record the free space on the drive. ok, we have two things now. again, whether we're using a bitmap or a link structure or whatever that might be, or maybe we're using free space extents or something like that, we have some way of managing free space and so the idea of consistency checking is say, well, i do n't know in the event of a crash got updated first or not. i do know that i can scan every file allocation table in every directory on this drive find all of the files and know what this file system says is allocated a file. i can do that. you can scan it all, might take a while, but i can do it. i can then scan the free space map determine all the things that have been allocated or free some file. i may not know what file it's been allocated, but it can know ones are free and from that point i can understand a chat and say alright, a free space might say you have blocks 234 through n free and a file allocation table might say your red file uses block zero and one. and that's consistent because i have one file that is using zero and one and a brief space map that says two through and are free. if red is the only file i have on the system and my free space map says that four. is not free. i only have 235 through n now one gets something wrong. i've got a file allocation that says you know what 4's not allocated anything. what? i got a free space map that says yeah, it is so that means i must have updated the pre space map but without updating the file allocation for some file something is n't consistent. so it consistency checking. what i do is now go back the notes here, do a bunch of phases. i built 2 tables."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","if red is the only file i have on the system and my free space map says that four. is not free. i only have 235 through n now one gets something wrong. i've got a file allocation that says you know what 4's not allocated anything. what? i got a free space map that says yeah, it is so that means i must have updated the pre space map but without updating the file allocation for some file something is n't consistent. so it consistency checking. what i do is now go back the notes here, do a bunch of phases. i built 2 tables. i scan the file system for all allocated blocks and what files they're in done that takes a while, but i can do it. then i scan the file system for all free blocks. ok, found the free ones now i check. and now we're planning. block should not be allocated more than one file that is not correct, right? we might be able share memory with shared memory pointers, but a file 2 files should not point the same blocks, it's it does n't make sense. so that's the problem, and a block should not be allocated and free at the same time. right. that makes sense. and in another way is a block. should not be unallocated and not free at the same time. it should only ever be in one of these two lists. after we do the check, then we use some logic fix the inconsistencies. i and this is what central like check disk does in windows. on linux, it's echoed fsck for file system check usually often people will convert that other four letter choice four we wo n't go there. but anyway, so here is some example, do n't consistent. i've got a file system that has eight blocks. i've got an allocation count that says block 01 and two are allocated one file. i do n't necessarily record in this one file it's allocated, but it probably should have, and it's not free. everything is consistent. i have just a one in each column and i do n't have a one and a zero. i do n't have 2110. it's either allocated or free. so ok, here's in version of of inconsistent where a block is not allocated and it's not free. so in that case, a simple approach is say, well, if it's not allocated, it does n't hurt anything. the market free if i want market allocated, i need know where it goes and"
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","i do n't necessarily record in this one file it's allocated, but it probably should have, and it's not free. everything is consistent. i have just a one in each column and i do n't have a one and a zero. i do n't have 2110. it's either allocated or free. so ok, here's in version of of inconsistent where a block is not allocated and it's not free. so in that case, a simple approach is say, well, if it's not allocated, it does n't hurt anything. the market free if i want market allocated, i need know where it goes and and i just do n't have that information right now. so the simplest approach is say i do n't wanna lose this block. i do n't wanna orphan it, so i'm just gon na mark it free and then if the user wants use it, they can. chances are what happened was in this case, the block was going be allocated a file, but the system crashed before it got that far. so in this case these are just allocates that block again later on. enough. ok, next one allocated and free. this is n't good either, and so the answer here might be 100 unallocated. that could be dangerous because now like lose data, the safest approach here is say, well, chances are, and now i do n't even know exactly what caused this happen. it might have been a situation where the user wanted truncate this file and i updated the free list before i actually removed the block from the file or something else, but the safest approach here is prevent losing data. i'm just gon na mark it the block not free and just leave the allocation where it is. ok. and then this this last one, is kind of weird. it happens. that's not my decision determine why that happened at this point. i just wanna fix it where we have a block that's allocated more than one file. i guess i do n't know necessarily know how that happened, but if it did, we need fix it. and so the solution might be well, i just remove it from one of the files. but again, for data loss perspective, do n't want lose data. so here's the trick. we take this block and we find another free block."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","that's not my decision determine why that happened at this point. i just wanna fix it where we have a block that's allocated more than one file. i guess i do n't know necessarily know how that happened, but if it did, we need fix it. and so the solution might be well, i just remove it from one of the files. but again, for data loss perspective, do n't want lose data. so here's the trick. we take this block and we find another free block. so in this case, maybe block six, we copy the contents of 1/4 block 6, make 6, not free, and we update one of the two files say one of them gets blocked 4 the other one gets blocked. six so they both can continue with a copy of that block, but they're an independent copy of that block, and like the copy on write, something that we did remember i mention. russian. yeah. would n't that mean that whatever process we might even get the point get on the party? will send you got a copy of one of of it, right? this is gon na be done at boot up time. we know other processes are running. this is the operating system saying this file system is inconsistent and i ca n't let it continue. i need make it consistent so i could just delete these files, but that's not good either. that's data loss, so i'm trying find a way fix this reduce the amount of data loss and make the file system consistent. that would suck. other questions? thoughts. ok, consistency checking. there are other types of consistency checking, but this is where we're going stop with that. all right, we got 20 minutes left. so last thing i want talk about is an actual honest goodness file system that uses these concepts and you can go and look up the spec for it. it's relatively long where it talks about this region, the disk is gon na contain this and this region. the disk is gon na contain that and it is the world of facts file allocation table. this is actually the name of a file system called file allocation table, not the name of the file allocation table. in general, they just happen use the same wording. i did n't make the rules, so i know that you were that so fat. this is designed by microsoft back in the day for what's first pc that it developed for a long lines with ibm. microsoft developed the pc."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","it's relatively long where it talks about this region, the disk is gon na contain this and this region. the disk is gon na contain that and it is the world of facts file allocation table. this is actually the name of a file system called file allocation table, not the name of the file allocation table. in general, they just happen use the same wording. i did n't make the rules, so i know that you were that so fat. this is designed by microsoft back in the day for what's first pc that it developed for a long lines with ibm. microsoft developed the pc. ibm developed the pc hardware they contracted microsoft write dos, the operating system, and they said all that go along with that operating system allow people persistently store files. you might say, well, is n't that really old? yes, it is. but faith is still in existence on some external media. usb keys, things like that often use fat or file system, so it is still relevant. we're going talk about bat 16, i'll talk about what that 16 means. but for now, in general, all versions of fat, there's about 12 fat 16. there's fat 32. all of them operate in a similar idea. but they just have slightly different widths of things based on the number. so how does that work? well, here it's how fat works. it utilizes kind of this idea of extents. i mentioned this extent right it, whereas there's multiple blocks next each other that are used and with the extent they could be variable size and they specific and we record how big a particular extent is. that says i like the idea of extents, but i do n't like this idea of having record in every extent how big it is. so i'm just going call a cluster like an extent, is a fixed number of sectors and inside the header region for the file system i'm gon na record a number says how many sectors there are per cluster, how many blocks there are per cluster. this number is typically 2, but it does n't have be. i so far so the minimum allocation in this file system is going be a cluster, is like an extent, essentially an extent. so inside the disk region, starting at the very beginning of the drive, we have some reserve region, sometimes called the boot sector, but this is gon na be a reserve region will indicate information about the file system as a whole. things like sector per cluster."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","so i'm just going call a cluster like an extent, is a fixed number of sectors and inside the header region for the file system i'm gon na record a number says how many sectors there are per cluster, how many blocks there are per cluster. this number is typically 2, but it does n't have be. i so far so the minimum allocation in this file system is going be a cluster, is like an extent, essentially an extent. so inside the disk region, starting at the very beginning of the drive, we have some reserve region, sometimes called the boot sector, but this is gon na be a reserve region will indicate information about the file system as a whole. things like sector per cluster. then we're going have a file allocation table, and then a special root directory, and finally the data region where all the clusters reside. i so starting at the beginning of the drive, we have the reserve region looks like this and inside here we have a bunch of things that kinda look familiar. sectors per cluster bytes per sector should be 512 for most drives, but might not. there's some reserved things. hobbies are the fat file allocation table is gon na indicate where the data blocks are and so number of copies of the fat gets us this multiple copy thing in case blocks go back. so we've got multiple copies of that, umm, and so on. so there's some other stuff in here. talked about drive geometry. this is more relevant when drives actually spun than we have sectors and tracks on them, but not so much anymore like number of heads. what's that for? a solid state drive. i guess it's zero. ah, a couple other things. i'm here. this like jump code, this was used essentially for well booting. we did n't talk about boot procedures or anything like that, but ultimately the firmware that's on our computer when the system receives power has search for a disk drive contains an operating system image. and let's use that information on there figure out how load and run the operating system initialize the rest of the system. so utilizes that. so this is information about the entire operating system. entire file system. ok. and here's some more descriptions of it after."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","this like jump code, this was used essentially for well booting. we did n't talk about boot procedures or anything like that, but ultimately the firmware that's on our computer when the system receives power has search for a disk drive contains an operating system image. and let's use that information on there figure out how load and run the operating system initialize the rest of the system. so utilizes that. so this is information about the entire operating system. entire file system. ok. and here's some more descriptions of it after. the boot sector or the reserve region is the fat, and so what file allocation table does is it says i really like this idea of changing the allocation for blocks are chained in order because i have worry about brightman patient and i can kind of like foot blocks anywhere it that's kind of nice. but i do n't like the fact that i if i wanna find the next block and the chain i have read the previous block. so when the bad developers did is they just said, why do n't we take all the chains and just put them in one place? that way we do n't have put them in the in the clusters or the data blocks. and anytime we wanna find where a file is, we can just read the entire fat and just get the pointers. then we want find the data blocks. we can. we already have those pointers. we can hash those locations in memory and that's what the fat is going happen. it's gon na have essentially an array of pointers where all the blocks are chained together. hope you remember though from chained allocation the big thing that we're gon na need is. it starts from there. we go the file allocation table figure out where go from there. the next slides so when pat does is it creates a directory structure with file name and amongst plenty of other stuff information about where in the starting cluster is ok, but they. so let's take a look at a directory entry and then we'll come back and talk about how the fat works. so this is what a directory entry looks like. in fact, it is 32 bytes long, is nice because if you're looking at an hexadecimal dumb, it's two rows of 16 bytes and they contains the name of the file and the files extension. a byte for a bunch of attributes date and time of last modification. there it is. spam. what cluster the bowl starts on and then from there we can go the fat figure out where the other blocks are"
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","so let's take a look at a directory entry and then we'll come back and talk about how the fat works. so this is what a directory entry looks like. in fact, it is 32 bytes long, is nice because if you're looking at an hexadecimal dumb, it's two rows of 16 bytes and they contains the name of the file and the files extension. a byte for a bunch of attributes date and time of last modification. there it is. spam. what cluster the bowl starts on and then from there we can go the fat figure out where the other blocks are and then a word on essentially 4 bytes indicating how big the file is. in bytes. so if ever respond know how big the file is, we do n't have search the entire file allocation table for all the blocks. the thing the things that we see about this that does n't do permissions. right. if you look at the at the attributes, we only have like archive. we have a read only that's kind of like permissions. we have a bit indicating whether or not it's a directory. we do n't say this user can read or write that file, so, but it is what it is. so then, here's an example and i got. so this was a directory entry. we have these characters representing the file name. these characters representing the extension and so this file is called file one dot txt e this then we have a bite that indicates some attributes over here and then we have date and time of last modification. we've got some values that are n't used, and then we have the starting cluster in here says 0b00 and then the file size. is n't that a comfort class? but i do wanna point out one thing. this file system was created on an x86 intel architecture machine. but wait until represents bytes for numbers is weird me. i do n't know why they chose do this, but it seems backwards. right now, we're just learn envy in this for those who took comport with the bytes or ordered it's left right and right left. you might say this must be starting cluster really large number. but it's not, because instead of numbering the bytes 0b00, this is actually the starting byte. this is the first byte. this is the second byte, so this says that it starts on cluster 11 because a is 10 and b is 11. and on hearing might say this is a huge file."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","right now, we're just learn envy in this for those who took comport with the bytes or ordered it's left right and right left. you might say this must be starting cluster really large number. but it's not, because instead of numbering the bytes 0b00, this is actually the starting byte. this is the first byte. this is the second byte, so this says that it starts on cluster 11 because a is 10 and b is 11. and on hearing might say this is a huge file. now it's actually a6 byte file because the bytes are ordered this way from right left that came up. that's little endian or big endian, but anyway, that's the way the bike ordering works. ok. other things see about a directory entry. in fact, the at least the older version of fat they added some extensions allow this be different. we have a limit here. along with file name, are we allowed have? yes it. 8 fights if we're using ascii, that's 8 characters. so originally in the file allocation system, back when ibm and microsoft are working together, all of the files in the system could be no longer than 8 bytes long. it is what it is kind of sting, but they ultimately added extensions this where you can actually create a directory entry and then say because we're using an extension, there'll be another extension the directory entry would attain an actual one longer name for the file, and then what they would do is the name here will be the first six characters that name followed by a tilde key, and then a number, a tilde character, and a number. maybe you've seen that. i do n't know if you if you do n't file listing on windows you can still get it show the shorter name profile, but that was used be the way it had be. anyway so. that's a directory entry and then here is the fat. so once we know the starting cluster for a file, we can then go the fat is just, you know, array of clusters indicate the next clusters in that file. so here's an example. the first two clusters in fact are reserved. thanks. just the way it is. and so there's special values that are in there. they indicate that they're reserved. after that we have cluster, so here's cluster zero cluster 123 and four. if we're using two blocks per cluster, we have two of them. thank you. file search 234 and so on."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","so once we know the starting cluster for a file, we can then go the fat is just, you know, array of clusters indicate the next clusters in that file. so here's an example. the first two clusters in fact are reserved. thanks. just the way it is. and so there's special values that are in there. they indicate that they're reserved. after that we have cluster, so here's cluster zero cluster 123 and four. if we're using two blocks per cluster, we have two of them. thank you. file search 234 and so on. now is where we get what this fat number means. fat 16 fat 12 fat 32. when the number indicates is how big a cluster number can be. so in that 16a cluster number is 16 bits in fat 32a cluster number is 32 bits in fat 12a cluster number is 12 bits. weird. they cram 2 clusters. it's like it's 3 nibbles, right? member a nibble being 4 bits. it's so you've got one cluster number that's spans. this weird bite? yeah, this was used for the old 300 quarter inch floppy drives. they were all. they were hard plastic coated drives and stick. they used fat 12 anyway, so this is pat succeed. so this demo is showing 16 bit wide cluster numbers right? so determine the byte offset inside the file for the data, i take the cluster number, multiply by the number of sectors per cluster, multiply that by the sector size, and then i can get the byte offset into the file and sense. ok, so for the one file here invite a file that began on sector on cluster 6 number big endian. this is not 600, it's 0006. it says that the next cluster here they cost search that cluster the next cluster is 6. so i go over the cluster 623456. this says the next buster is 7. that's the next one. this is the next cluster is 8. this is the next cluster is 9. this is the next cluster is 14 is accidental 16 + 4 is 20. so that's 01234567891011121314151617181920 and i see ffff, means this is the last cluster in that file. no worries. i can change allocation, there should be arrows that are all jumping around for that file, but the chain is stored in one place. the data blocks itself are stored in the data section, but the chaining is stored in the file allocation table. questions. ok."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","this is the next cluster is 8. this is the next cluster is 9. this is the next cluster is 14 is accidental 16 + 4 is 20. so that's 01234567891011121314151617181920 and i see ffff, means this is the last cluster in that file. no worries. i can change allocation, there should be arrows that are all jumping around for that file, but the chain is stored in one place. the data blocks itself are stored in the data section, but the chaining is stored in the file allocation table. questions. ok. next piece, once i scan the fat and i can get the blocks for a data, the data blocks for a file a file if you remember. might be. me. a directory. so in that case the data bits, the data bits, the data bytes for that file are actually a series of directory entries. we have one special directory called the root directory, always appears after the fact. after that, if we have subdirectories written inside there, we have read the data blocks for that file and get the directory entries from there. then we can get starting cluster for each of the files with. inside that directory, go back the one fat find where the data blocks are for those files. so again, we see in this case some indication of. of chained allocation. but we have one file allocation table, but we also then have separated out directories indicate where go in that file allocation table start. so what do i have now for you in the last four minutes? we're probably not going finish it. i posted this in canvas as well. i made a fat 16 file system called my file dot fs. i think i called it about either way. ok, it's a fat 16 binary file. there's a command in linux called hexdump, where if you dump this file out, he gives you an output like this. this shows you in hexadecimal the byte offset into that file, and if there's an asterisk, it says that this is zero. line is repeated down this location in the file and the challenges. now this is only for studying. this is not for. this is the study material. this is not for an assignment. for extra credit or anything, what are all the files in this file system and what are contents? and actually you could do the whole thing right from here because this file is not all this file system is not all that big."
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","this shows you in hexadecimal the byte offset into that file, and if there's an asterisk, it says that this is zero. line is repeated down this location in the file and the challenges. now this is only for studying. this is not for. this is the study material. this is not for an assignment. for extra credit or anything, what are all the files in this file system and what are contents? and actually you could do the whole thing right from here because this file is not all this file system is not all that big. and so, knowing what we know, we know that the first sector of 512 bytes is the boot sector. that's special reserve section that goes all the way down 200 is the next one. after that is the facts. hey, look at that. we've got the two reserved blocks and then we've got a bunch of other entries in our 16 bit 16 file allocation table. after the fact comes the root directory. the root directory consists of directory entries that are all 32 bytes long. so here's a directory entry. here's a directory entry we can look at the directory entry and see that the first byte first eight bytes is the directory entry on the file. so i've got a file called test dot extension txt. after that is a hex 20 are property bits. this is an archive file i just happen know what that file is, meaning it's just a regular file. it's not a directory and then we go down and we find that it's starting cluster after all the other reserved. these two values are the date and time of last modification. we say that this block this file starts at cluster not 300 but 0003. from there, we got the file allocation table and find austera 0123 ah, that's the last block in the cluster. so this file only is in cluster 3. and so then from there i can do the math and say this is on cluster three there are two sectors for cluster there's 512 bytes in a cluster. in a sector, we do the math. multiply everything up by three and then offset from the start of the data section, is after the root directory starts here, and we multiply it out it by word for it that this comes down this location right here and here is the data block for that file, consists of the string hello world. so can you do it for the other files?"
"""OpSys_Beyond_Data_Allocation_and_Performance_Transcript.txt""","and so then from there i can do the math and say this is on cluster three there are two sectors for cluster there's 512 bytes in a cluster. in a sector, we do the math. multiply everything up by three and then offset from the start of the data section, is after the root directory starts here, and we multiply it out it by word for it that this comes down this location right here and here is the data block for that file, consists of the string hello world. so can you do it for the other files? the other files inside the root directory is this guy called document extension is just blank, but we have a different property set this property. actually, i'll tell you indicates that this is a directory, so the data block starts at cluster four is down here of seven mile. that indicates additional directory entries. ok, so i'm out of time. do n't. so here's a challenge. see if you can and can finish this off. carson out and find the file. is this something you're gon na have do on the exam? good question. so let me stop recording here. short answer is no, i'm not gon na ask you interpret this on here, but i do want you practice and know what a file allocation table is in reference fat. the fat file system and how that works, so this is just a good practice. lembke, james stopped transcription"
"""OpSys_C_Programming_Transcript.txt""","meeting in _ general_-20240125_130300 - meeting recording january 25, 2024, 7:03pm 47 m 53s lembke, james started transcription lembke, james 0:11 hello. good. alright, so reiterate the announcement. no, no quiz tomorrow, so do n't worry about that. no quiz this week. and i'll spend 2. the project wl setup is due friday by midnight are well midnight. tomorrow is going be saturday, so you do n't get the idea. let's do friday. so that's in there. the other announcement that i have is this. i updated my schedule. i had a meeting schedule during. what am i posted student hours and so i moved some stuff around. this is a recurring meeting. it actually happens every week, so i wanted post that there i'm i'm looking. actually, i'm gon na look at my schedule and look, talk my family figure out when they want me home for, for the various things i might try and squeeze in an add another student. now, or maybe later in the day or sometime maybe on wednesday or something. but for now this will be my schedule as it stands. that being said, if you do wanna see me outside of when i'm scheduled here, just just let me know. send me an appointment. send me an email. send me a teams message and i'll make sure that i'm in my office, so that is the other announcement is that this meeting was put here. i let's see other things. no, that's no no other announcements that i need so. what we doing? we've been talking about os motivation, what operating systems are going do for us hopefully, and computer organization kind of using this lens of history figure out why computers are put together the way that they are currently. and we kind of have this situation where we have all these this hardware, these peripherals that need get hooked together. this idea of an instruction stream where the cpu does not exactly know what it's doing, it knows that it's executing instructions, but it does n't necessarily know what process they're for, cause the operating system might be doing some sort of round robin scheduling, we'll get, and we talk about scheduling. it knows just the one thing it's doing that one instruction that is executing and again if it's doing some prefetching or speculation, it might try and do other stuff. but in short, it just knows what it currently is executing in terms of an instruction."
"""OpSys_C_Programming_Transcript.txt""","this idea of an instruction stream where the cpu does not exactly know what it's doing, it knows that it's executing instructions, but it does n't necessarily know what process they're for, cause the operating system might be doing some sort of round robin scheduling, we'll get, and we talk about scheduling. it knows just the one thing it's doing that one instruction that is executing and again if it's doing some prefetching or speculation, it might try and do other stuff. but in short, it just knows what it currently is executing in terms of an instruction. as far as an ad, a load or a store, something like that and the idea that the next instruction, whether it's for a process or a program, whether it's chrome or part of the operating system, the cpu has no idea. one of the other it is just doing what it's told. ok, so from there i want talk about c and get into some sea type stuff. so you're working on setting up your windows subsystem for linux, or you're gon na be programming and see for those of you that like see, great. for those of you do n't like see, hopefully you'll be learning tolerate it, but that's what i mean. hopefully expecting you use in this class, not c++, not python, so we're gon na be using c so with that what i wanna start with, i got a bunch of notes out here that i kind of put together. this is not a powerpoint presentation. they're not super duper detailed, but it does kind of have a laundry list of things that i just kind of kind of have available for you. for reference, i'm gon na try and go through these for the most part, and i might refer back them just in case i forget about one important thing i wanna talk about, but the kind of categorized by kind of grouping of common topics. so that's there. so today we're gon na talk about variables and functions and multiple files. something open that up. oh, actually i had it open it up. but anyway, so in here you'll see here is just sort of bullet list of various notes for things with that also in canvas. i've got 2 links some external websites i find are pretty awesome. the first one is c.com is cplusplus.com, not the actual character plus sign. and while this is sort of a a documented station library for c, that's it."
"""OpSys_C_Programming_Transcript.txt""","so today we're gon na talk about variables and functions and multiple files. something open that up. oh, actually i had it open it up. but anyway, so in here you'll see here is just sort of bullet list of various notes for things with that also in canvas. i've got 2 links some external websites i find are pretty awesome. the first one is c.com is cplusplus.com, not the actual character plus sign. and while this is sort of a a documented station library for c, that's it. all flows are fairly good sea library set documentation. so umm, i see. well, let's just jump sideways here. python, java and a lot of other programming languages have sort of a library of common functions that are provided common functions for things that people would like do. often java is is huge pythons is pretty big. sees is also there. it's not nearly as big as java. c has one as well, but we're doing functions like getting user input, formatting, output, doing math functions. you can write your own sign and cosine function, but why reinvent the wheel? somebody said you know what, if you really cool, if we could just write this down and let everybody use it. so there is a standard library for c this shows the documentation for it and it tells you what header files and need include, and we're gon na come and work with some of these when we talk about various aspects of system calls, but for now, i just want mention that this reference exists. it's not as great as javadoc. i love javadoc. it is really good you write if you write good stuff for your, for your, for your explanation, but it is do a pretty good job at explaining stuff. the other one is. this reference tutorial i find it weird that they call it a reference. tutorial about tutorials point is is nice. i really like it. use it for a lot of stuff. it's not all inclusive as far as documentation of every aspect of c, but it does do a pretty good job at giving you a tutorial. so if you look at one of the examples that i did and you're confused with the statement or comment that i write and do n't want talk me, you can feel free add me explain it. but if you wanna go and work through this tutorial get additional practice that's there too, that's tutorial point and that is linked also in canvas as well."
"""OpSys_C_Programming_Transcript.txt""","it's not all inclusive as far as documentation of every aspect of c, but it does do a pretty good job at giving you a tutorial. so if you look at one of the examples that i did and you're confused with the statement or comment that i write and do n't want talk me, you can feel free add me explain it. but if you wanna go and work through this tutorial get additional practice that's there too, that's tutorial point and that is linked also in canvas as well. these two links here o all right. so that being said, see what is. see, i do n't talk about the history of c or why they call it c and as i think it's related at one time there was a language called a and then there was a language called b and then somebody said, well, why do n't we just use the next letter in line? i do n't know if that's true or not. i could look it up, but that's i'm not gon na ask you that. but anyway, see is what it is. it's a programming language that we're gon na use in this class. umm. and so the things that i wanted mention and i've already shown you see, we've already looked at that and i actually got rid of it in my example here. let me just get this is remember when i made this, i'll just make this new file add dot c. this is cfo and so see like java requires us declare variables and c++ the same way variables are strongly typed when from the point at they're declared until they fall out of scope, they maintain type. so a for its entire lifetime must contain an integer. it can be changed a different integer, but it must contain an integer. i ca n't assign 6.2 a. if i do, the compiler will most likely either give me a warning or it will just convert it automatically for me an integer. i ca n't remember if the if the compiler automatically does casting or not. i ca n't remember that i do n't do that because i'm afraid of what might happen, so i'm always very explicit. i encourage you do that as well so, but anyway we have types. we have variables. we have functions. we have structures. yeah, there's there's not really, be honest with you a whole lot else as far as he is concerned. in java we have classes. we have interfaces and see we have classes. we have templates."
"""OpSys_C_Programming_Transcript.txt""","i ca n't remember if the if the compiler automatically does casting or not. i ca n't remember that i do n't do that because i'm afraid of what might happen, so i'm always very explicit. i encourage you do that as well so, but anyway we have types. we have variables. we have functions. we have structures. yeah, there's there's not really, be honest with you a whole lot else as far as he is concerned. in java we have classes. we have interfaces and see we have classes. we have templates. we've got a lot of other stuff and c and in java, but in ci like think of c as we have data whether that be a variable or a structure or a type that you create. and we have functions that manipulate that data. that's it. we do n't have references. we will, but sort of a pain point for a lot of people when it comes see and also c++ a certain extent pointers. we have pointers. when we talk about pointers or review that we'll, i'll say that a pointer is just the number. so if you think about it in that way, hopefully it becomes a little bit less intimidating because a is a number, right, seemed pretty nice, pretty easy. a pointer is just a number. so alright, let's look at some other stuff that we have with c and then we'll do some other examples. so c variable types i mentioned we have types and we have variable types. we have in short long cart or char, float, double signed and unsigned. these are modifiers 2 variables. we also have we can have combinations of things. we can have a short int. we can have a long int. we can have a we can have a short chart. does n't make a whole difference. we can have an unsigned in. in java we do n't have unsigned types, so that is a little bit more unique see in c compared java we have scoping, we have global versus local in a way that's no different than java, although i do n't know. i think all variables in java need be inside of class. is n't that correct? uh, does n't matter. this is n't a java class. in c, you can declare variables outside of a class in global scope. scope variables are scoped with inside the scoping braces, right if statements for loops with inside of a function. wherever those scoping braces are used, a variable is scoped that."
"""OpSys_C_Programming_Transcript.txt""","in java we do n't have unsigned types, so that is a little bit more unique see in c compared java we have scoping, we have global versus local in a way that's no different than java, although i do n't know. i think all variables in java need be inside of class. is n't that correct? uh, does n't matter. this is n't a java class. in c, you can declare variables outside of a class in global scope. scope variables are scoped with inside the scoping braces, right if statements for loops with inside of a function. wherever those scoping braces are used, a variable is scoped that. so the question i have for you, something that is a gotcha in see, i do n't see plus plus in java if i just declare a variable into i semicolon and then i do a system dot print line i most likely what is the value that gets printed? what was that? i heard something, somebody says. what is this say zero? yeah, it's most likely zero. the jvm is kind of forgiving and it will initialize your variables something a known value. now for objects things like that, i guess objects are default initialized null until you create them with new, but it will be nice have some sort of a default value for these variables. in c, you guys cover that in your previous courses. what do you get if you just say in i semicolon and then in c++ you say. see out i. but it was there. yeah, it's weird answer, but it's true. you get whatever was there be like? well, what does that mean? whatever was there? well, we will. uh, if you look at if you remember the the the assembly language for this. i'm not going ask that you do this. is that the compiler here? is never as taking these literal constants literal values here and storing them in some location in memory. this is a a move or store instruction and if i did n't initialize ab, these two instructions would not be here and all it would have is the move something from memory into a register would represent that variable being loaded into the processor. this reads memory and so whatever gets stored in that register is whatever was in memory. here it was initialized 10100. if i did n't initialize them, i would n't get whatever memory cap and there's no code in here inside the execution. remember, this is being executed by the cpu. this is so speak something."
"""OpSys_C_Programming_Transcript.txt""","this is a a move or store instruction and if i did n't initialize ab, these two instructions would not be here and all it would have is the move something from memory into a register would represent that variable being loaded into the processor. this reads memory and so whatever gets stored in that register is whatever was in memory. here it was initialized 10100. if i did n't initialize them, i would n't get whatever memory cap and there's no code in here inside the execution. remember, this is being executed by the cpu. this is so speak something. we refer this as as on metal it's actually being run by the metal with silicone in the cpu and we can debate whether the silicone is the metal or not later on. but running in this on metal hardware and so there's nothing. that's no environment that's going initialize our variables. for us, our initialize our memory, so whatever memory happened have at that time, we'll be loaded. and so we get whatever. so be wary of that and be aware of the fact that when it comes variables, initialize the variables. please, because you never know what you're going get, chances are it might be 0 because when the system when your computer is turned off, all of memory is 0 and then when you turn it on it starts out from a known state is 0 known charge. ah but. yeah, things change as the the life cycle of of of the memory goes on and you get whatever you get. so alright, i do n't need debate that any longer. so what else do i want mention here about variables? i'm operators similar java. we've got arithmetic operators, unary operators for. that's actually it's hard read. canvas did n't really do a very good job with this, and that's actually a minus minus. it's just been format very well like canvas, so plus plus and minus minus. uh, that's for incrementing or decrementing a variable. i do n't have it on here. i probably should update that, but also plus equals and minus equals works inc for incrementing by more than one boolean operators we're doing if stuff or for if we're doing conditions for a while loop or for loops. bitwise operators. did you guys do bitwise stuff in cnc previously? than anybody ever done stuff with bitwise operators? you talk about the they exist and what they do. ok, a little bit."
"""OpSys_C_Programming_Transcript.txt""","uh, that's for incrementing or decrementing a variable. i do n't have it on here. i probably should update that, but also plus equals and minus equals works inc for incrementing by more than one boolean operators we're doing if stuff or for if we're doing conditions for a while loop or for loops. bitwise operators. did you guys do bitwise stuff in cnc previously? than anybody ever done stuff with bitwise operators? you talk about the they exist and what they do. ok, a little bit. so those all existence see, i guess i should say the other way wrong c came first. so they exist in c and java. java inherited essentially from c++. my favorite operator exists in ci. love that the ternary operator. lots of languages use that. do you guys learn the ternary operator? i love the ternary operator. it's essentially like doing 1 loves you do one line if statements. kind of in one line, is really cool if and else is shifts those also there. these are not like the shift that you would have for c out. these are actually like big wise ships where you're taking the binary and shifting it by various number of bits left and right. so that's more for i guess i got ta list that under a bitwise operator, but ultimately that's there literals similar java. i rarely use these. i've also what i'm referring a literal values. i've refer them in base 10 because that's how i count. i have 10 fingers. i have 10 toes, just that's the way i live. but you can specify literals and hexadecimal by specifying 0x in front of it. ah, the case of the of the letter does not matter. can be capital letter, lowercase. it's you are job. ok, control flow. if else do while all that stuff. if you look at the syntax of, see, it's going look identical what you might see in java. it wo n't look the same as you might see in python, cuz python's got white space for delimited limiting staff, but we use brackets just like in java. probably should mention that as well. arrays on and skip that first. second will come back that when i do an example switches and cases break and return. same thing. do n't forget, if you're going use a switch and a case statement, do n't forget your brakes cause things will fall through. unless that's really what you want and you want them fall through."
"""OpSys_C_Programming_Transcript.txt""","it wo n't look the same as you might see in python, cuz python's got white space for delimited limiting staff, but we use brackets just like in java. probably should mention that as well. arrays on and skip that first. second will come back that when i do an example switches and cases break and return. same thing. do n't forget, if you're going use a switch and a case statement, do n't forget your brakes cause things will fall through. unless that's really what you want and you want them fall through. but you do have use break get things jump and they jump out of the switch statement. return is all there. umm. i guess next should also be in here as well for the dual while and perform. i do n't know four loop in here so four loop should be in there. that's the thing, as angela do, while next is also there in sue. ok. still functions. see does not have classes. i mentioned that before, so we have data variables, structures we'll talk about. probably not today, but maybe, maybe tomorrow we'll see how far we get, but do we have data and we have functions that manipulate that data. that's it. and so functions are declared with return type and parameters. all the parameters must be typed because it's strong typing here and so we ca n't just use a whatever or type we auto policies you learn auto and c++, the auto type thing, ok, you ca n't do that in c you got ta do that. you got ta be clear on all of it. i do n't think so. i do n't think you can do it in see. i've never tried it, but i'm pretty sure that's a c++ thing. umm, if you if it does work more power you. but i do n't think we have that. so we have declare all of our functions at a variables with a strong worded type. let's see. no. ok, let's let's do that. we have a function that does n't return something. we declare it be void. let's see what else i want mention about. see. ah ok, java int lawn. java has a variable that's defined with inside. why? i think it's integer with capital i where you can specify where you can see the max and min value for an integer right? what is the maximum value you could store in an int in java? yeah, two billion 148,000,000 something."
"""OpSys_C_Programming_Transcript.txt""","ok, let's let's do that. we have a function that does n't return something. we declare it be void. let's see what else i want mention about. see. ah ok, java int lawn. java has a variable that's defined with inside. why? i think it's integer with capital i where you can specify where you can see the max and min value for an integer right? what is the maximum value you could store in an int in java? yeah, two billion 148,000,000 something. something something. yeah, sounds like that. but it's more or less plus or minus positive 2 billion and then the smallest number is about -, 2 billion, plus or minus one, and all the other stuff. but you get the idea, right? it's the closest power of two whatever the -, 2 the 32 minus something. right, it's about -. 2 billion, right. so this is a trick question. what is the maximum value you can store in an in in c? i'm glad i'm getting a bunch of blank looks because either you're bored of or you do n't know the answer, is totally understandable. and that's because i do n't either. the answer is we do n't know the answer by just saying what's the maximum of it. end we have ask for more information. the size of various variables is up the compiler decide how big they are. so if we declare something be an int, that tells the compiler i would like an int. it does not say i would like a four byte value. that is why the limits are in java, because java represents an int as4 bytes. so if you do the binary figure out how the maximum if everything was all ones versus all zeros, they get the maximum number. it ends up being why you end up with two billion or a java. you do n't have unsigned types, only have signed types, so that limits things because we have remove one bit because we have deal with the sign bit. but this is not a binary class. if you took a network protocols was not a requirement, but if you did under quarters, you probably got a little bit about number bases. but even there, we did n't really talk about representing negative numbers. so alas, here we are, but it has deal with how many bytes are allocated for that particular variable in java, in int is 4 bytes, a long is 8 bytes. so then you're range"
"""OpSys_C_Programming_Transcript.txt""","you do n't have unsigned types, only have signed types, so that limits things because we have remove one bit because we have deal with the sign bit. but this is not a binary class. if you took a network protocols was not a requirement, but if you did under quarters, you probably got a little bit about number bases. but even there, we did n't really talk about representing negative numbers. so alas, here we are, but it has deal with how many bytes are allocated for that particular variable in java, in int is 4 bytes, a long is 8 bytes. so then you're range and we can fit is bigger. a float is a four byte number, but it's used for units of precision. so what you can store in a float is slightly different than an integer. a double is 8 bytes in java and c it's up the compiler. uh, so notice and see, we do n't have a bite type. longer because it's something be aware of. most compilers will declare a character as one byte, because if you took network protocols, the ascii the representation of a character in us english, we can represent all of our characters in one byte, whether it be capital or lower case, and so on. but that's not necessarily a requirement. short answer is in order know how big a variable is, you have ask the compiler developer. ok. or you can look at the specification for gcc and it will tell you in. in our compiler gcc an int is will be 4 bytes, but we ca n't necessarily be sure of that if we're using a different architecture. that being said, if we want know how big a variable is, we can answer the compiler by using the size of the operator. so we can say the size of a, we can also say the size of int specify how big that is and it will return a number will be the number of bytes that variable or type contains. the minimum is 1 as far as i know, we ca n't have less than one byte being allocated by the compiler. that's a limit memory. memory has be accessed a byte at a time. i do n't think we have bit accessible memory anymore. maybe. and maybe we did it one time. ohh ok concerts anc we can make a constant in java. it's called final. we use final and cmos, plus we use consimilar inc we use cost. ok. questions."
"""OpSys_C_Programming_Transcript.txt""","so we can say the size of a, we can also say the size of int specify how big that is and it will return a number will be the number of bytes that variable or type contains. the minimum is 1 as far as i know, we ca n't have less than one byte being allocated by the compiler. that's a limit memory. memory has be accessed a byte at a time. i do n't think we have bit accessible memory anymore. maybe. and maybe we did it one time. ohh ok concerts anc we can make a constant in java. it's called final. we use final and cmos, plus we use consimilar inc we use cost. ok. questions. alright, so where am i at 124? let's look at some examples here. so this we got this. let's write some functions. so functions in c. in java you can declare your functions. as far as i remember, in your class in any order and the compiler figures it out in c variables, whether they be actual like variables with a type like this or a function need be declared before they're used. so you would n't do something like this. this would n't make a whole lot of sense. right. because the compiler is going from top bottom, this processor is going from top bottom, and if you look at that and you could say, well, i do n't know what a is. so if i try compile this compiler would say a is undeclared, right? i do n't know what a is. similarly, if i wrote a function. and i tried use it. let me actually fix this. put this back the way it was. good. when i try compile this i get. in this case i do n't get an error. i get a warning. it says implicit declaration of ad and online 4 is where this is saying line 4 column 12. that must be on while we're against it says i'm trying invoke a function that the compiler does not know about, and it's an implicit declaration because because this case, this implementation of gcc is smart that it's actually look ahead in this case. so it gives me a warning instead of an error an older versions of gcc and in some versions of a c compiler this will actually be an error and you wo n't actually be able compile your code. so this is saying, well, yeah, i i i do n't really know what ad is. so way fix this is."
"""OpSys_C_Programming_Transcript.txt""","i'm trying invoke a function that the compiler does not know about, and it's an implicit declaration because because this case, this implementation of gcc is smart that it's actually look ahead in this case. so it gives me a warning instead of an error an older versions of gcc and in some versions of a c compiler this will actually be an error and you wo n't actually be able compile your code. so this is saying, well, yeah, i i i do n't really know what ad is. so way fix this is. this declaring ad before it's used great. that's one way fix it, and i remember another way fix it. yeah, they're pretty decorations are proto declarations. yeah. so that word you could use that we call it a proto declaration, but that's exactly right. i like refer it as a forward declaration. i do n't know if that's necessarily the proper word, but i could do it this way if for some reason i wanted and sometimes i really like do this, i like put main front and center around the top of my files and everybody can see it. like, here's where the program entry procedure is all the other functions is gon na call or somewhere else, but so i'd like put me in a on the top if i wanted do that and avoid this warning i can. do something like this. declare my function without a body that tells the compiler that ad exists and that's gon na be its format, but it's actual implementation. it's definition has not been been defined yet, but that's its declaration. so i've declaring ad with the forward declaration, but i'm not the finding it until down here like a miller knows what it's types are here at defines what it does, and so now when i compile this, i wo n't get that error. ok, so you might now this is where you start. like, ok, throw tomatoes at me and say doctor lembke, you know, get off the stage. warnings are n't that bad. ok, this is not an error. the compiler did figure it out. it actually generated an executable and they that out, even though it gave me this warning. you have take my word for it because i fixed it and done different things. but ultimately this actually compiled, i would say be leery of warnings. leary, is that the right be worried about warnings? warnings are there for a reason."
"""OpSys_C_Programming_Transcript.txt""","like, ok, throw tomatoes at me and say doctor lembke, you know, get off the stage. warnings are n't that bad. ok, this is not an error. the compiler did figure it out. it actually generated an executable and they that out, even though it gave me this warning. you have take my word for it because i fixed it and done different things. but ultimately this actually compiled, i would say be leery of warnings. leary, is that the right be worried about warnings? warnings are there for a reason. they do n't necessarily indicate a problem with code, but they might actually be some something be considered a problem. i will say in this class i will show it in my lab descriptions that your code must compile without warning. so please make sure you you eliminate warnings because they really could be an indicator of a problem in your code. a situation where you might be indexing outside an array bounds or be missing a definition for something so, but make sure you get rid of your warnings. ok so. that's fine and dandy, and so you pay now the next question you would say is, wait, doctor. luke, you ok? that's fine that you can use forward declarations, but really what's kind? i'm writing a lot more code than i need so. what else might i want use a forward declaration for? right. this just kind of seems like a cheap reason and and be honest with you, if it is, it is kind of a cheap reason. umm, another use of a forward declaration is 4 while organization. ok, i like put functions grouped together and i would encourage you do the same thing. now, ultimately, it's gon na be your choice for how you program stuff, provided that you fit the style guidelines and everything like that and comment everything corrupt a correspondingly the style guidelines. but how you group and organize your code you can use. i do n't like using one file and i would encourage you use multiple files, but ultimately it's up you. so say for example, i'm writing a program that does some math. ok, i could put all of my math functions with main. but for code reuse purposes and just organizational, i kind of like the group things together. so for that what i might wanna do is separate things out in a multiple files. so i can do that in c in java you're more or less limited one class per file."
"""OpSys_C_Programming_Transcript.txt""","i do n't like using one file and i would encourage you use multiple files, but ultimately it's up you. so say for example, i'm writing a program that does some math. ok, i could put all of my math functions with main. but for code reuse purposes and just organizational, i kind of like the group things together. so for that what i might wanna do is separate things out in a multiple files. so i can do that in c in java you're more or less limited one class per file. i do n't know that you can put more than one class in a file, but again, this is n't a java class and i'm not done that. while i know you can do classes with inside of classes, so you can kind of get this idea of more than one class in one file but in see i do n't need put one function in each trial. i can group functions together. i like group them together in kind of by purpose. so safer i have for example i have my math file here and i'm going make him an add. i'll make a sub. ohh men. umm, so here's what i use the ok, i'll use the. alright, so here's our reason that ternary operator. so it says if a is less than b, return this value or assign this value what we what is returned. otherwise, use b and you might say what if a = b? well, then the men of a&b are that. that does n't matter. so that's like using that max is just the opposite. so ternary operator use it or not, it's up you. it does n't make a difference, but i i like use a lot, so here is that. alright, so now if i were. do this. i do n't need add it here anymore because i've got a do over here, but now if i was get rid of this here say well add and all the stuff for add is another file i do n't need need use any of this. if i try, maybe i should rename this then? call it mean if i try compile main dot c now i get an error saying i ca n't find ads and so where is at? well, it's in this other file. so i need declare what ad is for my function my my my code use it. so that's where i need a forward declaration. ok. and now we see another error."
"""OpSys_C_Programming_Transcript.txt""","i do n't need add it here anymore because i've got a do over here, but now if i was get rid of this here say well add and all the stuff for add is another file i do n't need need use any of this. if i try, maybe i should rename this then? call it mean if i try compile main dot c now i get an error saying i ca n't find ads and so where is at? well, it's in this other file. so i need declare what ad is for my function my my my code use it. so that's where i need a forward declaration. ok. and now we see another error. it looks a little bit different than the previous errors that i got before it's formatted slightly different. before it was saying like this in function was giving me a row and column and it's giving me this the the code that that had this the error or the syntax error. in this case, the warning down here i'm given an error that's from user bin ld and it's in function main. this weird text offset undefined reference add maybe say ok, have you experienced this before? may i ask you that you seen something like this before you? you have. ok, some people have others not. ok. the four stages of compilation. ok guys, remember these? what is the first one? you preprocessor. what's the second one completion? the compilation step. what's the third one assembly and what's the 4th 1 linker? great in the preprocessor stage, the output from the preprocessor stage is text text. it goes through all the preprocessor macros. we'll talk about that in a second. uh part 2 is the compile stage. it takes these high level statements and converts them into assembly language like the data s file assembly and the assembler takes the assembly language and converts it into the binary representation of whatever that might mean. remember in the processor, as much as we like call it a move or an add instruction, a processor does not interpret letters. it interprets umm binary data numbers and so that has be converted from the readable elise. debatable whether assembly is readable language into the binary, so that's what the assembler does line by line and then the linker says great. now that i've got this assembly language, i have find all of the external symbols. so in this particular case, i have an external symbol. yeah. why is it external? it's external because it's not in this file."
"""OpSys_C_Programming_Transcript.txt""","it takes these high level statements and converts them into assembly language like the data s file assembly and the assembler takes the assembly language and converts it into the binary representation of whatever that might mean. remember in the processor, as much as we like call it a move or an add instruction, a processor does not interpret letters. it interprets umm binary data numbers and so that has be converted from the readable elise. debatable whether assembly is readable language into the binary, so that's what the assembler does line by line and then the linker says great. now that i've got this assembly language, i have find all of the external symbols. so in this particular case, i have an external symbol. yeah. why is it external? it's external because it's not in this file. the output from the assembler is that binary data. it's some people call it object code. the object code for main here does n't have add in it, so the linker's gon na go and find it. and this is a linker error saying you know what user coder, whatever. i tried find ad but in any of the code that was compiled and assembled from main dot ci could n't find it. so i'm giving you an error saying you know what, you got ta go tell me where this ad thing is, because i have no idea. and that's true because ad does n't exist in the c file where is add. it's a math doczi. so in order have the linker flying add, i have find i have tell the compiler. also compile a dc. now it's not called adc, it's called math. there it is, and now it could find it. i got a fatal error no such direct file. yes, that's correct. so now when i compile these two files, when it's going do is gon na compile each individual file, assemble each individual file, give the object code for both of these files, and now the linker is gon na combine them together. and now when the linker needs search for add, it finds it because it has the object code for both files that it can group them together, generate the appropriate executable, in this case a dot out and it will work. ok, so why am i taking all this time say this is that this can be these errors come up, especially linker errors as like what happened they can be confusing. so or declarations. useful functions. useful multiple files can be useful for grouping things together."
"""OpSys_C_Programming_Transcript.txt""","so now when i compile these two files, when it's going do is gon na compile each individual file, assemble each individual file, give the object code for both of these files, and now the linker is gon na combine them together. and now when the linker needs search for add, it finds it because it has the object code for both files that it can group them together, generate the appropriate executable, in this case a dot out and it will work. ok, so why am i taking all this time say this is that this can be these errors come up, especially linker errors as like what happened they can be confusing. so or declarations. useful functions. useful multiple files can be useful for grouping things together. what's also kind of cool is i've i've got 10 different programs that all you need use the math stuff. i do n't need copy and paste my functions in all of those files, i can just use the math dot c in a whole bunch of different programs, so code reuse as well. great. that's the good thing about this. the downside here now is in every single file that i wanna use this add function i have i need forward declaration part. so i could copy and paste this every single file and music and i'd be kind of clergy because i do n't always remember. remember the proper format for that. so here is one other advantage of forward declarations, not advantage. other thing we can do is let's make a new file called math dot hi had her file and in there what i'm going do is include all of my forward declarations. in there. ok, now matt may have been main here. does not use anything other than sub or rather than other than add, but that's ok because a forward declaration just gets. get rid of his but not used. so instead of using. oopsies. hold on. stop. stop. i do n't know why that happened. my 4 declaration as i defined here. what i wanna do is essentially take the contents of mathe and jam it right here. so i could do that with a preprocessor statement called include math dot h. so now i do n't have worry about knowing what the foreign declaration is for add or subtract or whatever."
"""OpSys_C_Programming_Transcript.txt""","does not use anything other than sub or rather than other than add, but that's ok because a forward declaration just gets. get rid of his but not used. so instead of using. oopsies. hold on. stop. stop. i do n't know why that happened. my 4 declaration as i defined here. what i wanna do is essentially take the contents of mathe and jam it right here. so i could do that with a preprocessor statement called include math dot h. so now i do n't have worry about knowing what the foreign declaration is for add or subtract or whatever. i just include that the compiler, actually the preprocessor is gon na bind map dot h, grab the text verbatim, janet right there after the preprocessor stage stage, and then compile like code and all the forward declarations will be there whether i'm using the function or not. and that's kind of nice because now if i change anything, i just change my header file and my math dot ci probably have change all the users of it. but anyway, it makes it a little bit easier than having rewrite and change all of my forward declarations every way. ok, so what does this look like? this is where i think it's pretty cool that we can output stuff and stop the compiler in various stages. i can do a gcc dash capital e main dot c and i can see. sure enough, this is the text output from the three processor. all of these found symbols are such a like comments. we do n't need them. we can ignore them and we see that the include of math dot h gets jammed right here in plain text. and then here's the rest of maine. so while i wrote that this is the code that's actually sent the compiler. ok. ok, so kind of cool header files. please use them please. i i i use them way more than i than than i than i probably should anyway so. gotcha. what did i just do? i'm including math inside main dot c and i'm including math dot h inside math dot h. yeah. is that good? what's going happen? let's take a look. if we look at running the preprocessor, we see. well, i kind of have a recursive include, because what's gon na happen here is. the preprocessor is going run."
"""OpSys_C_Programming_Transcript.txt""","please use them please. i i i use them way more than i than than i than i probably should anyway so. gotcha. what did i just do? i'm including math inside main dot c and i'm including math dot h inside math dot h. yeah. is that good? what's going happen? let's take a look. if we look at running the preprocessor, we see. well, i kind of have a recursive include, because what's gon na happen here is. the preprocessor is going run. it's gon na say ohh the user wants include math dot h and it's gon na find math dot h take the contents of this verbatim, jam it inside main dot c here and then it's gon na run the preprocessor. that's gon na run. it's gon na see map dot h it's gon na go out and find math dot h, grab the contents of it, jam it right where that was previously, and run the preprocessor again. and nauseum. if i try run this and just run the general compiler here, it's gon na ultimately get me an error saying i have more than 200 recursive includes of a single header file. those are great. so the solution is just do n't do that right? it hurts when i do that. well, then do n't do that. right. ok, sometimes this ca n't be avoided. it's kind of a long story. i do n't really have time explain why that could happen, but it's onions. it really ca n't be avoided. so the solution for this for a solution for this is use what's referred as include guards. so what i did was. i essentially attached a preprocessor if statement this include file. this header file and it's gon na say if a magical barrier would not magical. that's other. do n't magic here. if a variable called mathf in the preprocessor scope is defined, skip over everything down. this end, if if it's not, continue on. so the very first time math dot h is included by the preprocessor, it's gon na run and math underscore h is not defined."
"""OpSys_C_Programming_Transcript.txt""","so the solution for this for a solution for this is use what's referred as include guards. so what i did was. i essentially attached a preprocessor if statement this include file. this header file and it's gon na say if a magical barrier would not magical. that's other. do n't magic here. if a variable called mathf in the preprocessor scope is defined, skip over everything down. this end, if if it's not, continue on. so the very first time math dot h is included by the preprocessor, it's gon na run and math underscore h is not defined. then it's going go line too, and it's going define a variable inside the preprocessor space that says map underscore h is defined and then it will go down and continue and that i will include bath outage again, will go and grab math dot h as a text file and it will read it and the very first thing in there is that if statement say if math underscore h is not defined. but guess what? it is now and so it skips over. that essentially gets rid of the inclusion of this stuff in here, and then it will continue on. so we will only get math under mathe included. once. one thing that's important note is if you chew when you choose your names for your include guards, make sure that you unique that header file and not used elsewhere. otherwise you could have unexpected behavior. questions. yes, it's actively make them very well anything. yes, you can use whatever you want there. i often like just use the name of the header file just because it's easy for me remember, but you can use whatever you want. some people like start with underscore. yeah, it is what it is, so. all right, i'm going actually fix this make it not like that. good. that's still works ok. couple of other things about this or we run out of time, yeah. i'm including a header file. my header file consists of forward declarations for functions that are in my source file, right? people asked this question a lot. unfortunately, most of the time i give them a lame answer because my examples are usually small and the answer when i show it them is like yeah, but that's not a problem. and i say yes, it's true. if include is, no matter is no magic the include, there's no magic header files."
"""OpSys_C_Programming_Transcript.txt""","couple of other things about this or we run out of time, yeah. i'm including a header file. my header file consists of forward declarations for functions that are in my source file, right? people asked this question a lot. unfortunately, most of the time i give them a lame answer because my examples are usually small and the answer when i show it them is like yeah, but that's not a problem. and i say yes, it's true. if include is, no matter is no magic the include, there's no magic header files. i like argue with people say ohh on windows, so i'll say no. on docx, that's a microsoft word file. it needs be opened by microsoft word. it ca n't be opened by anything else. i'm like it's it's just a fire. it can be opened by notepad++. i can open a docx in chrome, i can open up a docx in many other different applications. they might not be interpreted well levels applications, but it's just a file for those that have gotten far enough in the windows subsystem for linux project. i asked you like research the fundamental files on a linux system. i do n't say that text files are different than word documents are different than executables. those are all regular files, and so similarly with the preprocessor. when i say include math dot h, there's no magic a header file. there's nothing say that, that that i can limit that so i can go in here and say include math dot c and what that's going do is the preprocessor is going go out. it's gon na find math dot c and jam it right there, right. and so as a result, when i when i run the preprocessor here. we see that the output consists of the implementation of all of the functions that were in that dot c along with my code, right? that works and looks ok, and make matters worse or better, how are you gon na say it? a full compile works. it finds all the symbols it found. found add right and so you look at that and say, well, ca n't i just include all my c files altogether in one thing and then just have it work? and unfortunately, for what it's worth, the answer here is yes, it works. i do n't want you do that, though. and now then this is where i have only a lame answer."
"""OpSys_C_Programming_Transcript.txt""","we see that the output consists of the implementation of all of the functions that were in that dot c along with my code, right? that works and looks ok, and make matters worse or better, how are you gon na say it? a full compile works. it finds all the symbols it found. found add right and so you look at that and say, well, ca n't i just include all my c files altogether in one thing and then just have it work? and unfortunately, for what it's worth, the answer here is yes, it works. i do n't want you do that, though. and now then this is where i have only a lame answer. if people say, well, why doctor like you, why ca n't i? why are you only letting me include header files? does anyone know of a good answer for why i do n't want you include source files? yeah, if you're duplicating a lot of the code, so it's just that makes the entire than binary blowing. ok, that's a big one. and that's the answer that i often will give, except in this example you'd be like. well, there's not a whole lot of code here, and i'm like, yeah. ok. right. sure. so the answer was given here was say that if i include all of my source files in all of my other source files, then i could have a very large bloated. program the other. the answer here is by including just code. if i do n't include things in the proper order, i might have forward declaration or symbol problems where it's not able find certain symbols. in this case, i included the sort of the client files, the files that i'm using first before the actual. i guess the the holster though the actual implementation before the code that uses it, right? but i could include things that a different order and then cause dependence problems. so by only using forward declarations that kind of organizes our code better and only including header files. it just seems better for organization and is less prone for errors. you have take my word for it. ok. so for this class, i will say that in the lab descriptions, but i will also say it now do not include anything other than header files do not include source files."
"""OpSys_C_Programming_Transcript.txt""","i guess the the holster though the actual implementation before the code that uses it, right? but i could include things that a different order and then cause dependence problems. so by only using forward declarations that kind of organizes our code better and only including header files. it just seems better for organization and is less prone for errors. you have take my word for it. ok. so for this class, i will say that in the lab descriptions, but i will also say it now do not include anything other than header files do not include source files. if you want do something where you're using multiple files, include the header file, and when you're actually compiling the file, specify in multiple files on the compiler command line. ok, i got one minute left. make sure you see. if i did n't think of forget anything else we talked about compilation. we talked about multiple files, alright, library functions. ok. we're not gon na talk about a whole lot of the library functions, especially not in the next 30 seconds, but one thing i do want mention here is when it comes library functions like std io dot h, you'll notice that in here it says that they're called that and then they use these like braces like this. these less than greater than around the file. when it comes system library functions, we will need use this this style of including. so later on we talk about printf. we will need include std io h like this. what this tells the compiler do is if you notice over here on the left side, math thought each is right there, the compiler knows where find it. so by using quotes that says just look locally for that file. here you want the compiler search the entire system library path where all the system library header files are. you use these less type greater than braces. there's actually a command you can write will show you where the compiler is searching for better files. does n't searching for stuff and if you use the last night greater than it will search all the system paths. if you use folks, it will just use the local path, so that's it. sorry, i went over time, so we'll stop there. we'll continue with this. tomorrow, tomorrow's friday. so have a good night. we'll see tomorrow. lembke, james stopped transcription"
"""Opsys_Condition_Variables_Transcript.txt""","meeting in _ general_-20240328_130424 - meeting recording march 28, 2024, 6:04pm 43 m 43s lembke, james started transcription lembke, james 0:06 the little hello. ok. so operating systems welcome isolation and protection. abstractions are cool. ah, so what are we doing this week? we are doing see monday. if you remember all the way back monday, we talked about producer and consumer, i kind of feel like it is, at least in my opinion, a good sort of encapsulation of ways that we can use a lot of these mutual exclusion mechanisms, some of ours and mutexes and condition variables. so we talked about that and. some examples on how you can use the different mutual exclusion mechanisms for producer and consumer. we do have a quiz on friday after using concurrency, so essentially everything up well starting in our thread topic up until really producer and consumer type stuff. so what are we doing today? today we're doing deadlock, so that's the topic for this, so let's just dive into deadlock and we'll see how far we get if we finish well, we'll be done with deadlock. if we do n't finish well, we'll continue tomorrow. uh, so? deadline. what is deadlock? there's a member of like. what? what is that we we talked a little bit about what that means. yeah. ohh, that's one like. i'm not gon na some more more prevents the code from actually proceeding forward, either from preventing it from blocking or preventing it from ever unlocked. ok, so one answer and i'm gon na try repeat it and maybe do my best not twist your words, but it's a situation in execution ca n't proceed because of somebody or somebody, a process or a thread or multiple processes or threads holding on resources. ok. and in a way that's right in the previous notes i talked about deadlock being this aggressive holding of resources, right and aggressive is kind of maybe more of an emotional word. like what does aggression mean in in terms of a process? i mean, processes do n't have feelings, they're not angry, they're not aggressive. they just, in a way, it's holding of a resource that you're not going give up, right? so yeah, i like that definition. other thoughts on deadlock? now i think that's pretty good now where this is a topic on deadlock. so not livelock."
"""Opsys_Condition_Variables_Transcript.txt""","and in a way that's right in the previous notes i talked about deadlock being this aggressive holding of resources, right and aggressive is kind of maybe more of an emotional word. like what does aggression mean in in terms of a process? i mean, processes do n't have feelings, they're not angry, they're not aggressive. they just, in a way, it's holding of a resource that you're not going give up, right? so yeah, i like that definition. other thoughts on deadlock? now i think that's pretty good now where this is a topic on deadlock. so not livelock. livelock is sort of not the opposite, because the opposite of deadlock is not deadlock, is this systems running livelock is another situation we're not getting any work done, but the appearance makes it look like we're getting something done because we're constantly in a way you would say it's like an aggressive releasing of resources. i do n't really know. that's really the right way of saying it, but or the passive holding of resources, it's no, i do n't want it. you take it and we're kind of like playing hot potato, where we're passing things back and forth where nobody seems want the resource. but as a result, we spend all of our time passing this resource back and forth and it looks like we're doing a lot of work right as far as, like i'm asking the resource back and forth, we're getting a workout, moving things back and forth, but we're not actually doing useful work now. you might argue that passing a resource back and forth might be useful work if you're playing the actual game of hot potato, but in the world of actually like computing some mathematical thing or playing a game or doing something, yeah, passing a resource back and forth is not really all that useful. so for this topic is on deadlock. so what do i mean by that? and we kind of already talked about that is so for this discussion. i wanna be a little bit more general. ok."
"""Opsys_Condition_Variables_Transcript.txt""","you might argue that passing a resource back and forth might be useful work if you're playing the actual game of hot potato, but in the world of actually like computing some mathematical thing or playing a game or doing something, yeah, passing a resource back and forth is not really all that useful. so for this topic is on deadlock. so what do i mean by that? and we kind of already talked about that is so for this discussion. i wanna be a little bit more general. ok. and in the deadlock examples that you may have run into with flagger ahead or in the examples that i gave with yeah in the in the previous examples using mutex locks, there were specific pthreads, but in this particular case i wanna be a little bit more generic in can explaining deadlock maybe more hand wavy just in terms of resources in general? later on, we'll talk about how we can do that in a pthread context or a posix context, but i'd like start more generic and then go more specific. so here is my thought. ok, we have lots of resources on the system. we have memory here cpu we have io. we have files you can probably come up with a whole bunch of other different resources in our computer. we have our monitor, might be a resource speakers, so on, ok, we've got stuff, right and we have processes, threads, whatever you want refer them as when it comes deadlock. yeah, it's 601 and we have resources that may need be used mutually mutually exclusive in that we might have a situation where one thread needs have control over one of these resources. when it comes something like cpu, ok, yes, only one process can be executing on the cpu out of time. so the way it would kind of consider it a lock, but again we've got resources, memory, things like that, and we have mechanisms, some of ours, mutexes, condition variables. there are others, but these are we talked about that allow us lack out resources. ok, so. deadlock. here is the outside. we're gon na talk, general. now going the posix. ok, but this is just an example here. i'm a situation where we might run into deadlock, right? and i say that specifically might run into deadlock because when it comes deadlock, we'll talk about some mechanisms for trying prevent or avoid deadlock. and might is a big thing."
"""Opsys_Condition_Variables_Transcript.txt""","so the way it would kind of consider it a lock, but again we've got resources, memory, things like that, and we have mechanisms, some of ours, mutexes, condition variables. there are others, but these are we talked about that allow us lack out resources. ok, so. deadlock. here is the outside. we're gon na talk, general. now going the posix. ok, but this is just an example here. i'm a situation where we might run into deadlock, right? and i say that specifically might run into deadlock because when it comes deadlock, we'll talk about some mechanisms for trying prevent or avoid deadlock. and might is a big thing. is it guaranteed that we will get into deadlock in this particular situation, right? say for example i've got one thread executing thread one routine and another thread executing thread two routine. if the operating system says i am going schedule thread bound run first and this thread for whatever reason because it's got a high cpu time quantum run its its work, it could achieve and receive a lock on you, unlock one, grab a lock, unlock two, then do some more work, unlock it, unlock two and unlock one and return right. you could unlock these in any order i for whatever reason, just the way my brain works like think about unlocking something in the reverse order in i locked them, but ultimately you get the idea here. hopefully that if this thread were run and do work in between doing these locks and actually completion would be fine. so by executed thread one completion and then executed thread 2 completion, no deadline. anyone have any questions or thoughts about that? ok. but that being said, i have no control about limited control over when the operating system is going decide who run when. so it could say thread one you get run and right here in this comment while it's doing some work, the operating system might say thread one, you're you hide your turn and the cpu, it's now somebody else's turn and it says right you, it's your turn, right. you're gon na run. it's gon na lock. run two and then it's gon na wait and then the operating system will say ok, right? two, you've had your turn. now it's thread one's turn. thread one tries go down here and lock mutex lock two and what happens? who's got the lock on lock 2? the thread too, right?"
"""Opsys_Condition_Variables_Transcript.txt""","so it could say thread one you get run and right here in this comment while it's doing some work, the operating system might say thread one, you're you hide your turn and the cpu, it's now somebody else's turn and it says right you, it's your turn, right. you're gon na run. it's gon na lock. run two and then it's gon na wait and then the operating system will say ok, right? two, you've had your turn. now it's thread one's turn. thread one tries go down here and lock mutex lock two and what happens? who's got the lock on lock 2? the thread too, right? right it, right. we've got ownership right with locks. we know who owns it, so the operating system says i'm sorry, thread one, thread two is got that locked. so you need block on this mutex locks waiting queue. you're stuck, right? two then, is the only one essentially, in this particular case, eligible run. because this guy's blocked. it's very two your turn and it says alright. i would like lock lock one and at that point the operating system says ok. sorry, right, one has n't. so you are going get put on the waiting queue for lock one and the operating system says who else gets run? well, fred, one is law is stuck waiting on lock 2. red two is stuck waiting on lock one and we're not going proceed any further. and this is that ok, right. how else can we get deadlock? i would say that this is a specific instance of a resource, right? we have a lock. a lock is a resource. what does that lock referring? you know, it might be a lock where we need lock something out before we access some line of code access a global variable. the mutex lock itself does n't indicate what resource we're utilizing, it's just a lock and lock. something else, right? it's up us as programmers figure out what the lines of code are that are going be in this dual work section. but the unique thing about a lock and maybe not unique, but the one property about a lock is that it's on or off. there's only one it's either open or closed. it's either locked or unlocked."
"""Opsys_Condition_Variables_Transcript.txt""","you know, it might be a lock where we need lock something out before we access some line of code access a global variable. the mutex lock itself does n't indicate what resource we're utilizing, it's just a lock and lock. something else, right? it's up us as programmers figure out what the lines of code are that are going be in this dual work section. but the unique thing about a lock and maybe not unique, but the one property about a lock is that it's on or off. there's only one it's either open or closed. it's either locked or unlocked. we have one instance, so speak, of that lock, so only one thread can control it, but we could run into deadlock for other reasons. and this is where we get a little bit more generic. ok, so this is important when it comes deadlock. and so right now it might not seem all that important. why i'm spending so much time on it. but later on we get deadlock avoidance. this becomes more important. we could run into deadlock when we have multiple instances of a resource. so in this particular case, say we have 200 resources up something, and independently a thread might request resources and so a caveat here is this request function would say i'm gon na allocate so many resources this thread out of how many i have, and if i do n't have enough, you have wait until there is enough, right? so in this case same idea. thread one executes completely completion. it can request any resources request 60. at that point, we went from 200 120. then we went down into the math, right, 60 resources left. then we weighed. then we release all of our resources. we're back up 200 and we, richard, right? this guy requests 70 resources. if there was 200, that would leave us with 130 resources. we request the more that leaves us with 50 and then it's going be some more work. release some all we're back up 200 and learning winter, right? but we have no control over when the context switch is happening or limited control like keep saying that we could have a context switch. in fact, inside this do work section. so in that case, we're gon na request 80. we're left with 120, then thread 2 is gon na run. it's gon na requests 70 and we're left with 50 after that."
"""Opsys_Condition_Variables_Transcript.txt""","we request the more that leaves us with 50 and then it's going be some more work. release some all we're back up 200 and learning winter, right? but we have no control over when the context switch is happening or limited control like keep saying that we could have a context switch. in fact, inside this do work section. so in that case, we're gon na request 80. we're left with 120, then thread 2 is gon na run. it's gon na requests 70 and we're left with 50 after that. then thread one could run and it's gon na request 60 more at the operating system. says. i'm sorry, there's only 50 there. i'm not gon na like, give you as many as i have you requested. 60. i'm going wait until you have 60. it's gon na say wait. you're stuck. there's not gon na run, and it's gon na say i would like 80 more resources. the os says there's only 50 left. sorry, you have block and now we're in deadlock. ok, so this is another potential situation for deadlock, but we have multiple things, stances of a resource. ok, so questions hopefully. i mean, you would say, ok, well, is it more complicated than that? well, really it's not. they're like, is what it is. i will say yes and no. we'll get a situation where it is slightly more complicated, but it's more just a continuation of this over and over again, so refine. the definition of our discussion of deadlock, this idea of 1 process holding on something that another process needs right, you'd say, well, that's deadlock. the world of theorists and operating system world said. ok, we're gon na analyze deadlock, and if we're gon na come up with these four conditions take that situation where one process or thread is holding onto a resource that another process needs while that process holds is holding on a resource that the previous process needs. we're gon na analyze this and come up with the four conditions for deadlock. alright, and here's what they are. so mutual exclusion says there will be a situation or if what we can get it better. like if there is a situation where a process can hold a lock on something, a situation where only one process can run or one thread can run and mutual exclusion right hold and wait."
"""Opsys_Condition_Variables_Transcript.txt""","ok, we're gon na analyze deadlock, and if we're gon na come up with these four conditions take that situation where one process or thread is holding onto a resource that another process needs while that process holds is holding on a resource that the previous process needs. we're gon na analyze this and come up with the four conditions for deadlock. alright, and here's what they are. so mutual exclusion says there will be a situation or if what we can get it better. like if there is a situation where a process can hold a lock on something, a situation where only one process can run or one thread can run and mutual exclusion right hold and wait. this is another condition for deadlock, in a process may hold on a resource or a lock while waiting for something else. right? alright, let's condition for deadlock. no preemption. there's no way for a process that's holding on a lock get rid of it. this is been aggressive holding the only way for a process release a resource is if the process wants release the resource. there's no way gank it away from them. right. and then the last one is circular wave, where there exists a closed chain in one process is waiting for something from another process is waiting for something from another process and it loops back around the initial process. this circular weight is where deadlocking gets slightly more complicated because in my previous examples i only had two threads deadlock foot involve 3 threads, or five threads, or 100 threads or 5000 threads. however many we're allowed create if the first thread is waiting for second, something that the second thread needs was waiting for something in the third thread needs brings something the thread needs all the way back around was waiting for something that the first thread has. alright, i'll circle ok here. all four of these things are true. we are in denmark. person. yeah, the third iteration? yeah. when it's saying you forcefully removed is that by like another threads moving it or that thread like? well, if it's if. yeah, good question. so no preemption, so no resource can be forcefully removed, forcibly removed from the process holding it. it's the idea that if i have a resource and i give it up, that's not forcibly, that's i do n't want it anymore. so i am passively or being nice and saying you can have it. i'm done with this resource."
"""Opsys_Condition_Variables_Transcript.txt""","when it's saying you forcefully removed is that by like another threads moving it or that thread like? well, if it's if. yeah, good question. so no preemption, so no resource can be forcefully removed, forcibly removed from the process holding it. it's the idea that if i have a resource and i give it up, that's not forcibly, that's i do n't want it anymore. so i am passively or being nice and saying you can have it. i'm done with this resource. that's not a force a force would be someone saying, you know, i use that example of the ball on the playground, right? i'm playing with the basketball. if i want say ohh john, it's your turn and i've passed him the ball that's not forcibly being released. forcibly being released is. i'm playing with the basketball and and i've got john and sally and bill and and and alicia that all want use that basketball. and i'm like, nope. sorry guys, i'm gotten. i'm gon na sit there and keep playing with it. and finally, there's the teacher on the playground that says jim, you've had your time with the basketball. please give it alicia. that's forcibly giving it away. i get rid of it when i do n't want. that's one minute. so that no one like take it, nobody's taking from. that's it. no preemption. two question. other questions? yeah, you could still care about. akale system, so this is not specific extra. eventually, like interactive like instance or example of a particular operating system, this just says if we have all four of these, we can call ourselves in deadlock. what we do after that try and prove or try and get rid of deadline is a different thing, right? if you kill a process and all that process is resources are forcibly removed, you just and preemption right and so one of the things we'll talk about later on is if all four of these are true. we are in deadline. if any one of them is removed or turned off, we are not in lewander,. so if we wanna stop deadlock or prevent it from happening, all we have do is pick one of these four and prevent it from happening. and that's your example there, right? we can stop deadlock by hitting control c, killing the process that could cause other problems on our system, but it does essentially cause preemption."
"""Opsys_Condition_Variables_Transcript.txt""","if you kill a process and all that process is resources are forcibly removed, you just and preemption right and so one of the things we'll talk about later on is if all four of these are true. we are in deadline. if any one of them is removed or turned off, we are not in lewander,. so if we wanna stop deadlock or prevent it from happening, all we have do is pick one of these four and prevent it from happening. and that's your example there, right? we can stop deadlock by hitting control c, killing the process that could cause other problems on our system, but it does essentially cause preemption. other questions? ok, so let's go on here and let's talk about deadlock mitigation. so these are the four things that we'll talk about. it will take us the rest of the time that they most likely no. they'd like medication. starting engines. here's my question though, for you, before we talk about this is deadlock back, let's get into the philosophical world. let's put on our philosopher hat is deadlock van we says yes, that who says no. ok, why is deadlock back? ok, deadlock is bad because we're not getting any work done. i'm with you there. great. why is deadlock good? was that? it's not harming anything. ok? i like that. this is why it's a philosophical discussion. yeah. other than thoughts, kind of like. is it detectable? ok, that means it's in a way. is that means because it's good or not or not good, right? it's good that it's that it's good, it's good that it's bad, right? oh, it's so good, but it's bad, right? it's so bad that it's good. yeah, it's. that's why i say it's a philosophical thing because i agree with you. it's bad because we're not getting any work done. i would like get work done on my computer. i do n't want my computer sit there doing nothing. it's generating heat. someone might say that's good, but you know there's other ways for me generate heat. so in that case deadlock is bad, but you might say that deadlock is good because what's the alternative? we could crisis system. we could corrupt something, right? think about the race condition."
"""Opsys_Condition_Variables_Transcript.txt""","that's why i say it's a philosophical thing because i agree with you. it's bad because we're not getting any work done. i would like get work done on my computer. i do n't want my computer sit there doing nothing. it's generating heat. someone might say that's good, but you know there's other ways for me generate heat. so in that case deadlock is bad, but you might say that deadlock is good because what's the alternative? we could crisis system. we could corrupt something, right? think about the race condition. case right that example where i have multiple threads all trying access variables at the same time. if those global variables right where i got the wrong answer right represented something very critical, like maybe something in the medical field where it was applying something some treatment some person and it applied the wrong amount of some medicine. i would rather the system maybe just chooses not or maybe cause damage right in certain situations. choosing do nothing might be a better situation than allowing the system proceed if it's going cause damage the world. do n't. there's a bad is it good? well, it is what it is. that's my father - in - law would say so. that being said though, for each of these mitigation strategies, i wanna kind of keep in mind that philosophical idea, because it's not always good have deadlock. but it's also not always bad. ok, so deadlock detection. here's the next the the one that we're gon na talk about next, alright, or first you could say so for that. i want draw a picture. as i like draw pictures. deadlock detection. that's as detection below. so you ca n't read my writing, is probably a lot of you, because i ca n't even read my own writing. but anyway, alright? check notation. and this is where it's going be cool. alright, we have a process here, a process i'm going draw a circle and we have some resource. whether it be maybe a lock or a page in memory or an io device, it's something that we want allow have exclusive access. remember, cause mutual exclusion is a is a requirement for deadlock. ok. all right. so that's what those are my symbols. let's then talk about two things, a request and a cold. ok."
"""Opsys_Condition_Variables_Transcript.txt""","and this is where it's going be cool. alright, we have a process here, a process i'm going draw a circle and we have some resource. whether it be maybe a lock or a page in memory or an io device, it's something that we want allow have exclusive access. remember, cause mutual exclusion is a is a requirement for deadlock. ok. all right. so that's what those are my symbols. let's then talk about two things, a request and a cold. ok. if i have a process, in this case p here that wants a resource r, i'm gon na draw an arrow it that says process p would like have controlled access resource r and then hold. this is a square. i'll draw the arrow the other way. if a resource is currently held by a particular process, ok. so. if we look at this example and we say, alright, yeah, we know that there's a potential for deadlock here. let's assume that the red one is allowed execute and stops right here, right at this request of of mutex selective. but inside this comment thread 2 not run and it got it's locked unlocked two and then continue execute. so at this particular point, let's assume the execution is right here in this thread and right here in this thread and thread two has a lock unlock one and thread one is a lock on the. sorry, thread two is a lock. unlock two and three. one is a lock on lock one, so at that point what we have is. thread one, i'll call it t1. has a lock on lock 1l1, so it holds lock. once the arrow goes this way and gt2. holds a lock on l2. ok, that's that first part. and then right here thread one is requesting a lock unlock 1a lock two and thread two is requesting a lock unlock one. so that is thread one is requesting a lock unlock two. so request is an error going out of the process and thread two is requesting a lock unlock one. so we have an arrow going out of the process. right there is my notation of that situation, and we already previously discussed that we were in deadlock, right? so looking at this picture now, i got an arrows across. that's all you have just real on that. but there are actually touching each other and just thoughts in this picture. but my point that's over here with me. but what do we see about this particular?"
"""Opsys_Condition_Variables_Transcript.txt""","so request is an error going out of the process and thread two is requesting a lock unlock one. so we have an arrow going out of the process. right there is my notation of that situation, and we already previously discussed that we were in deadlock, right? so looking at this picture now, i got an arrows across. that's all you have just real on that. but there are actually touching each other and just thoughts in this picture. but my point that's over here with me. but what do we see about this particular? if you're calling a graph, that's happening. that you might indicate that we're debra. yeah. yeah, we have a loop. we have a circle now. it's not really a circle because, well, my my lines are curved, but we can start at any place in here and by following the arrows we can go this way. this way this way and we can get back where we started. if we were draw a situation or a state of the system like this, if we find a cycle, we know we're in. devon, this is deadlock detection. this graph is referred as a. resource allocation, graph allocation graph and the idea here is if i actually spell graph right is we could have our operating system keep track of everything that a process holds and everything that a process requests. and if at any time we have a cycle dating system, will know that we're in deadlock. it's pretty cool, is n't it? and so what's neat about that is if we go down here the resource allocation graph. if we have this situation in the state right, we're not a deadlock because here we have two processes that do n't request resource. we're not a deadlock because we know that only one of these processes are ever going obtain the resource, so maybe this guy later on will obtain it, but the era will go the other way. it will use the resource and then hopefully release it and then this guy can get it and then there will go the other way for them this error will be gone completely and we're allowed complete execution. the lowly we're not done like here, but here. this is like the example from earlier. we have a cycle, so we are in denmark. questions. thoughts. no. you can actually see this happening. uh. see somebody implementing this later on i will say when we talk about deadlock."
"""Opsys_Condition_Variables_Transcript.txt""","it will use the resource and then hopefully release it and then this guy can get it and then there will go the other way for them this error will be gone completely and we're allowed complete execution. the lowly we're not done like here, but here. this is like the example from earlier. we have a cycle, so we are in denmark. questions. thoughts. no. you can actually see this happening. uh. see somebody implementing this later on i will say when we talk about deadlock. ohh, sort of what is the word i use deadlock recovery that he threads actually could do this, but they do n't. uh, if you look at pthread lock for example, you could see a situation where if a process obtains a lock, you could actually in the operating system create a data structure for this graph. why would this be potentially problematic? how many processes do i have in my system? potentially a lot. how many locks might have processed might process create? potentially a lot. how many resources do i have? one for every lot. and so one of the things that is sort of something think about, you know, overhead like the overhead of creating a resource allocation graph can be pretty hot in terms of the amount of memory that we have. we have a large system with lots of losses and a lot of resources. ok, so that's something think about. literally talk about overhead too much in operating system. we just said in previous topics this is what the operating system does, but one of the goals of the operating system designer is keep overhead low. why? well, in a way, i paid good money for my memory on my cpu. i do n't want my operating system suck it off every single time a new version of windows comes out and the amount of storage i need for windows goes up by gigs. like i spend good money for this hard rock, i do n't wanna feel a lot with operating system stuff. i wanna play all the ring right and so something think about. keep overhead low. ok. other thoughts on deadlock detection? we'll come back it before the end of the day. good. deadlock prevention. ohh sorry, one more thing on resource allocation graphs that i want mention is if you look at literature outside of my notes and i've actually got it in here just make you aware of it is they will say right here. if there is a cycle, deadlock may exist when they when but, but it may not."
"""Opsys_Condition_Variables_Transcript.txt""","right and so something think about. keep overhead low. ok. other thoughts on deadlock detection? we'll come back it before the end of the day. good. deadlock prevention. ohh sorry, one more thing on resource allocation graphs that i want mention is if you look at literature outside of my notes and i've actually got it in here just make you aware of it is they will say right here. if there is a cycle, deadlock may exist when they when but, but it may not. we look at that and they'll say, wait, what deadlock may exist? what does that mean? well, the argument that's usually given for why it says it may exist but may not, is this where if we augment this picture put dots under it? because it what are the dots? make but that's indicate number of resources. if i have more than one instance of a resource, in this case i have a cycle, but it's not in deadlock because there result of having more than one instance of this resource. this resource might be held by p1p2, but then also requested by p1 and the operating system can grant that just grants that the other instance of the resource right. doctor luke's argument this is, is this really 2 instances of the same resource or is it too different resources? we could consider our resource category and say i want i have two instances of resource r1 for them make r1 dot one and r 1.2 and then they're just different resources. as a result, i've got 2 boxes here and then you do n't have a cycle. that's my argument, but i've mentioned it now because books and other, you know, stack overflow, whatever. like you mentioned, that was an idea, but in terms of the resource allocation graphs in general, if there is a cycle, there's most likely deadlock. if you only have 1 instance of each resource. alright, so let's go deadlock prevention. deadlock prevention takes the conditions for deadlock and attempts do the converse or contrapositive or whatever the logical term is. i ca n't remember what it is. it's sentence right conditions were deadlock. say if all four of these exist, or you could say we are in deadlock if and only if all four of these exist, right? that implication, or whatever i again, i ca n't remember a lot. that was discrete now, right? but you did that kind of stuff with the logic stuff. ok."
"""Opsys_Condition_Variables_Transcript.txt""","deadlock prevention takes the conditions for deadlock and attempts do the converse or contrapositive or whatever the logical term is. i ca n't remember what it is. it's sentence right conditions were deadlock. say if all four of these exist, or you could say we are in deadlock if and only if all four of these exist, right? that implication, or whatever i again, i ca n't remember a lot. that was discrete now, right? but you did that kind of stuff with the logic stuff. ok. no, i'm not that great at it. but i do remember something deadlock occurs if and only have four of the. all four of these conditions are true. that being said, we can say that as a result, if any one of them are not true, is not true, are not true. ok, if if any one of them is false, we're not in deadlock. so deadlock prevention says all i have do is implement an operating system in such a way where all four of these can never happen. that woman will be a deadline. herein lies the philosophical question about is deadlock good or bad? because some of the situations in we avoid deadlock by turning on these balls, what does in a situation where it's like, well, am i gon na break something right? let's look at mutual exclusion. ok, one way avoid deadlock is not have any mutual exclusion mechanisms, right? we just say we're gon na get rid of. we're gon na allow you create key threads, but we're not going let you create some of ours, pthread, pthread mutexes or condition variables, or any of the other mutual exclusion mechanisms. well, what what? i ever have deadlock? no, but that makes the programmers like job a lot harder. it's how do i avoid race conditions where i do n't have mutual exclusion? how do you do that? can you do it in all cases? i did do that. so so yeah, i did do some examples where we used like that cpu atomic operation right where we could increment by defection add or function subtract and it fixed some of the situations where i could have correct values. but there are some situations in data structures that that's really hard, and there's a whole like world of research out there."
"""Opsys_Condition_Variables_Transcript.txt""","it's how do i avoid race conditions where i do n't have mutual exclusion? how do you do that? can you do it in all cases? i did do that. so so yeah, i did do some examples where we used like that cpu atomic operation right where we could increment by defection add or function subtract and it fixed some of the situations where i could have correct values. but there are some situations in data structures that that's really hard, and there's a whole like world of research out there. and if you're curious, you go look it up called concurrent data structures in they've got data structures that people have developed, like linked lists and things where you can insert something into a linked list concurrently while somebody else is trying modify that linked list and it wo n't corrupt the list. and you think about that and be like, well, wow, because you've got all of these, if you want have a doubly linked list, you've got head pointers. you got tail pointers, you got previous, you got next. how do you do that in such a way where you can insert an element where if i'm trying insert the and modify the next pointer, somebody else is n't trying alter the previous pointer at the same time enjoyably? i would just say i am inserting something into this linked list. i'm gon na lock it out. so nobody else can modify it so that i can modify it and then i'll release it when i'm done. well, if we get rid of mutual exclusion, we ca n't do that. so philosophically, this is awesome, but it's not always easy do. we got ta think about it. but you could envision an operating system where you just do n't let mutual exclusion have. we're just get rid of pthread locks or something. hold on. wait a process, nate. i'll hold allocated resources while waiting for others. ok. how do we fix this? well, we could develop an operating system in you try lock a mutex. and you get the one mutex that we try lock. if you try lock another one while you're holding on a resource, you ca n't. like you get rid of holding. wait, right. if you do that right. this lock i'm like 2 when saying the operating system would say i'm sorry you ca n't lock lock too because you're already holding on the lock. one. ok. hold on. wait, just grind them."
"""Opsys_Condition_Variables_Transcript.txt""","well, we could develop an operating system in you try lock a mutex. and you get the one mutex that we try lock. if you try lock another one while you're holding on a resource, you ca n't. like you get rid of holding. wait, right. if you do that right. this lock i'm like 2 when saying the operating system would say i'm sorry you ca n't lock lock too because you're already holding on the lock. one. ok. hold on. wait, just grind them. can we do that in all cases? no. again points more burden on the programmer. oops sorry. where are my conditions for deadlock? they go no preemption. right, that's a problem, right? for dental work causing deadlocks. so if we allow one thread say you are a higher priority thread. so if you request a resource that somebody else has locked because you're the highest priority, maybe you get get it yanked away from, or the person with the lower priority yanked it away, right? the teacher on the playground, they are the thread with the higher priority. they can yank the basketball away from me and give it alicia. redemption. is that safe in all cases? again, it's almost philosophical. be like well, is it a good idea or not? right. if i'm holding on a lock and i'm playing with the basketball on the playground, ok, yes, i might be really sad have that. basketball. is it the way for me? but it's not necessarily gon na break anything on the playground. it's not gon na cause the playground fall apart. the basketball will most likely still keep bouncing away. no problem. but that's one situation where i got a basketball in the playground, but it was something where i'm holding on something for a critical reason. right. i am holding on a safety harness and i'm using it hold on someone, right? that's my critical resource and all of a sudden, if somebody preempts and yanks away the safety harness and we both fall off and hurt ourselves. no, that's the problem. so maybe i do n't want preemption in that case, right? how do you define what is good and safe when it comes preemption? that is a philosophical problem, but dual and finally circular weight. how do you prevent circular weights? well, the top one, how do i prevent me from waiting for something else somebody else is holding."
"""Opsys_Condition_Variables_Transcript.txt""","that's my critical resource and all of a sudden, if somebody preempts and yanks away the safety harness and we both fall off and hurt ourselves. no, that's the problem. so maybe i do n't want preemption in that case, right? how do you define what is good and safe when it comes preemption? that is a philosophical problem, but dual and finally circular weight. how do you prevent circular weights? well, the top one, how do i prevent me from waiting for something else somebody else is holding. well, in a way, by eliminating one of these three, we kind of get that for free. but again, it becomes a programming problem. you could say you do n't wanna have deadlocks. just do n't have a circular weight. i do n't think it hurts. then do n't do that. sometimes it's hard not do that, so all of these are doable, but yeah, i would say those optically it just takes some thinking. and if we wanna do that in our own code, certainly we could do that. we can repost x as is and just change the way we think about our code and as a result we can make it so it never deadlocks. questions. ok, let's go. let's go a little bit deeper here. deadlock avoidance. ok, let's consider this. this is where the the world of deadlock and analysis becomes even more like the street map, right state machines think about the state of the system. what is the state of our system? it's the contents of our cpu. all the registers what cpu is currently doing, it's the contents of memory. the values that are stored in memory maybe the the hard drive. umm, the locks that we have created, the state of all those locks. who's holding on one? ok. the designers of deadlock avoidance said if we consider all of the states that the system might be in and there might be hundreds of thousands if not millions of different states than some convenient, we can create a venn diagram where we have saved that are safe, where deadlock can not ever happen. we have saved that are unsafe in deadlock could happen, and then we have states that are definitely in deadlock. what do i mean by that? this example. yeah, the red one. red by itself, if we did not have a thread it all red one is always safe. right. there's never a situation where thread one will ever run into deadlock."
"""Opsys_Condition_Variables_Transcript.txt""","the designers of deadlock avoidance said if we consider all of the states that the system might be in and there might be hundreds of thousands if not millions of different states than some convenient, we can create a venn diagram where we have saved that are safe, where deadlock can not ever happen. we have saved that are unsafe in deadlock could happen, and then we have states that are definitely in deadlock. what do i mean by that? this example. yeah, the red one. red by itself, if we did not have a thread it all red one is always safe. right. there's never a situation where thread one will ever run into deadlock. ok, if there's a situation where all we have is spread the system is safe, right? if we have a situation where we have both threads, the system is unsafe because we might get into deadlock. this execution does not guarantee that we will be in deadlock. it might. it will be a deadlock if we get thread one here. thread 2 here and then let them both continue, but as a result it's unsafe. it's not necessarily in deadlock if we do it run up in that situation where thread one gets here and then thread two runs and gets the here. now we are in deadlock. that makes sense. so deadlock avoidance attempts essentially through an algorithmic bookkeeping, keep track of the state of the system and never let the system get into an unsafe state. and the way one algorithm for that that happens is it's as if at any given time up thread or request resources, the operating system looks at the resources that are available on the system and it says i will honor that request if it, only if later on if i look at all of the resources that you will ever request and that anybody will have a request if that's less than the available resources all along the requests. otherwise i will disallow the request. so for example, at this point i request thread, i request 80 resources right? i have 200. if i look at all of the other threads and look at all of the requests they would ever want make, does 80 + 60 + 70 + 80 add up more than 200? if so, doing so will will prevent me from being in a safe state, so i will disallow that request. so that's pretty cool that we could do the bookkeeping just like a a resource allocation graph. they see a problem with all that."
"""Opsys_Condition_Variables_Transcript.txt""","so for example, at this point i request thread, i request 80 resources right? i have 200. if i look at all of the other threads and look at all of the requests they would ever want make, does 80 + 60 + 70 + 80 add up more than 200? if so, doing so will will prevent me from being in a safe state, so i will disallow that request. so that's pretty cool that we could do the bookkeeping just like a a resource allocation graph. they see a problem with all that. processes have be relevant in a way they have know the maximum number of resources that they will ever request throughout the course of execution. in this example it's dual. i know that thread one is only going have a request 140 resources, thread two request 150. it's written right there in the code. but we ca n't always do that, right? what prevents us from knowing this? things like user input, right? could you see prompt the user user enter the number of resources you would like me allocate? you do n't know what this is. just gon na type so as a result this process, when it runs, ca n't tell the operating system. ohh, by the way i want request 500 resources it does n't know so deadlock avoidance is cooled. in theory, but in practice it's hard. all right. last topic, is the one i loved him most of all of them. deadlock recovery. ok, we have deadlock prevention, we talked about is, you know, philosophically can be difficult do. but if we think about how we write our programs, we can for the most part find good ways prevent that law. i'd like avoidance puts less work on the programmer, but more work on in a way, knowing what the program is going do, that's not always practical, but we have done like recovered, so we have deadlock detection. so let's take a look at the situation where we implemented pthreads in such a way where they can detect this cycle, keeping him understanding that we ask, we're gon na be willing accept the overhead that's associated with all that building spread, right? what are you gon na do? this gets back the news deadlock. bad or not? right, you could say i'm going try and break that long once i detect it bye. yanking a resource away. well, what if yanking that resource array causes corruption on the system?"
"""Opsys_Condition_Variables_Transcript.txt""","so let's take a look at the situation where we implemented pthreads in such a way where they can detect this cycle, keeping him understanding that we ask, we're gon na be willing accept the overhead that's associated with all that building spread, right? what are you gon na do? this gets back the news deadlock. bad or not? right, you could say i'm going try and break that long once i detect it bye. yanking a resource away. well, what if yanking that resource array causes corruption on the system? is that good and the bad up you the side, right. so we could terminate everybody. right. but at any prejudice kill everyone. not necessarily what i wanna do. we can turn a process as one by one. now we can we get a philosophical discussion? who do you kill first? what do you terminate first? ok. like we could do some priority thing. ok, in a way, we can all of these are possible. as i say, these are options that requirements, but it's something think about if you're gon na implement an operating system and implement deadlock and covering. preempt the resources. right. we can yank resources away. ultimately, this gets down like the deadlock prevention ideas, right? we could try and break this by releasing resources essentially. third option, i like this. you do not like. and what i find funny about this and why i like that about recovery, is in the world of posix. if you look at pthreads and look at pthread attributes and pthread mutex attributes, they do n't do deadlocks protection. why? because there's no really good way figure out what do with it. could you imagine if we tried do a pthread mutex lock and there was deadlock detection and the operating system said uh, you tried lock a mutex so as a result that's gon na cause deadlock. so i'm just going kill the threat. maybe in some situations that's ok, but in others if i'm computing some sort of matrix multiplication or doing something i need that answer from that thread. killing is not gon na help. sorry. that's what i got on deadlock questions. i know there's a lot of philosophical discussion, but the big thing, the big takeaways here is knowing the conditions for deadlock and what they mean, and understanding that if we break one of them, but that will stop deadlock. but then also this idea of these philosophical discussions of how do you do that?"
"""Opsys_Condition_Variables_Transcript.txt""","maybe in some situations that's ok, but in others if i'm computing some sort of matrix multiplication or doing something i need that answer from that thread. killing is not gon na help. sorry. that's what i got on deadlock questions. i know there's a lot of philosophical discussion, but the big thing, the big takeaways here is knowing the conditions for deadlock and what they mean, and understanding that if we break one of them, but that will stop deadlock. but then also this idea of these philosophical discussions of how do you do that? and is it good or bad? and what are you gon na do when you recover it? so we got resource allocation graphs, we got conditions for deadlock, we got mitigation strategies. questions. thoughts. so there's a lot of flipping through slides. i do n't have a lot of examples on it, but at the very least, that's enough for today. thanks for coming. lembke, james stopped transcription"
"""OpSys_Deadlock_Transcript.txt""","meeting in _ general_-20240401_130129 - meeting recording april 1, 2024, 6:01pm 48 m 1s lembke, james started transcription lembke, james 0:07 hello. hello, great. all right. welcome operating systems. let's see where we're at here. welcome this week. it's week. ohh it's not week 10. let me fix this before i forget, otherwise i will screw it up and we'll end up with two week 10's and there. so there we go. it is week 11, so what do we have left? can you believe this? we have 11121314 and 15. we got five weeks left, 15 more days of this, and then we have finals. and then we're done for this for the year, right? did i do the math right? i hope i did that right. ok, good. good. so we got a couple more topics left, but we're getting into my favorite topics of of operating systems and you might say if they're my favorite, maybe i should talk about them first, but all this the feel, i feel like for a while is a lot of the topics in this class. i kind of like have take the time explain them you, not the whole truth. but then, once you know enough about them, then we could fill in all the gaps and get the rest of it. so that's where we're headed for for the rest of the semester is we're gon na take essentially a lot of the stuff that we already covered. and we're gon na go back it. and now that we know and have experienced it, fill in some of the gaps and hopefully make it make a little bit more sense. so we're moving on from threads and concurrency and deadlock. i did not all sign here, but my announcement i think as far as the quiz is considering that the only thing we really covered was a kind of a philosophical hand wavy topic of deadlock is i'm gon na hold off. we're not gon na have a quiz on friday. we're just gon na move forward talking about scheduling and then get into memory management probably by the end of the week and that worry about it. quiz. it'll be. i'll i'll worry about. we will. you will get tested on deadlock. i do wanna assess that. i wanna ask you questions on it, but we'll wait until probably the final exam on that one."
"""OpSys_Deadlock_Transcript.txt""","i did not all sign here, but my announcement i think as far as the quiz is considering that the only thing we really covered was a kind of a philosophical hand wavy topic of deadlock is i'm gon na hold off. we're not gon na have a quiz on friday. we're just gon na move forward talking about scheduling and then get into memory management probably by the end of the week and that worry about it. quiz. it'll be. i'll i'll worry about. we will. you will get tested on deadlock. i do wanna assess that. i wanna ask you questions on it, but we'll wait until probably the final exam on that one. so we're talking about process scheduling and we'll, uh talk about memory management. we'll probably have a quiz next week, but i mean, that's so far away. i do n't wanna think about that right now. so where are we at? what are we been talking about? what we talking about? process scheduling ca n't talk about that a little bit. yeah. on friday, before the quiz, i'm still grading that i hope get graded totally back you guys by thursday. all right, so what are we talk about about scheduling really, we kind of reviewed this idea of processes in general and this this idea. and i keep reiterating it because i i feel like it just it just it seems be more sense the more i talk about it, the fact that the cpu is executing an instruction stream and it does n't know what a process is, the operating system gets control, whether that be through a system call or a trap, right where the operating with the cpu switches mode, it loads the trusted operating system code or it gets control via a timeout that it sets where it says invoke me every so often because i wanna do something and that thing. that it might do is schedule another process run. the operating system is keeping track of all of the threads or processes as far as like context and is doing this idea of a context switch where it's switching from one process another, giving us the impression that more than one thing is happening at a time. and so as a result, we had this process state and the five state diagrams of stock and the five state diagram. and ultimately, i said this was great. if we only had one process because it when it comes time update a process of state, it knows exactly process update."
"""OpSys_Deadlock_Transcript.txt""","the operating system is keeping track of all of the threads or processes as far as like context and is doing this idea of a context switch where it's switching from one process another, giving us the impression that more than one thing is happening at a time. and so as a result, we had this process state and the five state diagrams of stock and the five state diagram. and ultimately, i said this was great. if we only had one process because it when it comes time update a process of state, it knows exactly process update. the one that's executing in the system, but we have multiple processes. we got ta find a way manage all of these figure out what they're all doing. we can look at an individual process state and it's process control block or thread control block. but when we have 6 processes or threads that are all waiting for something, we kinda got ta figure out how we organize that. ok, so brought about the idea of queuing and so here is my thought with process scheduling and queuing. here is the situation, right. we have multiple processes, yes, that is an abstraction that is a manufactured thing that the operating system creates for us. the cpu is just executing a bunch of instructions. ok. but we have multiple of them and we have organize them and this is where things get a little frustrated. it is that we have processes that are that do different stuff. well, it's not frustrating in the way i like that i like be able have my my processes do different things, but sometimes we have a process that is io intensive. what's an example of a process that's io intensive? good idea. yeah, taking input from people knows. ok, i'll process that. take input from a computer mouse. ok, great. i like that. what other things? yeah, i guess like word input from keyboard microsoft word. i like that. that's another good one idea, right? we've got keyboard, we have user input. most of the time word it's sitting there doing nothing and you would say no, i type really fast. it's constantly updating the screen and displaying stuff, but for human interaction we're really does n't need update anything until it receives input from the user input from the user is like. i keep saying this, but it's true. it's like an eternity the processor."
"""OpSys_Deadlock_Transcript.txt""","yeah, i guess like word input from keyboard microsoft word. i like that. that's another good one idea, right? we've got keyboard, we have user input. most of the time word it's sitting there doing nothing and you would say no, i type really fast. it's constantly updating the screen and displaying stuff, but for human interaction we're really does n't need update anything until it receives input from the user input from the user is like. i keep saying this, but it's true. it's like an eternity the processor. it probably could have been doing 10,000 other things while i was sitting there waiting type while while trying type a keyboard a key. even if i'm really, really, really fast typing, or even if i wiggle my mouse really really really, really fast, the cpu got a lot of other stuff that could be doing. yes, user input in general is more io intensive. other things that tend be io intensive moving files around because i got a lead files from the disk drive and move them from one place another. that's a lot of io because it's got a lead and spin out well when disks were still spinning, it would spin up that disk and it would spin around. now solid state disk so it faster but still takes a while ok cpu intensive. what's a cpu intensive task? and infinite loop. ok. yeah, i'll give you that one. i was kind of a cheap and cheap one. what else could be could be cpu intensive? was that livelock? ok. that's another yeah, livelock rap for do you wanna go for dinner? i do n't know what do you wanna go? i do n't know where do you wanna go, ok? graphics rendering tends be fairly cpu intensive. i mean, if you have a dedicated graphics card, ok, we can argue about that. but say you did n't, right? right. if i wanted render a some set of like intense graphic animation on my process on my system here does n't have a dedicated graphics card, it's got ta use software, so it's got ta run through the processor. that's very cpu intensive, a lot of number crunching, linear algebra, matrix math can be relatively cpu intensive. umm, training a model who got a lot of data train. that model sucks a lot of cpu instructions do all that math right? no. in short, we have processes that are different."
"""OpSys_Deadlock_Transcript.txt""","if i wanted render a some set of like intense graphic animation on my process on my system here does n't have a dedicated graphics card, it's got ta use software, so it's got ta run through the processor. that's very cpu intensive, a lot of number crunching, linear algebra, matrix math can be relatively cpu intensive. umm, training a model who got a lot of data train. that model sucks a lot of cpu instructions do all that math right? no. in short, we have processes that are different. cpu needs some spend a lot of time waiting. others spend a lot of time running on the cpu. we have multiple processes that all need get scheduled run on the cpu in our model, and you know it's kind of cheap, but we'll just bear with it. we have one cpu that can do one thing at a time, or one instruction stream at a time, so context switching is where the cpu gets a new thing run. now, it's not really a new thing. the cpu can only execute an instruction stream and so it continues execute an instruction stream, but the context switch idea is where we have multiple instruction streams and the operating system is sort of like interweaving them together so that the cpu, while it only is executing 1 stream, it might execute 100 instructions for one stream and then 100 instructions from another stream, but the gap in between my fingers is i'm lining these up is the context switch overhead ok, so some constraints here we wanna keep this cpu busy, so that's important. we do n't wanna have be sitting there idle. we want be we want keep our overhead low because if the if the, you know, i spent my good money for while i did n't not for this one, but for my own computer, i spent my good money on that processor. i wanna use my processor for my stuff and not sitting there executing windows right? that's another idea here. the one keep our overhead low and the last thing that i want argue. and again, we're going get philosophical here. so just bear with me is this. i want be fair or i want my operating system be fair. so what is fair? what does it mean be fair, right? well, playing basketball on the playground. what's fair? every kid gets 5 minutes with the basketball. ok, that could be fair."
"""OpSys_Deadlock_Transcript.txt""","i wanna use my processor for my stuff and not sitting there executing windows right? that's another idea here. the one keep our overhead low and the last thing that i want argue. and again, we're going get philosophical here. so just bear with me is this. i want be fair or i want my operating system be fair. so what is fair? what does it mean be fair, right? well, playing basketball on the playground. what's fair? every kid gets 5 minutes with the basketball. ok, that could be fair. what if one kid does n't want it? would say well, yeah, like i said, i get like a give that example before where i was flipping on my phone and like, well, i do n't want the basketball. ok, right. i'm checking my messages. i'm checking my text message. my wife sent me something very important, so i do n't want the basketball. let somebody else have it right. that might be fair because i do n't want it. but what happens as soon as i'm done talking my wife? is it ok for me say ohh the guy that took it instead of maine really should have been given 5 minutes, but i missed out on my turn so i want it right now. is that fair? you only that kid only got 3 minutes, but i did n't. i just gave up my time, so i should, you know, say, you know you're done. you do n't get it for the rest of the time i get it. is that fair? these are discussions that people have written all sorts of research papers on when it comes the fairness of a cpu. you might say i'm a process, but i'm waiting for user input. i'm microsoft word. i'm waiting for somebody hit a keyboard. bam versus i've got somebody that's rendering this big huge graphic thing and they're sucking up all the cpu. should i be allowed run on the cpu as soon as that user hits that keyboard key and say you know what, you've had your time rendering? i did n't ask for it, but when it was my turn, but now that it's, you know, now that i'm able run, i wanna go first. so there are operating systems out there that actually dynamically adjust process priority based on whether there are cpu intensive or io intensive and they give io intensive processes a higher priority because they're naturally waiting and they ca n't run anyone."
"""OpSys_Deadlock_Transcript.txt""","should i be allowed run on the cpu as soon as that user hits that keyboard key and say you know what, you've had your time rendering? i did n't ask for it, but when it was my turn, but now that it's, you know, now that i'm able run, i wanna go first. so there are operating systems out there that actually dynamically adjust process priority based on whether there are cpu intensive or io intensive and they give io intensive processes a higher priority because they're naturally waiting and they ca n't run anyone. so some things think about when it comes fairness. what is fair? so that asides, we're going keep this in mind, we got lots of instructions streams potentially execute. we got ta make sure that we do that. we do n't wanna have starvation, we want make sure that we keep our overhead low as far as operating system overhead is concerned and we also wanna be fair, whatever that definition of fairness is keep that in mind, those three things that we're doing this. so the next topic is about talk about is queuing so. queuing. i love queuing. he accept i ca n't spell it. you is there an eing you doing well? we'll call it that chewing. so what does it mean for queuing? what is it? what's a queue? waiting in line. ok. like that, i think in in great britain. i think they actually like they say it qq up at the door, something we say line up at the door. ok, right. so yeah, essentially this idea of a line we have, we'll ultimately have a bunch of processes, right? p1p2p3 all the way up he, i do n't know. and we'll give it a number. ok, all of these processes will have some sort of state associated with them, right? maybe p1 is eligible run. it's ready p2, maybe it's waiting for some io p3, maybe it's also ready and so on. we only have one process that we can run at any given time. we have one cpu that can do one thing, so maybe in this case down here, pn is the one that's running. everybody else that's not running, we need keep track of them. we have a process control block for them so we know what the current state is. when it comes all of the processes that are ready. we got ta find a way pick one run next."
"""OpSys_Deadlock_Transcript.txt""","it's ready p2, maybe it's waiting for some io p3, maybe it's also ready and so on. we only have one process that we can run at any given time. we have one cpu that can do one thing, so maybe in this case down here, pn is the one that's running. everybody else that's not running, we need keep track of them. we have a process control block for them so we know what the current state is. when it comes all of the processes that are ready. we got ta find a way pick one run next. say this pn has used up all of its time quantum as what they say for a for a scheduler and it says you've had your turn with the basketball. somebody else? it's a run or maybe pn says you know what? i do n't want the cpu anymore because i wanna wait for user input as a result. this guy is no longer eligible run and so somebody else has run. one do we pick? we got p1 that's ready and p3 that's ready. what's fair? i think at one time maybe it was last friday, somebody said, well, we got ta pick whichever one's oldest, whatever. one was the one that has been the longest since it's had the cpu right? the one that had the weight the longest. or you could say why do n't we just take all the processes that are ready run, line them up at the door and who's ever closest the door gets run next? the guy who's the farthest the door will put him at the end of the line, right? he's at the end. this gives about a queue. so what's typically done, and i i should n't say this here, is one way of doing it is we have a series of cues on the system. so for example, we have the ready queue. what this is is a data structure that we have the cpu here that says here is the cpu that's eligible run some instruction stream. the operating system has a process that's running on it, so in this case pin that's running. its context is loaded on the cpu and its instruction stream gets be executed. all of the other processes our stock in the ready queue, so here's my queue. here's the head i'm going drop backwards. here's the tail."
"""OpSys_Deadlock_Transcript.txt""","so for example, we have the ready queue. what this is is a data structure that we have the cpu here that says here is the cpu that's eligible run some instruction stream. the operating system has a process that's running on it, so in this case pin that's running. its context is loaded on the cpu and its instruction stream gets be executed. all of the other processes our stock in the ready queue, so here's my queue. here's the head i'm going drop backwards. here's the tail. sorry, just because the way the i probably should have put the cpu on the other side, but ok, you get the idea. and in here we have the process is lined up in order. so we have maybe p1 in here. who else is ready? p3 is ready. maybe that's the only two processes we have that are returned. he n is running and it has wait for some reason. maybe it's requested io? from user input or the timeout happened and it said pn you're done playing with the basketball, you're done using the cpu. you used all time. so what's gon na happen at that point is the os will run and it will take pin and it will pull it off the cpu. and says you've had your turn. he and goes at the end behind everybody else. now at this point, nobody is running except the operating system, really because it's the one that that's taking control take pn off the cpu and it will then go the ready queue and say who's ready, it will read pnp one here and put it on the cpu. so at this point, then now. jeffrey, what color do you use? he won will get set running. and so at this point then, if pn was removed because it had its turn with the basketball, pn state would get updated ready because it's in the ready queue, he won state will be updated running. and we move on. and we let p1 run precall right? alright, so why do i like this? why do i like this stuff? well. i've mentioned overhead, right? we've got how much of processes in this case i have two. actually, i probably should remove this here because pnp1 is no longer in the ready queue. no longer at the head if i do is like you like a linked list. what i like about this is right."
"""OpSys_Deadlock_Transcript.txt""","and so at this point then, if pn was removed because it had its turn with the basketball, pn state would get updated ready because it's in the ready queue, he won state will be updated running. and we move on. and we let p1 run precall right? alright, so why do i like this? why do i like this stuff? well. i've mentioned overhead, right? we've got how much of processes in this case i have two. actually, i probably should remove this here because pnp1 is no longer in the ready queue. no longer at the head if i do is like you like a linked list. what i like about this is right. this is not algorithms class, but you guys learn like the big o notation right at one time. right. ok, that's not unfamiliar. what is the runtime in order determine the next process run? i have just a simple key like this. yeah. yeah, i'm still. ohh yeah, it's constant time. if i have a head pointer, i just read the value that's there. ok, i can determine the next process one in constant time when it comes operating system overhead constant is the magic number. if it takes more than constant time do something in the operating system, that's where i start like. wonder. you know, i slept good money for the cpu. i do n't want the operations that the running through this huge long list and sucking up is cpu, so constant time is great so it takes constant time read the head of the queue. how long does it take remove something from a queue from the from, you know such a do pop front or whatever it would take remove the front element. what are gon na do? i'm using pointers here. i've got the head pointer i can look up that in constant time if i wanna remove that, how do i remove something from a queue? was that? yeah, reassign the pointer. i guess i had requests head dot next or get next or whatever you want refer it as. that just moves ahead the next step done constant time. i like that. how long does it take add something the end? if i have a tail pointer. also, constant time. pretty cool, right? i could say tail equals, but yeah, well actually what i probably should do is say png next or previous equals hail dot previous and then set the tail equal pm. i think that right."
"""OpSys_Deadlock_Transcript.txt""","i guess i had requests head dot next or get next or whatever you want refer it as. that just moves ahead the next step done constant time. i like that. how long does it take add something the end? if i have a tail pointer. also, constant time. pretty cool, right? i could say tail equals, but yeah, well actually what i probably should do is say png next or previous equals hail dot previous and then set the tail equal pm. i think that right. and then perhaps i should have said the tails the previous next next be was in dublin, linked whatever it will be, right? but either way, it's a constant number of pointers shuffle. it's not like i'm i have move around every single element in the middle. i do n't think i either manipulate the head or have manipulate the tail and found some time that makes without your question or ask how does the os know when pull out the? like a well, that was the one that's running. that's just pm. that's the just the process identifier is what you have like a certain one time or. yeah. so the operating system i if it's if it's using a take turn style then make will have some amount of time that everybody gets take turns with the cpu. a time quantum is what? what they say and they say you'll get x amount of time with the cpu, so the operating system says cpu. you go ahead and run, but after x amount of microseconds. let me know so i can run so it sets a timeout so that after so much time we always gets run and then it's gon na run time. just run this rescheduling routine. ok, so that's the right queue. nice. i like it. but that's not the end. why is it not the end? because we've got processed 2 here that's waiting for something. maybe it's waiting for user input, right? that remember the two state model where all we had was running and ready if p2 is waiting on something was in the ridicule. ultimately, after enough turns have been made, p2 would get get loaded on the cpu and p2 would sit there and say, great, it's like me flipping my phone. i do n't actually need the cpu, so i'm just gon na sit here, do nothing and waiting, and then when he just turn this over, the operating system will put it back on the table when they're ready."
"""OpSys_Deadlock_Transcript.txt""","that remember the two state model where all we had was running and ready if p2 is waiting on something was in the ridicule. ultimately, after enough turns have been made, p2 would get get loaded on the cpu and p2 would sit there and say, great, it's like me flipping my phone. i do n't actually need the cpu, so i'm just gon na sit here, do nothing and waiting, and then when he just turn this over, the operating system will put it back on the table when they're ready. queue commission because now while it is efficient for me select process run, it is inefficient because the process in there doing nothing so. we know the queue, so we have the ready queue here and then we're also gon na do is have a waiting queue. where we have bunch processes, we need a head of the queue and a tale of the queue and up here is i wrote that really small this bear with me here. this says p2 because p2 is waiting. so now peter can sit there for as long as it needs, waiting for user input. every other process that is writing run and not waiting on something gets go through and see if you gets queued up and they're all taking turns. happy days. what happens when he's twos? i will request or whatever it means is that would be 2 is done waiting. it could be waiting for any number of reasons, but in this particular case we will call this the io waiting queue you're waiting for user input. we've definitely talked about io, but what happens is when an io device, some hardware device finishes when it's doing, it's going send a signal the cpu. kind of like a signal handler. and when the cpu receives that message, it loads the operating system it has. it's been pretty set up handle that and so much like where the operating system says. i would like run after so much time for doing the time time quantum. it also gets interrupted and the os gets run at the end of an io operation. so at this point, when this io finishes, the cpu gets interrupted and the os gets loaded, almost as if a user made a system call the operating system that figures out what happens and said, oh, this io devices done. ok, great. wonderful. he too is no longer waiting. what do we have do? the p2 is ultimately going be able run on the cpu. we got ta put it somewhere. it's not waiting."
"""OpSys_Deadlock_Transcript.txt""","it also gets interrupted and the os gets run at the end of an io operation. so at this point, when this io finishes, the cpu gets interrupted and the os gets loaded, almost as if a user made a system call the operating system that figures out what happens and said, oh, this io devices done. ok, great. wonderful. he too is no longer waiting. what do we have do? the p2 is ultimately going be able run on the cpu. we got ta put it somewhere. it's not waiting. so what? we're gon na put it on the ready so with the io completes, so i'll write this in green io complete. the os is going run and it's gon na take p2 off the ioq. and put it on the right queue, so wherever it's going go at this point, pm probably moved itself up. but ultimately here we could say p2 gets put on the end of the ready queue. it's no longer in here and then it we have update this from rating ready and then after enough time and enough people's turns, it gets moved. but the run on the cpu. i like it. the iq needs be slightly different. it ca n't just be a first in, first out or first. yeah. first in, first out queue, do n't be slightly different. why do you think it would need be something slightly different than that? yeah. is it possible that one thing that's in the queue finishes for the head if it was supposed snow? yeah. and that's exactly right. in this particular example, i got one process in the i / o waiting queue, but i might have other ones in here, right? maybe i got p2. i've also got p4. i've got p6. i've got p-10. i've got a bunch of processes that are all waiting on io. if if hands i owe device finishes, it's got ta get pulled out and put on the right here. so this essentially becomes what they call it, a priority queue or preemptive queue or whatever. and i'm not sure what the name of it would be, but we have be able remove something in the middle. right."
"""OpSys_Deadlock_Transcript.txt""","maybe i got p2. i've also got p4. i've got p6. i've got p-10. i've got a bunch of processes that are all waiting on io. if if hands i owe device finishes, it's got ta get pulled out and put on the right here. so this essentially becomes what they call it, a priority queue or preemptive queue or whatever. and i'm not sure what the name of it would be, but we have be able remove something in the middle. right. so something keep in mind what some operating systems do is they actually make a queue for several for each individual io device and that way then it just organizes in this case we have this idea of io waiting and it's a little bit more, more bookkeeping that we track of because not only do we have a bunch of processes that are all waiting for an io device, we have check on what io device they're waiting for and we got ta figure out how remove them when that io completes. another way of doing it, but again it's trade off. in this case, i would say between cpu usage and memory usage is if we had a separate waiting queue for every single io device that we have on our system. now we only have keep track of the processes for that one io device. what's also neat about that is you might you could envision a situation where if i've got 10 processes all waiting for the keyboard, as soon as the user hits a key, i could wake them all up and just say we're gon na drain the skew and put everybody back on the ready queue. makes sense. ok. what other cues could we have now that we understand this idea of queuing the list can go on and on well in the five state diagram all i had was waiting and that's be honest with you. what linux does too? it says you have a process that's waiting for something. as far as it stays concerned, but waiting is not just waiting for io. what other things can be we waiting for? what other reason? why might we have a process waiting? yeah. it's dependent on another processes where resources right? i like that a mutex lock, a process waiting on a mutex lock, is n't waiting for io. what's it waiting for? but for yeah, for another thread or processes process unlock that mutex, lock semaphore."
"""OpSys_Deadlock_Transcript.txt""","it says you have a process that's waiting for something. as far as it stays concerned, but waiting is not just waiting for io. what other things can be we waiting for? what other reason? why might we have a process waiting? yeah. it's dependent on another processes where resources right? i like that a mutex lock, a process waiting on a mutex lock, is n't waiting for io. what's it waiting for? but for yeah, for another thread or processes process unlock that mutex, lock semaphore. if you're waiting on a semaphore where the count is 0, you're waiting, but you're not waiting for io, you're waiting be signalled. so we might have additional additional cues on here. we might have a queue for. in this case, we'd have a queue for each mutex. the years mutex won and mutex 2. and with that also might be have its own corresponding head and tail pointer. we might have some of our waiting queue. here's another one. asleep queue. i have a thread where i say microsleep or you sleep or just sleep and pass a number. that process is really it's waiting. it's not waiting for io. it's not waiting on a new text. it's not waiting on a semaphore, it's just waiting for a timeout that's waiting for a certain amount of time. i so in that case we have processes that are sleeping. this queue is also kind of unique in that the process that i wanna pull off of this is the one that has the least amount of time left sleep. so now i have an array of priority order queue, so speak based on sleep time. so what's kind of interesting about what the way sometimes this is implemented is the head of the queue is represented and by the process identifier, obviously, but also the amount of time that has left the sleek and then every other concerns that might be recorded be the offset of the amount of time from the previous process. does that make sense? so now we know that the obvious, some good set a timer be just a difference in time between the different wait times. right. what else might we have? well, i guess that's probably not what's called. sorry."
"""OpSys_Deadlock_Transcript.txt""","so what's kind of interesting about what the way sometimes this is implemented is the head of the queue is represented and by the process identifier, obviously, but also the amount of time that has left the sleek and then every other concerns that might be recorded be the offset of the amount of time from the previous process. does that make sense? so now we know that the obvious, some good set a timer be just a difference in time between the different wait times. right. what else might we have? well, i guess that's probably not what's called. sorry. we do n't really talk about this, but there is a signal that you can send a process that forces it suspend this, say, wait, you need wait until as a system administrator i am forcing you wait until i tell you that you are no longer waiting on linux with the command line. it's actually hit control z. this suspend a process, so even if you have a process that's in an infinite loop, you can force it stop for a little while by hitting control z that sends it the sig stop signal. the operating system then says i do n't know what you're doing. i do n't care. i'm pulling you out the cpu and i'm putting you in the sustained you because you are not eligible run. somebody said you needed be suspended. you're waiting, but you're waiting for someone explicitly resume you. and then you could actually get sent a resume signal or and leaving number with the command is, but there's some command where you can do the parser process resume, but as a result then it will become no longer way. ok, so questions. yep. yeah. bunch of the cpu time is spent managing all these tools. i'm watching the cpu time is spent managing all these cubes. they'll the depends on the operating system implementation, so if you've been operating system that does n't support you text locks then you have worry about the mutex views right? but you need spend the this is a lame answer. you need spend the amount of time necessary manage all the queues, right? and so, you know, there's a lot. is a little it is what it is. ok. question. when a process is no longer waiting for something, is it does? is it always added the ready queue? given what we know, is there a situation we ask this question in a different way? penguin vision."
"""OpSys_Deadlock_Transcript.txt""","they'll the depends on the operating system implementation, so if you've been operating system that does n't support you text locks then you have worry about the mutex views right? but you need spend the this is a lame answer. you need spend the amount of time necessary manage all the queues, right? and so, you know, there's a lot. is a little it is what it is. ok. question. when a process is no longer waiting for something, is it does? is it always added the ready queue? given what we know, is there a situation we ask this question in a different way? penguin vision. the situation where a process moves from some waiting queue and does n't get put on the ready queue other than a process that's terminated ok, that's a cheap one, right? so if you have a process that's suspended and then ultimately later on gets terminated, it just gets removed from there and then consumed and it's gone. yeah. conditionals. conditionals. ok. well, i'll so because they need a weight on the actual like lock itself for it be the removed and then be conditioned actually wake it up be able go ok both of them. i love it right condition variables. remember condition variable has when you wait on a condition you specify the address of the condition variable and the address of the mutex lock. and i i said in order for the process continue, it must be signaled on the condition and it must be able be the owner of the mutex lock in our actually be able wake up. remember that in that case you're actually have a waiting queue for the condition. and awaiting queue for that mutex. so the process that initially waits on the condition is put here. then, when it signaled the head of the queue, it's pulled off of there and then put on the queue for the mutex until it's able be the owner of the mutex. so in that case, the process is state moves from waiting waiting or does n't change, but where it's waiting is moved. so it seems like a lot manage one of the saving graces, so speak, for all of this management is well, you might have multiple queues. in this case, i mean there could be even 100 or more different queues in my system. the advantage of of of the ones that of neat things that are process, can only ever be on one queue at a time, and you might say, well, does that make it any easier?"
"""OpSys_Deadlock_Transcript.txt""","so in that case, the process is state moves from waiting waiting or does n't change, but where it's waiting is moved. so it seems like a lot manage one of the saving graces, so speak, for all of this management is well, you might have multiple queues. in this case, i mean there could be even 100 or more different queues in my system. the advantage of of of the ones that of neat things that are process, can only ever be on one queue at a time, and you might say, well, does that make it any easier? the answer really is yes, because inside the process control block you can actually have a reference what queue is waiting on, and it's only one place you do n't have have like 27 different potential pointers different cues that are process is on. it's only ever gon na be on one queue, so it makes referencing of looking up what queue a process is on again constant time operation. ok, other situations where a process might move from one queue another, that's not the ready queue would be something like. i'm waiting on io ok and while i'm waiting for io, somebody suspends me. when i become resumed again, well, if my io operation that i'm reading on, is it done yet? i only put back on the io waiting queue. so you ca n't have this weird and away multiple state things say. i am blocked waiting on io and i'm also suspending. so that way if the io operation finished while i was suspended, well ok, that means when i become resumed again, i can go on the reticule. because i'm no longer io waiting, i'm just normal suspended. but if i resume while i'm still waiting for io, i ca n't get put back on the ready queue. i forget moved back the io waiting. so almost had this like boolean merging of multiple different states. in that case, you could also envision a situation where i'm waiting on a mutex and then also then suspended as a result. what i'm resumed again. i got ta go back waiting on this mutex. that makes sense. ok. questions about viewing? all right. where? out alright? let's talk about priority. i think one time somebody mentioned it would be pretty cool if we allow processes have different priorities. in what situation might you want allow different processes have different priorities? yeah. you there? that's fine."
"""OpSys_Deadlock_Transcript.txt""","in that case, you could also envision a situation where i'm waiting on a mutex and then also then suspended as a result. what i'm resumed again. i got ta go back waiting on this mutex. that makes sense. ok. questions about viewing? all right. where? out alright? let's talk about priority. i think one time somebody mentioned it would be pretty cool if we allow processes have different priorities. in what situation might you want allow different processes have different priorities? yeah. you there? that's fine. this is like what does that you're using in the background that's chugging away. it's something you do n't want, your you're correct. big step freeze up while promising do whatever it's doing ok. i like that. so the the the example is that was given was. i'm a gui, a gooey right that is rendering something. you want the system look responsive, right? and so maybe you give the the the gooey higher priority so that if it has something do, we want a lot, we want the user make it look like our essentially want the user have the impression that the system is n't locked up doing nothing, right? so if i have lots of processes that are all executing infinite loops, they've got a lot of work do. or maybe we've got lots of processes that are all in livelock. they've got a lot of not work but work do, but as a result we wanna make sure that the system does n't look like it's locked up. so ok, i like that one other thoughts on priority. ok, so that's enough. now that we know what we know about queuing, what do you wanna do? we've got a cpu. and we've got a ready queue. i'll actually draw at this direction with a head and a tail pointer, and we got a process that's going in the cpu and we have a process that might be pulled off. go the tail. or maybe it is stuck on some? series of waiting queues. so this is a waiting queue. here's another waiting queue so on. so in this case, the process was pulled off because of its time quantum. that's going back on the ready queue here. we've got waiting queues. how do you want handle priority? right. so we alright, so i i the very least inside the pcb. we can put the priority. that could be a number."
"""OpSys_Deadlock_Transcript.txt""","i'll actually draw at this direction with a head and a tail pointer, and we got a process that's going in the cpu and we have a process that might be pulled off. go the tail. or maybe it is stuck on some? series of waiting queues. so this is a waiting queue. here's another waiting queue so on. so in this case, the process was pulled off because of its time quantum. that's going back on the ready queue here. we've got waiting queues. how do you want handle priority? right. so we alright, so i i the very least inside the pcb. we can put the priority. that could be a number. whether you use a higher number or a lower number is, it turns out linux actually does use priorities. it uses, i believe, a lower number for priority instead of a. a lower number means a higher priority, but that does n't matter. we have this idea, but if i've got a whole bunch of processes in here that are honor priority, one do i pick next? so let's let's let's let's first off kind of make this i can get here. do you always pick the highest priority processor up? oh, that's right. ok, so if you've got a high priority process that's waiting, it ca n't run anyway, so we do n't get it. we'll just eliminate that, but in the ready queue, do you always pick the highest priority process? ok. what would you not? ok. so, good point if we have something of a high priority and it's always gon na essentially preempt or skip in line and everybody else, that's not fair, right. i'm putting words in your mouth, but ok, alright. here's my thought with that. should have been a higher priority process if letting it run always is not fair. alsophis. maybe there is no. there is no right answer. there is no wrong answer in this case. typically in the world of priority based schedulers, the idea is that the highest priority process that's ready run always gets run next. there are systems out there that will say i will let you assign a priority, but let it be more dynamic say ohh yeah high priority process you got run 6 times already. we're gon na let somebody else in the lower priority process run just because you've had enough. yeah, it's up. it's."
"""OpSys_Deadlock_Transcript.txt""","there is no right answer. there is no wrong answer in this case. typically in the world of priority based schedulers, the idea is that the highest priority process that's ready run always gets run next. there are systems out there that will say i will let you assign a priority, but let it be more dynamic say ohh yeah high priority process you got run 6 times already. we're gon na let somebody else in the lower priority process run just because you've had enough. yeah, it's up. it's. that's where why we have lots of papers published on on scheduling. but about be simple as far as keeping the overhead low. often the decision is the highest priority process that's ready run gets run. what have you have more than one process with the highest priority? well, now you got ta charge me. you might say we're gon na require that all priorities be distinct. then we do n't have that problem. that's kind of a cheap way say it. the other option would be if we have more than one process that is on the same priority, we're just gon na like, you know, like the like. take turns with the basketball right. you're all the high priority, so you get play around and if you guys wanna stop and you're waiting on something, then we'll let the lower priority processes run. ok, so under the assumption that we're going say always pick the highest priority pauses run, how are we going implement this? if we have one ready queue, how do we handle that? how do we pick the highest priority process that's ready? the idea is. they're all lined up here. index from the tail and then we find the highest priority process that's in here. ok. sure. what's the runtime complexity of that? order and ok, what did i say about operating system overhead? thousands of thousands goal. so if we i do n't search through the priority queue, the more processes we have, the longer it's going take. ok, once another way we can implement a priority queue. yeah, could have. should be on the vaccine. so you could always just skip ahead of it. ok, we could have it be a max sieve. what's the runtime complexity of inserting into a heap? see, i'm log in. we're getting better, but guess what? what letter? what? what is the letter inside there that i do n't like?"
"""OpSys_Deadlock_Transcript.txt""","so if we i do n't search through the priority queue, the more processes we have, the longer it's going take. ok, once another way we can implement a priority queue. yeah, could have. should be on the vaccine. so you could always just skip ahead of it. ok, we could have it be a max sieve. what's the runtime complexity of inserting into a heap? see, i'm log in. we're getting better, but guess what? what letter? what? what is the letter inside there that i do n't like? regardless of all the different mathematical formulas you could put in there, and whether it be login or n ^2 or log of log of log of log of n right, it's still based on the number of processes and really really want constant time. ok, we could do a hash. how long does it take compute a hash? what if we have collisions? no, you know there's always something. ok, so here's my solution. it's not my solution. whom i kidding. i kind of stacked the deck against you because i said, well, we have one ready queue, some right, one answer might be can we have more than one ready queue? so we have a process that is. running on the cpu inside its process control block indicates it's priority as soon as it pulled off the cpu, whether it be for time quantum or because it's waiting for some io or waiting for something, all we're gon na do is take it off the cpu and put it on the ready queue for its corresponding priority. we can look up the priority in constant time. it's in the process control block. we can insert something into a standard queue in constant time. we just have figure out queue it's is. if we have an array of queues, we can index into an array in constant time and now we can now put the thing on the tail of the appropriate ridicule in constant time. and what's really neat about that is now if we keep track of how many processes are in the each queue, we know that we can pull off the priority for other the element called the highest priority queue first. i know it's kind of cheating, but it allows us insert and remove something. faster than trying store something in a max heap or the granite. i love heaps."
"""OpSys_Deadlock_Transcript.txt""","if we have an array of queues, we can index into an array in constant time and now we can now put the thing on the tail of the appropriate ridicule in constant time. and what's really neat about that is now if we keep track of how many processes are in the each queue, we know that we can pull off the priority for other the element called the highest priority queue first. i know it's kind of cheating, but it allows us insert and remove something. faster than trying store something in a max heap or the granite. i love heaps. i'm a heap guy, but doing this again keeps. requires more memory, but what's neat about this is even though we have eventually lots and lots of different priority queues, we will always the max addition of all of the processes on all of these queues will be no more than the number of processes in the system, right? because the process can only ever be on one queue at a time. so while we do a little bit more bookkeeping is our storage is concerned now he's still are limited by the number of processes in the system and some operating systems probably had this far as well actually limit the number of processes you can ever have say when the when the, when the kernel is compiled and built, we're never going allow more than 256 processes. and so what they will do is they'll create all of the queues at the very beginning when the system boots up the allocate all the memory we need because they know exactly how much memory you're gon na need, because you could only have enough. you only have enough slots needed for every single process that will ever be in the system, and if you limit that and make it constant size, they guess what you know exactly how much memory you need for all the queues. ok. where we at here. so we have two minutes left. let me double check my notes here make sure that forget anything. hello. here we go. so fairness, here's the queuing thing. moving from one queue another, i mentioned this idea of blocked and suspended and so on. block queue, resume ok. and then here's that the multiple priority queues did that and so. we still have talk a little bit more about overhead when it comes fairness and this this idea of a timeout or a process gets a certain amount of time quantum. and you know, how do we choose the appropriate time quantum use? so we'll get back that."
"""OpSys_Deadlock_Transcript.txt""","so fairness, here's the queuing thing. moving from one queue another, i mentioned this idea of blocked and suspended and so on. block queue, resume ok. and then here's that the multiple priority queues did that and so. we still have talk a little bit more about overhead when it comes fairness and this this idea of a timeout or a process gets a certain amount of time quantum. and you know, how do we choose the appropriate time quantum use? so we'll get back that. but otherwise i think about the time so well. please let me examples next time, otherwise have a good day and i'll see you on thursday. lembke, james stopped transcription"
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","meeting in _ general_-20240129_130446 - meeting recording january 29, 2024, 7:04pm 45 m 54s lembke, james 0:06 alright, great. hello. hello. so where are we at? so what can operating systems isolation and protection abstractions are cool. although we have n't gotten there yet, we're still doing see review. so what i got canvas right here. so this week i got a new project for you, the stacked machine. this is utilizing c we wo n't have use any operating system services, at least not directly in this one. so that's out there. i also have a link a video that doctor shilling wrote a while ago. it's in youtube about make files. we might get make files today. we might not, but i wanna pulse that video because it's really, really good information about make files, other things posted my examples. these were not the exact examples i went over in class, but they are more detailed with comments and everything about how use functions and pointers and all that stuff. so that's out there in canvas. the next thing i wanna talk about a little bit here is the project. so if you click on this you get a link github classroom. but if you ultimately then clone your repository, what you get is not that you get. nope, there it is. yeah, you get. no, no, here you get this. this is the project and so this project. yeah, that could be. is that strictly about operating systems? it's about c and so what i want you implement essentially at its lightest is i'm giving you a header file with a bunch of functions, and what i want you do is implement those functions. it will require use pointers. will require you. maybe not necessarily. write your own, but use structs and we'll have use some some dynamic memory as well, and so for that, uh, we'll talk about that review dynamic memory and see today. but it is supposed be completely in. see, it does have you use a make file. i do provide for you make file so you do n't have be 100 % like super make file power user, but you have be familiar with it so that's why i posted that video for you refresh your memory in case i did n't get make files yet so a little bit about background about what a stack machine is."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","maybe not necessarily. write your own, but use structs and we'll have use some some dynamic memory as well, and so for that, uh, we'll talk about that review dynamic memory and see today. but it is supposed be completely in. see, it does have you use a make file. i do provide for you make file so you do n't have be 100 % like super make file power user, but you have be familiar with it so that's why i posted that video for you refresh your memory in case i did n't get make files yet so a little bit about background about what a stack machine is. essentially, what you're going be implementing with this header file is a stack computer in a way, and so you'll be implementing a stack data structure and then implementing operations on that stack, and so a little bit about the project description, what a stack is, hopefully remember a stack from data structures. but what i also asking for you do is implement some mathematical operations using the stack, and so i ask you also implement some test cases. i give you some tests. they are not all inclusive. i want you also include it in your submission, your own tests. you can add them a tester file that you're provided, or you can write your own. either way, it's fine. just make sure that you comment your tests and also write that that's part of the grade for this project. is also for you do some testing. ok, this is the sample test file and what essentially the stack machine requires a client do is create a stack structure is defined in stack mh. initialize that you will let implement this function and then do operations. you can push values. you can print out a stack. you can pop values. you can retrieve the top of the stack. you can clear a stack. you can do addition. i want the addition operation requires is for you push some values on the stack and what add will do and what all of these operations essentially do is follow a theme. it takes the first the top two values on the stack, pops them off, does the operation, and then pushes the result back on the stack, right? it does not return a result. other than success or failure, it does n't return the top of the stack. it just says did n't work or did n't it and so add. for example, we'll fail if there's not two elements on the stack."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","i want the addition operation requires is for you push some values on the stack and what add will do and what all of these operations essentially do is follow a theme. it takes the first the top two values on the stack, pops them off, does the operation, and then pushes the result back on the stack, right? it does not return a result. other than success or failure, it does n't return the top of the stack. it just says did n't work or did n't it and so add. for example, we'll fail if there's not two elements on the stack. you have add two things, so if you only have one thing on the stack and the user tries add, you should return failures. so things like that make sure you're also doing error checking. so there's a well test add, subtraction, subtraction is not a little weird, it's just subtraction, just the order of operations matters for subtraction. so as the description of of the two values need be subtracted from the other, the same thing for division that also matters order matters and addition and multiplication. it does not. so testing that, umm and then the big one that is sort of the trickiest 1 here probably is rotate where if you push a bunch of elements on the on the stack and rotate that number indicates the depth and what i want you do is take the top elements and you have go there. there's a description of what rotate should do. should take the top elements of the stack. however deep there are and take the one that's that number. deep put it on the top and push. the other ones around. so you're like moving around values on the stack, so that's rotate again, you ca n't rotate deeper than the stack has elements, so you would return error if you ca n't rotating something of0 depth should just do nothing but still succeed. rotating of depth one should also do nothing because you ca n't rotate the top, it's just pop the top push back on it does n't do anything in the stack and so on, and so that is what i want you implement for this project. the full description of all of the operations is in the header file, so this is stack mh you're given and it has a description of the structures for a stack node as well as a stack itself. and then in here in the comments, it describes what the operation should do and what the return value should be."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","rotating of depth one should also do nothing because you ca n't rotate the top, it's just pop the top push back on it does n't do anything in the stack and so on, and so that is what i want you implement for this project. the full description of all of the operations is in the header file, so this is stack mh you're given and it has a description of the structures for a stack node as well as a stack itself. and then in here in the comments, it describes what the operation should do and what the return value should be. so for the most part, the return value is -, 1 if it fails, or zero if it succeeds. i do n't want you print out an error message in these say, oh the stack is empty or something like that. just return -, 1 if it fails, or a zero if it succeeds. and so, for example, down here the rotate here is where i description of what i'm looking for for rotate and so it should be fairly detailed in the header file. if you have any questions let me know. ok, so deliverables. ohh so the other thing that you're given i wanna point out here is the sample again, not an all inclusive test case. i want you write your own at. in addition this, but the output from this or a sample output i've given as well in sample output dot txt, includes not necessarily exactly what i'm looking for your the way you do print is up you. exactly. this is an example, does not have look like this. the only thing i'm asking for for print is that you print out the stack elements and let me know part of the stack that you're printing out at the top and is the bottom. this is the way i chose do it. it's up you exactly how you might want do it, but make sure you help me, is the top and the bottom. so there's the sample output. otherwise, for deliverables, i'm asking that you implement the cc a source file. it is not included inside here, so not add that the tester file sample is in there as well as the sample output and the header file do not modify the header file. please leave it as is. just implement the functions as they are, and then there's also a sample make file in here. makes and builds your program, so i got."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","it's up you exactly how you might want do it, but make sure you help me, is the top and the bottom. so there's the sample output. otherwise, for deliverables, i'm asking that you implement the cc a source file. it is not included inside here, so not add that the tester file sample is in there as well as the sample output and the header file do not modify the header file. please leave it as is. just implement the functions as they are, and then there's also a sample make file in here. makes and builds your program, so i got. if you want learn more about make files and we have n't gotten there yet, watch doctor schilling's video. i encourage you watch it anyway, but that that is the next programming project that is due a week from tomorrow at midnight. while 1159 and 59th right, you get the idea. so a week from tomorrow questions awesome. all right, that's the programming project we got. make files. we got that and so on now examples. so remember the notes i've got the notes out there on pointers and structures as well as all the other ones out there. so let's go back up here. do n't forget about those because we did n't get dynamic memory. i probably should move that down this week, but you get the idea. i wanted just sign up, put them all in one place, but they're all there. so where are we going next? uh, alright. so this is in a way kind of where we left off. now it's not exactly where we left off because i did n't get a recording of our class and i recorded the other section. this is where we got with section with square. ok, it's not a circle. it's a square. hopefully it's ok, but anyway, what did they say? favorite shape was a square, and so we have square dot h and square dot c and let me just kind of quickly review that before we get into dynamic memory. so they said that a square had side length and a color and i said how do you represent color and that they said well with its rgb value of course and i said, yeah, you're right. what is this? just the number. and so what we also practiced with in that section was not only a structure, but also using the preprocessor."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","favorite shape was a square, and so we have square dot h and square dot c and let me just kind of quickly review that before we get into dynamic memory. so they said that a square had side length and a color and i said how do you represent color and that they said well with its rgb value of course and i said, yeah, you're right. what is this? just the number. and so what we also practiced with in that section was not only a structure, but also using the preprocessor. uh macros define values, so these are hexadecimal numbers that are defining for colors representing the amount of red, green, and blue from zero 255. up close you have took web apps. this will be probably familiar even if you had n't. this is essentially the idea we have two hexadecimal values for representing the amount of bread, 2 for the amount of green and two for the amount of blue. so if we have all red and no green and no blue, and that's red, if we have no red, all green and no blue, it's green and we have no green, no red and no and all blue, it's blue, otherwise nothing is black. all apps would be white and so on. umm. and so had some predefined values for color. and then we have similarly our two functions for edit square and get perimeter. but instead of circle we have square and then finally for and it's square. remember, passing in a pointer. this is key. by passing in a pointer, we do n't get a copy of the structure, we get a copy of the address of the structure member. a pointer is just a number, but that number represents an address of something in memory, and as a result we can use the pointer operator store values inside the structure and instead of overriding the local copy of the structure, we're dereferencing where that is in memory and actually storing those values in memory so that outside of this function, those values get modified and we would update a couple of examples of that. we're actually doing some operation here. we can pass just a copy of the structure that way in, in a way, even if we were try modify these values, it would n't get modified because this is a copy of the structures value. but we can still read the value and say that the actual perimeter is four times the side length, should be correct for the perimeter of the circle square. ok with me. all right."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","a pointer is just a number, but that number represents an address of something in memory, and as a result we can use the pointer operator store values inside the structure and instead of overriding the local copy of the structure, we're dereferencing where that is in memory and actually storing those values in memory so that outside of this function, those values get modified and we would update a couple of examples of that. we're actually doing some operation here. we can pass just a copy of the structure that way in, in a way, even if we were try modify these values, it would n't get modified because this is a copy of the structures value. but we can still read the value and say that the actual perimeter is four times the side length, should be correct for the perimeter of the circle square. ok with me. all right. so let's then go back main and here we are. so we have a square where i can initialize the square be side length of 100 with the color of red and then i can initialize the square and then also get the perimeter. so if i do that. uh main dot c and square dot c wrong. there we go. if i run it. we get perimeter, after the initialization of my square has a side length of 0, so the perimeter is 0 and then down here this shows. similarly, a problem that can arise, we kind of talked about this, this touched on this a little bit that if we declare an array and then try print out the array at like a really, really large index that we get lucky, right? arrays do n't know how big they are. we do n't get an array index out of bounds exception and ok, so that's what we're at. so what i wanna talk about now is a little bit more about arrays and then talk about dynamic memory. ok, so. uh. and i think stop me if if i mentioned this or not. either way, we can review it twice this idea of if a raised on how how big they are. well, i guess i would say a different way if a if we can access way outside an array bounds, what do we actually accessing? ok, i do n't know if i mentioned this problem. as mentioned, it quickly essentially in array here. well, conceptually i think of an array like i would in java an array is a thing. it's an object. well, ok, yes."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","either way, we can review it twice this idea of if a raised on how how big they are. well, i guess i would say a different way if a if we can access way outside an array bounds, what do we actually accessing? ok, i do n't know if i mentioned this problem. as mentioned, it quickly essentially in array here. well, conceptually i think of an array like i would in java an array is a thing. it's an object. well, ok, yes. but in see, it's not necessarily an object. it's not necessary, not necessarily. it is not an object. we do n't have objects at all in c we have data and functions that manipulate that data, and so in array and see, is n't an object. it's essentially this many of these things, so that was not the best way say that, but it in this case it is a grouping or a consecutive amount of integers. hence, how many are there? well, in this case it's well, this does n't tell us how many there are, but this tells the compiler how many there up in this case. here there are 10, so the compiler in memory will allocate 10 integers. how big is an integer? it's as big as it needs be. as big as the compiler says, it's going be, i happen know it's 4 bytes on our compiler and i can figure that out by doing the size of operator. what all of a sudden done? i do n't really care, it's just allocating space for 10 integers, all right? that's part one. so consecutively in memory we have 10 integers allocated and this array variable indicates the first element, the address in memory of the first element. so when i do this and i offset into array element four that does n't do some set of magic object representation. it just says wherever array is in memory, go where the 4th element is and the 4th element is four times the size of an integer, so that will be offset 16 inside where inside this array is. i do n't know what its address is. i can print it out, but i do n't really care. i know that the compiler can access bite offset 16 from the start of this array. this 100 then does the exact same thing. there is no balance checking. what this will do is it says compiler."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","it just says wherever array is in memory, go where the 4th element is and the 4th element is four times the size of an integer, so that will be offset 16 inside where inside this array is. i do n't know what its address is. i can print it out, but i do n't really care. i know that the compiler can access bite offset 16 from the start of this array. this 100 then does the exact same thing. there is no balance checking. what this will do is it says compiler. please go a rail not 100, is essentially says go the address at the start of array and access element. the element that is of offset size of it, is 4 * 100 is offset 400 and print out whatever is there and that happens be in this case -, 6 billion billions on these something similar number, right? because i did n't explicitly implement in initialization of that memory location. so i got whatever's there. if it was a location that my program did n't ever allocate, i would probably get a memory error saying you're trying access memory that you do n't have access. here i just got lucky. it happened be initialized for some reason. if i try run this again, i probably will get a different value or i'll get it crash. nope. i guess i got a different value. it better running a bunch times. maybe it would crash? maybe never would, but i know that this is not the correct value. how do i know that? well, i do n't know if it's correct value or not. i know it's not something i allocate. ok. so a couple of things here with us. i did size of array and i got 40 right. does that make sense? well, yes it does, because i've got an array of 10 numbers and i have n't personally know and you as well that an integer is 4 bytes on this compiler. ok, so 4 * 10 is 40. i will tell you this right now. do n't trust this? i think i mentioned that if i did n't, i'm gon na say it again. do n't trust it? why? because conceptually the compiler in this case knows the size of this array because it was just allocated in its scope and it knows that it's that big. but it does not always know it. remember i said that in array represents not the entire thing but only the address of the start of the array, right?"
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","i will tell you this right now. do n't trust this? i think i mentioned that if i did n't, i'm gon na say it again. do n't trust it? why? because conceptually the compiler in this case knows the size of this array because it was just allocated in its scope and it knows that it's that big. but it does not always know it. remember i said that in array represents not the entire thing but only the address of the start of the array, right? i said that or i tried. hopefully it did. right, i said that. right. ok so when an array is allocated locally, this really only represents the start of the array. the compiler in this case is smart enough know that because it was allocated right here at. knows how big it is, but in the in the in the time in i use an array as a function, do it. we see that down here i get 40 and when i call do it i get 8 and that's because when i pass this array do it, i'm only passing the reference or the address the pointer the first element where the array begins. ok. so the side of that is 8 the size of a pointer is 8 bytes is 64. five, because we have a 64 bit machine. ok. that is why you ca n't trust size of. because when we passed an array around, we pass it by a pointer. it's address, ok. questions. ok, so let's talk about addressing a little bit more and now we'll talk about dynamic memory. ok, everything that i've done up until now has been essentially using pointers and things like that on a static basis, right? we created a square. we did this right. this square is allocated right by the compiler and it's gon na be a square, and the compiler says ohh because the square and i say well, i told you how big a square was because i included square dot h and go look compiler where squared is defined and the compiler goes looks and it says ah that's right a square consists of a size and a color that's two integers. so the money allocate here is essentially the size for two integers. here it says i need allocate memory for this. how much do i need allocate? well, let me just look over here and by 10 numbers, 10 integers. great. i can do that all that static. that's me as a as a programmer telling the compiler then."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","this square is allocated right by the compiler and it's gon na be a square, and the compiler says ohh because the square and i say well, i told you how big a square was because i included square dot h and go look compiler where squared is defined and the compiler goes looks and it says ah that's right a square consists of a size and a color that's two integers. so the money allocate here is essentially the size for two integers. here it says i need allocate memory for this. how much do i need allocate? well, let me just look over here and by 10 numbers, 10 integers. great. i can do that all that static. that's me as a as a programmer telling the compiler then. what if we want do things dynamic? ok. and you and you guys say, well, ok, when would i wanna do something dynamically? ok. well, one of the things that i brought into where i want do something dynamically is user input, right? if i always know how much data or what data i needed declare, i do n't really need worry about doing it dynamically, right? and this particular case, i know how big a square is. i'm gon na use it so it's great, but what if i needed ask the user cell? i ca n't predict what the user's gon na type in on the keyboard, right? so if i wanted have the user give me a number so that i can create an array that that's, that's that long for example, right, i'd say how many integers do you want user? i'm not clear voyant as a programmer, so i do n't know what number they're going enter, so i ca n't statically allocate that. ok, now what i could do probably is say user you ca n't enter a number greater than like 250 and that way then i can limit it say alright, i know the user is n't going be allowed enter a number greater than 250 and i do n't wanna array should be at least one element so i'm just gon na head and always allocate an array that's 250 elements long and as a result then i always unjust do it statically and then just use as many as i need. ok. that's one strategy that makes sense. ok, but let's just talk about doing things dynamically. so how do i do things dynamically and see now that we know pointers we could do this right? so let's change our struct."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","ok, now what i could do probably is say user you ca n't enter a number greater than like 250 and that way then i can limit it say alright, i know the user is n't going be allowed enter a number greater than 250 and i do n't wanna array should be at least one element so i'm just gon na head and always allocate an array that's 250 elements long and as a result then i always unjust do it statically and then just use as many as i need. ok. that's one strategy that makes sense. ok, but let's just talk about doing things dynamically. so how do i do things dynamically and see now that we know pointers we could do this right? so let's change our struct. let's change our square. let's make it more like an object, ok? whether or not you want do this ok does n't matter. we're gon na do it anyway. so square in its square this says user, you need pass be memory that's already been allocated, right? that's essentially what this says. i want the address of the square a pointer a square just a number and address of a square that i'm gon na fill in for you. what if i was gon na be nice the user and say, you know what, user? you do n't even have have this allocated, right? i'm just gon na do it for you because you want do initialize the square. so so do that right? they're not same idea of like doing a constructor in java right? i wanna say square by square equals new square, right? i want the square initialize itself and forgive me the storage for it, so do this i'm going change this up a little bit. i'm going say let's do this. let's actually make this look like a constructor int. we call it side. int column. see, we'll just call it c, right? ok. we'll call it s&ci know, this is not gon na be proper, but anyway, so we got the values that we're gon na use initialize our square i.e. and then this is going have return something. now in java, our constructors do n't return anything they, they're just implicitly returning the object through the new operator. but in c, we're going return something. we're gon na essentially take the users input for side length and color, create a new square, and return that the user. make sense so far?"
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","we'll call it s&ci know, this is not gon na be proper, but anyway, so we got the values that we're gon na use initialize our square i.e. and then this is going have return something. now in java, our constructors do n't return anything they, they're just implicitly returning the object through the new operator. but in c, we're going return something. we're gon na essentially take the users input for side length and color, create a new square, and return that the user. make sense so far? ok, so what we could do is this, actually this actually would work, i think well you'll give it a shot. it's changed this say we're gon na return a square. you pass this in this you pass this in the squares parameters. so go back into your square. we come back over here, we say great. now what am i going do? i'm not going initialize the user square. i'm gon na make a square a struct, new square. give it a name. thoughts. so far so good. alright, let's use this then. let's take care of this. let's secure that for now. and now in here. we have that. what do i got? what's my problem? e expected equal attribute. let's actually call it a square instead of a squirt. all right. now it's my problem. sql. bit of an open brackets above 1 above it. ah, thanks guys. all right, so these are still my warnings for unused function and and my formats, but otherwise it worked and in fact let's just get rid of that. i do n't need this. now. good, alright. so what did i do? ok, that changed a little things around a little bit in a way this looks more like what we would perhaps expect out of something like java or sql plus. we have a constructor in a way that initializes a square and returns a square. ok. yes. what is this doing? this is actually you look at this and say, well, this is no different here because. i'm not using any dynamic memory. how do it? this is where things get kind of interesting. here i'm creating a new struct for a new square that's causing the compiler allocate that. it's initializing its values and i'm returning ok what am i actually returning in this case? what's being returned? just look at the return."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","we have a constructor in a way that initializes a square and returns a square. ok. yes. what is this doing? this is actually you look at this and say, well, this is no different here because. i'm not using any dynamic memory. how do it? this is where things get kind of interesting. here i'm creating a new struct for a new square that's causing the compiler allocate that. it's initializing its values and i'm returning ok what am i actually returning in this case? what's being returned? just look at the return. what is it? it's a structure for a square, right? and so this is where people start. look at this and they're like, if they're, if they're like, you're, like, really honest goodness, like c programmers, they look at me and be like you. this is not right, it works. it is right, but there is one thing that's happening here as and cr. what? integers, right integers that represent the parameters this function. they are as parameters copies of whatever the user passed in copies, right? they're not pointers, they're integer values. so when the compiler is gon na do is, it's gon na take the value of 100 that's allocated in main. copy that value and pass it in here. so i have one copy of 100 already made as this parameter. ok. and then i'm meeting a structure. ok, that structure is being umm set down the value of 100 and rent. it seems be one of my parameters are and then returning that structure ok. where is this structure allocated in memory? it's allocated in the scope, right? the scoping braces you guys helped me fix is allocated the scope of this function. when this function returns, that variable falls out of scope, right? and so it is no longer usable after this function returns. so as a result, the compiler says well if this is gon na be wrong be be lost. i have pass in this particular case as a return value, a copy of the structure. so now i'm making a copy of 100 and rank is pass in this parameters and then i'm making another copy of the structure. when i return it. ok. so then when i initialize this guy here in maine, this is allocated in the scope of maine and it gets a copy of whatever is returned. so i'm making another copy copy it back over here."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","so as a result, the compiler says well if this is gon na be wrong be be lost. i have pass in this particular case as a return value, a copy of the structure. so now i'm making a copy of 100 and rank is pass in this parameters and then i'm making another copy of the structure. when i return it. ok. so then when i initialize this guy here in maine, this is allocated in the scope of maine and it gets a copy of whatever is returned. so i'm making another copy copy it back over here. me that makes sense. alright, so the the the world of pure sea programs would say that's too many copies. we should be able do this better by just passing around pointers memory and having things built in, is why the old unit way that i did before previously or. i'm passing in a pointer is, so speak, technically slowly more efficient, ok. alright, so are you all still with me here? alright, let's move on now. let's let's implement this using dynamic memory. so how do we change this using dynamic memory? well, we're gon na do here is we're gon na allocate storage for this new square here and return the memory location of where that storage is. not the actual structure itself, ok. and remember how you allocate stuff in c allocate start. now, now i'm alec memory. allocate. ok, i love this. this is great. so how does it work? first thing we have do is include the library file. for malik, it's in stdlib dot h notice that we're using uh. greater than, less than, or whatever, including this tells the compiler search for it in the system library path. i do not implement a city live dot age. i did n't implement malik. i do n't want. it's rather that we want talk about how complicated and it's it is a. it is as complicated as it needs be, but i do n't want implement it because somebody else did. i just want use it so it's in the system library path square dot h that's what we implement it. so we're going do that. ok, so how do i allocate stuff alright? malik. we've not talked about man pages, but man, that is a short for manual and so in linux is a command called man and you can type man and then something and it will tell you and bring up the manual page for that."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","it is as complicated as it needs be, but i do n't want implement it because somebody else did. i just want use it so it's in the system library path square dot h that's what we implement it. so we're going do that. ok, so how do i allocate stuff alright? malik. we've not talked about man pages, but man, that is a short for manual and so in linux is a command called man and you can type man and then something and it will tell you and bring up the manual page for that. i just went google and typed man malik just because it's it also works that way too and it brings up the manual page for all the different ways alec malacate allocate stuff. there's malloc, calloc, realloc, realloc. you know what we're looking at, malik. so what does it say for malik? we look, it says it returns a pointer. a space and you give it a size. that's it. so when it comes c++, if you want allocate something, you would say like, uh, you could say new int. you could say new a new object type whatever you had the specifically specify what it is you are allocating in. see, you do n't do that. we do n't have classes. we do n't have objects. we have data and we have functions that manipulate that data. so we want allocate memory, we have allocate data. we have say compiler allocate some memory for me when i'm allocating stuff on inside the local scope of a function or the local scope of an if whatever, right we allocate it by its type and the compiler says i know how big that is, right? we allocate an. it knows how big that is, and so it allocates that space more, allocating something dynamically. we're asking the compiler allocate stuff, and it does n't necessarily know how big it is. we have tell them. makes sense. so if i want allocate 5 bytes, i just say malloc 5 got a nice. if i want allocate the space for an integer, what do i could do? this is where they get tricky, so let's go back out here before we get our struct thing. let's just go back this malloc bit up here. under malik requires a certain amount of bytes. how big is an integer? we know it's for cause we've done this a million like, so i will be honest with you on this compiler. not five."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","so if i want allocate 5 bytes, i just say malloc 5 got a nice. if i want allocate the space for an integer, what do i could do? this is where they get tricky, so let's go back out here before we get our struct thing. let's just go back this malloc bit up here. under malik requires a certain amount of bytes. how big is an integer? we know it's for cause we've done this a million like, so i will be honest with you on this compiler. not five. i can do this. malik returns a pointer. he does not return the variable. if it was gon na return the variable invited them, just call it an end in the 1st place. here, this says malek. 4 bytes for this thing. give me a pointer. give me the address of where in memory you allocated that stuff. that i can do something like this. my allocated equals 100 using the dereference operator, right? we're going dereference my allocated int and store the value 100 there. that does not take the remember, this is a pointer. a pointer is a number. report it refers an address in memory, but it's really just a number. by doing this, this tells the compiler go that location in memory and store something there. that's an equals operator, right? there's essentially a storm. with men. ok, this is great and i would say this works, but the world of geeks out there would say this is fine and wonderful, but it's not portable and what i mean by portable right. it does n't mean that i'm gon na pick, ok? my laptop is portable. ok, i can walk around with this code portable in this case means that this works on an x86 architecture that's uses gcc of a particular version that compile this code. and that's because gcc is allocating 4 bytes an integer. if i was take this source code and compile it on a different architecture with a different compiler that happens allocate an integer with a different number of bytes. now when i work, because if i do n't allocate enough storage. what this is gon na do is it's gon na try and store the equivalent a size of an integer at that location, and if i've not allocated enough bytes, i'm gon na get an error, right? so. how do we know how big an integer is? how did we know before?"
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","if i was take this source code and compile it on a different architecture with a different compiler that happens allocate an integer with a different number of bytes. now when i work, because if i do n't allocate enough storage. what this is gon na do is it's gon na try and store the equivalent a size of an integer at that location, and if i've not allocated enough bytes, i'm gon na get an error, right? so. how do we know how big an integer is? how did we know before? size up so the better way do this and i hate use the word better, but we'll just say another way do this is instead of saying 4 say size of int because we could specify and say the size of a variable by name or the size of a type. that's kinda cool about the size of operator. now, if we were recompile this with a different compiler that used a different size for an int, who would always have the right size? ok, so keep that in mind. so now we've got this we can allocate an integer. we can print it out. and why is sea lion yelling at me? and it says, ooh, you specified the format for an int, and i'm specifying what? what does my allocated int? it's a pointer, so if i want print out the the value i have dereference it. do n't forget that thankfully, sea lion is for is nice. and when i print this out, i get my number. wait. ohh let me. this is perimeter. here, let me just not do this. let's just focus on malik and free. there is my value 100. well, the prices are good. what am i missing? c you're trying remember that. or even java, this is fine. c++ this is not fine. see, this is not fine. in java, when i allocate an object, right? then my program or after a while, depending on how the scoping rules work. well, my variables fall out of scope. i lose reference counts and things like that, and then there's this, i'll call it magic. but there's this wonderful function that runs periodically in the java virtual machine that goes and cleans up all the stuff. that's no longer used, right? what does that call the garbage collector in? see, i do n't have a garbage collector in c++. i do n't have a garbage collector."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","then my program or after a while, depending on how the scoping rules work. well, my variables fall out of scope. i lose reference counts and things like that, and then there's this, i'll call it magic. but there's this wonderful function that runs periodically in the java virtual machine that goes and cleans up all the stuff. that's no longer used, right? what does that call the garbage collector in? see, i do n't have a garbage collector in c++. i do n't have a garbage collector. if you wanted remove or get rid of an object and see what plus plus what did you use? delete and see what do we have do get rid of our memory. we have the free it up right, so thankfully if we go back the main page. there's this function here called free takes a pointer. let's not worry about this underscore nullable for for for a while, but it just says it takes a pointer a storage location and if we do n't free it we get what's referred as a memory leak. and so when we're done with it, we need free my allocated int. ok, here's where people usually start arguing with me. and they say, yeah, great. that's fine, doctor longview. we. yes, i you free works, whatever, but you know, be honest with you, if we do n't actually free it when the program ends and the operating system says ohh, your program is done, i'm gon na consume all of your memory. that you used and yeah, so is memory leaks really a problem if our program terminates? the answer is no, it's not really a problem. it is a problem in this class though. free your maleks trees, please. my free the malloc free the mallets they need like have a protest shirt or something that says free them. please free them outlooks. ok. how do you know if you forgot bring the malex? it's hard. i can tell you actually, there's actually a wonderful program out there and i wanna show it you now while we have 5 minutes left, let me comment this out. say i forgot the free them alex. i can run 8 it out and it's not gon na tell me if i freed the maleks or not, but there is a tool and in fact actually i tell you install it here in. where is it? that's not it. ohgi career. valgrind or valgrind?"
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","it's hard. i can tell you actually, there's actually a wonderful program out there and i wanna show it you now while we have 5 minutes left, let me comment this out. say i forgot the free them alex. i can run 8 it out and it's not gon na tell me if i freed the maleks or not, but there is a tool and in fact actually i tell you install it here in. where is it? that's not it. ohgi career. valgrind or valgrind? i never know what the proper way pronounce it is, because i've never like heard one of the developers pronounce it, but. well, sorry valgrind. i'm gon na use valgrind because that's the word i'm that's the name. i i i learned it has. what is that? this is an analyzer of our of our program. so we're gon na run our program with inside the environment of valgrind, and it's gon na give us some information about our program as it runs, is pretty cool. one of the things that i can give us is memory information. so i first compile the program. wonderful. wonderful. and then i run valgrind and i run dot slash 8.0. only thing i have do is take what i normally would for a dot out and run belgrade and now when it runs i get a whole bunch more output. all these funny numbers here that print out in essentially belgrade, printing out some information. it's telling me ohh this is copyright. whatever gpl i'm concerned about the license, but version it is right here is the output for my program is 100 and then i get a whole bunch of dumps out all the statistics and what do we see is i have. ohh, at exit 4 bytes in one block. look at this two alex. one freeze, 1000 bytes allocated and down here we see that. we have ali. we have 4 bytes in one block that has been leaked. was not free and you look at that and be like, oh, that that's not great, but it does make sense. i now like an integer and i forgot the free it, so i know and we know that integer is 4 bytes. i allocated it and did not breed those 4 bytes and so it says you leaked 4 bytes. now the operating system included up in this case, but if they get leaked where? program does n't know that you know it's it's be honest with you, that's a really difficult statement say."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","was not free and you look at that and be like, oh, that that's not great, but it does make sense. i now like an integer and i forgot the free it, so i know and we know that integer is 4 bytes. i allocated it and did not breed those 4 bytes and so it says you leaked 4 bytes. now the operating system included up in this case, but if they get leaked where? program does n't know that you know it's it's be honest with you, that's a really difficult statement say. where are memory leaks are at least we could be. we can learn, you know that we have them. then finding them is up is up is up us. so what do we wanna see? we wanna see this. and exit 0 bytes and zero blocks, 2 alex, two freeze. great or great? now the amount of storage that's allocated. this is essentially and the the sum of everything that my program allocated, whether it was dynamically or not. but anyway, this shows that i have free. i freed all the maloofs, ok? alright, what else can i do with this? we got a little bit of time left here. i mentioned this idea of an array. we can use that allocate an array. remember that an array is just. a consecutive allocation of variables by type in memory, right? this is consecutive allocation of 10 integers in memory. this is the consecutive allocation of 1 integer in memory dynamically. but i can allocate more, right? what did i just do? i told malik allocate 100 times the size of an injured. how many bytes is that? and and i do n't really care. i know it's 400, but i mean that's just because i know about this compiler. but in general i do n't need know. i need know that it is 100 integers. and so from there you could dereference it like this. that's just gon na dereference and get the first element that i allocated in that space, or what's really cool is. and something like that. this is going go just like down here by recent for down here is it's gon na go the location 50 integers times the size of an integer from this space. right. so it's weird. i allocated it as a pointer, but i can access it as an array and that's because when i now let memory it's contiguous in memory. when i allocate an array, it's contiguous in memory."
"""OpSys_Dynamic_Memory_Allocation_Transcript.txt""","that's just gon na dereference and get the first element that i allocated in that space, or what's really cool is. and something like that. this is going go just like down here by recent for down here is it's gon na go the location 50 integers times the size of an integer from this space. right. so it's weird. i allocated it as a pointer, but i can access it as an array and that's because when i now let memory it's contiguous in memory. when i allocate an array, it's contiguous in memory. same thing. ok, i'm out of time. so we will probably finish this up next time, so hopefully this is worthwhile and we'll finish up our square thing and then we'll be done. thanks for coming. have a good day. lembke, james stopped transcription"
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","meeting in _ general_-20240503_130415 - meeting recording may 3, 2024, 6:04pm 45 m 55s lembke, james started transcription lembke, james 0:06 ok. hello, hello. welcome operating systems. i'm one last day, although maybe i'll say they're in the bible. i do n't mean say isolation, protection. abstractions are cool. you could all roll your eyes one more time. that's right. ah, but welcome review day. so hopefully everybody is and ready for the last day of the term, ready for finals week start next week. we made it. uh, let's see. what we got going on memory manager was due last night. i'm grading those. i'm about 1/3 of the way done. i really hope have them all graded and back you well before the finals. so you know where you kind of where you stand with all of your grades and everything. the only thing i probably wo n't have is the dropping of your lowest quiz grade. if you came do the office visit, but if you did that, i will make sure that i that i that i take care of that. but i'll wait. i'm gon na wait until after i get all the finals created and everything like that, but at least you'll know more or less where you stand as far as your greatest concern going into the final. that's my goal here. uh, so today is review. so what i wanna do is essentially walk through a list of topics that i kind of think are potential that i could ask questions on for the final exam and then give you the opportunity ask questions of me go over, you know, things like, is this gon na be on the final or is that gon na be on the final? could you go over an example of this or can we go back and go for our coding example of that? umm. and that's kind of my plan for today as far as material is concerned, i stand in all of my drawings and i had two pdf, one for each section. so i kind of grouped them so we've got a link for the recordings of the summaries for each section and then a list of the drawings. so if you want see the drawings that i drew in the other section, there more or less the same, slightly different, perhaps. but those are all the drawing. they're all one pdf i did n't really know the best way do this."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","and that's kind of my plan for today as far as material is concerned, i stand in all of my drawings and i had two pdf, one for each section. so i kind of grouped them so we've got a link for the recordings of the summaries for each section and then a list of the drawings. so if you want see the drawings that i drew in the other section, there more or less the same, slightly different, perhaps. but those are all the drawing. they're all one pdf i did n't really know the best way do this. i figured that was probably better than making like a separate file for every single one and then having a zip file. so it's all just one pdf and i do n't know many pages like this, but you can roll through that and see the drawings that i drew. otherwise i will update the recordings and the summaries after today when we have the last recording done. so you can use that or review and the last thing that i'm gon na do is as i'm going through the topics for the exam, i'll make a list of them and i'll post that in canvas so you can see the list of topics as well. and then you also have this recording, so hopefully they'll be plenty for study material for the exam. but what i wanna do here is just open up. i'm not this. ah, shoot. a sticky note here. it's something else i was working on. and i'm just going take notes here as we go. there we go and i'm going go through the term here and we'll see what we got. so as far as what we covered week by week here, we started with. os intro and motivation, and really what we spend the majority of the time in here talking about was remember in here was os intro and motivation, but that's really a generic topic but we spent some time talking about cpu architecture, not in the details of this is the instruction set architecture specifically for mips or x86, but just mention this idea that our in cpu executes an instruction stream. and some of those special there's a special registers bright special things that the cpu is gon na hold on. we've got the general purpose registers and the aclu and the special purpose things like the program counter."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","os intro and motivation, and really what we spend the majority of the time in here talking about was remember in here was os intro and motivation, but that's really a generic topic but we spent some time talking about cpu architecture, not in the details of this is the instruction set architecture specifically for mips or x86, but just mention this idea that our in cpu executes an instruction stream. and some of those special there's a special registers bright special things that the cpu is gon na hold on. we've got the general purpose registers and the aclu and the special purpose things like the program counter. so the registers the alu for the arithmetic logic unit, the program counter, and things like specifically that we have a load store architecture was the model that we were using that if we want have the cpu do something with data, it has get the data into the cpu. and the only way that it can do that is by reading or writing memory. and given that piece, then we talked about why we want have an operating system, because we have this idea of. multiprogramming. is not really multiprogramming, but maybe multi execution. the appearance of more than one thing happening at the same time when we have a cpu that can execute one instruction stream at a time. we talked about that idea, multiprogramming, and, of course, my favorite isolation and protection. that as soon as we have multiprogramming in there, we have find a way have these multiprogramming streams, not stop on each other. so we talked about cpu context, right? the contents of the registers and the state of the cpu we talked about what the context switches we moved from one process another. we came back and talked about context switching as well. all right. then we had our c review. functions, structures, variables. malloc free pointers, all that stuff. about a fair amount of time talking about all those different i'm structures and things, and i got the links the notes in here. went through a bunch of examples more. see review. i'll talk about make files, i'll be a separate topic in here. then from there we talked about system calls and processes. the trap the process for executing a system call. how we can get into the operating system? why we need a trap, right? why is this mechanism necessary? what happens when a trap happens? right. we talked about processes and in there we talked about the process state."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","about a fair amount of time talking about all those different i'm structures and things, and i got the links the notes in here. went through a bunch of examples more. see review. i'll talk about make files, i'll be a separate topic in here. then from there we talked about system calls and processes. the trap the process for executing a system call. how we can get into the operating system? why we need a trap, right? why is this mechanism necessary? what happens when a trap happens? right. we talked about processes and in there we talked about the process state. we talked about the process control block, the pcb information that we're storing about that process. those are kind of the big pieces behind processes. then we talked about creating processes. where fork and exec and how i kind of told you that fib where i said. ohh yeah, process a child process is a duplication of a parent, but then we went back talk about virtual memory and copy on write. i said, well, now that we understand how virtual memory works. ok. yeah, it's not really a copy, but for all intents and purposes it is a copy, right? that idea, the parent child relationship. our processes is important there as well. see here. hey parent child relationship and i wanna also mention here the umm parent child responsibilities. this is things like free the maleks right that a child process inherits the requirement free cause it's a copy of the parents address space. all right. then we moved on now that we had the idea of cpu executing instruction streams, the idea of a process with the process state, parent and child. then we moved on. now that we have this idea processes, how do we get them work together? so that was interprocess. communication. our ipc, some people call it and the things we talked about was, umm, a shared file. and actually in here somewhere, where do we talk about it? i i do n't see it in here in the list stop, but i know we did talk about it somewhere in here, but so i'll just put it here for lack of a better way play it. put it, we're talking about files and file descriptors. and what they're used for and where they're how they're stored, we've got this file descriptor table that's in kernel space inside the idea of a system calls and trap. we also talked about the dual mode operation."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","i i do n't see it in here in the list stop, but i know we did talk about it somewhere in here, but so i'll just put it here for lack of a better way play it. put it, we're talking about files and file descriptors. and what they're used for and where they're how they're stored, we've got this file descriptor table that's in kernel space inside the idea of a system calls and trap. we also talked about the dual mode operation. i keep coming back. sorry, coming back this dual operation mode dual operation. i'll just call that we had user mode and kernel mode. or system mode. i'm gon na come back up here under the os. motivation. we spent some time talking about the difference between os versus kernel, but that in there as well. and then also in here under the dual mode of operation, we also talked about user memory, uh, or space versus kernel memory or colonel space. the stuff that the operating system is storing for our process that the processes do n't have access versus the stuff that the processes can access, talk about what's in a process address space, right, text data, heap, stack, right. all right, in the file descriptors we talked about how use them, right? this idea of open read right close that kind of stuff. and then when we talked about ipc, we said that now we have this idea of a file descriptor, we can use a shared file communicate between parent and child. that kinda was n't the best because we had this internal file position pointer that we have manage and move around because both the parent and child share open file descriptors. mr probably mentioned that too parent child relationship, parent child responsibilities and what's shared and what's not shared between parent and child and i'll parent and child do n't share memory by default, but they do share open file descriptors, right? uh, what other things we talked about? we talked about pipes. we talked about message queues. we talked about shared memory. and this idea of using mmap. i think those are the all the ipc mechanisms we talked about. oh no, we did n't. we talked about signals. who am i kidding? signals that is important. see, this is why i go back through here because i forget. see here. shared memory and then everybody's favorite threats."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","mr probably mentioned that too parent child relationship, parent child responsibilities and what's shared and what's not shared between parent and child and i'll parent and child do n't share memory by default, but they do share open file descriptors, right? uh, what other things we talked about? we talked about pipes. we talked about message queues. we talked about shared memory. and this idea of using mmap. i think those are the all the ipc mechanisms we talked about. oh no, we did n't. we talked about signals. who am i kidding? signals that is important. see, this is why i go back through here because i forget. see here. shared memory and then everybody's favorite threats. so after we had this idea of processes are totally more or less totally isolated except for parent and child do share some things we said. alright, what if we could turn sharing on by default and we said what we wanna share? how we wanna handle that? so we had threads, so the process for creation. creating a thread? they'll or i guess ending the idea of a thread function we talked about actually. maybe i'll just make these separate items creating ending. a thread function for what it exactly how it executes? umm, what's shared and what's not shared between threads? how share threads share memory? all of memory by default, but they have own essentially context and own call stack, because if we share call stacks that we kind of are sharing execution, we really want do that, but we could pretty much share everything else. so share all of memory and then we have a independent. umm, call stack and context? umm. and then that led us into, i'm going make it a separate topic under concurrency and race conditions. so we talked about critical sections of code and then this idea of how do we lock out critical sections. so we had, umm, mutual exclusion. i'll call mechanisms. things like semaphores. summer 4. mutex lock. and condition variable. what they are, how they differ, how we would do use them? we spent some time talking about producer and consumer for that sharing access us a circular buffer, kind of a thing. umm. and here i also mentioned into the concurrency those requirements for concurrency. things like mutual exclusion, progress, bounded weight, right that if you have a process that's good or thread that's gon na wait, it should n't wait forever. it should be allowed lock out other processes."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","and condition variable. what they are, how they differ, how we would do use them? we spent some time talking about producer and consumer for that sharing access us a circular buffer, kind of a thing. umm. and here i also mentioned into the concurrency those requirements for concurrency. things like mutual exclusion, progress, bounded weight, right that if you have a process that's good or thread that's gon na wait, it should n't wait forever. it should be allowed lock out other processes. that kind of stuff. so i kind of i think i mentioned that as kind of requirements for concurrency. in the realm of race conditions, i kind of mentioned what can go bad with race conditions, why we have race conditions, or what, what what can what can, what problems they can cause. then all of the examples of the fact that, while we might think of i plus plus as one operation because of our load store architecture, it's actually multiple operations we have load. i from memory we have add 1 or whatever we're gon na add it in a register. then we have the store that back in memory and any time we could have a context switch so we could kind of incorrect values. umm. and one of the things i also mentioned was i'm going just mention it here that there are some atomic operations that you can do, but that does n't fix everything. that led us everyone's favorite favorite, with quotes flagger, head project, where you're synchronizing everything there. ok, so that was all the thread ones concurrency. producer and consumer. then we started. then we talked about things about deadlock, deadlock and i'm gon na mention deadlock and livelock in here as well. so conditions for deadlock. we talked about deadlock detection. so and remember the four conditions for deadlock. mutual exclusion. all the and weight. circular weight. oh, no preemption. umm talked about deadlock detection and with that we covered resource allocation graphs right where i had that this resource is held by this thread and this thread wants that resource that there was a cycle. that means that there could be deadlock, right? unless of course, there's more than one instance of a resource that i argued could say, well, if we made all the resources just independent then, and we only ever had one of them, we could still do this circle. we talked about deadlock avoidance. was this idea of if we can just uh oops deadlock. prevention."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","umm talked about deadlock detection and with that we covered resource allocation graphs right where i had that this resource is held by this thread and this thread wants that resource that there was a cycle. that means that there could be deadlock, right? unless of course, there's more than one instance of a resource that i argued could say, well, if we made all the resources just independent then, and we only ever had one of them, we could still do this circle. we talked about deadlock avoidance. was this idea of if we can just uh oops deadlock. prevention. and i got ta go back here because i always get these two mixed up. i do n't want tell you the wrong thing. let me go back the slides. i'm deadlock deadlock. so we have deadlock detection. deadlock prevention. ok, deadlock prevention is. eliminating any of the conditions or deadlock if we can prevent any of the four conditions for deadlock from happening, then we ca n't have deadlock and we went through them and realized that, ok, it might not always be practical eliminate them all or eliminate any of them. so then we end up with deadlock as a possibility. deadlock avoidance was this idea of detecting unsafe states. the idea that if we can figure out all the states of all of the locks on the system, find a way in we can detect a situation where we could be in deadlock and just do n't let that happen. all right, that was deadlock. and then livelock was also kind of included in there. but it's we mentioned that was idea of sort of this i hate call it like a forcefully giving up of resources cause that's not correct but it's this i give that example of what do you wanna do for dinner. i do n't know what do you wanna do? i do n't know what you wanna do with. threads are constantly releasing locks, but nobody's ever getting any work done. all right. deadlock. everything about the process scheduling. and the evaluation criteria. what's fair? like about fairness. umm, we talked about the evaluation criteria of turn around time. what else did we talk about response ratio? and. we have, and they're talking about wait time and then we also had start time and end time, but that was kind of based on our scheduling algorithm. we talked about scheduling algorithms. and in there we talked about preemption versus no preemption and the algorithms we talked about was first come first serve. we talked about shortest. job."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","and the evaluation criteria. what's fair? like about fairness. umm, we talked about the evaluation criteria of turn around time. what else did we talk about response ratio? and. we have, and they're talking about wait time and then we also had start time and end time, but that was kind of based on our scheduling algorithm. we talked about scheduling algorithms. and in there we talked about preemption versus no preemption and the algorithms we talked about was first come first serve. we talked about shortest. job. next we talked about umm, shortest remaining time and then i'll talk about round robin. within round robin, we talked about what a time quantum was and the advantages and disadvantages of a large versus a small time quantum. umm. and large versus small and a little bit about variable time quantums. in process priority, along with fairness, we talked about priority and we also talked about scheduling mechanisms. so things like queuing and all the different cues. i await cues and newtext wait queues and some of our wait queues and priority weight queues and ready queues and all that stuff. with that queuing stuff and then that led the process simulator programming project where you implemented and used some of those queues implement a process scheduler. ok. and then on doctor luke's favorite topic, memory management. so that was a lot of topics. so we started out talking about block allocation. fixed variable block dynamic block allocation. so there was fixed block allocation of both equal and unequal size blocks. umm, we talked about. dynamic block allocation and with that we had those algorithms of first fit best fit, next fit and worst fit. umm, we talked about internal versus external fragmentation, what that meant. in all of these, we talked about overhead in the bookkeeping, what the operating system has keep track of for all of that augmentation or additional stuff we need put in the process control block. umm. after black allocation, we talked about paging and that was things like virtual addresses versus physical addresses. and that translation we had page tables, we talked about the memory management unit. the mu and the and the translation look aside, buffer the tlb and what those do. we talked about the bits of a page table. not only do we have the page table representing ohh with page tables, we also talked about ohm pages and frames. pages are part of the process. frames are the physical addresses of physical locations of physical memory. his number frame number."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","after black allocation, we talked about paging and that was things like virtual addresses versus physical addresses. and that translation we had page tables, we talked about the memory management unit. the mu and the and the translation look aside, buffer the tlb and what those do. we talked about the bits of a page table. not only do we have the page table representing ohh with page tables, we also talked about ohm pages and frames. pages are part of the process. frames are the physical addresses of physical locations of physical memory. his number frame number. we talked about bits like the present bit talked about the dirty bit. and what else do we talk about with virtual memory we talked about? ah, copy on right. and this idea of page sharing and how we can actually implement shared memory by just manipulating the page table of the two processes so that they're pages point the same frame. umm. and then we talked about swapping. when we have, when we have ohh swapping and let's talk about this way page faults and swapping if we want reference a page that's not in memory, the operating system has come in, take over and actually load the page into a - frame in memory. and there was a result. it might require picking a victim page, swapping one out the swap space and disk, led us a couple of algorithms for choosing a victim page. so the, so i say it's important know the the process or handling a uh, we'll call not process, but because that's ambiguous, these steps were handling a page fault. umm. and then the. victim page algorithms. things like first in, first out. least recently used. and then i'll mention it. the optimal of course because we're not clairvoyant and we ca n't foresee the future, but the optimal being least needed in the future, right, or the one neatest needed longest in the future. all right, memory management that forget anything. no. like so and then file systems. so with file systems we talked about a bunch of stuff we talked about what what record. we had the data and the metadata for a file met a you know sara dash in here? umm, what else do we have about file systems impact about uh file allocation, this block allocation mechanism. actually, while we were in here, we talked about what record, but we also talked about sort of the io hardware connections. that it's connected this bus, so we have issue an io request."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","like so and then file systems. so with file systems we talked about a bunch of stuff we talked about what what record. we had the data and the metadata for a file met a you know sara dash in here? umm, what else do we have about file systems impact about uh file allocation, this block allocation mechanism. actually, while we were in here, we talked about what record, but we also talked about sort of the io hardware connections. that it's connected this bus, so we have issue an io request. it's not a direct addressable device. we have ask it load things into memory. then we talked about file allocations and how we have have a sort of a minimum of a block allocate a file, and we talked about contiguous. we talked about chained and then we talked about indexed allocation and then also along the lines of file allocation we talked about extents. and how we have keep track of the bookkeeping or where the blocks are in the different mechanisms. all these we add advantages and disadvantages associated with them. umm. and and why? ultimately, there is no one perfect solution. different file systems do different things. all right, well, after file allocation, we talked about this idea of a directory structure. or you could call it a folder structure. i'll put that in there because windows uses that and in there talked about name resolution on how we can go from a name is essentially a file path the data blocks for the file. alright, it given the name of a file and where it's located, where is the data block store? where are the data block stored right? umm. and this contract with an open why we need open close. uh, because of that? so that was by allocation directory structure and sort of metadata allocation. and then from there we talked about ohh free space free space management. so we talked about bitmaps, bitmap bit vector, bit field is really the same name, but i just called it that called. i use those words interchangeably and then i'll linked. and the advantages and disadvantages of doing all of that. ok. and then the last topic on file systems was consistency checking and fixing and the different algorithms we had for that. we had a duplication and then we also had the consistency checking where we where we checked the free list and the allocated list and went through different strategies for how fix up the consistency of the file system. umm, so i'll just call it. i'll just call it consistency."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","i use those words interchangeably and then i'll linked. and the advantages and disadvantages of doing all of that. ok. and then the last topic on file systems was consistency checking and fixing and the different algorithms we had for that. we had a duplication and then we also had the consistency checking where we where we checked the free list and the allocated list and went through different strategies for how fix up the consistency of the file system. umm, so i'll just call it. i'll just call it consistency. and i call it also call it allocation versus free checking. umm. and also in here we talked about why it is necessary. why this happens? blocks can fail. i know operations could fail, system could crash in the middle of doing multiple io operations. ok. and then we made it down here, is now today. ohh, i'd talked about well, i'll just put this in here. we talked about an actual example of that 16. so i do n't think i can put it all on one screen, but. uh, i think that's that's for the most part, what we talked about this semester, when you list it out like this, it seems like a lot, but it's enough. i think it's enough. i think we did a good job. of course i'm biased. i was up here in front of room, but it's the bottom of the hour. that was what i was hoping get through. so now is my my chance ask. what questions do you have? yes. so i guess in terms of what could expand my question format, are we just looking at quickly than those type of questions or multiple boys? sure. so the question is, what question format would it be? and the answer is along the lines of the quizzes. i'm, as you can imagine from boiler, i'm talking in class or asking on a quiz or even asking in a programming project. i'm big on why i'm big on knowing the advantages and disadvantages, tradeoffs. things like that. so just knowing what a file allocation or what contiguous allocation is might be nice, but knowing why it's not always perfect in all situations that has its advantages and disadvantages, and so why would you wanna use it? why would n't you? those types of things. so when it comes things like programming, i'm not gon na ask you write code, ok? that was i i"
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","i'm, as you can imagine from boiler, i'm talking in class or asking on a quiz or even asking in a programming project. i'm big on why i'm big on knowing the advantages and disadvantages, tradeoffs. things like that. so just knowing what a file allocation or what contiguous allocation is might be nice, but knowing why it's not always perfect in all situations that has its advantages and disadvantages, and so why would you wanna use it? why would n't you? those types of things. so when it comes things like programming, i'm not gon na ask you write code, ok? that was i i my like i said, my chance get ask you write code was all these programming projects that you either enjoyed or did n't. but you know, that was my chance have you write code. so that being said though, i might give you code and have you interpret it, where's the critical section here? how do i synchronize this, that kind of stuff right, without having actually write code? you could say you need a mutex lock here and here, and the reason is because of this right. that type of stuff where i give you code, but i wo n't ask you write code. other questions? yeah, the person you quoted, i answer your question. ok. yeah. oh, yeah. i so they answered so question is you know are we is the exam gon na be like some some some final exams. i know when i was in college, i would say, oh, the final exam is comprehensive, but because you had a midterm, i'm gon na learn more towards the second half of the semester's material. well, first off, we did n't have a midterm and i i'd like make sure a test your knowledge on on everything we covered. so what i like do, and i have not finished writing the exam, is i like go kind of like main topic by main topic and say let me ask you a question or two on this and a question or two on that, a question or two on that. so that's essentially the the plan. and like i said, it's gon na be like idea is, if i were staple all the quizzes together and give that you. but i know that would be way too long, so it's not gon na be that many questions, but that's gon na be along those lines. any questions? umm."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","so what i like do, and i have not finished writing the exam, is i like go kind of like main topic by main topic and say let me ask you a question or two on this and a question or two on that, a question or two on that. so that's essentially the the plan. and like i said, it's gon na be like idea is, if i were staple all the quizzes together and give that you. but i know that would be way too long, so it's not gon na be that many questions, but that's gon na be along those lines. any questions? umm. i'm thinking somewhere between 10:11, maybe something like that. drawing questions you may have draw something on there. can you have a drawing question? i would say do n't, do n't. do n't be alarmed see ohh look you want me draw something like i wanted me know what memory looked like. you wanted me know what a disk drives geometry looks like, or you know what what a particular type of memory map might look like, right? so yeah, certainly i could. i could see myself asking you something like that. other questions? yeah. well, the questions. be more granular or towards being parallel? i do n't feel comfortable asking that question or answering that question if that's alright it. other thing. ok. i will tell you right away because it's kind of a syntax related question, just like i wo n't ask you questions about writing code, i'm not gon na ask you questions about writing a big file, yeah. you have plenty of time practice, hopefully with making make files as part of your programming projects. other things, yeah, sure. i wish i could make this all on one page, but if i made the font smile and if you would be able see it. of our should i go? i do n't even know if i did this. our process, process, process, process, process, yeah. well, anything that's shared between parent and child. so if a parent opens a file descriptor, or as you learned from your tsh with pipes, if a parent pipes and creates file descriptors for the pipes, you have make sure that the child closes all of the ends of the pipes that it does n't need. so file descriptors are big one. apparently, child share matt shared memory. so if a parent shares maps shared memory, the child is required unwrap it."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","our process, process, process, process, process, yeah. well, anything that's shared between parent and child. so if a parent opens a file descriptor, or as you learned from your tsh with pipes, if a parent pipes and creates file descriptors for the pipes, you have make sure that the child closes all of the ends of the pipes that it does n't need. so file descriptors are big one. apparently, child share matt shared memory. so if a parent shares maps shared memory, the child is required unwrap it. so just like we have free the malex, we have close all the opens and all the pipes we have am on map all the m maps as a as a child. so yes, all that that type of stuff. yeah. i'll come back. christian. yeah. what happened if you have parent child who parent child process we share problems carter child x and then the file is strictly never closed. ok. so remember we mentioned that and we actually did that in the ttsh with pipes that filed the scriptors remain open across an exec, right? so that's where you did a dupe. you did a pipe and a dupe, and then an exec, and in that situation the file descriptor remains open and the child process executing a new program might not know that it needs close it. in that case, you ultimately trust that when the child process terminates, the operating system will actually clean up all those file descriptors. in that situation, there's really not a whole lot you can do have the child process clean up the open file descriptors, because the code that it would have known that they exist is gone. and so that's kind of an exception the closing of everything, is that yeah, there's really no way do that, but that's kind of what you end up having do. same thing with malex, although in that particular case when the child process execs it's address space is wiped and replaced with the new program. so as a result, any males that have been maligned would be implicitly free when the address space is rewritten. same thing with shared memory. other questions? yeah. of the system ball thing, i do n't really the user versus criminal. there's like no. sure, be happy too so. we have. our cpu is executing an instruction stream. alright."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","same thing with malex, although in that particular case when the child process execs it's address space is wiped and replaced with the new program. so as a result, any males that have been maligned would be implicitly free when the address space is rewritten. same thing with shared memory. other questions? yeah. of the system ball thing, i do n't really the user versus criminal. there's like no. sure, be happy too so. we have. our cpu is executing an instruction stream. alright. this instruction stream, if it's running a user process right, the cpu does not know that it's executing a process, it knows it's executing an instruction stream, does n't know the difference between one process or another, or between a process and the operating system. it's just doing a fetch, seeing an instruction that it needs execute, and it's executing that done. if a process needs execute or access some sort of operating system resource, right? something that the operating system is storing in os memory, things like information about itself or the file system, right? all that metadata that's storing the data blocks for a file is an operating system address space. so if we want have that process or that instruction stream that's currently executing access operating system resources, the only way do that is by asking the operating system do something. you could foresee a situation where a process just says i need it be privileged. so i'm gon na escalate my own privileges. but i mentioned that that's kind of like locking up all of the goodies in a safe and throwing the key on the floor and saying no. no, please do n't open that door. right. anybody that's coming along with that's not privileged could walk around, take up the key, open the lock the safe and get access all my goodies. i do n't wanna do that. i want allow them access the stuff that's in the safe, but they only want them access that on my terms. so what do they do instead? they ask me if they say doctor lembke or operating system. can you please go into your safe and get the information i needed and i will say ohh sure that process in real life is you asking a question of me do it and i do it for you in the cpu world that process is a trap. the cpu needs load operating system code, so in memory we have a region for the os. we also have all of the frames now for user process code inside the os."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","so what do they do instead? they ask me if they say doctor lembke or operating system. can you please go into your safe and get the information i needed and i will say ohh sure that process in real life is you asking a question of me do it and i do it for you in the cpu world that process is a trap. the cpu needs load operating system code, so in memory we have a region for the os. we also have all of the frames now for user process code inside the os. there is the os entry routine. when the system boots up and the operating system loads, i mentioned that in while we were going through that 16, there was a section of the hard drive say this is a bootable dr and the operating system is here. the firmware on the system loads the operating system. that operating system then is the only process that's running, and it's not even really a process. it just runs, the cpu starts executing the operating systems instruction stream, allowing the operating system set itself up. the set up the rest of the computer. what it does is it takes that os entry routine and it says cpu. if anytime a user would like request information from me, i would like you load that instruction and i will run and take care of it. so when this instruction stream runs, the system is running in. it's got our little mode bit. here it is running in user mode. if an instruction is encountered, that is something that is restricted like an instruction for accessing an io device, the cpu says i am not running in the proper mode. i ca n't execute that instruction, so i am going not let that work. that's why user processes ca n't access io directly. if a user process wants access an io device, it has ask the operating system. be an open fault or a read or write call. and so the instruction stream executes a trap. and that trap that we talked about was syscall. when the cpu. sees our syscall instruction. that syscall has a number associated with it. for what it wants, the operating system do. that syscall instruction says ah, i need enter system mode, but i'm not just gon na enter system mode and let that user processes instruction stream continue, because that would be a breach of security, a breach of isolation and protection. it will execute the system call by suspending the current instruction stream and loaded the operating systems trusted entry point. so it loads the os entry point."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","sees our syscall instruction. that syscall has a number associated with it. for what it wants, the operating system do. that syscall instruction says ah, i need enter system mode, but i'm not just gon na enter system mode and let that user processes instruction stream continue, because that would be a breach of security, a breach of isolation and protection. it will execute the system call by suspending the current instruction stream and loaded the operating systems trusted entry point. so it loads the os entry point. and continues executing the stream. now we're entering the os, but the system, the mode now is set the system mode. the only time will be allowed execute in system code is if we're executing os code we trust hopefully. now i'm running an escalated privileges and i'm running in system mode or kernel mode. i have access all of memory as virtual memory can be turned off in system mode. the operating system can access its memory as well as the memory for every other process. all the frames and it can retrieve whatever the user wanted, and here's what one of the neat things about privileges. if i have high privileges, i can choose give them up. if i do n't have high privileges, i ca n't just ask for them. i ca n't just get them. i can. i can. i can release them so the operating system when it's done doing its operation, accessing the disk or whatever load blocks for a file, it can then return. and as part of that return, the mode gets set back user mode and we continue executing the instruction stream associated with the process. but it is now continuing along executing in user mode. when user mode is turned back on, the operating system could turn on virtual memory and as a result the mmu is doing physical the virtual physical memory address translation and that process is only then that instruction stream is only allowed access its brains, it's user space, its brain, it can not access the operating system because the mu and the page table prevents the translation for that physical address. that's it. user mode, kernel mode, user space, kernel space. sounds a little more maybe, i guess like like the analogy of the safe. keep it feels like it goes like now. we can talk like the robot that's working on that. we have pick that up. so. so the process we're doing, hey, os make my privileges the fire and then do it."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","when user mode is turned back on, the operating system could turn on virtual memory and as a result the mmu is doing physical the virtual physical memory address translation and that process is only then that instruction stream is only allowed access its brains, it's user space, its brain, it can not access the operating system because the mu and the page table prevents the translation for that physical address. that's it. user mode, kernel mode, user space, kernel space. sounds a little more maybe, i guess like like the analogy of the safe. keep it feels like it goes like now. we can talk like the robot that's working on that. we have pick that up. so. so the process we're doing, hey, os make my privileges the fire and then do it. ok, so you do have a robot there? robot would be preprogrammed say i am not allowed do whatever you tell me. i'm only allowed do the stuff that i've been programmed with, and that's the and that's in that case, what the operating system is doing right? the operating system? yeah, it could be written in such a way, or it had system calls let a user process do whatever it wanted, but i would say that's not a good idea when you're writing an operating system, you should only write the operating system for doing the things that are that form the isolation and protection, right. so yes, yes, you could write it that way, but linux and windows and other operating systems are n't because they do n't want processes corrupt each other. that's what you're saying? there's only. the only of the team release the priorities that get them right, the way that we escalate our privileges is through a trap only loads operating system code is trusted. we ca n't escalate our privileges in any other way. that's a good question. this idea is kind of fundamental getting into the operating system world and so on. filtering you back other questions, i do n't know what time we get forced add here. i'm talking. yeah. so we're talking about signal and the product has set up in signal ending table. having it gets the signal that it is not self handled. that's not me. you know you can. alright, so we have that signal table and so there is, i do n't know 1819 or 20 something different signals that we could handle, some of them we are n't allowed install the sigma handlebar."
"""OpSys_FAT_and_Consistency_Checking_Transcript.txt""","filtering you back other questions, i do n't know what time we get forced add here. i'm talking. yeah. so we're talking about signal and the product has set up in signal ending table. having it gets the signal that it is not self handled. that's not me. you know you can. alright, so we have that signal table and so there is, i do n't know 1819 or 20 something different signals that we could handle, some of them we are n't allowed install the sigma handlebar. those two sigkill and sigstop. but if we do n't, then what happens is it follows the default disposition. we look in the man page for signal. it will tell you what the default operating system behavior is for all of the signals, and for most of the signals, the default behavior is terminate the process. something like this happens. something always happens. there are some that are by default ignored and that way you could say, well, nothing happens there because it's ignored. ok, the there are something that the the default is suspend the process and put it on a waiting field. see, now that we do all this stuff, we can understand. oh yeah, it just puts on waiting here. but for most of them, the default disposition is turning the process. yeah, because that's. this sticky that the ohh yes that was my plan. yes. yeah, probably. philip salaries. sleep. i will not be available. so question was will be available next week. i will not be available monday or tuesday, but i will be on site on wednesday. what i will do is i can update my calendar so that if you go into like the book of a book an appointment with me, you can see what powers on free and if you want know what i'm free, you can either book an appointment or send me a teams message, but i will be here on wednesday. i've got a bunch of meetings, but i should be in and out and then as well as thursday morning i will be available. i'll also be available thursday afternoon and friday, but i'm gon na go ahead and say that's probably gon na be irrelevant in most student. all right. well, i think we're out of time. thanks for coming and good luck. have a good weekend. talk you later. lembke, james stopped transcription"
"""OpSys_File_Allocation_Methods_Transcript.txt""","meeting in _ general_-20240429_130209 - meeting recording april 29, 2024, 6:02pm 48 m 53s lembke, james started transcription lembke, james 0:06 hello. hello. all right, so back canvas. let's review a couple of things here. so welcome. welcome operating systems week 14 was the file systems and we did a quiz on memory management. i'm still grading that, so i'll get that back you later this week. umm this week is file systems and review. so we're gon na finish up some odds and ends on file systems today and then on thursday, we're gon na talk about an actual, honest goodness file system out there that takes these concepts and actually builds something. and so we'll see how far we get with that. and then friday will be reviewed. i started umm, and i'll be adding this making a final exam review block in canvas so you can see that at the very bottom. so what i did is this is all of the blank quizzes that we had. no solutions, so if you wanna use those for practice questions, i've got the links up there the ai generated recording summaries and titles with the links all of the recordings in the two sections. so you can use that. i did put a note in here because i did n't want forget stop. so you can see that yes, you will be allowed in note cheat 1/8 and a half by 11 page handwritten if you wanna hand write it on a tablet right and print it out, that's fine, just not typed. actually like write it with your fingers and your hands both sides are ok prepared by you. they do n't. please do n't like get together as a group and then photocopy a note sheet. please make sure it's your own note sheet. ok. that's for the final. you can bring that with you. what review? on friday. so that's that, so. while systems let's we got a couple of odds and ends that i want finish up today on file systems and it has deal with in a way it's kind of meta if you remember the place where we ended up with last time was somewhere around here. this is the introductory slide, but it ultimately we work through file allocation and this was arguably maybe the more important part about files. yeah, but it it's just one piece of a file and that's the data associated with a file., when i think of a file that's really what i think of first, is the data."
"""OpSys_File_Allocation_Methods_Transcript.txt""","while systems let's we got a couple of odds and ends that i want finish up today on file systems and it has deal with in a way it's kind of meta if you remember the place where we ended up with last time was somewhere around here. this is the introductory slide, but it ultimately we work through file allocation and this was arguably maybe the more important part about files. yeah, but it it's just one piece of a file and that's the data associated with a file., when i think of a file that's really what i think of first, is the data. but today what i wanna do is talk about all the other stuff that goes along with a file system and how we can work on the fact that right, we've given this sort of thing in our lap, is a block oriented disk drive is block device. we have read and write blocks of data and ios have be accessed via a request. we can do direct access via memory and they're slow, and so we talked about different file allocation schemes and talked about advantages and disadvantages those. given those constraints that we do n't want it take forever for reading, we've got potentially a spinning disk with a read head that has move around, and so these were the three allocation schemes that we talked about, right? what i wanted do today is talk a little bit about file metadata, is up here. all this other stuff besides the data, things like file name, type, size, that kind of stuff, location. i want talk about the flip side. i guess you could say not really the flip side or the converse of file data, is perhaps a weird way of explaining it, but it is true if we have a disk drive that has blocks that we can use store data. we also in a way you might think take this for granted, but also in our disk drive need keep track of all the blocks that do n't have data on them. so i asked this why it given that information we just talked about block allocation, continuous chain like yeah continuous change and indexed. that's for where the data gets. why is it important keep track of where data is n't? yeah, you could search for them at the time, but that takes a long time since you do n't really know, you have go like every single block. but if you know where it is, you'd know how big and how. if itself. yeah. and that's exactly right."
"""OpSys_File_Allocation_Methods_Transcript.txt""","so i asked this why it given that information we just talked about block allocation, continuous chain like yeah continuous change and indexed. that's for where the data gets. why is it important keep track of where data is n't? yeah, you could search for them at the time, but that takes a long time since you do n't really know, you have go like every single block. but if you know where it is, you'd know how big and how. if itself. yeah. and that's exactly right. is that if a file system was static and i would say here's my disk drive with all of the files on it. tell me what files are on there. if i gave you the information or the map right, that file allocation table and said ohh this is using chained allocation and here's the file allocation table you could find where all the files are using that file allocation table. but file systems are n't static. they live. this had call like living things, but our system changes. we allocate more files, we delete files, we make files give, make files bigger. we make files smaller and this dynamic changing of stuff requires us either add or remove data from a file or from a file system, and as a result, when we specifically when we add data we need find a place put it and we ca n't override data that's already has data there. so we need figure out where data is free, where there's nothing stored there, and even that it's like, well, what is nothing. if we think of a disk drive that's spinning a magnetic disk, there's always something there. and it's really what's not being used right now for useful data. ok, so we have keep track of free space. we got ta keep track of metadata. the boring get there. i wanna talk about one other aspect of file system allocation for data allocation and that's extense and it's a pretty now say simple concept it it it is what it is. but if you look at our, let's just look at this continuous allocation, ok. the idea with contiguous allocation is you have a file that causes so many blocks and it has a starting block and a like. ok. and if we want allocate more data this file because of continuous allocation, we got ta most likely either. well, either move the file after it or moved the file itself a new place. so we can add more data it, right?"
"""OpSys_File_Allocation_Methods_Transcript.txt""","it it is what it is. but if you look at our, let's just look at this continuous allocation, ok. the idea with contiguous allocation is you have a file that causes so many blocks and it has a starting block and a like. ok. and if we want allocate more data this file because of continuous allocation, we got ta most likely either. well, either move the file after it or moved the file itself a new place. so we can add more data it, right? ok. chained allocation does something try and fix that, and that we can now put the file all over the disk. we just link all of the blocks together, right? and then index tries make this even make chain a little bit different in. while we still have links blocks, we do n't have all of them chained together. we have one block that should finds and says we're all the links are all the other blocks. ok. but i said that word a lot. that word. what word did i say block and that if a disk drive is a block oriented device, a file is allocated in terms of blocks? that's not always the case. umm, there is a concept called an extent, is what a lot of file systems make use of is. what they do is instead of allocating an individual block a file, they allocate it something different and they say ok what i'm going do is instead of allocating so these are extents. there's my disk drive instead of for a for a file. here's my fear. my blocks. ok. if i have a file here that's read and i need use, let's say four blocks. 012 and three extend the allocation says i'm gon na allocate blocks in groups. ok. so and essentially says i'm gon na take this idea. i really, really like the idea of contiguous block allocation. that's kind of cool, right? because not only does it keep the files all right next each other, it it makes it easier than because when i need do a read, i know that the entire file is right there and i can just read it all really quickly because it's just write one block after another. i'm spinning around. i like read my book my redhead once, so i like this idea of having a large number of blocks right next each other because i can read them all."
"""OpSys_File_Allocation_Methods_Transcript.txt""","that's kind of cool, right? because not only does it keep the files all right next each other, it it makes it easier than because when i need do a read, i know that the entire file is right there and i can just read it all really quickly because it's just write one block after another. i'm spinning around. i like read my book my redhead once, so i like this idea of having a large number of blocks right next each other because i can read them all. but i also like the idea of like indexed allocation and chained allocation, where file does n't always be right next each other, right? so what extent allocation does is it says instead of allocating an individual block a file i'm gon na in, i'm gon na allocate a grouping of blocks that are next each other, and that grouping of blocks is gon na be called an extent. so an extent essentially is light contiguous allocation. it consists of a starting block and a length. but then when i'm using one of the other allocation mechanisms like chained allocation chained right now, the way i've got it drawn links the blocks together. if you're using extent allocation, the chained allocation will link the extents together. that makes sense. ok, so if we did that, what we could do is say we are going allocate or blocks in the. initially we'll say this is going be 1 extent. and so we will say that this guy's extent starts at will make it interesting. we'll make it start at 012345. it'll start at 5 and it is 4 long, so this is 4 long, so that would mean that this extent goes from here this and this ok. if i need make this file bigger, right? what i could do is allocate another extent it. what's neat about extents is they're not always fixed size. i can make them as many blocks as i as my file system so chooses. ok, so i could allocate 2 more blocks and for that i'll just make another extent. there's block 4. here's block 5. here's one extent. this extent starts at we're going find a place put it, but we know it's too long and so maybe we'll put it here and here. so that would be 0123. that's 14 and 15, so starts at 14. there are 12345 and this is 1415. ok. so that's our extent allocation."
"""OpSys_File_Allocation_Methods_Transcript.txt""","i can make them as many blocks as i as my file system so chooses. ok, so i could allocate 2 more blocks and for that i'll just make another extent. there's block 4. here's block 5. here's one extent. this extent starts at we're going find a place put it, but we know it's too long and so maybe we'll put it here and here. so that would be 0123. that's 14 and 15, so starts at 14. there are 12345 and this is 1415. ok. so that's our extent allocation. and now from here then we could use index allocation and say that we are using an index but instead of an index indicating where all the blocks are, we have an index that indicates where all the extents start. ok. and then what we would do then is inside perhaps maybe the start of the extent we would have a special a block here or social part of this block at the very beginning we'd have some metadata that says this extent is for long. so we have a four in there and then here we have an extent here that would indicate that it's too long. not tv, olam, but the number 2 t wo. so far so good. makes sense. question. yeah, that's that's where the extent somewhere is. it also still like the ones with paired together well, and that's up you. there's a there's a tradeoff there, right? so inside the index block right now, if we look at index allocation. let me just pull it up in the notes because it's a better picture than what i could draw here. this index one just indicates the block where it starts, right? and that's because we only have one block. so and say the block where it starts and the block is it's unambiguous, it is just doubling right. if we were use this for extents, we could essentially make our index store 2 numbers, is the start of that extend and how long it is. we could also implement, but we still just store the start and at the extent, say how long it is in there. what is the downside? i think you're getting at. maybe i'll twist your words, but words in your mouth, though there is a downside of storing the extent length inside the extent itself, and also an advantage. once the disadvantage of storing the extent size of in the first block of the extent, yeah,"
"""OpSys_File_Allocation_Methods_Transcript.txt""","if we were use this for extents, we could essentially make our index store 2 numbers, is the start of that extend and how long it is. we could also implement, but we still just store the start and at the extent, say how long it is in there. what is the downside? i think you're getting at. maybe i'll twist your words, but words in your mouth, though there is a downside of storing the extent length inside the extent itself, and also an advantage. once the disadvantage of storing the extent size of in the first block of the extent, yeah, it's a lot like it's lost or deleted. you do n't know how many watts past it are associated with that sniper. ok, so file system consistency is a problem. yes. so yes, absolutely. if we lose the first block, we do n't know. but if we lose our index block, we also have a problem for the entire file, right? so consistency is still is still a big a big deal. and so i do n't want discredit that that was not the answer i was looking for. that's still mostly an answer i've been really think was an issue, but yeah i did. yeah, the first flight find out more gerrits,. yeah, you got ta do reading, right? that's the other thing, right? if i just store, i wanna find all the find how big this file is. i got ta figure out, and i got ta. i got ta go and read every single expense, first block. the how long you extents are but the the advantage of that is though. hi can distribute in a way where all the sizes are. i do n't. the store as much in the index block, right? not always said that the index block here the number of things i can store in here is limited by the block size, right? and so if i have one index block, i can only store right? if i'm using an 8 byte number in here and i've got 512 bytes, i can only store so many 8 byte numbers inside that index block, so that limits the size of the file. they'll make the store 2 numbers, or how big the where the accent starts. how big it is non limited even more. ok. and so that you could argue and say, well, ca n't use an extent for an index one."
"""OpSys_File_Allocation_Methods_Transcript.txt""","and so if i have one index block, i can only store right? if i'm using an 8 byte number in here and i've got 512 bytes, i can only store so many 8 byte numbers inside that index block, so that limits the size of the file. they'll make the store 2 numbers, or how big the where the accent starts. how big it is non limited even more. ok. and so that you could argue and say, well, ca n't use an extent for an index one. well, ok, yeah, that would allow you make the index blocks bigger. and so there's trade offs there and that's very expensive. kind of cool. it seems like it's a really simple concept and just say well now i have a variable length allocation right? and it is, and that's why it's used in a lot of file systems. there's allows us in a way make our index allocation or flexible, because now we can set that allocating one block, we can allocate a whole bunch of contiguous blocks. ok. other thoughts? questions about extents, we still had deal with this consistency thing. we'll come back that part. ok. alright, let's talk about free space. actually, let's talk about free space. yet i wanna talk about one other thing. file location ok. we mentioned that i would like put my files in category categorical groups right where i would like say all of my grocery lists are in one directory. all of my video game save files are in another directory, right? and then only that. but i would kind of maybe like have the ability do multiple levels of directories where i've got a directory called lists and inside the list i have another subdirectory for grocery list and another section called the do list and maybe above my list directory. i've got a directory for just documents in general where i'm going store all my files, right? and then in my saved games directory i've got all my different games because i've got a whole bunch of different saves for all my different ones, and i've got different games underneath there, right? so directory structure hierarchy is is important. so in i unix world, they're called directories or linux world. they're called directories and a windows world. they're called folders and still sim. still similar idea is that a directory is a special file in the data associated with that directory."
"""OpSys_File_Allocation_Methods_Transcript.txt""","i've got a directory for just documents in general where i'm going store all my files, right? and then in my saved games directory i've got all my different games because i've got a whole bunch of different saves for all my different ones, and i've got different games underneath there, right? so directory structure hierarchy is is important. so in i unix world, they're called directories or linux world. they're called directories and a windows world. they're called folders and still sim. still similar idea is that a directory is a special file in the data associated with that directory. with that file, i should say it that way is not like real data. it's not like text data and then went back. it's essentially pointers all of the things that are contained within it. what might those pointers point? well, it all depends on what your file system implementation is like. but if we think about how we're actually allocating things. right, like this, right? we got ta file allocation table because this is a a file name and it's starting block right the directory itself. might be. a file where it's data. might be a file allocation wait. let's think about that. what? do i need just one file allocation table for the whole file system? if i only had one place store all of my files, that makes sense, right? but if you think about it this way, if i've got 5000 files on my file system, right? i. maybe sometime i wanna know where all 5000 of those files are all at once, but as a human, if i'm using my computer, maybe i'll go down. that was it, not siri. what is it called cortana? there it is. on windows, search for for all of my files, but often when i wanna go through and find files in a particular way, i'm more concerned about files in a particular directory, not files on my entire file system. so when it comes a directory, right, this shows allocation for all of the files in the file system, but the directory itself here. we can have a master location, flight c colon or slash in a linux file system, but inside that the only thing that needs really be in there is the file allocation table for the files that are inside that directory. because i wanna double click it right on my c colon, have it open up and show me just the stuff that's in there."
"""OpSys_File_Allocation_Methods_Transcript.txt""","on windows, search for for all of my files, but often when i wanna go through and find files in a particular way, i'm more concerned about files in a particular directory, not files on my entire file system. so when it comes a directory, right, this shows allocation for all of the files in the file system, but the directory itself here. we can have a master location, flight c colon or slash in a linux file system, but inside that the only thing that needs really be in there is the file allocation table for the files that are inside that directory. because i wanna double click it right on my c colon, have it open up and show me just the stuff that's in there. i do n't really care what's in c colon slash windows slash system slash whatever. in fact, windows slash is n't want know what those are. i only want see what's in the sea colon record, so there is the file allocation table for those files and then if i double click on another one of those right, that would be a directory and then i wanna see the file allocation table for the files that are in that directory, the file names. makes sense. so if we did that right, let's just, let's just go there. ok, let's stop there and say like inside and directory is a special file, right? that where the file itself contains file allocation, the information for where the files that are contained within inside that directory reside what they are, what names are, and where blocks are. we could presume a world now where if i wanted find a file, if i knew where it was, i would have essentially start at the master directory and work my way down the tree and either a brent first or a depth first search. now i know this is not a data structures class, but you guys remember right, breton burst in depth first search hopefully. they get down my file. ok. so. question though. i want access this file and i want read and write it right, right. it's like. the process for finding the files data blocked, regardless of how the allocation mechanism is specified, indexed whether i'm using chained, whether using contiguous, whether or not. i'm using extents, whatever it's gon na boil down, i'm going get the data blocks for this file, and once they're in memory i can read and write them, right? but what happens if someone? clicks."
"""OpSys_File_Allocation_Methods_Transcript.txt""","i want access this file and i want read and write it right, right. it's like. the process for finding the files data blocked, regardless of how the allocation mechanism is specified, indexed whether i'm using chained, whether using contiguous, whether or not. i'm using extents, whatever it's gon na boil down, i'm going get the data blocks for this file, and once they're in memory i can read and write them, right? but what happens if someone? clicks. drags that file another place. it moves the bot ok what do i have do? i move one file from one directory another. knowing what we just talked about, what does it require? updating the directors ok. ready update the files databases. i see some handshakes. no, right. there's the file in that file allocation table, right? it's blocks are n't moving, only where it is, and so where it is, is it indicator inside the directory file allocation table. so i can see the move the entry for this file from one file allocation table another. ok. all right, that's step one, alright. that too. what happens when i delete a directory? that good? what? what? what do we wanna do for consistency sake? what? what right? looking through the lens of what we already know. file file systems. what do you do if you try delete it? delete a folder in windows. yeah, you know, you delete all the files inside of the perfect existence y setting. ok, right. my application my operating system is keeping track of the blocks from my file in memory and when i want do a read or write inside operating system memory, it is controlling the actual bits and bytes for that file and it's copying the data that i want write that file over memory so that ultimately after a while that information can get written back disk ok. if i file gets deleted while i am trying access that file. anything i try write that file while my process is running. is lost. i want do that because my application is expecting this file be there. it's accessing memory so. summary here is. searching a file system can take a while, so once we do that i do n't want this file. it's been moved around too much or be deleted, or have its parent directory deleted, or have its parents parents directory deleted because. once the immune system has a bound and resolve this file."
"""OpSys_File_Allocation_Methods_Transcript.txt""","if i file gets deleted while i am trying access that file. anything i try write that file while my process is running. is lost. i want do that because my application is expecting this file be there. it's accessing memory so. summary here is. searching a file system can take a while, so once we do that i do n't want this file. it's been moved around too much or be deleted, or have its parent directory deleted, or have its parents parents directory deleted because. once the immune system has a bound and resolve this file. manipulating and changing it for such a, making it go away and cause my application essentially have undesirable effects. so and the world all. open and and pointers. so what i wanna do here? is go down this ok. accessing the disk drive is costly. searching a directory for searching for a file with inside the directory structure can also be costly because every single time i need access and directory and read the data directories blocked or it's file allocation table that takes time. once i've done that, i do n't want it change and move around much. because it's gon na cause inconsistencies in my data, my data is gone. no, does n't wanna be gone. so solution here is what the operating systems typically will do is they will do a search for file metadata, store that in memory and because now we have an inconsistency here, we have noticed an inconsistency. but we have two places, right? we have memory. nope. let me use a different color. let me try and explain this a different way. here we have memory. we have distraught. here is my file on the disk, ok. the representation of all my files blocks ok. here is the cpu. ok, access the disk drive, i keep saying this over and over again. takes a long time, right? so what our operating system will do for performance reasons? this says cpu is take the file once it searches the directory. on linux this is called a name lookup is i have a file that i wanna access c colon slash my users, lunky, documents, onedrive, whatever. all deep in the directory structure and it's gon na find while searching through all of the directories metadata file allocation tables 4 where the blocks are for my file. he will take this file and it will most likely maybe not grab all of it, but it will cache a certain amount of this file in memory once it binds the data blocks."
"""OpSys_File_Allocation_Methods_Transcript.txt""","this says cpu is take the file once it searches the directory. on linux this is called a name lookup is i have a file that i wanna access c colon slash my users, lunky, documents, onedrive, whatever. all deep in the directory structure and it's gon na find while searching through all of the directories metadata file allocation tables 4 where the blocks are for my file. he will take this file and it will most likely maybe not grab all of it, but it will cache a certain amount of this file in memory once it binds the data blocks. and now, just like dirty fits in paging, i had two copies of this file. i have one copy that's in memory and one copy that's on disk, right? if some other process comes around and says this file needs be deleted because i do n't want this file anymore, i have n't consistency. i have a file that's cached in memory and a file that's on disk, and if a process continues keep writing this file, a happy days as soon as that process terminates. if the operating system tries write this back this, then file is gone. of zant, correct. we want make sure that this consistency is maintained until everybody using this file is done with it. ok. and this is the reason. the one of the reasons for this idea of a contract? why we have open a file first? if you look at the way we're we've we've talked about files descriptors, right? we do an open read and write and then it close and you might look at that and say why do we have do this open? why do n't we just do reads and writes and specify the file name every single time and say operating system right my file operating system write file file? here's the file name, but instead we do an open. we've got this file descriptor table thing. we've got all this is the bookkeeping that the operating system is keep track of, right? we got this file position pointers. it seems like a lot of work, but it's because of this inconsistency potential. the operating system is gon na search the directory takes forever and it does n't wanna have do that every single time. i wanna do a disk io. i want be able find where the blocks are for this file and store them in memory so that in the future i can just say ohh the user wants write that file. i know where those blocks are, i'm just gon na write it directly."
"""OpSys_File_Allocation_Methods_Transcript.txt""","we got this file position pointers. it seems like a lot of work, but it's because of this inconsistency potential. the operating system is gon na search the directory takes forever and it does n't wanna have do that every single time. i wanna do a disk io. i want be able find where the blocks are for this file and store them in memory so that in the future i can just say ohh the user wants write that file. i know where those blocks are, i'm just gon na write it directly. that of all i give, the operating system is a name now every single time i do a write, the operating system has do an exhaustive search through the directory structure find where the blocks are for that file, and that takes a long time. that makes sense. thumbs up. so once we search for the file, we grab the blocks. just cash them, we cash the idea of them in memory and this is done via an open and an open, then is what keeps track of that reference count inside the file descriptor table. i've ever do n't forget that, so that if somebody were try and delete that file, the operating system will say no, i'm sorry, you ca n't do that because somebody has an open reference count that file. and on windows it will just say another process is using this file. you ca n't delete it. you ca n't move it, and that's because we do n't want the data for this file change around on disk while it's currently being cached in memory and we do n't wanna not cache it in memory because the search for this file every single time we do an operation takes forever. so that's our solution that. right. all right, directory and file locations. ok. questions. right. let's move on free space management now that we talked about file allocation and file location and file resolution. incidentally. there are also other special files. you're afraid of shortcut in windows. i did this because i wanted play around with it is i made a file called test called text test dot text and slept it blank and made a shortcut it. and on windows you ca n't do this, can you right click on a shortcut and go open or edit if you want. like, really. see what that shortcut really is? windows wo n't let you. it'll automatically resolve it its target and just give you access the target. but with wsl we actually get 2 files."
"""OpSys_File_Allocation_Methods_Transcript.txt""","you're afraid of shortcut in windows. i did this because i wanted play around with it is i made a file called test called text test dot text and slept it blank and made a shortcut it. and on windows you ca n't do this, can you right click on a shortcut and go open or edit if you want. like, really. see what that shortcut really is? windows wo n't let you. it'll automatically resolve it its target and just give you access the target. but with wsl we actually get 2 files. we actually have a test dot txt and a test dot txt dot lnk is kind of like a windows internal special file and we can use that see what it is and if we use something like hexdump. we can see that. what hex dumps does? is it dumps out the contents of a file in hexadecimal, and if we do dash c, it does the translation of what that might look like and se characters as well, and so actual shortcut in windows is just data, but that data itself, if we look over here on the right, you can see that somewhere down here shows that will actually points a directory location for the actual target file. so this shortcut probably has a bunch of other things in it that i do n't know if you'll look up what it actually like file format is, but that's just one thing i wanted show you is that a directory as essentially a special file that contains file allocation entries for the files contained within it, a link or a shortcut in windows, and a link in linux contains information about a target file, but not billy data associated with that. and then the target files themselves are just regular files. i know you could do this in linux. i do n't know how you can do this in windows, but in linux you can actually make a shortcut or a link another link then links another link. so that makes actual like file name resolution even more complicated because not only now do i have search the directory for something, i have look at the at that file in the directory and see if it references a link and resolve where that link points. look at the data blocks. questions. nothing. interesting question. resolve this file anyway, alright. let's talk about free space. here's my disk drive so. let's allocate some blocks. there's one file. there is no one. there's no. and then maybe i'll use black."
"""OpSys_File_Allocation_Methods_Transcript.txt""","so that makes actual like file name resolution even more complicated because not only now do i have search the directory for something, i have look at the at that file in the directory and see if it references a link and resolve where that link points. look at the data blocks. questions. nothing. interesting question. resolve this file anyway, alright. let's talk about free space. here's my disk drive so. let's allocate some blocks. there's one file. there is no one. there's no. and then maybe i'll use black. we've got a couple of blocks that are allocated for managing file system information. where the file allocation table is for the master or root directory and and so on. so. we have blocks that are free, or maybe we're using extents that are free. either way, more or less we got. let's just go back and blocks make it simple. we got blocks 3 - 4 and then these three down here that i ca n't recommend the numbers for what we know about file allocation. how do you want manage free space? what do you guys think? we ca n't use contiguous free space allocation, free space management, free space monitoring, because we have files in there. yeah, you index this treatment back, ok, in index of all the free blocks. index of three blocks. i like that. what is that? what would that indicate? well, i guess we would have a list. and inside that list, what consists of a bunch of numbers. so we would have the number 34. 1213 and 14. so along those lines i like that. how many blocks might i potentially have free? ok, the answer is it depends the the the corporate answer it depends on. how big my drive is, right? so i have a one terabyte drive. how many blocks do i have? a lot. let me ask you this how big would n't you? these numbers need be reference all those blocks. 8 bytes 4 bytes. well, let's see. 4 bytes allows 32 bits. allows me reference what i think it's $ 30, four giga blocks, so i can just block me 512 bytes, like quite a quite a tb, right? but i do. ok, so what i'm getting at is if we were store this as a number, that means stephanie list potentially of all of the numbers that we have store that are free could be pretty big. ok, so."
"""OpSys_File_Allocation_Methods_Transcript.txt""","these numbers need be reference all those blocks. 8 bytes 4 bytes. well, let's see. 4 bytes allows 32 bits. allows me reference what i think it's $ 30, four giga blocks, so i can just block me 512 bytes, like quite a quite a tb, right? but i do. ok, so what i'm getting at is if we were store this as a number, that means stephanie list potentially of all of the numbers that we have store that are free could be pretty big. ok, so. we can do something different though. instead of storing an index of free blocks. why do n't we store our bitmap or some people call them a bit vector or a bit field? instead of referencing the number, what i can do is just store 1 bit and say if the bit we look at bit 0123 whatever. if that bit is one, we know that block is free. if it's zero, we know it's allocating. so in this particular case, now with this dry, i do n't have the store 16 eight by numbers, i can just store 16 bits. that's a lot smaller. and so in this particular case, if i was using not indexed allocation or block management, but bitmap management, i would have a bitmap of. let's see 0001100000001110. and suddenly the actual number that i would need store inside my free space manager is essentially that 16 bit number. if that's a big by join was ok. so advantages of this. it's pretty quick find a free block right. we want make sure that we keep this thing efficient. if i wanna allocate a block a file, i got ta find a free block, right? that was what comment it said. what? why do we need check if free space? we need keep track of free space because we wanna make sure that we can allocate more stuff files later on. so if we can find the next three block really quick, that's awesome. ok, i could just scan through this. these bits are small, they fit in memory pretty pretty easily, and it's pretty easy for me find the net free block. yeah. downside. it gets back my original statement. i'll we were scoring numbers, that's a lot of data. we have start. actually did the math here because i got it on my on my slide. ok, you have a buff. there's no it's on the next one."
"""OpSys_File_Allocation_Methods_Transcript.txt""","so if we can find the next three block really quick, that's awesome. ok, i could just scan through this. these bits are small, they fit in memory pretty pretty easily, and it's pretty easy for me find the net free block. yeah. downside. it gets back my original statement. i'll we were scoring numbers, that's a lot of data. we have start. actually did the math here because i got it on my on my slide. ok, you have a buff. there's no it's on the next one. sorry, this is managers in we need store all of the bits and it's probably advantageous read all of the free space in the memory and not have this be living on the disk because now anytime we had changed the size of any file, we have do a disk write that takes a lot. so umm, if we're using 512 byte blocks for a one terabyte hard drive, that's that many bits approximately 2 * 10 the 9th bits, is about 250 megs of memory for the bitmap. ok. and you might look at that and say i thought jim, 58. i've been good money for this memory, right? i do n't wanna have the operating system sucking it off all sucking all of it. that's for one one terabyte drive, right? and so ok. and i'm not gon na be like, you know, this this stalgia guy, but the very first computer that i took with me college at 64 megs of memory. i do n't want it all use up for bitmaps for, but you know how much free space i have on my hard drive so. what else can we do? well, that's. yeah, i think it's split up the big maps. so searching the range of over blocks of each and then you do n't have other wants. let me split off the bit map so i could see that. ok, so maybe if you then have multiple bitmaps and so if you could find a free block in the first one then you do n't have worry about reading the next one. ok. and that would be interesting idea. i never thought of all that. umm, but it actually is along the lines of the of my other allocation mechanism that i wanna talk about."
"""OpSys_File_Allocation_Methods_Transcript.txt""","so searching the range of over blocks of each and then you do n't have other wants. let me split off the bit map so i could see that. ok, so maybe if you then have multiple bitmaps and so if you could find a free block in the first one then you do n't have worry about reading the next one. ok. and that would be interesting idea. i never thought of all that. umm, but it actually is along the lines of the of my other allocation mechanism that i wanna talk about. you might say arguably that you would end up reusing the same blocks over and over again if you're a lot of allocations and freeze, and so if you are trying prevent like drive where where if you read and write the same block more often, you might wear it out quicker. but that's interesting, interesting thought. yeah. the one that i have in here is more related or more along the lines of the memory manager programming project where in the memory manager or in chained allocation all i need store and chained allocations is essentially the first block of the file and then if i read that block i can get the next one by looking at the the link the next one and the chain late free block management says instead of keeping all track of all of the free blocks, all i'm gon na do is keep track of the first free block. three block list begin. begin name and you can say alright, the first free block is block 3 done and then three the last little bit of it would have a number indicating the next free block and then this guy would have a number here indicating the next play block and this guy would have a number here indicating the next free block and this guy would have this and then this would have an indicator that says i am the last free block. and that is linked block management. what i like about this well. it's easy find a first free block right there. but just like what chained allocation? in order find all of the free blocks, i have traverse the whole list. ok, that kind of stinks. if i wanna find lots of free blocks, i'll find where all of them are, and the downside is if one of these free blocks breaks. now i've lost half of the free space on my my hard drive. so silver bullet. so there really is no silver bullet in a lot of the file systems that i've worked with."
"""OpSys_File_Allocation_Methods_Transcript.txt""","it's easy find a first free block right there. but just like what chained allocation? in order find all of the free blocks, i have traverse the whole list. ok, that kind of stinks. if i wanna find lots of free blocks, i'll find where all of them are, and the downside is if one of these free blocks breaks. now i've lost half of the free space on my my hard drive. so silver bullet. so there really is no silver bullet in a lot of the file systems that i've worked with. a lot of them use bitmaps for for doing free space just because it's it's. it's quick and easy find, and it in a way i do n't have worry about this problem with failures now if the bitmap is lost, i'm still stuck. that gets back into the consistency in general, but that's typically what i've seen. no. book wise, this is a better picture here. when we got deeper free space side right takes time. sure. it's the priest. slice blocks if block breaks, the chain is lost. no. ok, so you're talking i would. where else are we out here? ok. the last topic for this i think it will stop with this after today is performance and talk a little bit about consistency next time and then we'll move on so. but i did mention this that this guy always taking a long time, right? compared like accessing memory ok. so. the operating system, just like with memory, when it comes file systems, tries keep tries take advantage of. i think i mentioned this word of spatial locality or temporal locality. remember number? what those words meant? number spatial and temporal locality. temporal time wise, meaning time. meaning that if right, this is the motivation for the least recently used paging algorithm, that if i wanna access a memory page now, chances are i'm gon na need it again very soon in the future. so operating system please do n't get rid of this page because i need that right spatial locality is if i'm accessing a page, chances are i'm going access a page very close it pretty soon, because if i'm executing code it's like a book most of the time, unless i do a jumper, a branch, i execute it from top bottom. files are similar way and that if i wanna want access a file members are."
"""OpSys_File_Allocation_Methods_Transcript.txt""","meaning that if right, this is the motivation for the least recently used paging algorithm, that if i wanna access a memory page now, chances are i'm gon na need it again very soon in the future. so operating system please do n't get rid of this page because i need that right spatial locality is if i'm accessing a page, chances are i'm going access a page very close it pretty soon, because if i'm executing code it's like a book most of the time, unless i do a jumper, a branch, i execute it from top bottom. files are similar way and that if i wanna want access a file members are. if i'm accessing a block with inside the file, i'm gon na need that block again very soon, and also if i'm accessing a block inside my file, chances are i'm gon na need use the next block also fairly soon, right? so while our operating systems often will do, is this essentially? this picture here and i mentioned already, and i'll just reiterate this. this idea of a cache and so if i'm accessing a file when i open a file and i access the first block of that file, my operating system is probably not just gon na access the first block. it's probably gon na read a whole bunch of blocks because they have issue an io request read a block of that file. it's just gon na just gon na get a whole bunch of them because james azar, the memory that i'm using in my system, i'm not using all of it. so if i'm not using it right now, i might as well use it for something so they operating system says we'll just fill it up with files and we'll cache it. furthermore, when i do a write, the operating system is n't gon na write that this file in memory and immediately write it disk. and fixed time. what it's gon na do is it's gon na write it memory and then later on, if it's got nothing else do, people flash this stuff out get out of my out the this later on. this idea essentially uses memory as a big file cache. and i could tell by the by the way things are going here, i think i'm out of time. so we might talk, come back, come back this next time. but for now, let's stop there. thanks for coming. lembke, james stopped transcription"
"""OpSys_File_Systems_Intro_Transcript.txt""","meeting in _ general_-20240425_130429 - meeting recording april 25, 2024, 6:04pm 43 m 47s lembke, james started transcription lembke, james 0:08 hello. hello. alright, so here we are. welcome operating systems. i got the recording going. let me go canvas here. that's my email. let me go canvas here. where are we at right now? quiz tomorrow. i've never management alright, notes file systems. that's all right. that's if you can remember all the way back tuesday. no, it was monday. we were doing this stuff and i was motivating. at this picture that. we have find a way as an operating system learner, developer, designer, whatever you want refer it as figure out how handle the situation where we have all this io hardware and we wanna deal with persistent storage because when our users turn computer off, everything that's in the cpu and that's in memory is gone and we wo n't need a way for things persist. and the way we do that is we putting persistent storage. and the way this is hooked up makes a little bit more things a little bit more difficult for our applications in that these applications are executing instructions on the cpu, is the load store instruction architecture. and so the cpu has access data via load and store that data is gon na come from memory cause that's what it's hooked up through this high speed controller, the cpu does not have a direct way access a disk drive and say load from the disk drive. so if i wanna load from a file. i need help and that operation that's required do that is by issuing an io request the io device take data off of this device and load it in the memory because that's the only way that the cpu can access data is through memory. that's the first piece we have this io request that we have deal with and we do n't really, at least from my perspective as an application developer, i do n't wanna have know how build an i / o request. i do n't want know the serial ata protocol. i do n't wanna know the other protocols that are available are or different hard drives. scsi is another one. i just do n't want have know what that is. i want have the operating system do it for me because i wanna be able just read a file cause that's what i do as a human, i open up a book that i read it. i do n't have figure out well, how do i print this book? how do i"
"""OpSys_File_Systems_Intro_Transcript.txt""","i do n't want know the serial ata protocol. i do n't wanna know the other protocols that are available are or different hard drives. scsi is another one. i just do n't want have know what that is. i want have the operating system do it for me because i wanna be able just read a file cause that's what i do as a human, i open up a book that i read it. i do n't have figure out well, how do i print this book? how do i i i open it right? i open the book that i read it ok, so after that also these devices because they're so slow our block oriented, you ca n't read and write a byte. so for my application i really wanna access persistent data as its bytes it's data. and array of bytes of device. here is an array of blocks and adding more fuel the fire. i have store any number of files on this in one array of blocks, so i got ta figure out how organize that data so that we do n't have situations where one file is in the middle of another one or something like that, right? this is what the physical aspect of it is, and virtually or logically, i would like my application be able do this. access a file as an array of bytes, a bunch of data. i'd like be able classify that data right raya bytes 1 file. i'd like also be able classify my biles in grouping by category, right? all of my grocery lists are gon na go in one location. all of my documents for maybe operating systems class goes in one place. all of my images that i took on my family vacation and like put them in one place right, a grouping of files together. they could make it even even more deeper. it'd be really kind of cool if i could have a photos directory and then inside that directory have like summer trip disney world. and you know, fall trip cancun and whatever, right. and that have this the pictures for that neither further categorized in there. so directory hierarchy. i'd like the group things together, ok? and then we had more fuel the fire and say ok, now i have a file is a bunch of data, but i also like data about the data. i'd like be able name my files. i'd like be able know when i last accessed them. i'd like be able know what file type they are."
"""OpSys_File_Systems_Intro_Transcript.txt""","and you know, fall trip cancun and whatever, right. and that have this the pictures for that neither further categorized in there. so directory hierarchy. i'd like the group things together, ok? and then we had more fuel the fire and say ok, now i have a file is a bunch of data, but i also like data about the data. i'd like be able name my files. i'd like be able know when i last accessed them. i'd like be able know what file type they are. i'd like be able know if i can like be able lock out others from my computer so only i can read my files instead of somebody else's things like that. i'd like be able know how big my files are. and i'd like be able do a bunch of operations them, right. data is one thing, but i got ta be able read it. i got ta be able write it. i got ta be able move things around. i got ta be able modify this metadata and you know, i got ta make sure that i applied tonight files fail get bigger and smaller. all right. so in there we talked about changing permissions, move, delete, rename. another one that i did n't mention that i'm gon na put on here right now is truncate. truncate is a another word of make it smaller. ok. all right, so. let's go and go the notes here. and i took a look and we looked at some of these before and just kind of the data as far as what a file is. the devices are blocked oriented, we've got hd's and ssd's are but now sd's are faster, but still pretty pretty slow compared the cpu and. the next thing i want talk about is. file allocation under the assumption that the operating system is going take care of all of these io requests and abstracting that away. ultimately, the operating system is gon na has deal with the situation where we have an array of blocks, not an array of bytes, and blocks are typically 512 bytes. and these blocks we need use allocate 4 files. we have hundreds, potentially thousands, of files that we need put on this drive, and we got ta organize this data alright. files on the same size they can grow and shrink during life. they can be deleted. they should be able be organized in a hierarchy. we got ta handle that. and so let's take a look at some solutions."
"""OpSys_File_Systems_Intro_Transcript.txt""","ultimately, the operating system is gon na has deal with the situation where we have an array of blocks, not an array of bytes, and blocks are typically 512 bytes. and these blocks we need use allocate 4 files. we have hundreds, potentially thousands, of files that we need put on this drive, and we got ta organize this data alright. files on the same size they can grow and shrink during life. they can be deleted. they should be able be organized in a hierarchy. we got ta handle that. and so let's take a look at some solutions. and that's the topic of today, is how knowing what we know now and this background of files, not files but io devices. let's try and look at it through the lens of just the hardware and io request a block or a bunch of blocks. how do we organize our file? right, so let's get these paper. let's drop picture. so first one contiguous allocation. sort of naive approach, but it works. i can focus is a little bit better, yeah. now, how is it gon na work? we have our disk drive ok. contiguous allocation. ok, so i said it's an array of blocks, so we got ta draw some blocks. this is what we're kind of given by the device. i'll draw a bunch of dots on here, because if these represent 512 point blocks, chances are we probably have a lot more than 16. if you look at a drive that's like a tb, you take a tb divide by 512. that's a lot of blocks, so these are the blocks and they're given a number for do as logical block address an lba. ok. and so in this particular case, this would be blocked. zero. this is block 123 and so on, ok. and the idea with contiguous allocation is just that. we have a file and it's gon na have data, right? we need allocate storage that file and so what we're gon na do is, well, let's first off get some files. so i'll make a couple files. here's a blue file a. its name is a and it's gon na consist of two blocks, zero and one. here's a green file b and it's going be 3 blocks. 01 and two. and then we have a red file c will be pretty big."
"""OpSys_File_Systems_Intro_Transcript.txt""","we have a file and it's gon na have data, right? we need allocate storage that file and so what we're gon na do is, well, let's first off get some files. so i'll make a couple files. here's a blue file a. its name is a and it's gon na consist of two blocks, zero and one. here's a green file b and it's going be 3 blocks. 01 and two. and then we have a red file c will be pretty big. well, in the in the grand scheme of things, just a little bit bigger than the other 201 - 2345 and six. so it's gon na be 7 blocks, ok. question. the minimum block size or other double lock size on our hard drive is fixed. it's typically 512 bytes. it could be bigger. different operating systems might format drives in a different sector or block size, but they're typically 512 bytes. some now drivers are getting be bigger than maybe 4096 bytes, but we have a fixed block size, but whatever that number might be right? so question, what if i ever file that is 8 bytes long? i've got a really short grocery list. i've got ta file. it just says hello world. then i say that. what do i do? how do i? how do i? how do i? how do i store that it's smaller than a block? and actually, maybe i'll make that more generic. what if i have a file that does not exactly equal the size of an exact block and ending number, so i've got a file that might be 800 bytes. yeah, you like that? dear, just make it that big, right? so at 8 by file now uses a minimum of 1 block. a800 byte file uses two blocks. we just round up the nearest block size. ok. we kind of have do that. we're kind of stuck now. you look at that and say, well, that's wasted space. yes, it is wasted space. here is one advantage keeping our block sizes small disadvantage of keeping our block size as small is if we have read them in a block unit, we can actually tell the drive read multiple blocks that are next each other. but if we have read a lot of blocks, that's gon na take longer read. so hopefully the idea is we can find a good, happy medium between wasted space and iota."
"""OpSys_File_Systems_Intro_Transcript.txt""","you look at that and say, well, that's wasted space. yes, it is wasted space. here is one advantage keeping our block sizes small disadvantage of keeping our block size as small is if we have read them in a block unit, we can actually tell the drive read multiple blocks that are next each other. but if we have read a lot of blocks, that's gon na take longer read. so hopefully the idea is we can find a good, happy medium between wasted space and iota. but with the hard drive, i feel like it's less concerning than than it's something like memory, where a tb of hard drive space is not nearly as expensive as a tb of memory space. so if we waste hard drive space, ok, it's debatable. it's not great, but it's not as bad as if we waste memory. sounds good. alright, so round up the nearest science. so with contiguous block allocation, here's what we're gon na do. the operating system is going consume some blocks as overhead. ok, what does that overhead gon na be? it's gon na be for something i'm gon na refer for now as the fat, the file allocation table. so on some block there will be a our location that will consist of the file allocation table. i can write this correct file now location table. this will consist of some metadata about where these files are, kind of like a map, ok. and then from there, we'll worry about what's in there in a second with contiguous allocation. what the operating system will do is it will just lay out the files in it continuously. so lock zero and block one of the blue file will go there block 01 and two of the green file will go there and block 012345 and six of the red file will go there. so what do we store in the file allocation table? will we store the file name in this case? i've got ab and c some identifier of the file. then we also this we have the name, we have the. starting block. this says that a we'll start on block one. b starts on block 3 and c starts on block 0123456 and then we have the block count. and it says that a is 2 blocks, b is 3 blocks, and c is. when i say seven blocks. and that's it. so now if we need read the file, say i wanna access file a"
"""OpSys_File_Systems_Intro_Transcript.txt""","i've got ab and c some identifier of the file. then we also this we have the name, we have the. starting block. this says that a we'll start on block one. b starts on block 3 and c starts on block 0123456 and then we have the block count. and it says that a is 2 blocks, b is 3 blocks, and c is. when i say seven blocks. and that's it. so now if we need read the file, say i wanna access file a i go the file allocation table and find i wanna read file a and this information says file a is on block one and it's two blocks long. so the operating system can issue an io request say, load two blocks starting at block one, load that into memory for me and let me know when you're done, and then i'll let the application access file. like this? i like this. yeah. nice. what we like about, ok first off. it's pretty quick find where a file starts ok. right part 2. i know that especially for like a spinning disc. ok, this is where the where the advantage of continuous block allocation is pretty awesome for a spinning disk. if i want read the files, i do n't wanna have be jumping all over this drive because i got ta move that read head in and out right? and that takes milliseconds move the thing. it's a spring. it's got ta go back and forth. and then i got ta wait for that head that disk spin around underneath it. the disk spin pretty fast like 10,000 rpm. ok, that's pretty fast. and so the idea here is that if i can keep that file contiguously really close together, i can get that red hat in the right spot, and then the rest of the file will just like spin right back past the redhead. like, really fast. and i can read those. it's still gon na be a lot slower than memory, but it's gon na be a lot faster than if the blocks were all over the drive. ok, so i like that the second thing that i like is i do n't the whole store a whole lot of metadata, right? this data here is overhead. i paid good money for my drive. i do n't wanna waste drive space. ok, a tb of hard drive space is a lot cheaper than a tb of memory, but still i do n't wanna waste it. i'd like keep my waist low."
"""OpSys_File_Systems_Intro_Transcript.txt""","it's still gon na be a lot slower than memory, but it's gon na be a lot faster than if the blocks were all over the drive. ok, so i like that the second thing that i like is i do n't the whole store a whole lot of metadata, right? this data here is overhead. i paid good money for my drive. i do n't wanna waste drive space. ok, a tb of hard drive space is a lot cheaper than a tb of memory, but still i do n't wanna waste it. i'd like keep my waist low. ok, those are good things, ok. so what's the trade off? what do n't i like about this or what? do n't you like about this? think about file operations. yeah, right. growth, yes. how do i make a file bigger? i said that i need be able do that, so we ca n't in a way. it would be really kind of nice and i could imagine an operating system doing that this say ok applications, i will give you this file system and it'll work really cool. it would be pretty fast, low overhead, but by the way, all of your files need be. you have tell me how big the files are and you ca n't make them any bigger or any smaller throughout the course of lifetime. now, in some situations that's ok, but in other situations not so much. so that's one concern, but how could i actually allow for a variable size file in this system? so i wanna make file a smaller. i wanna truncate. i do n't wanna truncate it from two blocks one block. can i do that? how do i do that? what steps do i need? yeah, i mean, i guess you can remove any blocks that are n't needed anymore for data would either leave just an empty block or you would maybe shift every block over. ok. did n't want him these things. i like this couple. couple of things that were said, if we wanna make this guy smaller, let's just show that what i could do is say i wanna remove right and this is what's kind of interesting is what i did say. well, what if i wanna remove from the beginning of the file, right? i wanna truncate it from the beginning. well, for all intents and purposes, i do n't really know what the data is in here."
"""OpSys_File_Systems_Intro_Transcript.txt""","ok. did n't want him these things. i like this couple. couple of things that were said, if we wanna make this guy smaller, let's just show that what i could do is say i wanna remove right and this is what's kind of interesting is what i did say. well, what if i wanna remove from the beginning of the file, right? i wanna truncate it from the beginning. well, for all intents and purposes, i do n't really know what the data is in here. i really only consider with how much storage is needed, so even if i removed the first block, conceptually it's still just a one block file, so i could still call it block 0. so if i want remove this and reduce it, what i could do is just this. say i'm gon na free this and make this only one block. ok, so i can just delete this free it up. and then down here the allocation table would say ohh the starting block is still one, but the block count is no longer two. it's now one not. ok, i have a hole and you could say, well, that's fragmentation. yes, i've got a fragment in here that's an empty block. but say for example, in the future i have another file that i wanna create that only needs one block. i can put it there or if later on i want make this bigger, i can make it bigger, allocate that block. so yeah, it's not the greatest have a whole, but it's not the worst either. the problem becomes, as you mentioned is. what if i want make file 3 or file b bigger? what do i got ta do? i ca n't put a block here. if you really cool say, let me just allocate this slot right here next file c because what i'm storing is continuous allocation. i'm blocked for this file down here is not contiguous. no. when i got ta do is well, i could shift this file over. that's gon na take some work because i got read every block and then write every block in that file. or i guess i got ta have do this? i could take this file here and move it the end liao, have 16 blocks here so it does n't really under the assumption i have more blocks right?"
"""OpSys_File_Systems_Intro_Transcript.txt""","if you really cool say, let me just allocate this slot right here next file c because what i'm storing is continuous allocation. i'm blocked for this file down here is not contiguous. no. when i got ta do is well, i could shift this file over. that's gon na take some work because i got read every block and then write every block in that file. or i guess i got ta have do this? i could take this file here and move it the end liao, have 16 blocks here so it does n't really under the assumption i have more blocks right? i can just move that and write and then add it at the end and then when i do that i have update where in the file allocation table where that file is located. what is doable but problem with this really is the moving. it's a relatively large io request. ok, these are small in terms of blocks, but if i have a file that's two gigs, i might take a long time move a file around. so in in a way that's kind of the downside of contiguous allocation, i like the advantages here because the files are all like really murre, each other, and it really easy read low overhead as far as what storage is concerned. but making a bigger as hard now as overhead, it takes a lot of time. so depending on what your application is, if you've got a situation where you've got a lot of files that are changing size, this may not be the best option. but if you've got a lot of fixed size files. tell me this will work. well, depends. alright, so that's contiguous allocation. let's go back and look at the book picture that i have. so there's the continual allocation. i advantage past reading disadvantage ca n't really increase file size and it is prone fragmentation right? we get this little hole that we're deleting files and or reducing the size of the files. ok so. what we do instead? and her allocation mechanism # 2. chained allocation. chained allocation attempts fix the problem of changing file sizes. so we still have our drive. we still have our blocks. we still have a block allocated for the fat and we so we've got block 0123 and so on. and we're going have our same file. so i'll just write it up here ab and c, but i say a was two blocks, b was three blocks and see was seven blocks. ok."
"""OpSys_File_Systems_Intro_Transcript.txt""","what we do instead? and her allocation mechanism # 2. chained allocation. chained allocation attempts fix the problem of changing file sizes. so we still have our drive. we still have our blocks. we still have a block allocated for the fat and we so we've got block 0123 and so on. and we're going have our same file. so i'll just write it up here ab and c, but i say a was two blocks, b was three blocks and see was seven blocks. ok. so i'll just keep a note of that. and so it continuous allocation. we allocate the blocks just in order. ok, with chained allocation, we do this. we take a little bit of each block as overhead, right? and at the end of each block or at the beginning, really does matter, but somewhere in the block we type a number or store a number. this number is gon na be kind of like a pointer number of pointers in c are just numbers. they point a location conceptually, but that number it represents represents a reference a location in memory. in here we have a number that will represent the next block in the file, and so jane delegation, we just do this so we can still lay out a file like this 01 and then b will be 01 and two. but instead of laying it out continuously like this, what we do is we take at the end of here and say if this is block 0, the next block in this file, we put a little two at the end. the say that the next block in this file is in logical block 2. or we could draw an arrow like this conceptually, and then this guy here would have some indicator like or -, 1 or something indicate that it's the last block in the file. and so same idea. this guy would have an arrow pointing the next block. this would have an arrow pointing the next block and then 0123456 and then each of these would have a pointer next block. ok. so then in the file allocation table. we still have the file name abc, but then in here we need some indicator of the first block. so in that case, a's first block is 1's, first block is 3 and 0123456 c's first block is 6."
"""OpSys_File_Systems_Intro_Transcript.txt""","or we could draw an arrow like this conceptually, and then this guy here would have some indicator like or -, 1 or something indicate that it's the last block in the file. and so same idea. this guy would have an arrow pointing the next block. this would have an arrow pointing the next block and then 0123456 and then each of these would have a pointer next block. ok. so then in the file allocation table. we still have the file name abc, but then in here we need some indicator of the first block. so in that case, a's first block is 1's, first block is 3 and 0123456 c's first block is 6. and for all intents and purposes, that's really all we need store block allocation and be able find the blocks because all we have do now find all the blocks in the file is just read a block in the file and we know where the next one is. if you want get more complicated, if you can have previous pointers too, like a linked list, but i'll i'll that we do n't really need that, they just find the next block alright. growing a file, say if we want grow this file. all we got do here is take this, find the next free block in here and say we want grow the blue file. we will add two and we'll update this not be this, but point this is going come out not the greatest, but hopefully we'll get the idea. the next block in the file, and what's really interesting about that is we do n't even need update the bilocation table at that point. question this still get that good. ok, so good question. i getting back what i like. what i do n't want? ok, let's start with let's. let's come back that. what do what's what's nice about this? miles can now grow. and so long as i have a free block on my drive. but you can use it, you know, even if somebody said, you know what, i need shrink the size of b. ok, i'm gon na shrink it by a block. i can do that, i can delete this. i can delete this. this is now the last block. i've got a pre block and you could say i've got a whole. i've got a free block in the middle somewhere. well, if i wanna make file a bigger again, that's fine."
"""OpSys_File_Systems_Intro_Transcript.txt""","but you can use it, you know, even if somebody said, you know what, i need shrink the size of b. ok, i'm gon na shrink it by a block. i can do that, i can delete this. i can delete this. this is now the last block. i've got a pre block and you could say i've got a whole. i've got a free block in the middle somewhere. well, if i wanna make file a bigger again, that's fine. i can put it in the middle here and just make this three and just update this pointer now point up here. yes, i have a fragment, but i can always since i have allocate files in an increment of blocks. i can always just use one of those blocks filling in. i'm not gon na have like half a block fragment. then you will, is a problem that we ran into with that dynamic memory allocation, we end up with these weird small itty bitty holes. here, everything's blocked. that's cool. files can grow true. i know what i do n't like about this. what do n't you like about this? i mean it, it seems like mechanic like you would still get a uh like the performance if they work and they do it right, there are no. so back contiguous right. the advantage of what was need of all continuous allocation is that all of these blocks were right next each other. so is that hard drive? umm. planner is spinning around. we can read them all right next each other. we going read the entire contents of the blue file file a. yeah. these two are contiguous, but once i read that now i got ta go all the way over here and i got ta go up here and i got. i got ta go all over the place read this drive during this file. that's not great. furthermore. i did n't talk about this now again, with ssd's this becomes less of a problem because there are more or less the same access time regardless of where they are in the drive. but for hard disk drives, we still have, we still have deal with this. ok. that's why is that if the drive if the blocks are n't contiguous, we got ta read them all over the place, part one, part 2 make even matters worse is with the contiguous block allocation. i knew where the first block was and how many blocks read."
"""OpSys_File_Systems_Intro_Transcript.txt""","i did n't talk about this now again, with ssd's this becomes less of a problem because there are more or less the same access time regardless of where they are in the drive. but for hard disk drives, we still have, we still have deal with this. ok. that's why is that if the drive if the blocks are n't contiguous, we got ta read them all over the place, part one, part 2 make even matters worse is with the contiguous block allocation. i knew where the first block was and how many blocks read. if i want read that whole file so i can issue an io request say, read all of these blocks, i want read the entire file, go and read these ten blocks with chained even if even if i did have tell the drive go read this block here and go read that block there and go read that block there and go read that block there and i had wave like build all that up into one io request. yeah, the drive would be moving all over the place where this had going in and out, but i ca n't even do that here because i do n't even know what blocks tell the drive read until i read a block because i do n't know where the next one is until i read the first one. so now i'm kind of forced read these one at a time. that sticks. that's even a double sort of performance hit, ok? third thing i do n't like about this. drives are built out of physical things, right? we live in a world where things break, right? i do n't. i do n't like that. i do n't. i wish they did n't, but it seems me that the more moving parts something has, the more common it is break. so with the spinning disk, those things break. ok. if we end up where and this sometimes happens where like the magnetic disc there were played with like magnetic things and you can take a magnitude of and erase portions of them. if one of these blocks goes bad, that's not great, ok? because i'll lose data. what we've contiguous block allocation and one of the blocks goes bad. i lose the data and i that might not work out great. i might be able recover it, but i can at least get all of the file blocks, provided that the fat is a broken, but picks that later on right with chained allocation."
"""OpSys_File_Systems_Intro_Transcript.txt""","if we end up where and this sometimes happens where like the magnetic disc there were played with like magnetic things and you can take a magnitude of and erase portions of them. if one of these blocks goes bad, that's not great, ok? because i'll lose data. what we've contiguous block allocation and one of the blocks goes bad. i lose the data and i that might not work out great. i might be able recover it, but i can at least get all of the file blocks, provided that the fat is a broken, but picks that later on right with chained allocation. if i have a block that breaks right here in the middle, not only do i lose that data, but it also lose all of the data after it because i've got this broken chain. uh so? but i can create the files. yeah bro. other questions? thoughts on unchained allocation? all right, so what do i got ta bar about chained allocation? yep, no fragmentation. yeah, must read previous block. ok. yeah alright. so enter the world of carsons comment. defragmentation or consolidation? we talked about that if the blocks were all in order. it'll be kind of like contiguous allocation, so. defragmentation is a thing. actually you get think you could still do this in windows. used have do this as the world of our files lives on right in a chain block allocation mett, idea you can see that at least files grow and shrink and other files grow and shrink. the longer we let this run, the worse it gets. right. and so i remember i was in college. the file systems that were typically available and and built for windows. are things are not quite like this anymore because the file systems are are different and we have ssds does n't require this. uh, actually, the system would start get really, really slow. the longer your system live and you change the size of your files, so what you would do is you'd right click on your hard drive and you go into properties or you go into the into the the service tools on there and there was a button you can click would be disk defragmenter and what it would do is it would essentially analyze all of the files on your disk, figure out ones were n't in order, so speak, and it would figure out all the operations it would do."
"""OpSys_File_Systems_Intro_Transcript.txt""","uh, actually, the system would start get really, really slow. the longer your system live and you change the size of your files, so what you would do is you'd right click on your hard drive and you go into properties or you go into the into the the service tools on there and there was a button you can click would be disk defragmenter and what it would do is it would essentially analyze all of the files on your disk, figure out ones were n't in order, so speak, and it would figure out all the operations it would do. and then your hard drive would crunch and spin for a really, really long time as the operating system is moving around all of these blocks put them in order. and it was really cool. you look at a youtube video for it. there was a you could watch and it would show a graphical representation of what it's doing and what blocks it's moving, and it would color them different like. here's the bad blocks that went bad that i could n't see that are n't good anymore. and what i'm gon na do is take these. these are our blue, means they need go the beginning of the drive. these are are, are red and this means i need go the end of the drive and these ones that are teal are the ones that have already moved. and i i really reason why i feel like this is near and dear my heart's had a friend of mine that really like watch the disney bragg mentor go. it was like watching a movie with him. no, anyway. ok, so i think this block allocation. defragmentation. and doctor lumpies hast. alright, let's talk about one more then attempts try and fix some of these. it's still not the perfect one, but at least it tries fix a little bit. indexed allocation. and. we like. i like these pointers. i like the pointers because it allows a file grow and shrink. i do n't like the fact that being chained together. could potentially cause me lose everything after a failed sector, and i do n't know where all of the blocks are without reading a previous block. i'd like be able, even if i had deal with the fact that blocks are scattered all over this drive, i'd like be able look at the file and say here are all of the blocks for this file, 182232 and 45, without having read all of those in order."
"""OpSys_File_Systems_Intro_Transcript.txt""","i like the pointers because it allows a file grow and shrink. i do n't like the fact that being chained together. could potentially cause me lose everything after a failed sector, and i do n't know where all of the blocks are without reading a previous block. i'd like be able, even if i had deal with the fact that blocks are scattered all over this drive, i'd like be able look at the file and say here are all of the blocks for this file, 182232 and 45, without having read all of those in order. ok, so index tries fix that, so i've got a was two blocks b is 3 and c is 7. so and then here's my fat. what indexed does is it says. i'm gon na use some block indicate information about the entire file system. and then what i'm going do is i'm gon na allocate all block for each file. o i'm going call it the index node, so what i'm gon na do for a here is i wanna allocate say this block and this is the index for a and then b was green. i'm gon na create over here the index for beep and then i'm gon na allocate this one, is the index for cok. the file allocation table. we'll do this. it will have the name and it will have the index number, index, block number, abc. this says that a's index block number is 012 bees in the earth's in the x block is 0123456789 and seasoned x block is 01234567. ok, great. so next question is alright. well, then what the heck goes into an index block? i'm getting there. so inside the index block for a. will be essentially a listing of all of the blocks that contain the data for that file. so i'll say that a's block 0 is here and a's block one is there. then this would be inside the index for a we'd have 0123 and for and then inside the index block for file b. they bees blocks are 01 and two that would be block 123456. 056789 and 10 and then the index block for c. would say it's blocks are in. let's see how many blocks do we have? seven so 0123456. that says that the data blocks for c as in 1236. 811121314 and 15, yeah. ok, there's still not continuous, so that's not great for the spinning, yes, but."
"""OpSys_File_Systems_Intro_Transcript.txt""","then this would be inside the index for a we'd have 0123 and for and then inside the index block for file b. they bees blocks are 01 and two that would be block 123456. 056789 and 10 and then the index block for c. would say it's blocks are in. let's see how many blocks do we have? seven so 0123456. that says that the data blocks for c as in 1236. 811121314 and 15, yeah. ok, there's still not continuous, so that's not great for the spinning, yes, but. i now know using these index blocks without having read all the blocks of the file where all the blocks are. so if i want offset into that file and say, i really do n't care what's in the first two blocks, i only wanted get what's that offset 1000 or 1100 and beyond. i can go the index lock, figure out blocks on the drive is the start of what i'm looking for, and just read that one or that whatever, right. that's nice. i've less ios than i need deal with. that's good. what's the battlements? takes more space. it takes up more space. we have more overhead. now we have a situation in, right i'm using on all the blocks now because i have another block for each file that any allocate. that's one problem. problem 2, is something i did n't mention earlier, but it's a problem with this particular allocation mechanism. a block is fixed size, right? we said it's it's it might be 4096 bytes or it might be 512 bytes. it might be something else, but it is some set number. if it was 512 bytes inside the index block, even if that contained just a list of numbers, these are block numbers, logical block numbers. ok, if i'm a terabyte hard drive, that's what everyone said is what billion a billion bytes that no more. i ca n't remember. i divide that by 512 and that tells me how many blocks are in this device. ok, right. i need store that as a as a number, so inside this index block i need store a bunch of those numbers, could be way way near the end of the drive. a really large number, so these might be the b like 8 bytes long."
"""OpSys_File_Systems_Intro_Transcript.txt""","ok, if i'm a terabyte hard drive, that's what everyone said is what billion a billion bytes that no more. i ca n't remember. i divide that by 512 and that tells me how many blocks are in this device. ok, right. i need store that as a as a number, so inside this index block i need store a bunch of those numbers, could be way way near the end of the drive. a really large number, so these might be the b like 8 bytes long. in order have a number big enough store what block number it is, these are small and they can fit this essentially in one bite, and so you can say, well, you can store 512 numbers. no, it's going be smaller than that because i have store the block number. ok, if i'm only allowed one index node per file, i can only specify so many numbers of blocks in here, so it limits the size of a file. yeah. smile is gon na be 512 bytes times the number of blocks that make up that bio. in contiguous allocation. i do n't really have worry about that. i just had figure out where the starting block is and how many blocks there were that number for block count could be the rest of the drive, right? and so that could be a pretty large file for chained allocation. well, i can just keep chaining them together. i only have recording the first block and they're all chained together, so i could keep growing as many blocks as that file needs, but with indexed. i'm stuck. i'm limited how much i can fit in an index. so the answer then might become and some file systems do. this is say, ok, great. maybe inside my file allocation table, instead of specifying b index block, i'll say the index blocks, right? how many index blocks there are and say you get have more than one? or maybe i can combine the index locks into some sort of like chained allocation, where one index block will point the next index block. but by doing that, we still now we're kind of getting into more overheads and say well, in order read the entire file. now i got ta find all the index blocks so this trade offs have all of this. right. so. questions on indexed allocation. and so then here's my example. here avantages no fragmentation, right? another problem with that we could add it removed from the beginning, middle end."
"""OpSys_File_Systems_Intro_Transcript.txt""","or maybe i can combine the index locks into some sort of like chained allocation, where one index block will point the next index block. but by doing that, we still now we're kind of getting into more overheads and say well, in order read the entire file. now i got ta find all the index blocks so this trade offs have all of this. right. so. questions on indexed allocation. and so then here's my example. here avantages no fragmentation, right? another problem with that we could add it removed from the beginning, middle end. they're problem. you'll need reindex blocks. file size is limited what we can fit in the mix and we still have deal with this situation of integrity. ok, with chained allocation, if a block breaks, i lose everything from where the point of the breakages the end of the file. take your allocation of a block breaks. i just lose that data block index file system index allocation if a lock breaks, i lose that data lock. that's for the data with the metadata. this becomes a little more serious if the index block breaks, i lose the whole file, right if the file allocation table. it's like there are block breaks. i lose all of the files in the file system. ok, so we have find a way, at least intentionally, think about, well, how do we protect ourselves from breakage, right. if the whole drive breaks, what we lose all of the data, you know, we're stuck. there's nothing, paul. we can do about that, but if any this an individual sector breaks or individual lot breaks, the kind of nice if we could recover. so how are we going do that? i'll leave that up as a topic for next time because i'm running out of time, but that's gon na be kind of part of our next thing is how do we deal with breakages? how do we improve performance and how do we manage free space on these drives? ok, so otherwise we'll stop there. thanks for coming. do n't forget about the quiz tomorrow. lembke, james stopped transcription"
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","meeting in _ general_-20240119_130313 - meeting recording january 19, 2024, 7:03pm 47 m 45s lembke, james 0:03 search. lembke, james started transcription lembke, james 0:06 well hello. all right. great. awesome. so share my screen there we go. o welcome operating system. so what are we doing now? i mentioned in the syllabus that we're not gon na dive right into operating systems at the beginning, mainly because i'd like kind of review and kind of build up some background of what it is that we either know or should know or maybe we do n't know, but we forgot. but just build up our knowledge of things so that we can build on that ultimately get into operating system services, i mentioned the 1st, about half, maybe slightly less than half of that semester will be utilizing operating system services. what the operating system can offer us as programmers, and then we'll talk about how the operating system builds those by digging in, you know, deeper down the rabbit hole or pulling back the curtain, whatever you want refer it as, we'll get there. so what am i do? what are we gon na do today? today, we're gon na do a couple of things. umm, i got some pictures and these notes are also in canvas so you can follow along there if you'd like. i do my best post notes ahead of time if i forget, i apologize, but i will always post that eventually, no. so history. why are we here? i like ask the question why i like encourage you ask me why. so why? why? why? why? what is very important, but the why is sometimes equally as important. we're gon na start out with the y and alright, this is not a history class. i really, really wish i could satisfy your humanities elective by giving you a history of computing. umm, maybe someday, but unfortunately that's not today. but i do wanna talk about history, mainly because i i look at this and unfortunately, well the my glasses are whatever i like talk about this idea of a lens. and i could say we can look at something through the lens of a particular person or a particular whatever age of people and say ohh that does n't make a whole lot of sense. i wonder why they did it that way, right? i'm sure you probably experienced this, especially in the world of history. you look back and be like, that's weird. why they do it that way?"
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","but i do wanna talk about history, mainly because i i look at this and unfortunately, well the my glasses are whatever i like talk about this idea of a lens. and i could say we can look at something through the lens of a particular person or a particular whatever age of people and say ohh that does n't make a whole lot of sense. i wonder why they did it that way, right? i'm sure you probably experienced this, especially in the world of history. you look back and be like, that's weird. why they do it that way? well, the reason why you think it's weird is because you know what you know. now, if they had, they with air quotes knew what we knew. now back then, they may not have done it that way either. that was a lot of adjectives in a weird way of saying that, but you guys get the. letters. when did computers start? maybe 1940s, maybe 1950s, maybe before that. some argue that computers even existed back, you know, in ancient times. ultimately, this is where i'm gon na begin and talk about what we have. and so basically the big thing i wanna talk about is this idea of an instruction set architecture and the general purpose computer do n't 1940s nineteen 50s. unfortunately, i hate say this. a lot of our technology that we use today was developed in the world of the military weapons of war. i do n't like that, but it is what it is. and so we think about 1940s nineteen 50s computers were essentially calculators in a way, there was a large style of that that was intended either fight people or hurt people or, you know, find a way stop the people from hurting people, is good, right. you think about what is it? the imitation game alan turing. alan turing is my homeboy. right came up with this idea right of how can we break encryption? right. you know, kind of started us off right in the world war two time frame. really kind of helped out a lot, but this is where our sort of background in computers is going begin. this idea of a general purpose computer and when i draw some pictures of that, hopefully it'll become clear from there we get into this idea of information age where, yes, computers do stop, but we actually have more data in that that we're working with than really the computers being powerful."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","right. you know, kind of started us off right in the world war two time frame. really kind of helped out a lot, but this is where our sort of background in computers is going begin. this idea of a general purpose computer and when i draw some pictures of that, hopefully it'll become clear from there we get into this idea of information age where, yes, computers do stop, but we actually have more data in that that we're working with than really the computers being powerful. when i was growing up, it always seemed like the the the the processors developers, amd and intel were battling each other and be like ohh we have faster gigahertz right now. i got a 2 gigahertz processor or 4 gigahertz processor. for some reason you do n't really about that so much anymore. now it's it's all more about a number of cores, or perhaps there's even a section about that. how many cores and how much can we do? but in a way, it's getting the point now where we have processors that are pretty fast and we have all, lots and lots of data, a lot of information that we're processing. i did n't today. now we got the idea of internet of things or running out of ip addresses and this idea of artificial intelligence, large language models, who knows where it's gon na go from there. but that is my my spiel of history for where we're going and the big motivation here is data. where am i going? what can we learn from this? right hardware is complicated. well, maybe i like. i like that word, but also do n't like that word. complication is it's only complicated and compared something else, and it's only complicated if you really do n't know how it's working. we're going learn how more, more or less how operating systems work. and so right now you might look at windows and say, wow, windows is complicated. it's doing a lot of stuff. ohh yeah, yes it is doing a lot of stuff, but once we just break it down into pieces using our lens you know it, hopefully we'll be. we'll be clear, and i say that from a lens perspective is because it can also give us tunnel vision if we look at an operating system and its whole, it's gon na do a lot."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","and so right now you might look at windows and say, wow, windows is complicated. it's doing a lot of stuff. ohh yeah, yes it is doing a lot of stuff, but once we just break it down into pieces using our lens you know it, hopefully we'll be. we'll be clear, and i say that from a lens perspective is because it can also give us tunnel vision if we look at an operating system and its whole, it's gon na do a lot. if we look at processors as a whole, they do a lot, but if we just break it down and say, you know what, i'm not gon na worry about this other thing. we're just focus on one piece of the operating system and we'll learn that and then later on, once you know that, you could start making the connections. and so we're gon na spend time learning these different operating system services and learning them in isolation. but then ultimately start connecting them together. ok, so this is another bit that we can learn from this. umm, this is a really cool graph. it's showing the amount more or less ok. this is kind of an an average. it's not the absolute amount of data that we have as humans that we are generating over the years and we can see this is in terms of zettabytes. i do n't know how many zeros that are. there is like one how many zeros i know we've got 1 billions and then trillions and then is that after trillion? no. what? no. what is after trillion? because gigabytes. what? and does n't matter. it's a lot. ok, that's the whole the whole idea is that we are generating lots of data. somebody might argue that a lot of the data that we're generating this copies of data that we already have. and so you look at like a large language model and it has a has a an index so speak or things that it's categorized, but that all has come from somewhere else. ok. yes, i know we've got a lot of data that we're duplicating well, the mentally we are generating a lot of data and you could say well that kind of stinks. we have store this somewhere. well, that's all fine and dandy, but also we see that storage is becoming cheaper. so we have bigger computers that store a lot of stuff, but they're not getting a whole lot more expensive, ok."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","and so you look at like a large language model and it has a has a an index so speak or things that it's categorized, but that all has come from somewhere else. ok. yes, i know we've got a lot of data that we're duplicating well, the mentally we are generating a lot of data and you could say well that kind of stinks. we have store this somewhere. well, that's all fine and dandy, but also we see that storage is becoming cheaper. so we have bigger computers that store a lot of stuff, but they're not getting a whole lot more expensive, ok. alright, so history, we've got general purpose computers. ok, computers that are n't designed for a specific thing in mind. they can do whatever we want, right? i buy. do you want or? we're given this laptop right from msoe use for class. it's not a msoe built laptop specifically for you use for class, and the only thing you can do is take notes. you can install steam on. there you can install other things on there and it will work right. it's general purpose, not necessarily that it can do everything, it's that it, it is not targeted at a specific, ok, ok, general purpose, we got that data. we have lots of data that we're generating. we have find a way efficiently be able read and write that data. ok, done and price, this is not a auction or price or whatever class, but realizing that we do n't while we have lots of data places store that data is n't all that expensive. the last thing i want mention up here is. i say that abstractions are beautiful. abstractions are cool. i like abstractions and this is one of the motivations behind an operating system and that we have all this hardware and you might say hardware is complicated, right? let's let's talk about that. sorry, i'm jumping around. keep up. you got ta keep up. doctor. doctor lopez moving. i've had my coffee. all right. computers. you guys have all used computers for years. i talked a little bit about the why and the motivation here, but let's talk a little bit about the what what's a computer? what's in a computer? what do what do we have in our computer? why is a computer complicated? what's in there? what makes up the computer? euler. you learn what's in a computer."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","you got ta keep up. doctor. doctor lopez moving. i've had my coffee. all right. computers. you guys have all used computers for years. i talked a little bit about the why and the motivation here, but let's talk a little bit about the what what's a computer? what's in a computer? what do what do we have in our computer? why is a computer complicated? what's in there? what makes up the computer? euler. you learn what's in a computer. you guys know this? not if you know the answer right. crosses. we were processor. right. we have. umm, ok, we'll call it a graphics processor. memory. storage. bye. ah, we have io. i'm gon na call this mainly because i really wanna hurt myself because i ca n't spell. peripherals. what do we have? we've got ta monitor. we got a mouse. i do n't know. we have speakers. but also we got we got got a network card not really a card. right. we have keyboards alright. ad nauseam. you can probably come up with any number of io devices. well, i've got my camera, i've got my gopro. but i got i plug that in there, right? i've got, you know, my, my, you know my xbox controller or whatever that i use for my games or whatever it is, right? i got my bluetooth device, i got my headphones right. you can keep talking about all these different peripherals that we have, right? ok, so that's that. i'm going try and do this. we'll see how well it works. not bad, could be better. so we've got this hardware on here. we have been talking about how it's connected, but i say abstractions are beautiful, right? why do i like abstractions? because when i use my computer. as a user, i want double click on something and have it open and allow me edit it. so for example i wanna double click on a file like. this powerpoint presentation and i want microsoft powerpoint open that file and display it for me. guess what? nobody mentioned over here that there's a powerpoint file. as part of our computer, right? we can, you might say. well, is n't that on my computer? yeah, well, where is it?"
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","because when i use my computer. as a user, i want double click on something and have it open and allow me edit it. so for example i wanna double click on a file like. this powerpoint presentation and i want microsoft powerpoint open that file and display it for me. guess what? nobody mentioned over here that there's a powerpoint file. as part of our computer, right? we can, you might say. well, is n't that on my computer? yeah, well, where is it? on my computer, will you could say, well, doctor lucky stores and in his box folder. ok. what's a folder? nobody said that our computer has folders in it. i'm not going down the the supply room, getting a bunch of file folders and jamming them in that computer doing that right? this abstractions are beautiful. the operating system developers come up with something called the file system. when we take that for granted, i take that for granted. we might take that for granted that there is a disk drive and it's not a spinning disk or i have a solid state drive and this thing i believe and i have at home the whole bunch of spinning disks is platters that spin around like that, right? it's a hardware thing and on there inside that hardware on the platters, whether it be the platter spinning around or the solid state drive is essentially an array of bytes. right. and so the blocks storage and i do n't need it when i open up my powerpoint file, i do n't need it say i would like read block 1182532 and 16 and i'm gon na figure out what that binary data is and create a file on that right. they do n't need do that. we have the operating system that's creating this abstraction called the file system, is organizing things on disk for us. right. abstractions are cool. i do n't have worry about how that's put together. ok? other pieces i've abstraction memory. what i write a program in java or or or c or c++ or whatever you name it, i can run that program and it executes and i do n't have worry about. well, what else is running on this system? am i gon na accidentally read a a variable that chrome has stored? do i even want be able do that right? so that's kind of a a concern of mine, right? we say we have memory, but we have memory. one thing we do n't have memories."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","what i write a program in java or or or c or c++ or whatever you name it, i can run that program and it executes and i do n't have worry about. well, what else is running on this system? am i gon na accidentally read a a variable that chrome has stored? do i even want be able do that right? so that's kind of a a concern of mine, right? we say we have memory, but we have memory. one thing we do n't have memories. we do n't have a memory dim for every single program that's gon na run. we have one bank of memory, so the operating system is abstracting that away and providing a world of isolation and protection. i said that once, if i do n't say that 100 times before the end of the semester, i'm probably doing something wrong. isolation and protection. i have the operating system isolates things from other processes so that they do n't hurt each other. they do n't screw something up. could you imagine if i wrote a java program that when i ran it all of a sudden my chrome crashed? not good and also security if i am running chrome and i'm going a website that's ecommerce related and i have type a credit card in there. i do n't want some other program, microsoft office or whatever be able read the contents of memory and grab my credit card number and send it off someplace malicious. i am trusting chrome with that number and i do n't want anybody else get it. isolation and protection abstractions are cool. thumbs up questions. alright, so computer hardware. let's talk about how computers now are put together. this is a high level picture of computer. kind of crew, but it it's a good start. ok, we'll get there or there are. so what is the computer you mentioned? we have some cpu, some central processing unit. it's hooked up memory right in our general purpose architecture. we're going refer this as a load store architecture, ok? what that means is the cpu needs have data inside it in order operate on it. if it does n't have that data, it needs go get it, and it needs load it from somewhere, right? where is it gon na load it from? am i load it from memory? it might get it out of some some peripheral io device, right? we have load something out of there keyboards. this is really when we talk about io, it's gon na be kind of interesting."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","we're going refer this as a load store architecture, ok? what that means is the cpu needs have data inside it in order operate on it. if it does n't have that data, it needs go get it, and it needs load it from somewhere, right? where is it gon na load it from? am i load it from memory? it might get it out of some some peripheral io device, right? we have load something out of there keyboards. this is really when we talk about io, it's gon na be kind of interesting. keyboards, you might say. well, there are bunch of buttons. yes, they are a bunch of buttons, but they have storage in them and the cpu needs be able determine what you typed and so it has get that information out of the keyboard. all right, so. that is that picture. let's. and i've been. yeah. what time is it? 120 alright so. so let's dig deeper into here. those are that may have taken combo org or maybe have taken computer architecture or maybe you just know this. let's blow this picture up. ok, here's my cpu. here's memory. it's a black box. all right. i will ultimately get why we're talking about this, but let's start with the what? ok, what is inside of our cpu? no, no. did you guys do you guys take convert some of you i know have taken cardboard 20 cs 26112. maybe you took digital logic, maybe you just know this what's inside the cpu? yeah, there's that program counter a program counter. ok. what else do we have? i mentioned that the cpu has operate on data, right? ok. that makes sense. we all we have lots of data. data is my friend of mine used say right? so the cpu's got a store data somewhere. i mentioned that memory exists. memory is a place for us store stuff. it is not part of the cpu, so what do we have inside the cpu we have? something called registers. ok, i'm gon na add up on this and call them general purpose. general purpose registers in the world of older computers, all the registers were specific. they had a specific purpose in mind. they could n't be used for a general purpose. well, what does it mean general purpose? it means that there is no. specific purpose. that's a lame way of saying it."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","it is not part of the cpu, so what do we have inside the cpu we have? something called registers. ok, i'm gon na add up on this and call them general purpose. general purpose registers in the world of older computers, all the registers were specific. they had a specific purpose in mind. they could n't be used for a general purpose. well, what does it mean general purpose? it means that there is no. specific purpose. that's a lame way of saying it. it's you can use them for whatever we want. ok, what is a register? a register is a place put something. plain and simple, what can we store in a register? well, we could store a number. we could store a character, a letter. we could store part of a picture, but the idea here is that we are limited in the amount of things that the cpu can be doing at a time. mono of things the cpu can be holding on just like my brain. i'm limited amount of things that i could actively think about at a time. i start forgetting things, usually after trying remember about 10 things you remember about 10 things. then i start forgetting. ok, so if you say my idea, there's so many registers in there. the very first architecture that i learned it was 32. i do n't know what be honest with you. how many registers are in uh, uh like this processor? but it does n't matter. there is some finite number of registers and they're so big this is not a class on binary representation, but i will either will cover it or we will need talk a little bit about number bases. if you took network protocols or we took digital logic or even comp org, you probably covered different number bases. binary, hexadecimal and so on, but prefer the register with be. how big these are when i learn computers, they were always 32 bits. now i pretty sure all of our architectures now even on our phones are 64 bits at least. so we're gon na go with 64 bits. so that means that the width of these is 64 bits. what does that mean? it limits the numbers of the the size of the numbers we can hold on and talk about and also limits the amount of characters. typically, if we look at a character that's one by each, so each register here can hold up 8 characters each. but what i'm getting at here is that it's something small."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","now i pretty sure all of our architectures now even on our phones are 64 bits at least. so we're gon na go with 64 bits. so that means that the width of these is 64 bits. what does that mean? it limits the numbers of the the size of the numbers we can hold on and talk about and also limits the amount of characters. typically, if we look at a character that's one by each, so each register here can hold up 8 characters each. but what i'm getting at here is that it's something small. it's not a whole lot of stuff that's cpu can be doing at a time. ok, registers places put stuff. ok, once we have a place put stuff, we should probably have something that allows us do something with that stuff. it's a very hand wavy way of explaining it, but we need something that does computation. what is computation? ever think about this? we're getting kind of deep here. this is not a psychology course, but what does it mean compute something? what can we cook that. yeah, it generate a number based off like a series of equations of other numbers. generate a number based off a series of equations. i like that answer. i will twist your words and turn it into math. ok, math is computing things. moving things around could be computing things, moving things back and forth, that memory, ok. but if we're going do that, we need something do that in. so people often draw it like this. i'm not 100 % sure why, but it is the drawing that people use, so we're gon na use this drawing too. we have something called the alu. what does that stand for? it stands for and. i'm gon na say this wrong elja break logic unit. no, you're right, not algebraic. see, this is why i need you guys in this room correct me. arithmetic logic unit, not arithmetic, but arithmetic logic unit and they get spelled the same way. but anyway, what this is is a bunch of circuitry that does arithmetic and logic things, so that's where we do things like add, subtract, multiply, and divide, boolean operations and or not that account stuff. it's all done by the alu, so if we want add 2 numbers together, what do we have do? well, our numbers will be located in memory over here somewhere. ok."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","arithmetic logic unit, not arithmetic, but arithmetic logic unit and they get spelled the same way. but anyway, what this is is a bunch of circuitry that does arithmetic and logic things, so that's where we do things like add, subtract, multiply, and divide, boolean operations and or not that account stuff. it's all done by the alu, so if we want add 2 numbers together, what do we have do? well, our numbers will be located in memory over here somewhere. ok. the thing we have do is take the contents of memory. now what is memory? sorry, i need talk about that. i should do this. what's memory? from abstraction level. now we know. yeah, basically, just hold all the data on the computer. yeah, it holds all the data and not all of the data, but it does. it holds data. we're limited the amount of can hold, but we're limited in terms of like, gigabytes, right, 16 gig is not uncommon. so i'm big data in there, but ultimately it's an array of bytes. imagine if everything in here was like a byte array like you're learning java or something like that. right? memories. right bites. so we can access memory by. essentially it's index in memory and so memory is numbered and so we have byte 0 through byte infinity. i hope i wish we do n't, but under the assumption we did right, we have an address. so data is located in memory ok? in order use it, we have bring it from memory into a register via some load instruction, right? this is load and store instruction. this is important. we have things at the cpu could execute, the cpu can do things. those things are instructions. it's instruction set. the things that can do i say this now and it seems weird, but i will come back this idea. i've instruction set later on when we talk about cpu modes, but for now we have the set of things that the cpu knows how do. we ca n't really teach it new things. it's kind of hard coded with what it's allowed do, but we have a set of instructions. one of those might might be loaded. we take our data, we put it in a register, we take our other item, we put it in a register and we can send those in here."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","the things that can do i say this now and it seems weird, but i will come back this idea. i've instruction set later on when we talk about cpu modes, but for now we have the set of things that the cpu knows how do. we ca n't really teach it new things. it's kind of hard coded with what it's allowed do, but we have a set of instructions. one of those might might be loaded. we take our data, we put it in a register, we take our other item, we put it in a register and we can send those in here. so we might have something like an instruction add says add the contents of s1 s2 and store the result in tg the target. these might be registered numbers register identifiers, but there's some way tell the cpu. here is what i'd like you do. i'd like you add these two things and store the result there. i might be adding two things and storing the result in the same place, but the idea here is that we're only operating on the stuff that's inside the cpu. alright, this is referred as a register register operation and that we're actually doing the operation directly in our registers. some cpu is actually support other operations like a registered memory or memory memory operations or it will actually grab the stuff from memory, do the operation and write the result back memory. we're not gon na talk about that in here. we're gon na talk about the cpu using data inside itself. ok. questions that lu. alright, next thing, this idea this instruction set add might be one of them. we might have a load say, load something from memory into a register like s1, but what i'm getting at here is that at it has parameters associated with it, almost like a function call, right? in this case, the actual operation is the registers that we wanna operate on, and so if it was just something as simple as app. our cpu hardware could be actually a lot simpler and there are cpu hardwares out there that that's the only operation you could do. if you want do an ad, you add the thing and the things you're gon na add are just assumed java, the java virtual machine is kind of like that. what it leads me the next thing i like draw as a circle, but i do n't know if that's necessarily standardized. the control unit. this is the brains for the brains, so speak, it says."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","our cpu hardware could be actually a lot simpler and there are cpu hardwares out there that that's the only operation you could do. if you want do an ad, you add the thing and the things you're gon na add are just assumed java, the java virtual machine is kind of like that. what it leads me the next thing i like draw as a circle, but i do n't know if that's necessarily standardized. the control unit. this is the brains for the brains, so speak, it says. when i'm executing some operation, i need as a cpu, i need take these parameters and send out appropriate electrical signals all of the different components of the cpu have it do the right thing. this is a hardware thing. it's almost like a like a switch and say alright, this is what i'm reading. this is the operation i like do. i need as a control unit, send a signal, poke, flip a switch on the aclu say, switch yourself add mode. you're gon na be executing an add instruction. you can do a whole bunch of other stuff. you can do subtract. you can do multiple and you can you divide, you can do and or whatever, but i would like you at this point do add so it uses the circuitry for adding two numbers together. that's what control you know needs be able do that. then the control unit needs say hey registers. sometimes this is referred as the register file. all the registers together it says registers. i would like you send the output of s1 and s2 into the lu. please, right. these could be different numbers. and then finally we need send the appropriate circuitry for the wires that might be between the aclu and the and the register file say, hey, i would like you flick the switches and select the target location be this register the target register. alright, control unit. and now we get back. caleb's spot. suggestion here of this idea of a program counter. the last sort of big piece that i want talk about inside of our cpu is our control registers. these are special purpose registers that we may not have direct access, but they are important for setting the state of our processor and processors have steak now it's just not a class in abstract algebra or anything like that, but we have a state. what is state? not like i live in the state of and sconsin. not if you know the answer."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","caleb's spot. suggestion here of this idea of a program counter. the last sort of big piece that i want talk about inside of our cpu is our control registers. these are special purpose registers that we may not have direct access, but they are important for setting the state of our processor and processors have steak now it's just not a class in abstract algebra or anything like that, but we have a state. what is state? not like i live in the state of and sconsin. not if you know the answer. i'm not gon na ask, you know, ok, some of you are, you know, are state is really. it's hard describe. i say. what value? now i know why you did n't answer because i'm trying find a good way say it as well, right it is. it is what it is, in a way. state is what i am. i am here. this is my state. now i move over here. my state is slightly different because i'm over here. it is essentially all the parameters that make up who i am. my state. now you can might say that they're your properties as well, but the state of the cpu consists of the contents of all of the registers. it consists of the what it's currently doing. how do we indicate what the cpu is currently doing? we got this control register called the pc. the program counter. what does that store? now we got ta go a little bit deeper. sorry, we got ta go down deeper. we got ta go. sites that a little bit figure this out. i'm gon na sidestep all the way over here memory. remember i mentioned that the cpu can only operate on what it knows what? it's what's in the register file, right? ok, you can operate on what it knows. what? how does it know what it needs do next? right, it needs a way actively think about what it's currently doing. i'm drew these instructions here, often. magical sort of la la land. but they are n't in la la land. they got ta be somewhere. everything has be somewhere. we ca n't just say no. put that on. no, it has be in a specific place so. where are all of our instructions? well, when i write my program. it's initially on disk. but we'll talk about when we execute a process in our operating system."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","right, it needs a way actively think about what it's currently doing. i'm drew these instructions here, often. magical sort of la la land. but they are n't in la la land. they got ta be somewhere. everything has be somewhere. we ca n't just say no. put that on. no, it has be in a specific place so. where are all of our instructions? well, when i write my program. it's initially on disk. but we'll talk about when we execute a process in our operating system. eventually, one of the steps that the operating system does when it allows our runs our programs is it loads that program off of the disk drive, right? and the reason it's on the disk drive is because memory is all fine and dandy and and it's great, but as soon as we turn our computer off, we lose all of our memory. right. the only place that we can store something that's persistent is on this drive somewhere. ok. so we'll get that. we'll talk about that when we get the io. bye. we can assume for this particular case that is part of our process creation, is what's going be operating system is going do get our program running on the cpu. is it needs load our program instructions into memory. thanks and they get put in memory. and then what? it's gon na do is. it's gon na tell the cpu start executing an instruction at this particular location. i mentioned that memory has addresses. it's like an array from zero infinity. these program instructions are located somewhere. this might be, i do n't know, 800, and this might be, umm, 1642, three, eight. i do n't know some number that indicates the end of our program, and so tell the cpu what do next, the operating system says alright, the cpu has got this control register called a program counter. it stores where in memory it's actually executing, so it's says. if we take 800. and store that in the program counter. now when the cpu needs execute something, it knows what do. it says load the contents of 800 into me. where is that gon na load it? when is me, well, we have another register. the isr the it's the instruction register that says this is the register that is storing what we're currently executed. so it says this program counter register here is wired into memory."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","it stores where in memory it's actually executing, so it's says. if we take 800. and store that in the program counter. now when the cpu needs execute something, it knows what do. it says load the contents of 800 into me. where is that gon na load it? when is me, well, we have another register. the isr the it's the instruction register that says this is the register that is storing what we're currently executed. so it says this program counter register here is wired into memory. it takes the contents of this the data, sends it out and says i need read this location. memory is hooked up the cpu via a bus, not like the magic school bus or like what we wrote in school when i was well, doing your kids. my boss is just a bunch of wires. the cpu is connected memory via the system boss of the front side. boss of everyone refer it as of this cpu memory bus. some people call that just a bunch of wires on those wires. it sends the signal that consists of all of the values that are inside the program counter. i say values and that that all the bits that are associated with the program connor they go out along the memory address bus and on the back side comes the data. the data from there gets brought into the cpu stored in the instruction register, and now the cpu who knows what it's doing. i mentioned that in that way, because while i say the cpu knows what it's doing, it's all just a bunch of wires and a bunch of transistors, so it's not really like the cpu is clairvoyant or that it knows what's going on. it's it's just hardware use our. we like say i like say they're smart, but they're not. they're just hardware. it's like your car. your car does n't wanna drive itself. your car is n't a human. it's not a lie. just drives, it just goes. it just is built on the mechanics. that was that was put in it. same idea. the view is built off of the mechanics that was put in it. in this case, it's a bunch of registers and transistors that store stopped. this information and this register then get sent in the control unit and then the control unit then can generate all of the other hardware signals that are needed or doing an instruction execution. and all of this happens billions of times a second. right, but that cool."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","it just is built on the mechanics. that was that was put in it. same idea. the view is built off of the mechanics that was put in it. in this case, it's a bunch of registers and transistors that store stopped. this information and this register then get sent in the control unit and then the control unit then can generate all of the other hardware signals that are needed or doing an instruction execution. and all of this happens billions of times a second. right, but that cool. and i just spent the past whatever, 20 minutes explaining something that happens, you know, in, i mean, i've barely understand. what? how fast it's going man so. hello. where's my? there it goes. this is a little bit nicer. picture, then, then perhaps, then what i do in the more, and so we have this idea of a system box. well, i do n't know if we're not talking about that. we have some special purpose registers, and they're not talking about all of these. and then we have this thing called the execution unit. i like lu. it's just seems make more sense me. umm. and that's it. so back the parts of a computer, did we get everything? i guess we did n't mention a bus, but we got that in there. now we also mentioned a couple of other things. storage is in here. you could say that storage is essentially an io module. a lot. a lot. i all kind of operates in a similar i idea, so i kind of like lump them all together. uh processor. definitely specific thing. main memory, definitely a specific thing. io modules separate, you might say. well, where's the gpu? where's the graphics card? you can throw tomatoes at me. i like the lump things like graphics cards and things like that amongst all of the io modules. badly, because i like connect my monitor my graphics card and a monitor is an output device. it's weird think of it that way. i kind of think that for granted, but it really is an output device now that we have gpu is being more general purpose. you can actually do a general purpose computation on the gpu. this sort of i owe versus processor is kind of being a little bit more foggy, but it is it is. it is what it is. ok. what is memory question? yes, let's go back over here."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","badly, because i like connect my monitor my graphics card and a monitor is an output device. it's weird think of it that way. i kind of think that for granted, but it really is an output device now that we have gpu is being more general purpose. you can actually do a general purpose computation on the gpu. this sort of i owe versus processor is kind of being a little bit more foggy, but it is it is. it is what it is. ok. what is memory question? yes, let's go back over here. question so. all machines need a physical drive, so that's a really good question because the answer is no. so you can run a computer disk list. ok, in the boot procedure, when you turn your computer on right it the power supply provides power the computer, right? and that's sort of the very, very genesis case of the computer turning on what runs when the computer initially turns on. it's not the operating system. it's not your your processor or prepare exact processor. it's not your process. it's not a program that you wrote the process or right, has some startup proteins, and it's gon na essentially execute the firmware that's on your main board. your motherboard, right? the firmware is is where you get words like efi or bios or things like that or cmos or whatever that boots up the computer. there's hardware that's inside of persistent storage on a separate location on your meeting board that's in charge of initializing the system and bringing the system up. once that does that, and sometimes you'll see where it'll do like hardware checks, sometimes you put call the post right, like computer is posting, it goes, it goes. it used kind of my older computers used go deep and then this little like thing that would beep say that this turning the thing on the the the the actual like motherboard main board doing some checks on that ok that being said as part of the the main boards firmware what it will do is it will start walking the io devices walking the hard drives say does this hard drive have a boot sector on it and a bootloader allow the system boot up. nope, that hard drive does n't does this one."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","once that does that, and sometimes you'll see where it'll do like hardware checks, sometimes you put call the post right, like computer is posting, it goes, it goes. it used kind of my older computers used go deep and then this little like thing that would beep say that this turning the thing on the the the the actual like motherboard main board doing some checks on that ok that being said as part of the the main boards firmware what it will do is it will start walking the io devices walking the hard drives say does this hard drive have a boot sector on it and a bootloader allow the system boot up. nope, that hard drive does n't does this one. if you have multiple hard drives on the system, that's one thing where if you actually have a physical device that is storing where your operating system is, the motherboard will find the boot sector and find where the bootloader is, and then run that and load that into memory start the computer initialize the operating system. other mainboards do n't. systems do n't have a hard drive in think like you know, like an embedded device might not. a hard drive level, you know, be honest with you at ibm. but i worked there. we had servers, hundreds of servers that had no hard drives in them whatsoever. how did they boot up, you'll say? well, these these that boot. what would happen is the motherboard would have a network card burned in soldered essentially as part of the main board that was the network card that you could hook up a cable. or maybe it was wireless and the firmware on your motherboard would have be enough smarts. instructions burned onto it, but it would know by executing the appropriate instructions it would do a dhcp query get an operating system operating system get an ip address and send a request out. broadcaster request on the network say hey, is there a server out there that could host an operating system for me so that i can boot up and then maybe they'll be a server that would respond and say here i am and then that server would provide the operating system boot up image and that's the way you can do netboot telling people call it pixie boot for pre execution environment. uh, and then it will put the operating system. so no, you do n't need a hard drive in there, but you do need have some software, some firmware, some code execute that will initialize and bring the system up. and where is that generally?"
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","broadcaster request on the network say hey, is there a server out there that could host an operating system for me so that i can boot up and then maybe they'll be a server that would respond and say here i am and then that server would provide the operating system boot up image and that's the way you can do netboot telling people call it pixie boot for pre execution environment. uh, and then it will put the operating system. so no, you do n't need a hard drive in there, but you do need have some software, some firmware, some code execute that will initialize and bring the system up. and where is that generally? bergen said it's like brand new, right? so on side your main board, they'll be some sort of saved data on a chip, some sort of storage that's on the thing. it used be stored in a place that was battery backed up and if your battery went dead you would like thank your computer. but that's not the case anymore. there's a persistent place where they load that element, and so if you wanna update something's out. do that you have update the bios of the the firmware and your machine and you're getting out that we'll have do is i'll have reboot your system and a protective mode or special mode model update the programming. it's kind of a hand wavy when it's done. yes, you do n't need construct. other questions? ok, i'm running out of time. no, i got 3 minutes. i think i'll finish this up in 3 minutes. ok, so let's look at memory hierarchy. ok, this is from one of the books that i said. what was optional? so, but fair use of the music. ok, mention that there are registers. these are facts. these are things that the cpu can execute within side the execution of an a single instruction. main memory we mentioned that that is a component of the computer. ok, i do n't remember. i researched this or looked this up but cpu is cycling and turning over at like 2, maybe 3 gigahertz right? so that is really fast. so that means it can be doing what 3 billion things every second. ok. that's a pretty big amount of fitness memory. i mean how fast memory is apparently the cpu. i could. it's for you under megahertz, and cpus are in gigahertz, well priced. yeah."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","main memory we mentioned that that is a component of the computer. ok, i do n't remember. i researched this or looked this up but cpu is cycling and turning over at like 2, maybe 3 gigahertz right? so that is really fast. so that means it can be doing what 3 billion things every second. ok. that's a pretty big amount of fitness memory. i mean how fast memory is apparently the cpu. i could. it's for you under megahertz, and cpus are in gigahertz, well priced. yeah. so dr five, it's it's buried depending on on on who your manufacturer is that give you different stats, but it is along the order of maybe 110th the speed of the cpu, sometimes even slower than that. so that being said. this is where things kind of anger me. i mentioned that the program counter contains the address of the next instruction execute right? and the cpu can only be doing one thing at a time. ok, if we have multiple cores, this is an example of a single core, right? so chances are cpus probably have eight, maybe 16 cores, so it can be doing more than one thing at a time, but for simplicity sake let's assume we have a single core cpu. we can do one thing at a time, so i'm gon na load an instruction from memory and execute it. then i'm gon na load the next one execute it. well, the amount of time it takes for me load that i could have been executing at least ten other instructions. so now essentially my cpu is slowed down the slowest element, right? it could have been doing a lot more stuff and that sucks. well, that stinks. sorry. we have find a way get more stuff out of memory faster and so the world of geeks said. you know what? why do n't we do this? not this. why do n't we add more memory? that's faster. not as fast as main memory. maybe not as fast as registers, but it's cheaper and we'll just put it in between there. it's called catch, and there's different differing levels of cash. and so what the actual cpu is going be doing is what's purdue as prefetching, what it's gon na do is it's gon na grab a whole bunch of instructions all at once because, well, the cpu is n't smart."
"""OpSys_History_and_Evolution_of_Computers_Transcript.txt""","why do n't we add more memory? that's faster. not as fast as main memory. maybe not as fast as registers, but it's cheaper and we'll just put it in between there. it's called catch, and there's different differing levels of cash. and so what the actual cpu is going be doing is what's purdue as prefetching, what it's gon na do is it's gon na grab a whole bunch of instructions all at once because, well, the cpu is n't smart. the people that develop cpu are smart and they realize that if i'm executing a program, chances are what is the next thing i'm gon na execute? what's the next line of code i'm gon na execute after executing the current line of code? next line, the absolute next one in the file. so if that's the case, why do n't you just grab the next one? and chances are i'm gon na execute the next one after that. so i'm just gon na grab the next, i do n't know, 100 instructions. stick them in the cache and now the next thing i need do i want access the next instruction janet desire. it's gon na be there. if it's not, then we'll pay the penalty for going memory. if i could do like a branch where i'm jumping off some function, who knows where. but for the most part, i'm going be executing the next thing loops if statements. ok, things are all wrench in the works, but they're doing just regular computation. just gon na blast right through it. other things in here electronic desk magnetic disk we do n't really do so much with optical disk. probably not anymore. magnetic tapes? who? what we got this fire memory. so i am out of time. i will continue with this on monday and then we'll get in see review. so thanks for coming. have a good weekend. that's right. lembke, james stopped transcription"
"""OpSys_Interprocess_Communication_Transcript.txt""","meeting in _ general_-20240222_130643 - meeting recording february 22, 2024, 7:06pm 42 m 51s lembke, james 0:05 there goes, i think, yeah. alright, great. welcome everybody. operating systems isolation and protection abstractions are cool. what have we been doing? we've been doing this a bunch of stuff, so if you can recall all the way back monday and seems like a long time ago we finished processes. we finished fork, we finished exec and now i said we're gon na take a sidestep here and talk about file descriptors. and we did and we worked through a file descriptor. is how it references an entry into the file descriptor table, and i drew this picture. and i drew it. hopefully in focus that's a little better. where if i have the script there is created by the operating system and it we get a number that represents that file descriptor, it references an entry in the file descriptor payable and that file descriptor table can contains things like the file position, pointer. if you look at the linux documentation that refers the first it as the file top set, but it's just the pointer into that file as far as where we are currently reading or writing as well as the reference the data blocks you will read, we do n't specify where in the file we wanna read, we just say read from the current file position. what we wanna write a file, we do n't specify where we just say i would like write for this file at the current file position. the operating system make sure that it advances the file position pointer with every read and write. it advances it by the number of characters read or written. that unless of course there was an error where it does n't change the file position pointer and just returns -, 1. ok. and with that, we had this example i had in ca n't put in canvas where we were opening a file specifying not what, not only what file we were opening, but what our intended purpose is the access. we're here. we're doing it for reading and writing. we're gon na do some reading and writing, and then that's modifying that text file and then finally making sure that we always close right, just like we free them. alex, always close the opens anytime we open a file descriptor. we need close it this particular case. it's very explicit."
"""OpSys_Interprocess_Communication_Transcript.txt""","and with that, we had this example i had in ca n't put in canvas where we were opening a file specifying not what, not only what file we were opening, but what our intended purpose is the access. we're here. we're doing it for reading and writing. we're gon na do some reading and writing, and then that's modifying that text file and then finally making sure that we always close right, just like we free them. alex, always close the opens anytime we open a file descriptor. we need close it this particular case. it's very explicit. we are doing an open, but we'll find when we talk about some of the other mechanisms today that we can get a file descriptor by not explicitly opening something, it might get something created for us indirectly or through another system call. if it's a file descriptor, we've got close before we're done, whether we return on an error or we return successfully. ok, file descriptors. happy days. let's go back now. what i want do now is go back the previous set of slides set of make good on something that i may have said incorrectly on purpose so was not was whatever accidentally on purpose, but i kept saying this over and over and over again that when we fork, parent and child are independent copies. the child is a copy of the parent, but the child and the parent do n't share anything. they do n't share variables. they do n't share global data. they do n't share anything except, ooh, this is actually not 100 % correct. now that we understand ever brewed file descriptors, they do not share memory locations. what they do sharefile descriptors ok, this is where things get a little bit more interesting. now we know file descriptors. we have this. if we look at a file descriptor, i've got this one sign here says that a file descriptor is what? it's a number. it's a number. we store a number where. in a variable, ok, when we fork we get a copy of this address space that says user right? so all of these numbers, variables, contents of memory get copied down here in operating system land. the operating system is ultimately going create another process control block for the for the new process. what it's gon na do is it's gon na have that new process control block for the new process reference the same file descriptor table."
"""OpSys_Interprocess_Communication_Transcript.txt""","it's a number. it's a number. we store a number where. in a variable, ok, when we fork we get a copy of this address space that says user right? so all of these numbers, variables, contents of memory get copied down here in operating system land. the operating system is ultimately going create another process control block for the for the new process. what it's gon na do is it's gon na have that new process control block for the new process reference the same file descriptor table. now when the child process and the parent process both access a file descriptor number, they're gon na access the same file descriptor table entry, and then share those files. so while i say that they do n't share memory, is true, they do sharefile descriptor numbers because they're copies and the child does a copy of the parent and they share entries in the file descriptor table. why is this interesting? well, as a result, apparent can open a file and the child can parent. can both use it communicate with each other. this is persistent storage in the file system and we can read and write that and as a result we can share. so let's take a look at how we can do this, and then we'll look at how this is n't all that well, it's kind of, i would say, clergy or janky. i think is perhaps the more appropriate acronym or whatever use now, but anyway, not acronym. what does that adjective use now? but anyway, let's take a look. so it's best with an example. so let's create a new file. i'm going call it forked file. and then i need copy and include a bunch of stuff, a bunch of stuff for system calls. you know what i think? i probably need all this stuff i'm going open. i need you standard for read and write. i need std io because i'm gon na do printf error. cause i'm gon na do the global variable for errors and string that image for str error. i'm just gon na go ahead and ask include std lib right away as well in case i wanna do like exit that's an std lib. so we'll do that. alright, so now what i'm going do is open a file and then fork and then both the parent and child access that file so they can communicate. yeah."
"""OpSys_Interprocess_Communication_Transcript.txt""","i need std io because i'm gon na do printf error. cause i'm gon na do the global variable for errors and string that image for str error. i'm just gon na go ahead and ask include std lib right away as well in case i wanna do like exit that's an std lib. so we'll do that. alright, so now what i'm going do is open a file and then fork and then both the parent and child access that file so they can communicate. yeah. the big limiting factor here was that the child really could n't send anything the parent because it's a copy of memory. it's not the same memory and the parent after the fork ca n't send anything the child, so let's just. let's just do this. let's make a file descriptor. need open a file name, just call it temp and i'm going open it for read and write because the parents going read and the child's gon na write or the child can write and the parents can read it does n't matter. we want them both be able read and write each other. this temp file does n't exist over here. you'll see. so i'm going use some additional parameters and say i want the operating system create it if it does n't exist. and then i got ta figure out how do this. i got ta figure out when i create a file i have give it permissions for the new leaf created file and i'm gon na use. i want the user me have read and write permissions so that is this board with. right. ok, so open temp. read it for reading and writing. created if it does n't exist, and if it does n't exist, create the file with read and write permissions for the user. so i can actually read and write the file. ok, good. but then i got ta do this wonderful stuff here. but not open temp dot txt. why will let? well, at the system, tell me and then i'll just return. one good. and now that i have the file descriptor opened, if i fork, i know that my child will share that with me, so i can just form create that. and then do our checking here. would not fork. why not umm. or tell me. we have opened a file. we have close it before we return. not so that's error case. if we have zero, then we're the child. otherwise, we are the parent. here."
"""OpSys_Interprocess_Communication_Transcript.txt""","well, at the system, tell me and then i'll just return. one good. and now that i have the file descriptor opened, if i fork, i know that my child will share that with me, so i can just form create that. and then do our checking here. would not fork. why not umm. or tell me. we have opened a file. we have close it before we return. not so that's error case. if we have zero, then we're the child. otherwise, we are the parent. here. both the parent and the child are have close the file descriptor before returning, so i'll just put that in there make sure we do n't forget. hey, now that we've got this now, we should be able read and write this file and have them communicate with each other. in the previous example, as soon as we wrote the file, it was reflected in the file system, so we should be able do that. so what i wanna do is have the child write something the parent, so i will write the file descriptor. hello parent and in fact actually let me just do it this way. that way, then i can just reference the variable and the length of the message. it's just easier that way. ok, then i'm going close it and exit successfully. yeah, make sure you close before you return. now what i should probably do is also check the return code from right make sure that the right succeeded. if it did n't succeed, i should print a good error message. in this case, i do n't see a reason why it would fail, but for now i'll just say print f child wrote parent. done. now the parents then is needs wait for a message from the child. the child's gon na write this file, but it does n't know that the message exists yet. if apparent was try just read immediately and there was no data in the file, read would say hey, nothing read, i'll return 0 bytes, so i'm gon na have the parent weight for the child finish so that we can actually get data in the file. so the child can actually run write us our message, means i also need include sis. wait so many header files, but anyway we'll get. we'll get them all in there eventually. kinda be nice be able say include star, but that would probably not be great either. so anyway, we're going wait now."
"""OpSys_Interprocess_Communication_Transcript.txt""","if apparent was try just read immediately and there was no data in the file, read would say hey, nothing read, i'll return 0 bytes, so i'm gon na have the parent weight for the child finish so that we can actually get data in the file. so the child can actually run write us our message, means i also need include sis. wait so many header files, but anyway we'll get. we'll get them all in there eventually. kinda be nice be able say include star, but that would probably not be great either. so anyway, we're going wait now. we're going read from the child, so we're going need a place put it. 400 bytes and then we can read from that file descriptor into the buffer. the size of the buffer. as the compiler knows how big it is, and then we can print something like parent got. the message, is whatever is in the buffer. then it will close the file descriptor and then ultimately return. here i suppose i could put something like exit in here just just make the parent and the child. kind of duplicates of each other, but it's 601 so long as i close it. if i return here, it's gon na be the same outcome. so i'll just do that. ok. and virtually i ca n't fit all this on one screen, but. now, pretty close thoughts with me. right. so let's run this. is so here it's compile this what i call it. fork file. good. let's run it and we get. child wrote parent ok parent got what? nothing. ok, so let's look at my file. hey look, the file got created. that was great because i said created if it does n't exist and set the permissions properly. so that's great. and if we look at the file here, there is our message hello parent. i did n't. we get. they did n't apparent. yeah. yeah, it is. yes, let's say that's an easy one, but it's not necessarily easy. it's not necessarily intuitive, but it is true. remember i said that parent and children share open file descriptors. as a result, they share entries in the file descriptor table and bam, right. here is the file position, pointer or the file offset pointer and the parent and the child share this. so when the child went do a right, i do n't have right on this picture."
"""OpSys_Interprocess_Communication_Transcript.txt""","yeah, it is. yes, let's say that's an easy one, but it's not necessarily easy. it's not necessarily intuitive, but it is true. remember i said that parent and children share open file descriptors. as a result, they share entries in the file descriptor table and bam, right. here is the file position, pointer or the file offset pointer and the parent and the child share this. so when the child went do a right, i do n't have right on this picture. but when the child went do a write, it wrote data the file and then the operating system advanced the file position pointer be after the end of the right or the first bite after the the the right was done so the data got written in the file. but when the parent went read from that file, the file position pointer was at the end of the file where the child had written. so the operating system said great time read, we're at the end of file. so parent you get read 0 bytes. has things like we do well. i mentioned that there was a system call out there is actually kind of helpful. called elsik and it's leak. that's leak. apparently a band called week. i'll seek. there it is, and it repositions the file offset or the file position pointer and we can specify a file descriptor and offset for how far we wanna move it either positive or negative, and a whence is a relative value, and the whence is one of three things. either we're seeking it at a particular spot, seek setting it, seeking it relative its current location, or seeking it relative the end. so if i want the parent be able read this, i have have the file position pointer be the beginning of the message. so i have zip it back the beginning of the file. so i can do that by going back over here and say after we waited for the child write the file, we can do it elsik into the file descriptor in offset of 0 seek set the set it 0. and now when we compile this and run it. we get hello parent. ok, alice file system. i like this. i like this because it's something i'm used. we're reading and we're writing. the child was sending data the parent where it writes parent, reads, write, read, write, read. what i do n't like about this, i do n't like lying 33. i do n't like this elsie thing because."
"""OpSys_Interprocess_Communication_Transcript.txt""","so i can do that by going back over here and say after we waited for the child write the file, we can do it elsik into the file descriptor in offset of 0 seek set the set it 0. and now when we compile this and run it. we get hello parent. ok, alice file system. i like this. i like this because it's something i'm used. we're reading and we're writing. the child was sending data the parent where it writes parent, reads, write, read, write, read. what i do n't like about this, i do n't like lying 33. i do n't like this elsie thing because. i do n't really want have move the file position point around every single time i wanna read data. partly because in this particular case i knew where put it, and so what if i did n't? did n't know where put it or i did n't know how big the message was or i did n't like there's some things about this or what if i wanted the child write multiple messages the parent and i want have the parent read each one, you could say ok, well, the child could separate them by a new line and the parent could then read them in and use like str token or something like that break them into pieces or something like that. maybe we have some other eye catcher. and that's i you know i i'm thinking networking here but those have taken network protocols even if it has n't. i'm really kind of thinking i'd really like this be like a stream of data with a child can stream and like send potentially a whole bunch of data. the parent and i do n't have manage this file position pointer if i want communicate between parent child. i really just wanna do that and not have worry about. well, we have move the position pointer forward or back like the parent wants data just give me data if there's data there, give it me. if there's not, let me wait. right. ok, that might be a lame motivation, but i'm just gon na skip it and go on the next thing anyway, because there is another way do it, i want talk about, is this going back these slides and i wanna go down. right, this was shared file. here was the problem. pipes. ok, here's what a pipe gets us we have bias. ok, so we have the idea of reading and writing a file descriptor."
"""OpSys_Interprocess_Communication_Transcript.txt""","if there's not, let me wait. right. ok, that might be a lame motivation, but i'm just gon na skip it and go on the next thing anyway, because there is another way do it, i want talk about, is this going back these slides and i wanna go down. right, this was shared file. here was the problem. pipes. ok, here's what a pipe gets us we have bias. ok, so we have the idea of reading and writing a file descriptor. i kind of like that cause reading and writing makes sense me. but i do n't like the file name thing because now i have give a name this communication channel and i'm just communicating with parent child, so a name does n't really make a whole lot of sense. it's persistent in the file system, so if i really do n't need it anymore, i got unlink it or delete it. that's just kind of weird. and so what i kind of want is this temporary communication channel where i can write data and read data from it. kind of like a water hose and say the child's gon na pour water down the hose. the message the parent and the parent can read the data out the other end of the pipe pipes. the operating system does this for us. it says here user you wanna do this. great. i will create an anonymous communication mechanism that you can use called the pipe because there is 2 ends of the pipe. now i'm gon na make it a little bit more complicated for you, but if you get used it, it's not so bad with the file. i have one file descriptor that's shared. because of the way the file descriptor pointers work for a pipe, i need have two. i'm going have a right end where you're gon na be able write data on one end and a read end where you can read data off the other end just like. of course you put water in one end. it goes through the pipe, the hole is and it goes out the other end. i like think of this like my daughter plays like this on the playground where she has been got these little like. i do n't know, like coins that, like could go up, pipe down the ground and you can talk through them. and there's a kid on the other end. could like put list of imagine a situation if you could only talk and then the other person just sat there and listen."
"""OpSys_Interprocess_Communication_Transcript.txt""","of course you put water in one end. it goes through the pipe, the hole is and it goes out the other end. i like think of this like my daughter plays like this on the playground where she has been got these little like. i do n't know, like coins that, like could go up, pipe down the ground and you can talk through them. and there's a kid on the other end. could like put list of imagine a situation if you could only talk and then the other person just sat there and listen. you could send data through the pipe the other side of the playground. you have the right end of the pipe. the wri t dot ri ght, but the right hand and the read end ok. currently trains a position pointers, is great. and if there's data in the pipe, the recipient will receive the data from the pipe, and if there is n't data in the pipe, the operating system does a really unique thing right now with the file system. if there's no data in a file, the operating system just says like. i'm not good for you. read will return immediately. what? what a pipe allows us do is do what's referred as a blocking read, where if there's no data in the pipe, the operating system will say, oh, you want read some data. that's fine. there's nothing there. i'm just gon na block you. i'm gon na send your state be suspended and then not let you run until there's data there, is in a way i know what i'm looking for cause the parents waiting for a message from the child and so the pipe world do a lot of that automatically. i do n't have do an explicit weight like i did in this example. ok, so let's see how this works. new file fork, pipe. and let's go back in here because i never remember all the header files. i know these are probably pretty close. and let's see. so what i want do, let's go back my fork file. i'm not gon na open. i'm gon na use pipe. how do we use pipe? well, we go the main page. and it says pipe creates a pipe. thank you man page. well, anyway, it does essentially what i had in the slide. it creates a pipe with two file descriptors, so with open i had do things like specify the intended purpose and specify the file name."
"""OpSys_Interprocess_Communication_Transcript.txt""","and let's see. so what i want do, let's go back my fork file. i'm not gon na open. i'm gon na use pipe. how do we use pipe? well, we go the main page. and it says pipe creates a pipe. thank you man page. well, anyway, it does essentially what i had in the slide. it creates a pipe with two file descriptors, so with open i had do things like specify the intended purpose and specify the file name. pipes are anonymous. they do n't have a file name, they have a file descriptor. in fact, they have two file descriptors, the read end and the right end. the intended purpose? well, we're always gon na have a read, and we're always gon na have a write in. so we never have tell the operating system. i wanna read and write the fight. it just says. here you go. here's both ends. good luck, right? that's it. and finally, also we actually get a situation where if we look down here in the return value, it returns zero on success and -, 1 on air. so we're not any of these special cases. it's just like if pipe works, we get back zero. it would fails. we get -. one. ok, that's fine. pretty simple system call. so let's go back right here, and if i want pipe, i need create. an array of two file descriptors for the pipe and. we're going make a call pipe passing in the pipe fd's. this should be plural because i filed the script errors. and then if it returned -, 1, that means it fails. so i can do a print out of like type failed. and then i should probably do this and then return -. one could say we have an error, ok. then we're going do our fork stuff, because here's what's cool about pipe. while i did n't call open open a file descriptor pipe, did this implicitly. it opened two file descriptors, one for the read and and one for the right end was the result. i have filed the scriptors file descriptors are shared across the board, right? so i can have parent and child both share these file descriptors. it's a way get file descriptors without explicitly calling open, so let me go back over here my fork file."
"""OpSys_Interprocess_Communication_Transcript.txt""","then we're going do our fork stuff, because here's what's cool about pipe. while i did n't call open open a file descriptor pipe, did this implicitly. it opened two file descriptors, one for the read and and one for the right end was the result. i have filed the scriptors file descriptors are shared across the board, right? so i can have parent and child both share these file descriptors. it's a way get file descriptors without explicitly calling open, so let me go back over here my fork file. i'm going copy some of this because i do n't want keep retyping all these if statements over and over again, so then this is the child. else this is the parent. ok. couple of other things here. i'm closing the fd if fork failed. i have two ends of the pipe. now i have the read end and the right end. when i exit on error or exit on success i got ta make sure that i close both ends. ok so. instead of just closing afd, i got ta close pipe's of zero and close pipe f these of one. i could n't do a four loop or something like that, but it's probably just as many lines of code right at that way. ok. all right, so there's that. and now we got do some thinking here. and this is where pipes start hurt my brain. but it's something we got ta think about. the child is going send data the parent ok do the pipe so the parent is going read from the read and it's the kids sitting on the far end of the playground with ear up the plane and the child is going write the right end. it's the. it's the on the other end where its mouth and the comb. so the child is writing the parent, it is not reading from the from the pipe, so it does not need the read end of the pipe. by inheritance through the far, it gets both file descriptors, but it's only ever gon na use one of them, so we have make sure we close the part that we're not using. ok, so the child is not breathing. child is not reading so close read and that means we're gon na close pipe fd's and i never remember this. so i always have go back the. man page. and it says pipe creates a pipe, a unidirectional data channel level between enterprise communication. the array ok for the two file descriptors."
"""OpSys_Interprocess_Communication_Transcript.txt""","by inheritance through the far, it gets both file descriptors, but it's only ever gon na use one of them, so we have make sure we close the part that we're not using. ok, so the child is not breathing. child is not reading so close read and that means we're gon na close pipe fd's and i never remember this. so i always have go back the. man page. and it says pipe creates a pipe, a unidirectional data channel level between enterprise communication. the array ok for the two file descriptors. pipe 0 refers the read and and pipe 1 refers the right and i can never remember ones. so i want close the read end because the child is going be writing data the parent, so that's zero ok parent is not writing, so it we're going close the right hand. is one ok, in the future i will try use the word correct instead of the word right distinguish it from the right anyway, so you guys get there. so now the child is not gon na write, rather not going read it's, but it can write. so need where's my message? here's my message about this, and i should probably just i'll just copy this too just for a good status indicator. so the child is now going write the parent, and it's going write down the right end. ok, the parent is going read and needs a buffer store it in this. and it's going read not from this file descriptor, but from the read and pipe fd0. ok, good. good. when we're done writing, we need close. close right and and in the close the right end. and exit exit successfully. here we need close the read and and exit. those pipe have these zero and exit. questions. all right. so is it more code? maybe we got we got we have extra files descriptors we have deal with, but couple of things that we do n't have worry about we no longer have worry about elsik. it's kinda nice. the operating system takes care of handling all the position pointers. it takes care of this sort of internal linking between the read and the write end guys, and what i also think is really cool is i do n't have wait. i can just do a reading directly and now i'm waiting for the child finish because when the parent keeps running after the fork, if that is the case, it's gon na close the right end."
"""OpSys_Interprocess_Communication_Transcript.txt""","maybe we got we got we have extra files descriptors we have deal with, but couple of things that we do n't have worry about we no longer have worry about elsik. it's kinda nice. the operating system takes care of handling all the position pointers. it takes care of this sort of internal linking between the read and the write end guys, and what i also think is really cool is i do n't have wait. i can just do a reading directly and now i'm waiting for the child finish because when the parent keeps running after the fork, if that is the case, it's gon na close the right end. this is not gon na use it, and it's gon na read from the reading the operating system's gon na say. yeah, no data in the pipe, so it blocks and it says like anybody else run. ohh, the child can run so it loads the child, lets it run. it's gon na then write the right end of the pipe, and maybe it's gon na continue. who knows? it does n't make a difference. as soon as it writes, there's data in the pipe. so if the parent then wakes up again, they can then read the data that's in the pipe, get it back, print out what that is, and then falls and keep going. ok. question. yeah. so read on, the parent awaits anytime we read out of pipe. if there's no data in the pipe, it waits until there's data there and it's, but not normal. probably just this is pencil specifically for pipes. yes, if you're curious, that is one of the, you might say, well, what if i did n't want it block? there's another system called called pipe two allows you specify additional flags, and one of those flags is. do n't block where? what we'll do is, if there is no data in the pipe and you try read from it, it will give you a message or a value back saying there was no data there. ohh, but by default using pipe it will block when you try read if there's no data there makes sense. ok. while the questions. yeah, let's go back and read the code. yeah. so the the pipe is kind of a continuous flow of data, right? yeah, since the stream of data. yeah."
"""OpSys_Interprocess_Communication_Transcript.txt""","what we'll do is, if there is no data in the pipe and you try read from it, it will give you a message or a value back saying there was no data there. ohh, but by default using pipe it will block when you try read if there's no data there makes sense. ok. while the questions. yeah, let's go back and read the code. yeah. so the the pipe is kind of a continuous flow of data, right? yeah, since the stream of data. yeah. so if the read function waits until there is data in the pipe, when is it stop waiting like as soon as there's a single byte of data, does it only get that single byte of data? yeah, that's a really good question. and so this might be a partially lame answer, but i have an example of this so as well, but it returns whatever data is there. much. how much is there? i asked receive 100 bytes. the operating system is going fill in at most 100 bytes. ok. so that's one limit says i'm not gon na get more, but up here, the childhood we wrote, i do n't even know how many bikes is that? well, 14, something like that. so how do i know if i should keep waiting that there might be more data? how do we know when it's done right? here's the key this is what's cool about pipes is imagine a situation where you had a bunch of where you had a pipe, but now let's augment the pipe and we'll put my flapper valves on the end of it. ok, you have visualize this in your head. i'll type with little like flap on it that we can close. ok, that's what they close statements are. the operating system knows as soon as all of the right ends of the pipe are closed, it's. i mean it's operating system, it has access all that information. these are system calls and so it's keeping track of all this in the bookkeeping. so it knows that as soon as everybody that has an open file descriptor the right end closes it, there's no more data coming. nobody has the ability write anything else, so at that point it knows immediately. i know you asked for 100 bytes, but there's only 14 there and nobody else is gon na be able write anymore. so here's what you got, but that answer, ok."
"""OpSys_Interprocess_Communication_Transcript.txt""","i mean it's operating system, it has access all that information. these are system calls and so it's keeping track of all this in the bookkeeping. so it knows that as soon as everybody that has an open file descriptor the right end closes it, there's no more data coming. nobody has the ability write anything else, so at that point it knows immediately. i know you asked for 100 bytes, but there's only 14 there and nobody else is gon na be able write anymore. so here's what you got, but that answer, ok. so another reason why it's very, very, very important close your file descriptors so that you can tell the operating system information. so it wo n't keep waiting. all right, so let's actually now run this. not not not for file. it went fork pipe. there is child growth the parent parent got hello. no elsik, no waiting. whenever it's all there. ok, so get back dylan's question is what if we did something like this? where the child writes a message and then does something like, we're gon na have the child sleep for a second and then write more. there's have it just right. again that message again. under the assumption we actually include all of our semicolons. we see that while the child wrote hello parrot twice, apparent only got it once because at the point of the read the child wrote hello parent and then went sleep. at that point, the parent woke up and said i would like read some data and the operating system said i got 14 bytes for you. here you go because it does not know that the child was gon na write more bytes. so it just says. here's what you got. the parent then print out what it's got and then it exited. then you'll say. ok, great. why do n't we see the message saying the child wrote parents are we see his parent got this? what happened was. the parent closed its end of the pipe and it exited at that point because the operating system knows knows that the child is a child of the parent. when the parent terminates, it ends the entire process tree, so it's as if the child just got consumed and side alright, even though the child was waiting. then matter make a difference. the parent died, so the child's gon na die you."
"""OpSys_Interprocess_Communication_Transcript.txt""","why do n't we see the message saying the child wrote parents are we see his parent got this? what happened was. the parent closed its end of the pipe and it exited at that point because the operating system knows knows that the child is a child of the parent. when the parent terminates, it ends the entire process tree, so it's as if the child just got consumed and side alright, even though the child was waiting. then matter make a difference. the parent died, so the child's gon na die you. so little gotchas that make me sometimes wanna rip my hair out, but for the most part, if you just do n't do weird stuff, it'll it'll be ok. i will let you decide for yourself what it means do something weird. so i'll go back this rule of thumb is make sure you close your pipe ends when you're done, ok? and if you're a parent, if you really wanna wait make sure your child finishes, do n't terminate early. otherwise, you might accidentally terminate your child ok. yeah. ok, sorry. alright, so next thing, where are we at? we got 10 minutes left. i got i got. i got stuff here. ok, where am i at? i do n't have it listed here, but we kind of got this. a pipe is a unidirectional. there are communication mechanism. we can commute, communicate and send data one way, is kind of like a hose, right? i wish i, in a way had a magical hose where i could send water down the hose in both directions at the same time. does not work. water only flows one direction down the pike. if i wanna have water flow the other direction well, and you know the pipe. so pipes in the same way in programming, if a in this case in my example here my child communicated with my parents. if i want the parent communicate with the child and the childhood communicate with the parent or other send data the parent, what it in both directions. i need two pipes, so here's where. now you're gon na start throwing tomatoes at me and say, doctor lemke said pipes were cool, yes. it is, but this is now where things gon na look, lugy. so let's let's just copy this example over. so now i got this."
"""OpSys_Interprocess_Communication_Transcript.txt""","so pipes in the same way in programming, if a in this case in my example here my child communicated with my parents. if i want the parent communicate with the child and the childhood communicate with the parent or other send data the parent, what it in both directions. i need two pipes, so here's where. now you're gon na start throwing tomatoes at me and say, doctor lemke said pipes were cool, yes. it is, but this is now where things gon na look, lugy. so let's let's just copy this example over. so now i got this. instead of having just type, i'm gon na create two pipes, one for the child send a message the parent and one for the parent send a message the child. so the first one is going be two child. yeah. and the second one i need make another one here. a parent. and then pipe this. all right, here's the kicker. now when i'm here piping open the two parent pipe, i've already opened the two child pipe, so i have make sure that i close the two child pipe ends. it looks kind of weird, but i got do that. so here's my piping. now i've got a pipe going the parent and a pipe going the child. ok, i'm gon na fork. i have. how many file descriptors? four, i'm gon na keep track of this now, if fork failed, i have close these two. and close the two parent. both the read and the write and all right now child is reed is not reading no reading well the child is reading now, but it's not reading on the read and of the two parent pipe it is writing on the two parent pipe so it does n't need that one. so child is not reading. the parent. so it's going close the read and of the two parent pipe because that's the parents job is read on that and the child is not writing the child. so it's gon na close the right end of the two child pipe. alright, similarly the parent is not reading the parent, so it's going close the read end of the two parent pipe and the parents is not writing the parent. no. yes. so we're going close the right. sorry, i got my words wrong. alright, it's not writing itself and it's not reading itself, and that's two child. ok. so that's that."
"""OpSys_Interprocess_Communication_Transcript.txt""","so it's going close the read and of the two parent pipe because that's the parents job is read on that and the child is not writing the child. so it's gon na close the right end of the two child pipe. alright, similarly the parent is not reading the parent, so it's going close the read end of the two parent pipe and the parents is not writing the parent. no. yes. so we're going close the right. sorry, i got my words wrong. alright, it's not writing itself and it's not reading itself, and that's two child. ok. so that's that. so now when the child is going write, it's gon na write the parent two parent on the right end the message, and then it's gon na close the right end of the two, the parent. there's not going exit yet. now it's gon na read a message. so now i need a buffer. we need a place put that. we're going read from the two child the read end into the buffer, the size of the buffer, and then we're going close that child. the read and and now we can exit. just do that. ok, so we write the parent. we read from the parents. we're done. we're gon na write on the right end. we're gon na read on the read end of the other pipe. we're gon na make sure we close and we're done. we should have four closes 1234. good. now let's try do the same thing on the parent. so the parents going write the child that's going do the child on this guy parent wrote. ok. no, it's gon na read the parents. good parent got that. now we can close that cause done the parents. it's done reading. now it's going write the child, so we need a message. will be hello child. and now we're going write the child. on the right end. the message and the. sizov noodles esterlyn of the message. and we're actually doing alright. and then we're going close the two, the child right and and then exit. 1234 we read on the read end of the two parent we write on the right end of the two child, and then we close it and we're good. questions there your brain starting get tired. mine is. all right, it's a little confusing, but yeah, it all it all makes sense."
"""OpSys_Interprocess_Communication_Transcript.txt""","on the right end. the message and the. sizov noodles esterlyn of the message. and we're actually doing alright. and then we're going close the two, the child right and and then exit. 1234 we read on the read end of the two parent we write on the right end of the two child, and then we close it and we're good. questions there your brain starting get tired. mine is. all right, it's a little confusing, but yeah, it all it all makes sense. hopefully in the end. so now we're going compile this. i'm gon na calling it fork pipe 2. and have some acolon extra parenthesis and what am i doing? i'm missing the parenthesis here. there. and if i run this. oh, i do n't. i'm not putting out a status message. parent wrote child. and when the child reads, we should print this out. child god. upper. there. the thing pipes ok. i'm kinda out of time so and canvas. i took these examples and. for files, for pipe, fork, pipe, multiple pipe weight, that was. the other one we'll worry about exec with pipes tomorrow. so with tomorrow, do n't forget about the project. due tonight. we're good afternoon. see you later. lembke, james stopped transcription"
"""OpSys_IPC_Mechanisms_Transcript.txt""","meeting in _ general_-20240229_130421 - meeting recording february 29, 2024, 7:04pm 47 m 1s lembke, james 0:09 hello. hello. great. alright, so welcome. welcome class. what do we got going on? let's let me pull up canvas cause i can never remember. so haha, this is wrong. first off announcement it is, yeah, it is correct and it's also wrong announcement here is i mentioned that open forum. i'm not gon na be able go. i'm going the faculty demo lecture, please. if you're free, they're this time. please attend and give us feedback. the one thing that's wrong i'm going correct it right now is it is not in direct sell 110, it's actually in diercks hall 210. so, uh, if you wanna come, please do. if you go diercks hall 110, i believe that there might be a machine learning or a data science class going on in there. so you know that might be fun go. what the actual demo lecture is in 210, so it's like right? i think if you like drop one floor from where we are right now, i think that's where the room is. i think we're in 310, right? yeah. so that's an announcement, other announcement friday, we will have a quiz in class. it will be on file descriptors and pipes. the stuff that we talked about last week and then what i also did is i posted a whole bunch of examples here on stuff that we're gon na go through today. so plan for the week for the rest of the week is we're gon na finish up message queues today. we're gon na get in and talk about signals. and then on friday, we're not gon na finish it, but i'm gon na start talking about and introducing shared memory and that will be our last interprocess communication mechanism that we will talk about. there are others. umm would just wanna pick the ones that i think are the most important, maybe most commonly used. there are other ways for process be here communicate, but pipes, message queues, signals and shared memory are kind of the most popular ones. if you want communicate typically in another way, well, we'll get on the next topic after shared memory, will be threads, is really how we often will communicate between stuff. so that is where we're at. let's go where we were, where we are, where we were."
"""OpSys_IPC_Mechanisms_Transcript.txt""","umm would just wanna pick the ones that i think are the most important, maybe most commonly used. there are other ways for process be here communicate, but pipes, message queues, signals and shared memory are kind of the most popular ones. if you want communicate typically in another way, well, we'll get on the next topic after shared memory, will be threads, is really how we often will communicate between stuff. so that is where we're at. let's go where we were, where we are, where we were. let's just let's just keep going. and it was kind of right here and also right here, let me just take this picture and go back my picture that i drew, was this. and that pipes are cool because, well, as i'm sure that you are all working with and your programming project, they allow us stream data from one command another. they allow us stream data from one process another, is essentially what we're what you're doing, but it is really just that it's a stream. the data that is sent through a pipe is unstructured. it is a stream of bytes. so if we want send data between a parent and a child process or between any two processes, regardless of relationship each other using a pipe, they have know in a way what the data is gon na be formatted. apps, whether it's gon na be a string or a structure or whatever, they got ta know they have agree upon it, just like in a network protocol. you got ta have agreement on what these messages are gon na be formatted as. so and your message queues kind of gives us an additional context associated with our messages it it's not necessarily just gon na be a stream of bytes, but it is n't a way kind of a stream. we are still writing or sending a few and reading or receiving from a queue, but what we're receiving is not an array of bytes, it's a series of messages. so that's the first thing with the operating system gives us the ability kind of structure this. now when we look at the interface for sending and receiving, it's really going be a bunch of bytes, but it's gon na be a block as opposed just a bunch of lights. the other thing that the operating system provides for us with a queue, whether we like it or not, is that with a pipe we can kind of conceptually think of them and think of it as unlimited space."
"""OpSys_IPC_Mechanisms_Transcript.txt""","we are still writing or sending a few and reading or receiving from a queue, but what we're receiving is not an array of bytes, it's a series of messages. so that's the first thing with the operating system gives us the ability kind of structure this. now when we look at the interface for sending and receiving, it's really going be a bunch of bytes, but it's gon na be a block as opposed just a bunch of lights. the other thing that the operating system provides for us with a queue, whether we like it or not, is that with a pipe we can kind of conceptually think of them and think of it as unlimited space. we can write as much as we want a pipe. if we try read from a pipe that's empty, we we block saying, well, there's no data there, but if we try write a pipe whenever really gon na get into a situation with a pipe is full. now ultimately, yes, we are limited in our amount of memory and we will have a limit the maximum pipe size, but for all intents and purposes, we can keep writing where the message queue we have specify the structure as far as helping our messages as well as how many messages are going be on our queue. and then as a result, we can now have this idea of not only empty, but also full. and what do we have deal with? it are probably wanna deal with a full queue, specifically when we're sending. if we're gon na read from a full queue, ok, then you just get the next message. but we wanna write a full queue. it's like trying pour water in a bucket that's full. what do you wanna do? you wanna say? the buckets fall. you go take that water elsewhere and immediately return. or do you wanna just sit there and keep looking at the bucket, waiting pour stuff in it until somebody dumps something out of the bucket, right. so that's this idea of a blocking versus a non blocking for both receive and for send. now, because we have a situation where it's full, we'll find them. when we look at the man pages for send and receive, the default behavior in linux or posits operating systems is block always and say if you're trying read or receive a message from an empty queue, you block. if you try write a full queue, you block."
"""OpSys_IPC_Mechanisms_Transcript.txt""","or do you wanna just sit there and keep looking at the bucket, waiting pour stuff in it until somebody dumps something out of the bucket, right. so that's this idea of a blocking versus a non blocking for both receive and for send. now, because we have a situation where it's full, we'll find them. when we look at the man pages for send and receive, the default behavior in linux or posits operating systems is block always and say if you're trying read or receive a message from an empty queue, you block. if you try write a full queue, you block. there are other options turn that into a non blocking, but that is typically the the the behavior. ok. alright. so let's then go back the code now and say here's where we left off, more or less right here, where i've got a message queue that i'm creating called this queue. i'm going create the queue if it does n't exist, so there's a whole bunch of the different parameters that we have specified for open. there is n't like a create queue function, it's just an open with an optional created. if it does n't exist, so i'm gon na try and open it for reading and writing. i mentioned that message queue descriptors are not file descriptors, but they're message queue descriptors are also shared between parent and child. so i'm gon na do in this example is create a queue in the parent, do a fork and then both parent and child manipulate the queue. so i'm gon na open it for reading and writing, despite the fact that the parent is n't gon na do any reading. it's just gon na send a message the child, but they're getting the idea here. i'm hoping for reading and writing, decided not open it twice, once in the parent, once in the child, but we could do that. yeah. there you we're going create this exist if it does n't exist there tell the operating system what permissions give the queue is going be read and write permissions and then we have specify what the queue attributes are."
"""OpSys_IPC_Mechanisms_Transcript.txt""","so i'm gon na open it for reading and writing, despite the fact that the parent is n't gon na do any reading. it's just gon na send a message the child, but they're getting the idea here. i'm hoping for reading and writing, decided not open it twice, once in the parent, once in the child, but we could do that. yeah. there you we're going create this exist if it does n't exist there tell the operating system what permissions give the queue is going be read and write permissions and then we have specify what the queue attributes are. this is different than a regular file because a file kinda has many attributes are just create the file, but when the queue we have tell the operating system how many messages put on the queue or how many slots make, it's going be an initially empty and then what the size of each message is and the size of the message is going be whatever it's the size of my message here that i created is most likely going be somewhere around and the minimum. it's gon na be probably 4 by plus 10 or 18 bytes, but the compiler likes lay this out in even powers or two. sort of. color. uh, whatever the next power of two is 32 bytes. that the next power of two greater than six, greater than 18? yeah, but i do n't have worry about that. i do n't care. i'm gon na send messages, so i'm gon na tell the operating system just allocate space for the whole size and and then finally i mentioned that we got close the queue and we're done with it, just like we had close any file we open. queues are persistent. they stick around after processes terminate so well with the pipe. once all of the references the pipe have been closed, both the read and the write ends. the operating system says no one's reading, no ones writing, so i'm just going clean it up with a queue. it sticks around until explicitly deleted and so just like a regular file like my file dot txt, it sticks around until we actually explicitly delete it. no, that's where we're at. so the next thing i want do is now once we have the queue created an opened, we're gon na do our fork. so what i'm going do is go over here fork file and copy the. i get kind of tired of writing this over and over again, but it is true. we got ta write it."
"""OpSys_IPC_Mechanisms_Transcript.txt""","it sticks around until explicitly deleted and so just like a regular file like my file dot txt, it sticks around until we actually explicitly delete it. no, that's where we're at. so the next thing i want do is now once we have the queue created an opened, we're gon na do our fork. so what i'm going do is go over here fork file and copy the. i get kind of tired of writing this over and over again, but it is true. we got ta write it. so i'm going fork and if i have an error, i'm going do an mq close on the on my queue and then return. i saw just exit. otherwise. if the pit is zero, that means we're in the. child. if the process identifier is the child pid, is essentially anything not -, 1 and 0, then we're in the parent, so both parent and child are required close the queue. so i'll just put that in there. so i do n't forget. open both get close. it's weird. there's one open and two closes, but this is inherited the child, so we have close it. alright, so now we're going do a. the child's going do a receive. actually, let's do this. the parent will do a send. parent sends the cube, so we got ta figure out. let's see send the queue, we need a message. so i'm gon na make a message, and that's gon na be my. let's call it two child. and i'll use the as we learn from our c review. the inline struct declaration where i can just declare values right away. so i'll say the value is 10100 and hello is fills in this message here. all right, now i got send it, so i need learn how send. i got ta go canvas. no. send i'm i'm queue send. and we see that with send i need include mqh sure if that makes sense and that there's actually 2 flavors of zen. there is sen and thyme sen both looked fairly similar, except time send has this additional parameter associated with it. umm, i mentioned that we have options for blocking or nonblocking queues. the default is blocking both for reading and writing. what this time send says is operating system attempt send this message on this queue. if it's full, you're gon na block."
"""OpSys_IPC_Mechanisms_Transcript.txt""","send i'm i'm queue send. and we see that with send i need include mqh sure if that makes sense and that there's actually 2 flavors of zen. there is sen and thyme sen both looked fairly similar, except time send has this additional parameter associated with it. umm, i mentioned that we have options for blocking or nonblocking queues. the default is blocking both for reading and writing. what this time send says is operating system attempt send this message on this queue. if it's full, you're gon na block. i know that i understand that you're gon na block if it's full, but i only want you wait for so long before you just say you know what? no one's reading from this. it's still full. you're gon na have do something with it, so if you wanna have, like a timeout for sending something, you can put that in there. i'm not gon na worry about that now, but i do want mention that it does exist and this time spec is a structure specifying how much time you wanna wait. you can actually wait even like on the granularity of a nanosecond, is pretty short. but anyway, you could you could specify that. what i really wanna focus is up here send. i have specify the queue descriptor, is important because that's what queue i'm sending it. the message, the size of the message. ok. that makes sense. and then this last parameter is a message priority and that's something that i did n't mention with posix message queues. is that it actually is a priority queue and but messages are sent now for us. but based on the priority number, the operating system will automatically reorder the the messages so that the recipient will receive them in the order of highest priority. that's kind of nice. it's a nice option if i do n't really care about what the priority is, i i can just make them all zero or make them all one or make them all the same number and then the operating system will store them in the order in they were sent. but if i did n't care about priority, put that in there. i believe if we look in the man page though, priority is backwards in my brain. it actually uses the lowest number for a higher priority. so in orders them kind of like sorted order from least greatest. but for this example i'm just going use zero, so we're not gon na worry about that."
"""OpSys_IPC_Mechanisms_Transcript.txt""","it's a nice option if i do n't really care about what the priority is, i i can just make them all zero or make them all one or make them all the same number and then the operating system will store them in the order in they were sent. but if i did n't care about priority, put that in there. i believe if we look in the man page though, priority is backwards in my brain. it actually uses the lowest number for a higher priority. so in orders them kind of like sorted order from least greatest. but for this example i'm just going use zero, so we're not gon na worry about that. alright, so i'm pleased it returns. -, 1 on error and zero on success. so we'll keep that in mind. so mq send we'll send this message. we got ta send it the queue descriptor. we need send the message is a pointer the two child. this message size size of. struct message t and then the priority will just be 0 and if that's -, 1 then we had a failure. could not send. why? well, the health, the operating system tell us. uh, i'll just do this mq, close my q and exit with a bad return code. ok. otherwise, we'll close gracefully and return. one thing i wanna do in here because i do n't want the parent quit early. we'll just wait for the child finish and then we'll close it and return. i sent question. huh. mq close z. thank you. goodbye. alright, so that's send. let's look at the child. who's gon na receive? we see that receive looks very similar ascend, only that about the function. that declaration for the system call is different, but we have a version of received at a time received. same idea. send we can receive with a timeout. i'm not gon na receive with the timeout, i'm just gon na let it wait forever. we're gon na receive from a message description. we have a buffer where the operating system is gon na put our message for us. the size of that as well as a priority, and this is weird. we're not receiving a message at a particular priority."
"""OpSys_IPC_Mechanisms_Transcript.txt""","that declaration for the system call is different, but we have a version of received at a time received. same idea. send we can receive with a timeout. i'm not gon na receive with the timeout, i'm just gon na let it wait forever. we're gon na receive from a message description. we have a buffer where the operating system is gon na put our message for us. the size of that as well as a priority, and this is weird. we're not receiving a message at a particular priority. what this is gon na do is you notice this is a pointer, and when we were doing our sea review we we said that passing a variable by pointer is useful if we want someone fill in a value for us and end up remain outside. so if i pass a pointer an integer, what this will do is the operating system will fill in what the priority value is of the message that we just received. so we care about what that priority is. we can have the operating system tell us if i do n't care what the priority is and i just say, well, give me the next message, then you can pass null into there and the operating system will recognize it and not tell you what the priority is, right? i do n't really care what the priority is. i know that it's zero because that's what i just wrote, but if i did then i would use that. so right here, i'm just gon na use null. let's do that. so a child child receives a message and we're going, well, we need create a buffer for that message. we're not gon na initialize it anything because that's going get filled in on the receive and then we're going do this check here. it's going turn -, 1 on an error receive, and we're gon na receive from the message queue my queue. we're gon na receive into the buffer from parent and it's gon na be the size of a message. and i do n't care about the priority, so i'm just going use null. but not receive. and i'll just copy this there. mq close iq and exit with a bad return code because we had a failure. right there is the receive. child got message. let's see. you this is going be our from parent dot value one from parent dot value 2 and from parent dot text there's a message."
"""OpSys_IPC_Mechanisms_Transcript.txt""","we're gon na receive into the buffer from parent and it's gon na be the size of a message. and i do n't care about the priority, so i'm just going use null. but not receive. and i'll just copy this there. mq close iq and exit with a bad return code because we had a failure. right there is the receive. child got message. let's see. you this is going be our from parent dot value one from parent dot value 2 and from parent dot text there's a message. i'll do a nice return character so we get that formatted well, then we'll close and quit. there was a good, great. that's great. anything up? let's take a look. let's go and compile this mq demo. i got a couple of warnings. ok, so i did this on purpose because this is kind of weird. for what it's worth, while i'm sending a message, the operating system is expecting this parameter be a char star. so in this particular case, what i need do is just cast that a char star for both, then receive. and then when i compile it, i wo n't get an error. ok. there it is. child got message 10100. hello is the message i sent and you might look at that and say well, that's kind of uninteresting and in a way i kind of agree with you. but the reason why i feel like it's uninteresting is because we just spent the whole like, i do n't know, 3 - 4 days talking about pipes. and this really is not a whole lot different than a pipe. instead of using read and write where using send receive right. the only difference here though, is that this is a persistent queue. it's stuck around. it's still in my file system now. i'll show you where it is. uh, that's one thing. and there's a limit of size in in terms of the message capacity, so. let's let's let's let's set a way. just kind of pick this up a notch and say, alright, what does that mean? let's surround this. send in a four loop and then then make this interesting, let's send like i and like. 4i i do n't know, just some other data make it make these messages look different. so what did i do? alright. not if you know the answer. it's six, right?"
"""OpSys_IPC_Mechanisms_Transcript.txt""","and there's a limit of size in in terms of the message capacity, so. let's let's let's let's set a way. just kind of pick this up a notch and say, alright, what does that mean? let's surround this. send in a four loop and then then make this interesting, let's send like i and like. 4i i do n't know, just some other data make it make these messages look different. so what did i do? alright. not if you know the answer. it's six, right? we're looping 6 times. we're creating a new message. we're sending that message 6 times and the operating system is gon na copy this message off of the stack and this process into the message queue, and it's gon na hold 6 messages. the child's gon na receive one right? one message. and we're going exit. so after we're done, everybody's gon na close the queue. great. if this is a pipe, the operating system would say great, we're done. i'm gon na get rid of it and all the other data that you send will be lost, not with a queue. those remaining 6 -, 1 or five messages are going still stick around in that queue, even after all of these processes terminate, just like it's like writing text a file. that text exists even if all the processes terminate. so after i'm done, when i run this. sure enough, the child gets 00. hello because the first message that was sent is i with the value of 0 and value two with 4 * 0 is 0 and the message chloe but the other five messages are still in the queue. so when i run this again, the parents gon na try and send six more messages. well, they all fit. 5 + 6 is 11 is 1 larger than what will fit, so the parent will ultimately block when it tries send that 11th message as it's blocking you, the child will run and it's gon na read it and then provide a spot for that 11th message. it's gon na read another message, but it's gon na not get one of the newer messages. it's gon na get one of the five old ones that was sent previously. makes sense. so when i run this, i still have the messages where i as 1234 and five, so that should be 1/4 when i run this again."
"""OpSys_IPC_Mechanisms_Transcript.txt""","5 + 6 is 11 is 1 larger than what will fit, so the parent will ultimately block when it tries send that 11th message as it's blocking you, the child will run and it's gon na read it and then provide a spot for that 11th message. it's gon na read another message, but it's gon na not get one of the newer messages. it's gon na get one of the five old ones that was sent previously. makes sense. so when i run this, i still have the messages where i as 1234 and five, so that should be 1/4 when i run this again. so when i run it again, sure enough the child gets the next message that's on the queue. and if i run it again. now we have a problem. well, i mean it's not a problem per se, but it's maybe it's something we were n't expecting and that after running this twice, it's running it. once there was five messages left on the queue. after running it the second time, there's 10 messages on the queue after running a third time, the child can read the next message off the queue, is 2/8, but the parents still trying send the six more messages and there's not enough spots in the queue for that. and my line 52, the parents waiting all. i'm sorry the parent is not trying wait here. the parent is trying send another message the queue, but nobody else is reading that message off the queue and it's full, so it's sitting there waiting for somebody read a message. it sounds so it persists. so if i did n't want that happen and i actually wanted the queue be deleted after everyone is done with the queue, say for example on the parent side i have do an mq unlink. specifying the name of the queue. then the operating system will remove it. it will only actually unlink it though. unlink will only succeed if everybody has it closed. if anybody still has an open message queue descriptor that's member, that's that contract say this hue, this file is n't going get deleted out from underneath you, right? or through the windows message you try delete it, but a process is currently using this file whenever blah right? you ca n't. i'm like it. unless everybody's got ta close. so that's something consider. so let me kill this here. so that's cute, persistent limited in capacity. what else we got? where are they?"
"""OpSys_IPC_Mechanisms_Transcript.txt""","if anybody still has an open message queue descriptor that's member, that's that contract say this hue, this file is n't going get deleted out from underneath you, right? or through the windows message you try delete it, but a process is currently using this file whenever blah right? you ca n't. i'm like it. unless everybody's got ta close. so that's something consider. so let me kill this here. so that's cute, persistent limited in capacity. what else we got? where are they? we do n't necessarily need assume that we know where queues are the operating system just handles it for us. on linux i happen do happen know and i wanted show you where they are, just in case you're writing a program that uses queues and you need delete it and you're like, oh shoot, i have a bug and i forgot delete it. if you look in the directory on our linux called slash dev, this is a directory that consists of, not necessarily real files, but they are files that represent devices. so when you're researching file types on on linux, you know there was like character special or block special, or a whole bunch of other different special files in dev is where the operating system represents all of the devices on our system as a file. so i can do things like read the raw contents of my hard drives or read the raw contents of memory. kind of weird, but you can do that. one of the directories in helium notice is right here called mq and inside here. is my cue. so this is essentially where the operating system is storing the message queue. if i do n't want it anymore, i can just do a rm. mq this q and now it's gone. i. questions. yeah, if you have a if two different programs at the same name for the queue, but they interview. good question. so if two different programs or two different sets of processes are three different processes, or however many we have all try reference a queue of the same name, they will reference the exact same queue because it persists in the file system. it's just like if you had a whole bunch of processes that all opened my file dot txt, they would all reference that. now, if they all independently opened that file, they'd all have own independent reference it and own file position pointer. what were the queue? we do n't have file position pointers."
"""OpSys_IPC_Mechanisms_Transcript.txt""","so if two different programs or two different sets of processes are three different processes, or however many we have all try reference a queue of the same name, they will reference the exact same queue because it persists in the file system. it's just like if you had a whole bunch of processes that all opened my file dot txt, they would all reference that. now, if they all independently opened that file, they'd all have own independent reference it and own file position pointer. what were the queue? we do n't have file position pointers. we have send and receive, so if i have some rogue process that opens up a queue and just starts writing and sending messages it, it'll fill up my queue no problem. the way we can protect ourselves from that is with these. permission bits say if i do n't want anybody else write or send a message my queue, i can set the permission deny others or other processes access that queue and then when they try send it, they'll get a you ca n't send permission denied. so that's well, it actually would fail on the open, most likely because you ca n't open that with that particular set of permissions. so that's why we can protect ourselves. but sure enough, these are global for the system by name. that's i have have a unique name. if you want have different cues, good question, yeah. yeah, absolutely you can. so if i were run my program and then list that queue, i'll save you a long listing. this becomes as represented. it looks just like a regular file, so you can use the schmid command or change modifier change the permissions just like you would on any other file. so here i created it with read and write only for the user. but i can change that be something else that i wanted question. click questions. ok. actually i think change mod is not the modifier, it's changed the mode. maybe that does n't matter, but yes you can. ok. so that's cues. it's all i got cause they're so simple and simple. they're not simple. there's so similar pipes now, it just it is we already know pipes, so let's go on. let's make sure did n't forget anything. living size? yeah, blocking sundeep blocking. see your man pages, but seth start. ok, good. we got it. signals move on signals once the signal. i like signals. they're pretty awesome."
"""OpSys_IPC_Mechanisms_Transcript.txt""","maybe that does n't matter, but yes you can. ok. so that's cues. it's all i got cause they're so simple and simple. they're not simple. there's so similar pipes now, it just it is we already know pipes, so let's go on. let's make sure did n't forget anything. living size? yeah, blocking sundeep blocking. see your man pages, but seth start. ok, good. we got it. signals move on signals once the signal. i like signals. they're pretty awesome. why do i like signals is because they're different for all of the inner process communication mechanisms that we talked about today, is really file descriptors, pipes and message queues. and then next time we'll talk about shared memory. that those four are kind of all lumped. i like lump them into the same category versus signals kind of having slightly different behavior. uh. while the scriptors pipes, message queues and. shared memory are all sort of synchronous interprocess communication mechanisms. or i want confirm that was as explicit access inter process communication mechanisms. if a process wants communicate via that particular mechanism, it has say i am making an active decision use this pipe, right? it says i wanna send data on a pipe i'm writing it. i'm making that decision right? nobody's gon na make that a decision for that process. signals are different, and then that they're asynchronous. it's kind of like you're sitting at your desk and you're working, not expecting anybody send you anything. you're not expecting talk anybody and all of a sudden you get a text message on your phone and your phone goes bling and you say ohh i got ta check my phone. right. you wanna expecting that happen? you did n't make an active decision say i am waiting for this call. i'm not going do anything until that call comes in. no, you just you just got an asynchronous notification. signal is like that. the process in this case can run and run and run and run, do all of its job. all of its work and a signal can come in and the process is like ohh hey this this signal. i got ta do something with it. it's an asynchronous notification, so as a result, the way we deal with signals is a little bit different than the way we deal with all the other enterprises communication mechanisms."
"""OpSys_IPC_Mechanisms_Transcript.txt""","no, you just you just got an asynchronous notification. signal is like that. the process in this case can run and run and run and run, do all of its job. all of its work and a signal can come in and the process is like ohh hey this this signal. i got ta do something with it. it's an asynchronous notification, so as a result, the way we deal with signals is a little bit different than the way we deal with all the other enterprises communication mechanisms. because with the other ones we have call a system call this like i would like use this pipe or i would like use this message queue with the signal the operating system is going say process you got this signal. how would you like deal with it? but that process might be in the middle of doing something else that's kind of weird. it's like, well, how do i use or? how do i run code in the process? while i'm in the middle of doing something else you think about i'm in the middle of an infinite loop or something huge mathematical computation, and the signal comes in. i ca n't like return from where i am and then go and call another function or call an operating system system call. i'm in the middle of a computation. the cpu is doing something. so intuitively any. any thoughts on how you might be able do this? it's weird, yeah. i like the intuition because the answer is yes. so they're ok. good. so yes, do you thing is is right right. so if i'm executing an instruction stream, if i have nothing else that i'm keeping track up, i know the cpu is keeping track of the registers for for what i'm currently like operating on, and then the current instruction of executing. but the big sort of important thing about what indicates what i'm doing and what me what the cpu is doing is the program come. and so if it's in the middle of some computation, the program counter is gon na point a location in the text section. for what it's doing, and i can pull up that that picture. he also cpu picture. yeah. yes, right. and so if i want have the cpu change service and handle my signal, i could n't have a function right?"
"""OpSys_IPC_Mechanisms_Transcript.txt""","but the big sort of important thing about what indicates what i'm doing and what me what the cpu is doing is the program come. and so if it's in the middle of some computation, the program counter is gon na point a location in the text section. for what it's doing, and i can pull up that that picture. he also cpu picture. yeah. yes, right. and so if i want have the cpu change service and handle my signal, i could n't have a function right? i got ta have some code somewhere because like, here's what's gon na happen when the signal is received and what the operating system could do, because it has access all the processes, is just say, ok process. i'm gon na change your program counter heavy. run some other code. they might sound malicious, but we trust the operating system. but sure enough, that's essentially what the operating system is going do. it's gon na change our program counter, but it's gon na kind of do it in a safeway. ok, so let's take a look at how this works. no location i i've drew this picture before. things that the process gets submitted pilate things that the kernel has manipulating on behalf of that process. kernel face user space. inside colonel space, we have the process control block, right? what's in the process? control block bosses identifier, process state, parent process identifier, cpu context reference. now that we know this more stuff, reference the file descriptor table, right? other things, most likely that i ca n't remember off top my head, but there's a bunch of stuff that the operating system is keeping track of that's bookkeeping for this process. i mentioned process state. yeah, i think i did anyway. so now with the signal, we're gon na add another thing in here. a reference a signal handler table. ok, i'll signal is unique in that. it just is. it does n't have any really data associated with it. with a pipe and a message queue and with shared memory talk about next time. there's stuff associated with that, right? there's the data that we're writing the pipe. there's the message itself, the data associated with it. a signal is just a notification. it's a you received a signal. i'm poking you on the head or i'm tapping you on your shoulder or my phone buzzed. right. it's a vibration."
"""OpSys_IPC_Mechanisms_Transcript.txt""","it does n't have any really data associated with it. with a pipe and a message queue and with shared memory talk about next time. there's stuff associated with that, right? there's the data that we're writing the pipe. there's the message itself, the data associated with it. a signal is just a notification. it's a you received a signal. i'm poking you on the head or i'm tapping you on your shoulder or my phone buzzed. right. it's a vibration. it's a thing signals. they just are, but they do have one sort of property. is that there's numbers associated with them every signal, and there's about, i do n't know, 3040 different signals that could be received is associated with a number. well, signal numbers go from zero large number. ok. and when we send a signal, we send it by its value. it's integer value, so we can send different signals or different notifications by number. so inside the process control block is the list of signal handlers that this process has told the kernel. here the signals that i want be able handle, we do n't have handle all of them, and i so this references a signal table or a handler table. all right, let's stop there. now in user space, the user space has its associated memory, right? and the sections of a process's memory are text data. keep stack right? you know that and it's goes from starting address the ending address, whatever that might be. so here's what we're gon na do. the process here is going. let me do it outside different color here. let me do it in green. inside the text section, it's going define a function is going be our signal handler. ok, that will get stored and compiled by the compiler stored in the text section right when the process address space or memory is created, all of the cpu instructions that the compiler generated will go in the tech section. so this is gon na have some address, right? some number associated with it in memory, i wonder address. let's just give it a number just for just make something concrete. so that's an address 2000, ok. so what the process now is going do is it's going call a system call called signal. and it's going say operating system."
"""OpSys_IPC_Mechanisms_Transcript.txt""","ok, that will get stored and compiled by the compiler stored in the text section right when the process address space or memory is created, all of the cpu instructions that the compiler generated will go in the tech section. so this is gon na have some address, right? some number associated with it in memory, i wonder address. let's just give it a number just for just make something concrete. so that's an address 2000, ok. so what the process now is going do is it's going call a system call called signal. and it's going say operating system. if a signal that in particular number is received and i have tell it there, so i will say say signal six, i would like register a signal handler for signal six. what a6 mean? we can look it up, but signal 6 and i'm going pass in 2000 say if i ever received signal six, what i want you do is invoke the function that's located at address 2000. that's. then the operating system is going go down here, into the signal table. 01234 why do n't i choose 66? all of the entries inside the process is signal handler are by default null. saying you have not registered a signal handler for this and it's going take this look at 6 and put 2000 in here. and that's it. that's the registration section for a signal with me. and then the process says the operating system says thank you process for registering the signal with me. i will hold on that for you. you can go on and do your business and the process can go wrong and do all sorts of stuff. at this point. someone can send this process of signal another process our only option right a process is gon na send it's inner process communication. so some other process, whether it be a child or a parent or it does not matter even if it's some independent process that was created by some other umm, by some other process, can send six this guy. how does it do that? well, it uses another piece of paper. my paper. it uses a system call called kill. still, i do n't know why they called it kill. i wish it was like process send or something like that, but it's called kill. it kind of seems a little now not gon na go into debating words, but there is a system called called kill and system call requires 2 parameters."
"""OpSys_IPC_Mechanisms_Transcript.txt""","so some other process, whether it be a child or a parent or it does not matter even if it's some independent process that was created by some other umm, by some other process, can send six this guy. how does it do that? well, it uses another piece of paper. my paper. it uses a system call called kill. still, i do n't know why they called it kill. i wish it was like process send or something like that, but it's called kill. it kind of seems a little now not gon na go into debating words, but there is a system called called kill and system call requires 2 parameters. one is the process id of who's gon na get this signal, and the second parameter is the number of what signal we're gon na send. ok, so if this process id was i, i do n't know, 52, ok, this is the pit. ok then i can send 6 52 and then the operating system will send that signal the process. how does it actually send the signal? it sends the signal by invoking the signal handler. so this process here is going be executing something, so it's gon na have a call stack. so if we look at the call stack. for process 52, it's gon na have me on it most likely, and then it'll probably have. i do n't know. something else foo? maybe it voked ad maybe foo invoked ad, but we're gon na have some function set of functions on the call stack with our local property variables and most importantly the return address. ok. and we're going invoke the signal handler. we are n't. the operating system is gon na invoke our signal handler, so here's what it does in a make it safe, it's going it knows here. that i registered signal handler is the function at address 2000 right when kill is sent 52, the operating system grabs the process control block for process 52, finds the signal handler function inside the the signal handler table and finds 2000. let's give this a name. let's just call it sig hdr just give the function a name. and it's going say great. i'm gon na take your call stack and i'm going push a - frame on here for sig hdr."
"""OpSys_IPC_Mechanisms_Transcript.txt""","the operating system is gon na invoke our signal handler, so here's what it does in a make it safe, it's going it knows here. that i registered signal handler is the function at address 2000 right when kill is sent 52, the operating system grabs the process control block for process 52, finds the signal handler function inside the the signal handler table and finds 2000. let's give this a name. let's just call it sig hdr just give the function a name. and it's going say great. i'm gon na take your call stack and i'm going push a - frame on here for sig hdr. i'm going then set the program counter be inside the signal handler and you all now have a stack frame for executing that function, and then the next thing it's gon na do is it's gon na say alright, this is a function indication. all function invocations need local variable declarations. any parameters associated with the media get allocated, but they also they need a return address, right? so what's the return address from the signal handler? it's where we were when we were executed. the operating system is gon na interrupt this process, save the program counter for where it currently is, and then push the stack frame for this signal handler. the return address from the signal handler seemed be right where we left off, so it's going be weird. it's going be like as if that process invoked a function in the middle of its computation without actually invoking it. the operating system emulates a function invocation, but adding the signal handler the stack frame and then set the return address. see, we were executing an ad somewhere around here. it sets the return address for this guy be right there jump back wherever they were in ad. then the stack frame goes away. we continue on and that cool. talk the process. it's gon na appear like a function gets invoked asynchronously, but the operating system it's just doing its job. ok, so. let's get this. let's let's start this. we're not going finish it, but let's get this started. so do that, i'm going need a bunch of stuff. no, what? i'm not going be nearly as much. and it include signal that age. and. you know what? i got 3 minutes left. that's instead of writing this code, let's just look at the man page for signal."
"""OpSys_IPC_Mechanisms_Transcript.txt""","it's gon na appear like a function gets invoked asynchronously, but the operating system it's just doing its job. ok, so. let's get this. let's let's start this. we're not going finish it, but let's get this started. so do that, i'm going need a bunch of stuff. no, what? i'm not going be nearly as much. and it include signal that age. and. you know what? i got 3 minutes left. that's instead of writing this code, let's just look at the man page for signal. so we can understand what's going on and we'll actually do this example next time. so here is the overview of signals in the man page. talks about what the signals are. some of these things will come back too. there are system calls called signal for connecting a signal i mentioned kill kill. and if you want know what the signal numbers are. they're all listed down here inside signal dot h there's a whole bunch of pound defines that assign these actual numerical values, but for the most part people do n't usually use numerical values. maybe like what's 10? i do n't know what 10 is, but each signal on the system is given a name indicate what they are. so while these names might not make a whole lot of sense look at them, here's a more descriptive answer. so some of these might look familiar, and we'll talk a little bit about that next time as why they might look familiar, but sure enough, we do have a whole bunch of signals on the system. we also have some user defined signals down here do n't have any explicit meaning. uh, but that's that. the next thing we see is this column right here. action. i mentioned that initially a process has no signal handlers installed. they're all null, right? so what do you wanna do? if i was processed, receives a signal. and and there's no handler installed for it. we can do nothing. we could ignore the signal, right? ideas. yeah. did n't the parent you kill the process? it's a you got the signal, right? little bit, uh or serious perhaps, but yeah, doable. somebody else? i'm really good idea."
"""OpSys_IPC_Mechanisms_Transcript.txt""","i mentioned that initially a process has no signal handlers installed. they're all null, right? so what do you wanna do? if i was processed, receives a signal. and and there's no handler installed for it. we can do nothing. we could ignore the signal, right? ideas. yeah. did n't the parent you kill the process? it's a you got the signal, right? little bit, uh or serious perhaps, but yeah, doable. somebody else? i'm really good idea. another section they're like, well, if a signal is sent via kill, if a process does n't have a signal handler installed for it, maybe just make kill fail and return back the process that sent the that sent the signal and said i tried deliver this signal, but they were n't waiting for it. so now i'm returning a failure you. well, as it turns out, conrad is is actually more, let's say, not more correct, but the default action for most of these signals you'll see is term ignore. some of them are by default ignored. some of them are termed. if you look up top it gives a description of what the actual message, what the actual behaviors are, and so here is the description of what the default behavior is. are terminate the process ignore, ignore the signal? core is light terminated, but it also dumps the memory core for debugging purposes. start essentially sets the process state a state of stock says you're done and you're not gon na run. you're not deleted, you're not terminated, but you're just not allowed run until something explicitly continues you. that's kind of cool, but for the most part, if you look down here at the signals, most of them are either term or core dump. so sounds a little bit strong, when mean, but yeah, the default behavior for a lot of this is terminate the process. ok, i'm out of time. sorry, i went over, so we'll actually do a coding example next time take a quiz. talk about shared memory and that's we'll probably be enough. so thanks for coming. see you next time. lembke, james stopped transcription"
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","meeting in _ general_-20240208_130127 - meeting recording february 8, 2024, 7:01pm 48 m 19s lembke, james 0:08 hello great. ohh, all right. welcome operating systems isolation and protection. abstractions are cool and all that. so what are we doing? i ca n't try remember here, so we have been working through this picture working through c review and last time all the way on monday it's it. it's been a while. i feel like we started talking about system calls. on a finished talking about system calls today and then relate them function calls and then talk go into the next topic will take us the end of the week. so my plan is right now we kind of been teaching or i've been kind of been going through this class kind of piecewise. cartwright, ryan joined the meeting lembke, james 0:52 they do a bunch of hand waving, draw a bunch of pictures, then do a whole bunch of examples like when we gon na do some more material and then we'll do some examples. and i kind of like follow that. so the last week we were doing see review, we did a whole bunch of examples. this week can be doing a bunch of hand waving and drawing pictures for system calls and processes. next week, we're gon na go back and do a bunch of examples. i do have a couple of examples i wanna show you today, but until we really engrain our brain with the concepts and the hand waving and the pictures, the examples might not make any sense. i could throw at you, but i i do n't wanna confuse anybody. so we'll go back with these. so system calls ever remember system calls is remember those and the problem that we ran into in that in this picture we have connected the system a bunch of other stuff right here shows the direct link between memory and the cpu where it's kind of like wired together with a bus. the system boss, the front side bus so everyone referred you would have. there's multiple names for it, but then we have a whole bunch of io devices that are connected the system in various ways, and we motivated that. maybe not the best way. it was kind of lame, but ultimately motivated. the fact that i do n't really want all of my user code access all of these io devices all of the time."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","right here shows the direct link between memory and the cpu where it's kind of like wired together with a bus. the system boss, the front side bus so everyone referred you would have. there's multiple names for it, but then we have a whole bunch of io devices that are connected the system in various ways, and we motivated that. maybe not the best way. it was kind of lame, but ultimately motivated. the fact that i do n't really want all of my user code access all of these io devices all of the time. i also do n't want processes or programs access each other, so if i have a process with instructions and memory here because of my system is doing multiprogramming and giving me the appearance of multiple things happening at once. instruction for different programs need be in memory at the same time, otherwise the system would just not work fast enough. it would just be too small, so i do n't want have this guy's code access this guy's data. it's just a security problem and also the correctness problem cause this guy mocks the something all of a sudden it's gon na get go the wrong answers. and i'd rather have the models that i train be correct, or elden ring, you know actually work properly. so we want isolate processes and we also want isolate processes from the operating system code. the operating system is instructions is providing services like accessing io devices and it is the code necessary for doing that. i do n't want have a program start mocking with operating system code. it's i want break my system. ok, so what other is on purpose or on accident? right, we can be malicious on accident. it happens. we wanna do that. so the inventors of this hardware said let's do something about that and we'll set this idea or create this idea of the flying industry and the mode bits where we can set the cpu operate in different modes. and if it's running in user mode, it can only access certain stuff. it ca n't access all of the instructions. it ca n't access all of memory and we'll have a way, a mechanism that we need put in place allow the cpu escalate its privileges get into system mode where the operating system is gon na run. and the trick of the problem that we've talked about was how do we escalate those privileges without just saying, yeah, you go ahead and just escalate your own privileges. right. the military would n't like that."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","and if it's running in user mode, it can only access certain stuff. it ca n't access all of the instructions. it ca n't access all of memory and we'll have a way, a mechanism that we need put in place allow the cpu escalate its privileges get into system mode where the operating system is gon na run. and the trick of the problem that we've talked about was how do we escalate those privileges without just saying, yeah, you go ahead and just escalate your own privileges. right. the military would n't like that. i do n't like that, right? i do n't just want have a regular person say. ohh yeah i have but i have higher problem just so i'm just gon na run and i'm gon na flip the bits be system mode and then i'm going make it in vacation into operating system code. change the program counter and start it running. conceptually that works, but in all reality, if any program was allowed escalate its privileges, then we just lost all the security that we had available us. by having these mode bits right? so any motivated the idea of, well, what if we booted the system in system mode and the only code we loaded when the system booted was operating system and we said operating system, now that you're loaded and you're running in system mode, no user programs or no user processes are running yet we still have that the screen up that says windows is loading, right? it's going set up a special routine for system point entry and then tell that the cpu and then say i am now going release my privileges. that's one thing about being privileged is i can release my privileges. i can say, you know, i just do n't want them anymore. i am taking the initiative make myself less six months or less secure, but i'm letting myself access less stuff. i ca n't get more without asking, but i can offerup and say i would like restrict myself. ok. so let's operating system sets up. it's enter routine. it then changes the mode user mode, runs the first user program, and that program runs and can not access anything other than its own stuff because it's running in user mode. if it wants access system mode, it needs ask the operating system. the only way for the cpu load operating system code will be execute this instruction called syscall, is executable and user mode, and it will flip the mode bit system mode."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","i ca n't get more without asking, but i can offerup and say i would like restrict myself. ok. so let's operating system sets up. it's enter routine. it then changes the mode user mode, runs the first user program, and that program runs and can not access anything other than its own stuff because it's running in user mode. if it wants access system mode, it needs ask the operating system. the only way for the cpu load operating system code will be execute this instruction called syscall, is executable and user mode, and it will flip the mode bit system mode. but at that point, as a side effect of calling says, code says call, it will flip the program counter only point operating system code. that way we can escalate our privileges, but we will never execute a user program when those privileges are executed, we will only execute os code, right? and that was the the idea of a track. right now i'm reviewing this and offered in the past, people like doctor longview reviews too much, but this is important. like this is like this is operating systems like if you do n't start this. if i lost you here, then the rest of operating systems is gon na be like, i do n't know what's going on. you got ta know. you got ta know trap first. so we're gon na cover multiple times. ok. questions with me? alright, so this is what it looks like hand wavy on paper. what does it look like in actual code? let's go back over here my notes. here is the picture of the syscall. we've got this trap and why i mentioned this picture shows a mode bit of 1 bit on an actual intel x86 architecture. it uses 2 bits, but we wo n't necessarily go into that in great detail. we mentioned the system called table, is how the operating system knows what service execute. the user sets a register say what i'm gon na execute or what i want the operating system execute. then when it invokes a syscall and the cpu changes the mode and loads the operating system at the same time, the operating system reads that register determine what service execute, and that's in the system call table. and so then here is an example. in actual code, it's assembly code. i know. is n't that on the subway class, but we kind of have know this a little bit in order get the rest of the stock."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","the user sets a register say what i'm gon na execute or what i want the operating system execute. then when it invokes a syscall and the cpu changes the mode and loads the operating system at the same time, the operating system reads that register determine what service execute, and that's in the system call table. and so then here is an example. in actual code, it's assembly code. i know. is n't that on the subway class, but we kind of have know this a little bit in order get the rest of the stock. so here is our high level statement. we have a system called called write allows us write a particular device and so later on we talk about io. we'll say we'll learn that all of linux really when we're when we're accessing a device, it treats a device like a file and it gives you a descriptive a number associated with that particular device. all devices have a number associated with them and so what this is saying is i would like write some characters a device. this is a buffer for how many characters i'm gon na write. this is how long that is, or how many characters i'd like you write that device, and in this case it's going be some location in memory. but in this case it's a string literal that is hello world and if you count that it's 12 characters minus the null terminator. what device are we writing or writing device # 1? all devices are given a number just like a memory addresses, a number. a device is given a number one. in this case, is the output device or standard output? every single process is given 3 device numbers automatically 01 and 20 represents standard input, is like system dot in reading from the console from the user's standard output. system out in java or c out in c and then # 2 is standard error is like something that error or c error in c for outputting the error display error display one and two typically go the console like the terminal output 0 is reading from the keyboard. later on, if you're curious, you can talk about mouse endpoint and how you get that kind of stuff, but essentially think of device. so anyway, this says right device number one those characters. how does this get translated into assembly? well, just like what we did in hand, waving only, it's straight down code."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","system out in java or c out in c and then # 2 is standard error is like something that error or c error in c for outputting the error display error display one and two typically go the console like the terminal output 0 is reading from the keyboard. later on, if you're curious, you can talk about mouse endpoint and how you get that kind of stuff, but essentially think of device. so anyway, this says right device number one those characters. how does this get translated into assembly? well, just like what we did in hand, waving only, it's straight down code. the first thing we need do is move what operation we're gon na do # 1 into the rx register, says here is the operation that i'd like the operating system perform. if we look up in the system call table i i thought i showed you, you'll find that one is the system call # 4. right. right. there's 332 ish system calls that are in that table. one is right, zero is read. i ca n't remember what the other ones are, but we can always look them up. the rest of this is setting up parameters for what tell the operating system do, and then we make assist call at this point, this program stops the cpu, so speak. does n't necessarily know that it's executing operating system code versus user process code. this really understand that it just needs an instruction stream, but it does know when it executes assist call it has change the mode system mode and load into the program counter the address of the system entry routine was set up by the operating system when the system booted. then it will execute that code and then this code down below. here is the return from the operating system. this is not like this is contain operating system code, but the operating system code would execute right in here. then the second line of coding here shows another system call. it's the actual exit system call has the value of 60, is essentially tells the operating system. i would like quit and end my program and my process ok, so this is kind of implicitly called whenever main returns. but we can explicitly call it by calling syscall 60. ok. all right. two different ways look at the same thing. alright, so now let's go an example. i want do an example of let me pull up the web browser here. you name."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","then the second line of coding here shows another system call. it's the actual exit system call has the value of 60, is essentially tells the operating system. i would like quit and end my program and my process ok, so this is kind of implicitly called whenever main returns. but we can explicitly call it by calling syscall 60. ok. all right. two different ways look at the same thing. alright, so now let's go an example. i want do an example of let me pull up the web browser here. you name. anybody familiar with you name not expecting you be familiar with you named but you and name is a system call? and what you name does is it says operating system. i'm going provide you with a pointer. once a pointer a number. yeah. bam, what does it refer? a location in memory, right? if i'm going stop saying this after a while, but i'm gon na do it one more time. if my street was representing of all memory right e yale ave address of my house 3923 is a number. it represents my house. the value that's stored there is single story ranch with a gray exterior, right? that's the value of my health in this case, we are telling the operating system here is a location in memory. what i want you fill in some stuff, so we're gon na put this in of registered tell the operating system here is a location and i'm gon na invoke the you name system call with the syscall instruction. the operating system then will read this number and fill in this buffer. this structure with a bunch of information and that information is defined down here and what it's gon na fill in is information about the system, what the operating system name is, what it's version is, what what hardware we're running on and so on. this is not something that's specific see. it's specific this system we're running out, so it already get this information. we have ask the system how do we ask the system for anything? there is a system call alright, so let's program this up and we'll take a look at how this works at what we get. so it says in the the manual page in order use the struct uts name, i got ta include sys uname dot h that's where this structure is defined."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","this is not something that's specific see. it's specific this system we're running out, so it already get this information. we have ask the system how do we ask the system for anything? there is a system call alright, so let's program this up and we'll take a look at how this works at what we get. so it says in the the manual page in order use the struct uts name, i got ta include sys uname dot h that's where this structure is defined. so i'm gon na go back my c lion and create a new file and we will call it, uh, this call call you name for like a better word. and i'll make my main routine and i'll return 0 here. but then i need include the header files, so instead i oh, i'm going do that because i'm do printing and i need include sys. sis uts name dot hok then i need create my struct is called you. it's just called rts name, right? yeah, uts name. umm os info. ok, so what? this will do as soon as i write that and i compile it. this will tell the compiler allocate storage with inside the context of vain for a structure that's big enough store all the information that the os might give us. right. ok, so now we need. now we need call it. we just call it with this, passing in a pointer is gon na be the address of where we allocated the struct. ok. one thing that i want point out here is is it sort of a theme amongst operating system system calls, at least in posix and linux is they kind of follow a standard behavior. they have parameters and they've got they've got maybe multiple parameters. ok, that's true. right. but they also have a similar behavior for how they return, and that's just how kind of is the way the syscall instruction kind of works under the covers is that if there is a success, it returns zero. if there's a failure, it returns -. 1. that's very similar and the reason why i pride in practice with this in your stacked machine ordering project was that all the functions either return zero or -, 1 for this very reason. kind of get our mind in the right mindset of 0 means success -, 1 means error. if there is a specific error that happened, there could be any number of reasons why why our system call would fail."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","but they also have a similar behavior for how they return, and that's just how kind of is the way the syscall instruction kind of works under the covers is that if there is a success, it returns zero. if there's a failure, it returns -. 1. that's very similar and the reason why i pride in practice with this in your stacked machine ordering project was that all the functions either return zero or -, 1 for this very reason. kind of get our mind in the right mindset of 0 means success -, 1 means error. if there is a specific error that happened, there could be any number of reasons why why our system call would fail. it could be because you do n't have permission something. it could be because you're out of memory. it could be. i do n't know you name it. the operating system is gon na set a special global variable called air note, so this is a special thing that's accessible by your program that's global that says specifically what that error is. you ts name is kind of special in that it only has one particular error is buff is not valid if i give it an invalid pointer, the operating system is gon na say hey dude i ca n't copy data there, that pointer is not valid. it will return -, 1 and then set error node be that there's a memory fault. uh, but other system calls will fail for other reasons. there's some that could fail for i do n't know, 50 or so different potential reasons, so i want know specifically why something failed. i can look at the global variable called errno. otherwise i just move on, so in this particular example i'm going provide all the correct information, so not gon na worry about errors, but later on i will certainly do that. so in order do this, i'm just going say call you name and pass in the address of my struct os info. now, because i just talked about error messages, i'm going surround this with an if statement say if it is, uh, and i'm gon na do doctor lemke's trick so that i do n't accidentally do an assignment operation. although in this case it would n't make a difference because i ca n't assign a value a function like that, but i'm gon na do it that way, so if this returns zero, that means i have good values."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","so in order do this, i'm just going say call you name and pass in the address of my struct os info. now, because i just talked about error messages, i'm going surround this with an if statement say if it is, uh, and i'm gon na do doctor lemke's trick so that i do n't accidentally do an assignment operation. although in this case it would n't make a difference because i ca n't assign a value a function like that, but i'm gon na do it that way, so if this returns zero, that means i have good values. that means that the system call would have executed and the contents of os info will be filled in by the operating system with the appropriate information. and now i can just print it out os name. i think that's one of the fields. nope. sludge and let's take a look here. maybe this we'll see how all this works and not too bad. ah, this name os info dot sysname, and then i'll print off the. os release will be that's i guess it's two values. there's a release and version. do that and then we'll do something like i do n't know, dash, dash, dash. os info dot release and os info dot version not bad i guess i should put our new line in here. uh, we'll call it. i do n't know hardware, i'd i do n't know. who was involved? dot machine ok. ok, but they. alright, let's build this and run it and see what we get. please boot up os. yep. this call you name dot c good. looks like it worked and i got my eight out. so when i run it i get this. this is one thing that kind of frustrates me about this. oh yeah, sorry question. did you do anything special? no, no, it's just a. it's just a header problem, just like any other, so this is telling the compiler look for this header file in with the less than greater than symbols in the system library paths, and that sys represents a directory. so somewhere there's a system library path or include files that can change the directory sys and inside there is uts name dot h and it was able find it if it was n't able find it i would have got a compiler. there's nothing magic behind that, just it knows where search for it, because it's got a search graph with the system pattern."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","it's just a header problem, just like any other, so this is telling the compiler look for this header file in with the less than greater than symbols in the system library paths, and that sys represents a directory. so somewhere there's a system library path or include files that can change the directory sys and inside there is uts name dot h and it was able find it if it was n't able find it i would have got a compiler. there's nothing magic behind that, just it knows where search for it, because it's got a search graph with the system pattern. one thing i did see is that i solved hardware wrong our ward, but you guys that that's what i was thinking. but anyway, we get the information about our system now. what kind of frustrates me about this is i'm running on windows and it's giving me information about linux, but that's because i'm running windows subsystem for linux, but it's telling me that my os name is linux, that my release information is. this is the microsoft standard wsl kernel, and then that's the version, and then this is my hardware id is x8664 makes sense question. what are you getting? so when you do gcc of of of your file you get file that file. uh also also talk after class. did you get the same problem on in like the different language? yeah, there's a forward slash, not backslash. ok. actually, we'll talk after class, i guess because i do n't i i do n't, i do n't know. but that's a good question. alright, so sorry that that aside, now let's look, ok, so this is the system call and it's being executed. obviously something is being executed. it executed the trap. they've loaded the operating system code and this information was filled in by the os, ok. well, let's take a look at this from an assembly perspective then, since that's what actually happened. we should be able compile this with the dash capital s flag get it stop after the assembler. i'm sorry, after the compiler before the assembler runs and give us assembly instructions, but let me go down here and this is not all going fit on the screen, but at least we get an idea. so above here we've got the compiler declaring storage for all of our string literals, and all of our other literal values."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","well, let's take a look at this from an assembly perspective then, since that's what actually happened. we should be able compile this with the dash capital s flag get it stop after the assembler. i'm sorry, after the compiler before the assembler runs and give us assembly instructions, but let me go down here and this is not all going fit on the screen, but at least we get an idea. so above here we've got the compiler declaring storage for all of our string literals, and all of our other literal values. so here these are the string literal values that are needed for doing the format, the printf and so that that makes sense. it's like a model is colocating that it's got ta go somewhere. then in here we have the instructions for maine, and i'm not asking you know exactly how this works, but what it is kind of doing right here is we see this like sub q or doing some sort of subtraction. this is in a way that compiler allocating storage for that os info that uts names structure and so if we were look in the header file under this option we can find it i'm not 100 % sure why. yeah. still, you're. but anyway, that's something we can find it the actual size of that structure is looks like 400 bytes. ok. and we can look it up know for sure, but i do n't know that i need and then down here we see it's doing some allocation and working with that sword get it all set up. and then right here we have a call. and ok. and you can say, well, somewhere in here there must be a syscall, because if i'm making a system call, somewhere in here must be syscall. and what i have is a call here you name and then after that i have a call print that well. so ok, somewhere between this and here, that system call had have happened because i got the data and this is where it's printing out. so it i have have had it by now, but i do n't see anywhere in here where i'm accessing the system call. so where is it? it's magic. no, it's not magic. one reason why i'm showing you this is because. given the previous example here. it took from wikibooks, by the way. that's awesome. alright. doing this setup here as a programmer, i like function calls. why do i like function calls?"
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","so ok, somewhere between this and here, that system call had have happened because i got the data and this is where it's printing out. so it i have have had it by now, but i do n't see anywhere in here where i'm accessing the system call. so where is it? it's magic. no, it's not magic. one reason why i'm showing you this is because. given the previous example here. it took from wikibooks, by the way. that's awesome. alright. doing this setup here as a programmer, i like function calls. why do i like function calls? because well, as a c programmer, we have data and. auctions of manipulate that data. ok, right and a function call is pretty convenient. i know how do that. i understand that it's clear, so if i'm calls are confusing and from a compilers perspective, you have have special code in order be able see the word right? like this and generate the proper assembly instructions for syscall. could be a lot of work, so what the developers of the sort of the compilers and the working with these system call said? you know if function calls are really easy handle because we know how do that by generating just a call instruction that we can do that. why do n't we just take every single system call on the system and isolate them one place so that the compiler with source code for it and i'm sort of a target organized section of its code, or handling all of the system calls, and then anytime a user wants invoke those syscalls, instead of having it invoke the system call directly, we will have it call a function instead? that way if something changes and as far as how system calls are invoked, all we have do is swap out the library that the user program is calling and we have have the user program change. so if we had like a system update say we have a new way for you call this system call instead of having all of your user programs be recompiled, all you have do is do a system update. the library gets updated and you get use the new format for for invoking a system call, but your code does n't change because it just invoked a function call. makes sense. you see, that? got some nods. some people going if you're bored, that means you got it. i i kind of want bore you, but also also do n't."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","so if we had like a system update say we have a new way for you call this system call instead of having all of your user programs be recompiled, all you have do is do a system update. the library gets updated and you get use the new format for for invoking a system call, but your code does n't change because it just invoked a function call. makes sense. you see, that? got some nods. some people going if you're bored, that means you got it. i i kind of want bore you, but also also do n't. so here's what actually happens is that system calls in order make them look like a function call, we have some library that has a file in it, and i can show it you. it is cool. i have look at it once, so i was n't getting doing my my my research, my research the file that for doing all of the system calls right there's 300 and sub system calls on linux and all of those have be wrapped in that library. there's a file or set of files for doing that, but i want make a system call. i go function call but the seed library actually does the system call on my behalf. you do the trap get into the kernel, and in linux, and that civically libc libc also exists on other operating systems g libc, the canoe lib c or library for c does that for us on windows, in case they're curious. that's done via the native api and that's located at least as of windows 10. i do n't know if they moved it in windows 11, but as a windows 10 it was called and through the l.dll does that. and that stands for the nt or the new technology. i think we're just a version of windows from a long time ago. the l stands for dynamic link library, is a library inside windows that wraps all the system calls for you, but it's still doing this. track it has. the only way you can do it under the covers questions. ok. this slide is only for reference. i'm not going cover it, but it talks about sort of the history of linux system calls and how we're still able access a single point of entry based on all the different mechanisms."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","i think we're just a version of windows from a long time ago. the l stands for dynamic link library, is a library inside windows that wraps all the system calls for you, but it's still doing this. track it has. the only way you can do it under the covers questions. ok. this slide is only for reference. i'm not going cover it, but it talks about sort of the history of linux system calls and how we're still able access a single point of entry based on all the different mechanisms. the way we invoked the system call kind of is evolved over the life cycle of x86 as it's moved from 8 bits 16 bits 32 bits and now 64 bits and under the assumption that someday they'll do 128 bits, it'll probably even change from then on. but we'll see what happens. but if you're a colonel hacker, that can give you sort of an idea of how it works. ok. so 130 the last bit of stuff are some questions that i want us keep in mind will come back some of these, some of these we already answered, but i just wanna throw them out there just keep us brainstorming. and so we do n't forget. uh, so what do we have? how do we pass data a system call and for that i did n't directly did n't directly answer that question, but if you look at the system called documentation. we'll find that the way you actually pass parameters a system call. so for example, with the right, the one that i showed you in the example it says store number one in the rx register and then here is storing the different parameters in different registers. so in the operating system code ultimately gets invoked. it just reads those registered directly get what the parameters are. this is different than a function call or an a function call. everything is passed and handled via memory. we'll talk about that when we get in the processes, but for now, we make a system call. it's done via registers. ok. and so the other system call that i believe that where that was in there was sixty was exit not hex 60, decimal 60. there it is. exit and it just has one value is the error code and you'll see that some system calls like fork will get you next week or maybe even tomorrow has no parameters, you just call. ok. that's how we pass parameters. we are registers. that's the table. let's go back down our questions."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","it's done via registers. ok. and so the other system call that i believe that where that was in there was sixty was exit not hex 60, decimal 60. there it is. exit and it just has one value is the error code and you'll see that some system calls like fork will get you next week or maybe even tomorrow has no parameters, you just call. ok. that's how we pass parameters. we are registers. that's the table. let's go back down our questions. how many system calls do we need? i love this question. how many operating system services do we need well? biggest thing 51020. there was some movie. uh, i do n't know. what was it? someone was quoting and asking something in the answer. the question was at least one more. sometimes i kind of feel like when it comes system calls, that's kind of the way it is currently on linux we have. i think there's 333 hundred 35330 somewhere ish system calls for for that. another answer that somebody in the other section gave, i really was was awesome was how many system calls do we need? ask the posix developers, because that's the standard, and that's kind of true. but ultimately, the deposit developers have say from perspective how many they need. the short answer is i do n't know or investor could say it depends. it really depends on how many services we wanna provide. we're always thinking of more services provide, maybe someday if we have like generative ai built into the operating system will have a system called for that, who knows? i do n't know. i'm making this up as i go. ah, but it's really as as many as we need depends on what services we have. different operating systems have different system calls. that's embedded systems may not have as many because they do n't have as many. they're more special purpose versus your general purpose thing, like politics or the all right. and this last question is a philosophical question we will come back later on when we talk about processes and process scheduling is what process executes a system call, not what process per se. but it also kind of a follow - up question, i should have maybe said it differently, is does the operating system ever run and what is a process and what is an operating system? and it's arguable that an operating system does n't actually execute itself. it always executes on the behalf of a user program."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","they're more special purpose versus your general purpose thing, like politics or the all right. and this last question is a philosophical question we will come back later on when we talk about processes and process scheduling is what process executes a system call, not what process per se. but it also kind of a follow - up question, i should have maybe said it differently, is does the operating system ever run and what is a process and what is an operating system? and it's arguable that an operating system does n't actually execute itself. it always executes on the behalf of a user program. others will argue that no one operating system really does run on its own, has its own processes. but again, fill this out of the question, but we will definitely come back that. talk questions. i know a lot of hand waviness, but still we got ta cover it. so that's my end of system calls. so once we do that, now let's build on that and we'll talk about processes. and i mentioned that word and i've all. i kinda almost used the word processing program interchangeably in this class and i've kind of done that on purpose. but today is where we're gon na draw the line between what's a process and what is a program? i've so. what's the process? if i have an idea, anybody know anybody worked with this idea? and windows, we have the task manager right? you never use the task manager. yeah, usually i use it for like what the heck is my system doing right and i pull up the task manager and say who is sucking up all of my memory? right. or who is using all of my cpu, right? this lists our process. windows does n't call them that. i do n't know why this is, it did n't matter. well, i guess it does. here background processes. yeah, but what's the process? what's a program? in the cliche word, let's dive in. ok, so what do we have review. dual mode operation, right user mode, kernel mode, ok, user mode, restricted mode right can only execute certain instructions. i can only access certain parts of memory, right? if you try access something that you're not allowed, you get an exception, and then your your your application will most likely crash and somebody else gets run kernel mode. supervisor mode, system mode, privilege mode."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","what's a program? in the cliche word, let's dive in. ok, so what do we have review. dual mode operation, right user mode, kernel mode, ok, user mode, restricted mode right can only execute certain instructions. i can only access certain parts of memory, right? if you try access something that you're not allowed, you get an exception, and then your your your application will most likely crash and somebody else gets run kernel mode. supervisor mode, system mode, privilege mode. you get do anything you want, access all the instructions, access all of memory, and if you crash when running in kernel mode, good luck. alright. ok, so that's that. so here is my spiel. this is not necessarily a in a book anywhere, but this is kind of partially my definition and sort of emerging killer. a bunch of stuff. i'll program a static representation of operation operations and data. ok, compiled code. the big thing here that i want you take away with this is that a program is static. one static does not change and you could say it does change, but for the most part it does not change when i install a program. when i install microsoft word or i install elden ring installed install steam unless i have like an update that program, i do n't change it, it stays put. it's there. ok, right. two, it's a file. right. it's a thing that i can represent and store on my disk drive file. it's not special, right? on linux, we you in your first programming project or lab that are going it as you identified and looked at the six file pipes on a linux system. windows is something similar that. now windows does it's darkness try and tell you that a docx file is different file typethana.exe that there's a special thing associated with it. so just files on the disk drive. ok, same thing. this is just a file, it's just data that's being stored by our operating system. it is static. ok, once a process a process is, does an instance of active execution. you can also say it's a program in execution. we might have one program, but from that we might create multiple processes of it. ok, chrome is a prime example."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","now windows does it's darkness try and tell you that a docx file is different file typethana.exe that there's a special thing associated with it. so just files on the disk drive. ok, same thing. this is just a file, it's just data that's being stored by our operating system. it is static. ok, once a process a process is, does an instance of active execution. you can also say it's a program in execution. we might have one program, but from that we might create multiple processes of it. ok, chrome is a prime example. chrome is 1 program that runs that you can run, but every single tab that you that chrome runs because of isolation and protection reasons it creates every single tab as its own process. ok, so one program, multiple processes, ok, processes have been away, a state associated with them. and i do n't necessarily mean a state of execution versus suspended, and we certainly will get that. but they have a state of like what variables you have in memory, right? you might have a four loop that is the value of i, right? i is a variable. for that reason it a variables change the variable and so i'll particular state of a program consists of what values are it variable. it's variables have so every single chrome tab might be executing the exact same program, but the variables associated with each tab will most likely be different, even if i'm loading the same web page, it's probably gon na be slightly different when each tab is doing. so here is a map of programs and memories and i kind of try and drew that on that picture before, but this shows the picture from the william stallings book that each process has a location in memory associated with it and our operating system in protected memory is keeping track of all of the processes that are currently running on the system internally in this process list, we'll talk about a little more about what goes in this process list and what the process is allowed access versus what the operating system access is. but i do want mention that it's a lot of hand waving just, but it's important. ok, so why do we need processes? why do we need processes? it's kind of a funny question. i'm imagine a lot of people ask that question. in the past, i'm not gon na necessarily spend a whole lot of time about why we need processes."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","so here is a map of programs and memories and i kind of try and drew that on that picture before, but this shows the picture from the william stallings book that each process has a location in memory associated with it and our operating system in protected memory is keeping track of all of the processes that are currently running on the system internally in this process list, we'll talk about a little more about what goes in this process list and what the process is allowed access versus what the operating system access is. but i do want mention that it's a lot of hand waving just, but it's important. ok, so why do we need processes? why do we need processes? it's kind of a funny question. i'm imagine a lot of people ask that question. in the past, i'm not gon na necessarily spend a whole lot of time about why we need processes. we do, but in short, it's allow us take advantage of our cpu. because i mentioned before, at least i tried. i hope i did that. it's really hard keep our computer processor busy. because a lot of the times our computer processor is waiting for something, and often it's waiting for us, right? if i'm playing some game, waiting for it needs wait for some user input, even if it's polling the mouse 1000 times a second. that's that seems like a lot, but the cpu can be usually doing like a billion things a second. so 1000 times a second. right. a billion is, what, 10,000? thousands. that right? right. it could be doing a lot of other stuff while it's waiting for us move our mouse around, so we want keep the cpu busy and so one of the things one of the ways we can do that is multiprogramming. if the cpu is not able do something and it has wait for something, well would do something else right? right as well, it's not doing anything anyway. it could be sitting waiting there, twiddling it's thumbs, but i can be sitting there twiddling my thumbs. or i could be studying for operating systems while waiting for my friend give me a call. right? i could sit there and be like, oh, wait, my friend call me or send me a text. i guess who calls people anymore, right? or i could study for operating systems while i'm waiting for that call, say my idea, all the program. are too is."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","it could be sitting waiting there, twiddling it's thumbs, but i can be sitting there twiddling my thumbs. or i could be studying for operating systems while waiting for my friend give me a call. right? i could sit there and be like, oh, wait, my friend call me or send me a text. i guess who calls people anymore, right? or i could study for operating systems while i'm waiting for that call, say my idea, all the program. are too is. like kind of like be able try and do more than one thing at once, right? i like have microsoft word running in the background right while i'm doing all the lots of other things. the other answer is isolation and protection. we need this idea of a process because if we're gon na do multiprogramming, we need find a way isolate programs or active programs from each other. even though chrome is 1 program, i do n't want have one of my tabs access the memory of another tab, because if i've got stuff in amazon going on, i've got credit card numbers typed in there. i do n't want somebody else's website access the tab that has amazon on it get my credit card. so isolation factor not only for security, but also for correctness. i had. so let's take a look at a program and a process, and here is where we go. so what's in a program? a program consists of stuff that does not change. ok, we have text. once our program is compiled or our code is compiled, i do n't want my instructions change if i want them change, i'll recompile it or i'll download a system update. right. steam will get updated. download a new one, but for the most part should n't change data sections, static data, global data, constants, things like that. they should n't change. they should always be the same every single time i run my program, all of the constants that are in there should be those values every single time i run them. i do n't want somebody change what the value of 10 is. the value of 10 should be 10. there are some programming languages like you still let you do that. warning. right, ok, linking information. what libraries this thing is dependent upon? the only time that should change is if i rebuild the program."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","they should n't change. they should always be the same every single time i run my program, all of the constants that are in there should be those values every single time i run them. i do n't want somebody change what the value of 10 is. the value of 10 should be 10. there are some programming languages like you still let you do that. warning. right, ok, linking information. what libraries this thing is dependent upon? the only time that should change is if i rebuild the program. so if i'm using the map library do things like square root or something like that, that's a dependence, and that does n't change. symbol table. this is english words for our symbols. this is not necessarily required in a program. ultimately, when the cpu executes stuff, it just cares about memory addresses and registers. as you've auger, i personally would like know what the value of i is by name. hi what is i? what is my variable? the zipper does n't care. i might be address 4000, but when i'm debugging my program, i'd like know that so the symbol table is a way that variable names. we can strip that off if you're curious. i can show you how plus. anyway, that's in a program. ok, that's important text data linking and symbols. what's that process? well, we have a couple of things that should n't change and you could say well, yes, text is the executable code. it should n't change. well, yes. and i would argue then you would say, well, why do i need it in memory? why do i need it be part of my process? ultimately, we're gon na find that processes get loaded into memory. they're created from a program and despite the fact that we want might have multiple copies of the text in memory at the same time, we want have fast access our instructions and the fastest place that we can put it well would be inside the cpu. but we do n't have enough space for store at all. we have space in memory, so we're gon na put that in memory, despite the fact that we do n't want this change. but we'll talk about memory and memory protection and we can actually protect this so that we ca n't change it. there's a data section. this consists of things like global data, ok, things that need exist throughout the life cycle of the process. they might change."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","they're created from a program and despite the fact that we want might have multiple copies of the text in memory at the same time, we want have fast access our instructions and the fastest place that we can put it well would be inside the cpu. but we do n't have enough space for store at all. we have space in memory, so we're gon na put that in memory, despite the fact that we do n't want this change. but we'll talk about memory and memory protection and we can actually protect this so that we ca n't change it. there's a data section. this consists of things like global data, ok, things that need exist throughout the life cycle of the process. they might change. so we're gon na put it in memory, but it has some sort of initial value and it's value stored somewhere, and that's the stick around forever. if i have a global variable called i, it's always in scope, so it ca n't ever go away. so we're gon na store it in the data section and then finally we've got these three sections down here, one called the heap and one called the staff. and this is area that's reserved or dynamic memory, things that change, things that come and go. we'll find that seth is used for temporary data for the process or things that are local function calls or things that are local essentially scoping braces, and then we'll have the heap, is memory that persists, but it does n't persist outside the life cycle of the process. it just persists until it's explicitly free. that's things that you would use the new operator for in java or c or malloc airport programming in c ok, what time is it, miller time? no. i got time now. we're moving alright so. questions all right. but here's what we have we are program and process of this essentially the format for a program. not gon na ask you memorize this, but if you're curious i've ever done this. gone wikipedia and look up the format for a java class file. it's. it's published. it's it's, it's open source, right? java's open source, so if you want know how a class file look, it's in binary and the first like couple of bytes of a class file is a magic number so that you can know that it's a class file because you ca n't really trust the extension."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","not gon na ask you memorize this, but if you're curious i've ever done this. gone wikipedia and look up the format for a java class file. it's. it's published. it's it's, it's open source, right? java's open source, so if you want know how a class file look, it's in binary and the first like couple of bytes of a class file is a magic number so that you can know that it's a class file because you ca n't really trust the extension. similar a program on our linux system uses the health format, is the executable and linkable format, and it has a header on there says that this is an out formatted program and inside there we've got all the different sections that i mentioned previously. text. is this out there? extractions read only data. that's our constants. we have changeable data that is set sort of globally but but umm for just have allocated allocatable spaces with a bunch of other sections in here, i'm not gon na ask you memorize this, but i do want mention that this is sort of the way format works and then we have a process. all processes are gon na look something like this. we have text we have. this is memory and you could talk about the address from zero infinity. processes do n't actually have an infinite amount of memory. it's limited by the amount of memory on our system, but it's usually pretty big and so they're given an address space, a spot for text, a spot for global data, bss. they actually say what it's doing for it. i never remember what it stands for. bss block started by symbol anyway, that's what stands for. what it essentially means is it's global variables that do n't have an initialization. so if i was go in here and go my sister name thing and say int x = 10 and int y. acts as initial value. it's ten that gets stored in the data section. y gets stored in the bss section. it's a section. just another place store global data. it's just the way things are created. for the most part, you can just say it's where we store global variables in that location in memory. got ta be stored somewhere. it is always in scope right where i am in this file. x&y are always in scope, so they always have be allocated someone, so we put that in memory. and then finally, we have this heap and stack ok."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","y gets stored in the bss section. it's a section. just another place store global data. it's just the way things are created. for the most part, you can just say it's where we store global variables in that location in memory. got ta be stored somewhere. it is always in scope right where i am in this file. x&y are always in scope, so they always have be allocated someone, so we put that in memory. and then finally, we have this heap and stack ok. remember the cpu. who's this? conceptually, we think about it like this, where each of these programs now we understand program versus process. each of these processes you have run a certain amount of time. the cpu says i'm executing instruction stream, so what's going happen is the operating system is going set this up that over time it's going set the program counter point the text section in memory for one of the processes that process is gon na get the run. it's gon na modify a sneak and it's sad and it's maybe it's global data. it wo n't be allowed modify its text, but then after a certain amount of time the operating system is gon na have get involved it. we'll talk about that how that happens. we talked about seeking new scheduling and then it's gon na let the other process run by altering the program counter of the cpu point the memory location of the other process. and then we let it keep going. so i've said this in the past and i'll say it again and then we'll be done for the day. when it comes process management and processes on the system, the cpu does not know the existence of processes. all it sees is a string of instructions that it executes. processes are an os construct and you might say, but no, the operating the the cpu gets run in user mode versus kernel mode. that does n't indicate whether or not it's a process that's running or the os code right. we could allow a regular user code run in system mode. i do n't recommend it. it does just a bit, just a bit. just a flag in the cpu, the cpu is just executing instructions and whether or not it's mode is set the system mode or user mode. that's something that the operating system sets up for us because it knows what it's doing."
"""OpSys_Isolation_Protection_and_Processes_Transcript.txt""","processes are an os construct and you might say, but no, the operating the the cpu gets run in user mode versus kernel mode. that does n't indicate whether or not it's a process that's running or the os code right. we could allow a regular user code run in system mode. i do n't recommend it. it does just a bit, just a bit. just a flag in the cpu, the cpu is just executing instructions and whether or not it's mode is set the system mode or user mode. that's something that the operating system sets up for us because it knows what it's doing. and then, say, knows what it's doing, but the authors know what they're doing, and so processes are an os construct down here. os abstraction abstractions are cool. they're created by the os. they're managed entirely by the old, by the os, right? unknown hardware and a process sort of operates concurrently with other processes because of operating system managing that and they have this idea of safe state being the contents of memory that represents variables as well as the sort of the program color and what's currently being executed along with whether or not it's allowed run or if it's waiting for something it's waiting for user input, they're gon na talk about state next time. so i think a lot of time why even if i'm not, i'm gon na stop there. so questions. ok. well, thanks for coming. i'll see you tomorrow. lembke, james stopped transcription"
"""OpSys_Make_Files_Transcript.txt""","meeting in _ general_-20240205_130331 - meeting recording february 5, 2024, 7:03pm 47 m 0s lembke, james started transcription lembke, james 0:09 hello. hello it share my screen. yeah, we got the visualizer, got my code pane, got notes alright, so welcome operating systems. what are we doing this week? we are gon na be talking about system calls and processes this week. we've already. i'm gon na talk a little bit about processes. you've used processes and really there's not a whole lot extra the concept of a process that you do n't already know. what? we're gon na start start talking about is. like i say, in whether all you call it alice in wonderland or the wizard of oz, we're gon na pull back the curtain. see what's behind the curtain or go deeper down the rabbit hole. and now you want look at it or just look at how this stuff is done inside our computer, because you might look at that and be like, well, of course that's the way it works. well, when you start thinking about it, really you got ta be like ohh wait. but i got ta think about this. i got ta keep track of that. so one of the big things about this class is, did you think about this at a billy, we're going cover that now. so system calls is the topic of today. what finally gon na get into this world of isolation and protection? abstractions are cool. we'll come on another day, but this idea of isolation and protection. so let's go back our picture. let's get this the right way up and look at this picture here, ok. tell me what i'm going try and do. i'm gon na try and take this. and not well, i was gon na. i was. i was going try and do this, but let's go back over here. let's look at this picture and. it's kind of interesting that that was gon na work. yeah, i'll last. that's close enough. so here's our two pictures. so we have the picture of multiprogramming. and the picture of our cpu and i mentioned that. uh, and we kind of discussed it on one of the first date in the class about does the cpu really know what it's doing? and we had some arguments back and forth say yes and no one"
"""OpSys_Make_Files_Transcript.txt""","i was going try and do this, but let's go back over here. let's look at this picture and. it's kind of interesting that that was gon na work. yeah, i'll last. that's close enough. so here's our two pictures. so we have the picture of multiprogramming. and the picture of our cpu and i mentioned that. uh, and we kind of discussed it on one of the first date in the class about does the cpu really know what it's doing? and we had some arguments back and forth say yes and no one and they went there is really there really is no correct answer that this kind of more philosophical. yes it does. no, because if it's executing an add instruction, it knows how do that. but no, in that it does n't know whether this add instruction is associated with a bite. a big computation of like some large language model or the rendering of a computer screen for some video game or part of the operating system, or whatever. it's just executing an app is a really simple thing. when we combine that with the world of multiprogram, we see that while conceptually as a human, when i'm using my computer, i'm seeing the fact that all three of these programs are being run at the same time. rome can run at the same time as microsoft. word can run at the same time as minesweeper or something like that, right? and even more specifically, multiple chrome tabs can now be running at the same time, and that's what i see. what the cpu sees is this a stream of instructions, right? so it does n't even necessarily know that when it's executing an add instruction, even what program that adds for it's just i'm reading an add instruction and i'm doing it. is it for that chrome tab or that chrome tab or minesweeper or something else? it does n't know. ok, so here lies a potential problem and i wanna throw this at you. right. if this is our hardware and i do n't have a really great picture, i do n't know why this wo n't fit on the same screen, but if this is our hardware, so let's get rid of that now for a second. let's just make this bigger again. and furthermore, connected this and we have n't talked about how, but i'm just gon na march it. mark it on here. we have all of actually i've got that picture here."
"""OpSys_Make_Files_Transcript.txt""","ok, so here lies a potential problem and i wanna throw this at you. right. if this is our hardware and i do n't have a really great picture, i do n't know why this wo n't fit on the same screen, but if this is our hardware, so let's get rid of that now for a second. let's just make this bigger again. and furthermore, connected this and we have n't talked about how, but i'm just gon na march it. mark it on here. we have all of actually i've got that picture here. furthermore, connected all of this stuff, we have io devices and member and i ask this of you guys say, do i want allow since the cpu is executing 1 instruction screen of multiple processes, do i want allow everyone have full access the entire computer all at once? yes or no, but yes thing as far as everyone meaning not so users but every process. so i see some shakes now. no, i see some nods every that does. ok. so those that shook head course right. you you shake your head, you make eye contact. now you do n't want. why do n't you wanna have all the processes access the whole computer all at the same? ok, so so say along. ok. so accessing the same component simultaneously, what do you mean? like, ok, let's let's let's let's, let's i like that answer. so let's look at something like a mouse, right? something simple. it's a pointer device. you move it around and you get like an x&y coordinate of where a pointer is, and then maybe some sort of indicator of whether a button is pressed. we'll do a simple one button mouse. ok, if crawled wants access that determine if the user clicked on a website, what would happen if? and albine sweeper also trying access that device at the same time. it's a problem. it could be now for something like a mouse, because it's really kind of 1 directional. maybe not, because if a whole bunch of applications all are trying read from the mouse at the same time, it's not necessarily gon na cause a problem because the mouse could say. ohh yeah, here's the world i'm gon na broadcast the entire world of my computer. where the mouse pointer is right? but on this stuff, let's think about something like a network card."
"""OpSys_Make_Files_Transcript.txt""","it's a problem. it could be now for something like a mouse, because it's really kind of 1 directional. maybe not, because if a whole bunch of applications all are trying read from the mouse at the same time, it's not necessarily gon na cause a problem because the mouse could say. ohh yeah, here's the world i'm gon na broadcast the entire world of my computer. where the mouse pointer is right? but on this stuff, let's think about something like a network card. we can read and write data on a network card all the time, right? what if multiple processes were all trying access the network card all at the same time send data on the network? we can have problems. we could have multiple people's all trying write the same message all at once, and i wanna say i want request a website at the same time as i want request information about from the server about my elden ring instance and this other application wants send information about, you know i do n't have. i do n't know. i'm out of ideas. right. you get the idea, though. if everybody's trying overwrite everybody's data in the network card at the same time, we get gobbledygook sent out. we do n't really have control the access there. if everybody has access the hardware. similarly, if i'm trying make a request from my bank for my bank information and i'm using chrome because i wanna display that in my in my in my in my browser and at the same time that elden ring is running, maybe the manufacturers of elden ring happened be looking at that information and seeing my bank account information and all of a sudden up and make a transaction, right? so this idea of hardware access breaks down and becomes a problem a certain extent. now, again, not always, but often it does. so network card, another one this drives is another one. i do n't necessarily want everybody right in my disk drive at the same time because i could get gobbledygook and corrupt the data, so we need a way restrict this. ok, that's my motivation. maybe was kind of lame motivation, but that's what we're gon na do. so what are we gon na do instead? the cpu has something that is referred as modes. ok. that's what we're going do. instead, the designers of this hardware side. ok, i know that the cpu does n't necessarily know what it's executing it."
"""OpSys_Make_Files_Transcript.txt""","i do n't necessarily want everybody right in my disk drive at the same time because i could get gobbledygook and corrupt the data, so we need a way restrict this. ok, that's my motivation. maybe was kind of lame motivation, but that's what we're gon na do. so what are we gon na do instead? the cpu has something that is referred as modes. ok. that's what we're going do. instead, the designers of this hardware side. ok, i know that the cpu does n't necessarily know what it's executing it. well, in a way, it knows that it's executing an individual stream instruction for something, but it does n't necessarily know whether or not it's this process or that process. or maybe it's a process that i want have privilege access hardware. maybe it's a process that i do n't, and so as a result they said fine, since the cpu does n't know what it's doing, we're gon na have add some more hardware make it a little bit more special so that it kind of does know a little bit more about what it's doing. so the designers of that said, ok, great, we are going develop something called the cpu mode. ok, so that's my motivation. before we get that all on and just take a side step here and talk about operating system versus kernel. remember, this was doctor langley definition of an operating system. ok. uh software that provides services users applications. there are lots of more lengthy definitions of this, but this is kind of my definition and so with inside the operating system there is something called the kernel. they would heard this word. kernel. ok. colonel is, i would call it a piece of software that bridges hardware and software. ok. we mentioned our we motivated and we kind of talked a little bit that we do n't necessarily want everybody or every part of the instruction stream access all the hardware all the time. so the developers of the cpu and operating system developers said ok, we're gon na we're gon na issue and utilize this idea of a protected mode. ok, so. and then have this piece of software called the kernel that is going be privileged. it's going be allowed access everything but a, but a user process or a user instruction stream. i ca n't even say user process because it could be multiple processes that are also stuck together, but we'll have a situation where the cpu can only execute in a restricted mode."
"""OpSys_Make_Files_Transcript.txt""","so the developers of the cpu and operating system developers said ok, we're gon na we're gon na issue and utilize this idea of a protected mode. ok, so. and then have this piece of software called the kernel that is going be privileged. it's going be allowed access everything but a, but a user process or a user instruction stream. i ca n't even say user process because it could be multiple processes that are also stuck together, but we'll have a situation where the cpu can only execute in a restricted mode. yeah. let's talk about system calls and dual mode operation. ok, so user mode and kernel mode. if we look back at our picture do, let's go back over here. we have an add instruction. now i've mentioned that this is not a course in x86 assembly leverage. there are a lot of instructions that the cpu can execute in x86. i'm showing you potentially algebra, but there's a bunch of stuff we can move things around in memory. we can do a whole bunch of mathematical units, but if you look at essentially your program that you wrote in c. he was actually reading and writing memory. you're making function calls and you're manipulating data right now, i said right, we have data and functions that manipulate that data. where does the data come? it comes from memory. how do we manipulate it with essentially logic and algebraic operations? ok, that. ok, so we have a set of instructions that the cpu is allowed execute. then we've got all those special type of operations that we might want allow our cpu do things like. access memory for another process. right. we ca n't do that. chrome ca n't access memory outside of chrome with like about how later on, but there's some other stuff that we need be able do things also like accessing hardware i wanna read from the disk drive we just discussed this that we do n't want necessarily allow every process directly read and write the hardware, so we've got some other stuff that we need be able access. i mentioned the idea of processes. we work with processes and how we can have multiple processes running out of time. well, somebody's got ta be able run cpu instructions that even set that up, right? if a process does n't is n't able access somebody else's memory, it also then ca n't access memory initialize another process."
"""OpSys_Make_Files_Transcript.txt""","chrome ca n't access memory outside of chrome with like about how later on, but there's some other stuff that we need be able do things also like accessing hardware i wanna read from the disk drive we just discussed this that we do n't want necessarily allow every process directly read and write the hardware, so we've got some other stuff that we need be able access. i mentioned the idea of processes. we work with processes and how we can have multiple processes running out of time. well, somebody's got ta be able run cpu instructions that even set that up, right? if a process does n't is n't able access somebody else's memory, it also then ca n't access memory initialize another process. so we've got this other set of stuff that we want allow be executed on the cpu, but not under normal circumstances. ok, so we have two modes at the cpu is allowed run in and over here in these control registers we have a special register and on x86 it's called the flags register. that keeps track of what the cpu mode is, and so here's what's gon na happen inside the flags register. there's a mode bit, and in fact it's actually 2 bits. we were necessarily talk about that, but there is some flag in there that says what the cpu mode is being running. we know that during the cpu instructions stream execution, it does essentially two or three things. really it has fetch the next instruction execute. it has decode it, send it the control unit and then execute what's going on, right? the fetch execute loop show that in and week one. in addition that, what it's gon na do is when it fetches an instruction, it's gon na check the mode bit and say see if my mode bit is in nonprivileged mode user modes it checks is this instruction that's being requested allowed be executed in user mode. if it does, it executes it. if it's not allowed execute this instruction and user mode, it's an exception and crashes. well, we'll get the how it fixes that, but it sends an exception saying i am not currently in the mode. that allows you execute this instruction. so if i have a user process or user program right that i compiled it my c code and after it was compiled it had an instruction in there for accessing the disk drive, the cpu would fetch that and it would say alright."
"""OpSys_Make_Files_Transcript.txt""","if it does, it executes it. if it's not allowed execute this instruction and user mode, it's an exception and crashes. well, we'll get the how it fixes that, but it sends an exception saying i am not currently in the mode. that allows you execute this instruction. so if i have a user process or user program right that i compiled it my c code and after it was compiled it had an instruction in there for accessing the disk drive, the cpu would fetch that and it would say alright. can i actually like this and the cpu would say no because the mode is not set and as a result it would fail execute that instruction and not let the process or the instruction stream execute that instruction. everybody with me. that is isolation, not the only thing associated with isolation, but it is an aspect of isolation. this cpu is isolated only be allowed execute instructions in user mode that are user mode instructions. ok, so let's talk about operating system code. operating system is like the leader of our cpu. it is the the the privilege of user when the cpu is in system mode and the operating system is running. you can do a patch as i access the hard drive, the system will be in system mode. the cpu will say uh, i'm in system mode. that's great. i will execute that instruction and execute the the the the code that maybe access the disk drive or access something outside of this process's memory. so in user mode we are restricted, we can only execute a subset of instructions. we only have access a subset of memory addresses and we do n't have any access at all special instructions for accessing io devices would n't run in system mode or kernel mode. some people call it we have access 100 % of the memory that's available. we have access all of the instructions and we can have full access io devices. ok, dual mode operation. so next piece we have make it sure in our operating system or in our system in general that the only code that's allowed execute in system mode is the operating system. why? well, it just kind of talked about that well. so that user processes do n't have access all the hardware and ca n't step on each other. they do n't step on each other's memory, ok? so that's my notes on that. dual mode of operation user mode is ok. here's the more official definition of restricted mode of operation, only allows instructions be executed by the program."
"""OpSys_Make_Files_Transcript.txt""","so next piece we have make it sure in our operating system or in our system in general that the only code that's allowed execute in system mode is the operating system. why? well, it just kind of talked about that well. so that user processes do n't have access all the hardware and ca n't step on each other. they do n't step on each other's memory, ok? so that's my notes on that. dual mode of operation user mode is ok. here's the more official definition of restricted mode of operation, only allows instructions be executed by the program. certain construction right prevents errant process from crashing this system. ok, there are some instructions out there that you can execute things like halt. they do n't necessarily want chrome halt our computer. maybe with you, but i do n't. but that's that, colonel. ok, also called supervisor mode or system mode or privilege mode. it's essentially access everything. ok, now we've got that in there. here is my question for you. i have been instruction stream that is currently running a user process like chrome or elden ring or something like that right? i want i want now access the hard drive, the hardware or reading the hard drive. why might they want do that from there is the third one. why might a process want read the hard drive? two. yeah. see if you have enough space download something. ok, see enough space download something. i like that chrome needs access the hard drive request information say do i have enough free space? i need download file ok what else? somebody had control and microsoft word, right? yeah, access the hard drive and her read the file, right? we just sat and motivated that we do n't want have this process have direct access the hardware. so in order for it access the hardware, how does it do it? who is the only one on the system that can access the special instructions that are necessary for accessing the io devices on our computer? yeah, the operating system works. specifically the kernel. ok, so now let's get back the the sort of chicken and egg problem. i have a process and instruction stream that's running in user mode. i want access the hardware if this process was directly run the instructions. the access the io device access the disk drive the cpu is going do a fetch."
"""OpSys_Make_Files_Transcript.txt""","so in order for it access the hardware, how does it do it? who is the only one on the system that can access the special instructions that are necessary for accessing the io devices on our computer? yeah, the operating system works. specifically the kernel. ok, so now let's get back the the sort of chicken and egg problem. i have a process and instruction stream that's running in user mode. i want access the hardware if this process was directly run the instructions. the access the io device access the disk drive the cpu is going do a fetch. it's gon na try access and execute that instruction, and it's gon na fail because the mode is not set the system up, right. ok, that's good. but it's also bad because in this particular case the system needs access with this track. so what does it need do in order be able execute that instruction from a? hardware perspective right here. that did n't work very well. ok, my pen is all the way we need find a way flip this mode bit. right. ok, so here's a proposal. i have a process that's running. i need run this and flip this mode bit. so why do n't we just let it flip the mode bit say now i'm running in system mode. ok, let's go run that next that. right. that's and then we can call a function and you make a function call access the hard drive and then when that function returns, then we flipped the mode bit back user mode. and they say problem with that. i would n't ask that question if it was n't a problem was for that way. so maybe we should ask it this way. what is the problem with that? ok. i like that, but i'm a twist. the words you said another program might be wanted do that at the same time and i would say i'm gon na twist this around say what is the and what is the other concern? what is the problem with allowing any user programs change these mode flags? you know solution. yeah, it's basically says, yeah, it's like, you know what? i'm gon na do. i've got all of these special instructions that i'm gon na lock in my locker. i do n't know. lock it and i'm gon na lock it with a key. so when i twist that key, awesome, you ca n't access it."
"""OpSys_Make_Files_Transcript.txt""","the words you said another program might be wanted do that at the same time and i would say i'm gon na twist this around say what is the and what is the other concern? what is the problem with allowing any user programs change these mode flags? you know solution. yeah, it's basically says, yeah, it's like, you know what? i'm gon na do. i've got all of these special instructions that i'm gon na lock in my locker. i do n't know. lock it and i'm gon na lock it with a key. so when i twist that key, awesome, you ca n't access it. but what if i just want take that key and drop it on the floor and walk away? that's essentially what i'm doing. i got all these processes that can pound on the door and try open up that door and say, ha ha and then the cpu is like you ca n't execute those instructions cause i've done in the right mode. if we let any user process willy nilly change the mode, that's like me saying. ohh yeah ha, i ca n't get in the closet, but guess what? doctor lunky dropped this key. we lose the ability or isolation. ok, maybe it's a little bit nicer if user does n't happen see the key on the floor, but we have assume that they could, so we ca n't just let anybody change the model. so now here comes the next problem. how do we get that bone flipped? yeah. yes. ask nicely. i like that. no, seriously, it sounds like funny thing, but it is in a way ask nicely. what if we take that key change the mode and we give it doctor taylor was sitting in his office. who we trust, right? and in order get that key, we have walk over doctor taylor's office and knock on the door and say, doctor taylor, i really would like access the hard drive. would you be letting me? would you be? would be ok if i did that and he says i ca n't give you the key. sorry i ca n't give it you, doctor. lumpy, trust me, but i can go get it for you. you just go stand over there for a second outside my door. you can watch me. it's fine and he goes over the door, unlocks it, grabs what i needed from the hard drive, goes relocks. the door gives me. just what i needed."
"""OpSys_Make_Files_Transcript.txt""","would you be letting me? would you be? would be ok if i did that and he says i ca n't give you the key. sorry i ca n't give it you, doctor. lumpy, trust me, but i can go get it for you. you just go stand over there for a second outside my door. you can watch me. it's fine and he goes over the door, unlocks it, grabs what i needed from the hard drive, goes relocks. the door gives me. just what i needed. and then he goes back in his office. that's a little bit better. and that's what the cpu does, only not like doors. and doctor taylor's office, but essentially it has something pre set up right before i left for the day after i locked my closet, i had go over doctor taylor's office and say hey, doctor taylor, can you hold on this key and only let students in that you trust access only the things that they're allowed access and they'll say. ohh sure doctor. monkey. that's fine. and then i get go away. i have establish this trust. ok, so let's talk buddha on time, ok? here's what we're gon na do. here's my thought. ok, i did n't think of this, but the time was. this is my analogy here, but sippel boots up. what's the very first thing? the cpu does well, it does a lot of things, but ultimately after things get initialized on our system and the firmware that's running on our system gets running, the cpu and the motherboard starts looking for the operating system. the cpu starts up booting and running instead of privileged system mode. it finds the disk drive that has the operating system on and it loads the operating system because it knows the operating system has the ability initialize this system. the operating system says here is doctor taylor or the that's versions of doctor taylor. it says here is the person that i trust. here is cold in memories that i trust be the entry point for when somebody needs something's when they need contact the operating system or need unlock that door get access something. it sets a special routine in protected memory and it tells the cpu that. that's the os entry routine, although my focus is not that great. ok. i was n't allowed do that well because the cpu, when it booted up was in system mode and it trusts the operating system, so it loads the operating system initially."
"""OpSys_Make_Files_Transcript.txt""","here is cold in memories that i trust be the entry point for when somebody needs something's when they need contact the operating system or need unlock that door get access something. it sets a special routine in protected memory and it tells the cpu that. that's the os entry routine, although my focus is not that great. ok. i was n't allowed do that well because the cpu, when it booted up was in system mode and it trusts the operating system, so it loads the operating system initially. there are no user processes running because the system has n't even booted, but the trust with this locked door has been established and set by the os. let me ask you this question right. well, what i even ask you, let me just say this here, while a user process ca n't escalate its privileges. right. that would be kind of like cheating the system. someone with escalated escalated privileges can give them up. so while the operating system has the ability execute all the instruction when it's done and it's ready return user mode, it can say i am relinquishing my my privileges right? the wizard can say i'm giving up my magic wand. i do n't wanna be a wizard anymore, right? the offerings is they do that. so that is what it does. it sets up everything it needs improve those mode and then later on says i am giving up my privileges and i'm entering user mode. so i can run the very first user process, might be something like the operating systems gui. does n't need brian provide mode was the right winger process with me. all right, good. so we got that set up, we got doctor taylor set up. he's that os enter routine and now we can run a user process. and now we're running in user mode after all this stuff has been set up. the next thing we need do is find a way or the cpu or user process ask doctor taylor lend itself in, and we do that through a special mechanism that the cpu has called a trap. this is a big word. ok, so it's a short word, but it's very important. a trap? what is a trap? well, in all practical purposes, what is a trend like? i do n't have problems with mice, but i know that people do. they set up mouse tracks, right? the cliche, like you put the cheese on the thing and it's got the thing like, flips over on the right."
"""OpSys_Make_Files_Transcript.txt""","the next thing we need do is find a way or the cpu or user process ask doctor taylor lend itself in, and we do that through a special mechanism that the cpu has called a trap. this is a big word. ok, so it's a short word, but it's very important. a trap? what is a trap? well, in all practical purposes, what is a trend like? i do n't have problems with mice, but i know that people do. they set up mouse tracks, right? the cliche, like you put the cheese on the thing and it's got the thing like, flips over on the right. what does the trap do? what's intent? what is its purpose? ok, trap something. ok, once we have another word for that, it's the catch something it's like, right? and it's in a way kind of this surprise feature that says, ok, i'm gon na. i'm gon na be sitting here doing nothing, waiting for something happen. and as soon as a rat or a mouse or some creature i do n't want necessarily get into this steps on that trigger, right? we have a trigger mechanism and then it's usually a spring that slaps at all the sudden causes the thing engage. ok. in a way that's kind of what the cu has got, let me look at it in hardware perspective. the cpu is executing instructions and i mentioned these instructions like add logical operations, things like that in order access the operating systems entering one, we need a mechanism for a regularly you know user mode stream say hey doctor taylor, can you unlock them? can you unlock the door? hey, operating system, can you access the hard drive? and there's a special instruction like that the user process executes, say, call off the os entry procedure and ohh by the way, flip the mode at the same time and that's what a trap is. and our x86 system, that instruction is just called syscall. under normal circumstances, syscall does not work, but because the operating system has set up a special location in memory. but the os entry procedure and your point is. this call starts work when the cpu that's running in user mode sees the syscall instruction. it says i can do that. i'm gon na pause all execution of the current of the this string. find the os entry procedure because it was already set up by the operating system when the system booted."
"""OpSys_Make_Files_Transcript.txt""","and our x86 system, that instruction is just called syscall. under normal circumstances, syscall does not work, but because the operating system has set up a special location in memory. but the os entry procedure and your point is. this call starts work when the cpu that's running in user mode sees the syscall instruction. it says i can do that. i'm gon na pause all execution of the current of the this string. find the os entry procedure because it was already set up by the operating system when the system booted. so you see, you trust this routine. it's like me saying i trust doctor taylor. it sets the program counter point in the os entry routine. changes the mode, the system mode, and continues keep executing at that point. what instruction gets executed? where in memory? not if you know the answer. and a couple of knots. who's confused? ok, that's fine. i i will look at it again. what is the program counter do? what does it start? remember is the address of the next instruction that we're gon na execute in memory. normally the program color is pointing somewhere over here with inside the users instructions have user process. we're gon na batch from wherever the program counter is pointing bring that instruction in the memory stored in the. in this processor starting instruction, register the bits for that get sent into the control unit and the rest of the signals that execute that instruction are generated and sent the rest of the processor. when the system call instruction is executed, that syscall instruction is generated by the compiler and is part of our user program. that ultimately gets executed brought in the instruction register, decoded, sent the control unit that control unit. seeing that it's assist call says ah, this is assist call. i have find where the operating system entry routine is. i know that it's in memory up here, so it changes the program counter. 2 instead of pointing with inside the users instructions point into the os entry routine entry routine and then changes the mode. be. system. and because the program counter is now pointing in the screen arrow arrow after it's done executing the syscall instruction, the next instruction get fetched is. do you wanna send your routine? it brings in that instruction into the instruction register. turns that into the control unit and generates all of the signals that are necessary for executing the instruction in the os routine."
"""OpSys_Make_Files_Transcript.txt""","i know that it's in memory up here, so it changes the program counter. 2 instead of pointing with inside the users instructions point into the os entry routine entry routine and then changes the mode. be. system. and because the program counter is now pointing in the screen arrow arrow after it's done executing the syscall instruction, the next instruction get fetched is. do you wanna send your routine? it brings in that instruction into the instruction register. turns that into the control unit and generates all of the signals that are necessary for executing the instruction in the os routine. but because the mode has been changed system mode now, the operating system has full access the entire instruction set. all of the hardware and all of memory. it was a way for us allow the cpu escalate its privileges, but in the process of executing its privileges, only code that was allowed be executed is operating system code. that makes more sense. that makes sense. this is a trap. the syscall instruction. that was executed by the cpu issue that trigger the spring trapped the user process say you are no longer allowed execute. i'm going execute the operating system instead. ok, some people also call this a software interrupt. i'm going just call it a tramp because that's really what it is. questions. all right. in the book, not that we have a book for this class, but yeah, the operating system concepts essential, second edition book that i said was so supplementary information. it draws it like this. well, we have this idea of user mode or the mode bit is set one or whether it's one or zero or zero one. it's architecture specific. like i said, on x86 is actually 2 bits because it has like semi privileged mode or whatever. but ok, we're only gon na have it be on or off user mode or kernel mode, and it dries it like this. and the reason why i like this picture but do n't like this picture. is it kind of illustrates it like locking the door and throwing the key on the floor? and it says ohh yeah, we just flip the bit you system mode."
"""OpSys_Make_Files_Transcript.txt""","it's architecture specific. like i said, on x86 is actually 2 bits because it has like semi privileged mode or whatever. but ok, we're only gon na have it be on or off user mode or kernel mode, and it dries it like this. and the reason why i like this picture but do n't like this picture. is it kind of illustrates it like locking the door and throwing the key on the floor? and it says ohh yeah, we just flip the bit you system mode. now we do n't actually do that in order actually execute operating system code, we need execute this special trap mechanism forces the processor only execute operating system code when it flips that mode system mode, because we need that for isolation, our user mode processes must be isolated so they do n't step on each others toes, access each other's memory, all try access hardware at the same time. the only way for any process execute operating system code is execute the special trap, forces the cpu only execute trusted code when it goes in the system mode. and this picture kind of shows that, but i like show a little bit different way as well with me. all right. question i love questions. yes, there is multiple different system calls you can make, right. so when you do sis call and x86 and it goes in there and starts executing os code, how does the gpu know what different system call the user code wants make? ok. great question. and that was actually gon na be my next topic exactly right. so there's a lot of things. that's the question was there's multiple system calls, right? right. this in a way demonstrates that it's very limited. i guess at the very least, this idea of a trap, a system call is built on top of that trap, and a system call is essentially the way a user process or user instructions stream accesses operating system services. ok. and what the question was. explicitly, are n't there a lot of system calls? and i'm going put words in your mouth and and raise it up a little bit level and say, is n't there a lot of different requests that we could ask the operating system for? and the answer is yes, right with my key analogy, we can go up doctor taylor and say right there's not just one thing in the closet that i've locked up."
"""OpSys_Make_Files_Transcript.txt""","i guess at the very least, this idea of a trap, a system call is built on top of that trap, and a system call is essentially the way a user process or user instructions stream accesses operating system services. ok. and what the question was. explicitly, are n't there a lot of system calls? and i'm going put words in your mouth and and raise it up a little bit level and say, is n't there a lot of different requests that we could ask the operating system for? and the answer is yes, right with my key analogy, we can go up doctor taylor and say right there's not just one thing in the closet that i've locked up. there's probably hundreds of different things that i've locked up in the closet, and you might want ask doctor taylor for just one of them. so there's a lot of different things you can ask about. you can ask you, uh, access the disk drop. you could ask access a network card. you could ask you know what is the version of operating system that i'm running right? what is the name of my system? all of this stuff is being stored by the operating system and we do n't necessarily have access it by executing regular cpu regular c code. so yes, how then if there's a lot of different operations that we can do, how do we tell the operating system what we're gon na do when we have one trap 1 mechanism access operating system code? and that is through what's referred as the system call number. so as part of executing the syscall instruction, there is going be and i'll show it you essentially. our register and what we're going do is we're gon na put a number in a special register that we have access as at in user mode. ok, we'll put a number in there and then we'll invoke the syscall instruction that that pulse one and only one operating system routine into the cpu when that operating system routine runs, one of the very first things that's going do is read that register. notice when i said that we're gon na ask you this. call the operating system. sorry the the cpu does n't do a whole lot of changing with the rest of its state and so as a result, all of the contents of these registers do n't change."
"""OpSys_Make_Files_Transcript.txt""","ok, we'll put a number in there and then we'll invoke the syscall instruction that that pulse one and only one operating system routine into the cpu when that operating system routine runs, one of the very first things that's going do is read that register. notice when i said that we're gon na ask you this. call the operating system. sorry the the cpu does n't do a whole lot of changing with the rest of its state and so as a result, all of the contents of these registers do n't change. so when the operating system code runs, it has be responsible enough not step on one of the processes toes, but it also then has access the register that that processor set, or that that process set. so we're going set a registered value say what system call we want execute. we're gon na invoke the sys call will load the operating systems entry routine that operating systems enter. routine will read the register say what operation we're doing, and then essentially branch off with a big huge long if statement where it needs go next, and that's referred as the system call table. if you want know the specific words in there, all of the system calls that the that the operating system can execute are all referenced by number in a big huge system call table, and it's kind of like a big switch. where they say ohh if the system call is 1 then go execute this routine. if the system calls two then go execute this other one. once we've switched into system mode, the operating system can branch wherever it needs, but we just have get there. and so we do that via the system called table. two questions. other questions. this is usually where people like, oh, i do n't like operating systems, but it's so cool. that's how it works. alright, so let's keep going. we've got ta trap. why do we need system calls? i think we pretty much covered all this stuff. isolation protection, right? the kernel needs run in privilege mode. the user process is not, so we need this crap. veganism. ok, can process a share, every anything. we'll talk about that answer is no isolation. we'll get there. an interprocess communication. can we share stuff with the kernel? well, we have n't talked about that. we are currently have the ability share stuff with the kernel because all we have do is set something in memory or set a register and then invoke the trap."
"""OpSys_Make_Files_Transcript.txt""","isolation protection, right? the kernel needs run in privilege mode. the user process is not, so we need this crap. veganism. ok, can process a share, every anything. we'll talk about that answer is no isolation. we'll get there. an interprocess communication. can we share stuff with the kernel? well, we have n't talked about that. we are currently have the ability share stuff with the kernel because all we have do is set something in memory or set a register and then invoke the trap. so yes, we ca n't. all right. so on this idea of the system called table. i wanna i wanna mention that they're in the notes. umm. and then we'll we'll be done for the day. cause you know we're we got a lot going on. so there's some calls are invoked by number, though we set a register say what number we're gon na execute. the kernel then finds the code that's necessary based on indexing that into a table. i mentioned that like a big switch, so linux and the system called table, there is a. there's a 32 bit but 32 bit as system calls and 64 bit system calls. these are pretty much not used anymore because most of our processors processors are 64 bits. i mentioned that that they're here for legacy purposes. if you wanna look them up, windows has a system called table as well. windows does its darndest try and hide this from you. it does n't really want you do it. wants you know what they are, what they really want you do from a windows perspective is use the system library functions that are available. but there are system calls in windows. windows is an operating system that runs on x86, so it has do this. it has do the trap thing as well, so let's take a look at what these are. maybe. ok so. chromium has a set of os docs, so here they are. here is a system called table for linux and so the very first system call number is 0 is the system call for read. that's essentially for reading the file system, ultimately gets down reading like the disk drive and it's system called 0. so what you have do is set the special register rax on x86 the # 0 and you'll execute the read system calls when you execute the syscall instruction, and so the list goes on and on. so we've got read, write, open, close. that's for file system stuff."
"""OpSys_Make_Files_Transcript.txt""","here is a system called table for linux and so the very first system call number is 0 is the system call for read. that's essentially for reading the file system, ultimately gets down reading like the disk drive and it's system called 0. so what you have do is set the special register rax on x86 the # 0 and you'll execute the read system calls when you execute the syscall instruction, and so the list goes on and on. so we've got read, write, open, close. that's for file system stuff. here's some more stuff for getting statistics about files from working with memory for dealing with signals that you'll talk about. the more stop with memory, some shared memory stuff and so on and so forth, and the list goes on and on. there's gon na be some system calls for getting information about user processes, we'll talk about when when we get processes, umm. and all the way down. oh sorry, i went too far the very bottom in we have essentially as a kernel version 4.10, i do n't know how what they're currently at for the windows for the linux kernel 300 and 3332 different system calls that we can invoke on linux. they said the windows ones are there as well. they're a little bit harder read. but these are the windows ones as well. so for all the different flavors of windows, we can see what the details are. for them. i got. i got ta bounce and then we have go look and see what all these different numbers mean. but windows does n't really want you know what system calls are, so a lot of these are things i. yeah, look at me like add atom. that might be an atomic for atomic operation. there might be some stuff for allocating memory, but. i only wanted show you these. so you know that windows does do system calls. we're gon na work with linux system calls because the documentation is there and windows linux is posix. it's part of the portable operating system. umm i it conforms the portable operating system standard and so that's we're gon na do so. but the windows ones do exist. ok. questions then. alright, system calls are typically categorized together. we will cover these sort of in luncheons. there's file management system calls for accessing the hard drives, typically information maintenance."
"""OpSys_Make_Files_Transcript.txt""","so you know that windows does do system calls. we're gon na work with linux system calls because the documentation is there and windows linux is posix. it's part of the portable operating system. umm i it conforms the portable operating system standard and so that's we're gon na do so. but the windows ones do exist. ok. questions then. alright, system calls are typically categorized together. we will cover these sort of in luncheons. there's file management system calls for accessing the hard drives, typically information maintenance. that's for like retrieving information about the system or information about processes, process control for creating an ending processes communication, whether they're gon na communicate between processes or communicate with other computers across the network. there's device management stuff. these are things for like accessing. like specific information about a particular card io device, and then we'll talk about the behavior when we show them. but there's five major categories of system calls, and we'll go through these over the coming weeks, sort of in turn, the next category. the first one, we're gon na cover this process control and information maintenance and then we'll get into communication and file systems later on. and so we'll talk about system calls, what they are, and then we'll talk about how they work under the covers solid. i think i'm out of time right now. yeah. so let's stop there. thanks for coming. umm. and enjoy the rest of your day. lembke, james stopped transcription"
"""OpSys_Memory_Fakeout_Transcript.txt""","meeting in _ general_-20240415_130244 - meeting recording april 15, 2024, 6:02pm 49 m 10s lembke, james started transcription lembke, james 0:08 ok, hello. so welcome operating systems this week. these past two weeks, i think we've done a fair amount of stuff, yet there's not been a whole lot of stuff for me show for it and canvas it is what it is. it's not great or bad, but announcement. so we had a quiz last week. friday. i'm glad we're scheduling. i'm still grading that the process simulator i send out that notification and i extended the deadline. it's now. two on wednesday i will have a new programming project out on wednesday, so that will be the last one for the term and it will have deal with memory management, is the topic we're in the middle of right now. we're gon na have this week. we're moving on. we're talking and kind of going more specific in memory management and going be talking about virtual memory. specifically, we kind of looked in talking about that for a while, but i just put that in there and we'll see how far we get. we might get into file systems on friday. umm no quiz this week i would have. i would like we will have a quiz next week on memory management, but we have n't really finished enough of memory management for me really give you a complete quiz on it. so we'll we'll have that on week 14 on memory management. so questions i did, i think i noticed known announced this. i did finish grading flagger. i had those grades would be out there. i pushed my feedback form or other text file your rebuilt. as well as your grade and should be in canvas. double check my work and make sure everything jives with all of that. so ok, so where were we at on friday or well, we had a quiz on friday, but in the midst of all of this is we were trying solve some of these concerns that i had with virtual memory where we have a limited number of pages now and now we have pages and frames. we do n't have a limited number of pages. we have a limited number of frames i'm gon na use that word right because physical memory is divided into frames and with our virtual memory system and paging. frank pages go into frames, so i mentioned that we were gon na let the the process. live in a world word can access in unlimited amount of memory."
"""OpSys_Memory_Fakeout_Transcript.txt""","so ok, so where were we at on friday or well, we had a quiz on friday, but in the midst of all of this is we were trying solve some of these concerns that i had with virtual memory where we have a limited number of pages now and now we have pages and frames. we do n't have a limited number of pages. we have a limited number of frames i'm gon na use that word right because physical memory is divided into frames and with our virtual memory system and paging. frank pages go into frames, so i mentioned that we were gon na let the the process. live in a world word can access in unlimited amount of memory. at least it's gon na think that it can access and unlimited amount of memory. right. and i showed that math where if we are in a 64 bit address space we have like 16 billion gigabytes that we could potentially allow this process have. we do n't have that much memory, but we're gon na let it think that it has that much memory. and by utilizing the page table, we can then determine what pages it's actually using. so that's stage one is we say well with that a process no longer has tell us how much memory it wants use. we just say you can use as much as you need. well, up 16 billion gigabytes, right. ok. then the next step was if a process is gon na potentially tell us that it needs up 16 billion gigabytes, how are we going organize this in a way where we do n't actually have allocate 617 billion gigabytes worth of data? official with a frames because we do n't have that many frames we have in this picture 10. you can do the math if you've got 16 gigs of memory. how many frames? that is 16 gig divided by 4096. page size gives you 100 frames. that is right. and they said the way we're going solve this is by not having the process tell us how much memory it needs and that we're just not gon na allocate any frames for the process until it tells us that it needs use them. so the program when it process is created from that program, we're not really gon na put anything in memory. we're just gon na let the process run and we're going create a page table that's essentially empty and utilize these extra bits that we do n't need store."
"""OpSys_Memory_Fakeout_Transcript.txt""","and they said the way we're going solve this is by not having the process tell us how much memory it needs and that we're just not gon na allocate any frames for the process until it tells us that it needs use them. so the program when it process is created from that program, we're not really gon na put anything in memory. we're just gon na let the process run and we're going create a page table that's essentially empty and utilize these extra bits that we do n't need store. do n't need this because that that that offset those 12 bits we do n't need store those, we just store the frame and then we got a bunch extra bits. one of those bits is that alan bit. we just clear them all be 0. create our page table for all the pages and then as a process access is something so the example i gave was the very first thing but the process is going do is access name is the program entry procedure we're giving by the compiler. this is where things are pretty cool, because the compiler can actually tell the operating system exactly where maine is, exactly where the entrance into this program is when the operating system creates an adverse space and puts those instructions inside the text section inside the process control lock when the operating system creates the process, it can put that entry address right in there because process live in virtual address world, you can say, well, how does the compiler know what the operating system's gon na load it? and now actually that we're talking about demand paging the operating system does n't even know where it's gon na put the process initially, because it's gon na load the pages as they're needed. this is where virtual addresses are awesome, because every process can have the exact same location of an entry procedure because they're all own thing. and in the executable standard, the help standard, the executable and linkable format, is what posix operating systems use. there is an entry address field that's specified inside the file, just like in a java file. the dot class file has a file format and you can find where mania is by looking through that file, right? but it's in there. there's a spec for it. we're not gon na talk about the specs for those files, but they exist. you can look up in the i wikipedia billing is really good place see this, but anyway what a process runs the program calendar here will be sent the entry procedure."
"""OpSys_Memory_Fakeout_Transcript.txt""","there is an entry address field that's specified inside the file, just like in a java file. the dot class file has a file format and you can find where mania is by looking through that file, right? but it's in there. there's a spec for it. we're not gon na talk about the specs for those files, but they exist. you can look up in the i wikipedia billing is really good place see this, but anyway what a process runs the program calendar here will be sent the entry procedure. the cpu will attempt issue a load do a batch of that instruction from the next section, so it knows what the execute and it's gon na send the virtual address the mu. the mu is using the memory management unit. the mu is using the translation. lookaside buffer the tlb that's been populated by page table entries from the operating system do virtual physical memory address translation when attempts do the virtual, the physical memory address translation, it's gon na grab the page number, might be one was impact section and it's going say is paid 1 valid. page 1 is not valid. it's zero, and so the mu here, the memory management unit will issue a a signal the cpu, like a trap. we're executing a system call only that signal that it sends the cpu is called page fault saying something is wrong. i ca n't do a virtual. the physical memory address translation. so the cpu just like when it gets a trap instruction or a syscall or whatever excuse the trap, it's cpu loads the operating system handle this page fault. the operating system will then take the appropriate page that was requested, and this case, page 1, figure out a place in memory put it behind. a free frame and there is lots of free frames. it just it's the first one in this example. it could pick any free part. free frame memory is uniform. access is probably time is concerned regardless of what frame i put it in. it takes the same amount of time. something's so different, right? takes less time access the beginning than the end, but memory is pretty symmetrical, so we put one here and then we update the page table and say that page one is now in frame 4. so the valid bit be won and then let the cpu x where it left off. now the memory management unit when it's referencing the page. ah, the frame for page one. in the page table says hi it's valid now."
"""OpSys_Memory_Fakeout_Transcript.txt""","it takes the same amount of time. something's so different, right? takes less time access the beginning than the end, but memory is pretty symmetrical, so we put one here and then we update the page table and say that page one is now in frame 4. so the valid bit be won and then let the cpu x where it left off. now the memory management unit when it's referencing the page. ah, the frame for page one. in the page table says hi it's valid now. so i can do virtual physical memory address translation and i can access memory. questions. ok. can i get a thumbs up though? right. that process process that set of actions cause i wanted distinguish the word from process because a process is now something that we think about as a instruction stream. but that set of actions is referred as a page fault and now i've got it written here as far as what happens. so the memory management unit triggers that there is an invalid page. so initially that the page is not present in memory and we need have the operating system get involved fix it, ok. question how long does this take? when do you think the access the process of page fault? think about all the things that have happen so musd the signal trap. ok, that's pretty quick. same thing as we execute assist call instruction do it. but system call well, once we execute that dial, the cpu has load the operating system. ok, that's the save its context of the current process that's executing and then we have load the operating system code. and then the operating systems got ta do something, right? we have n't really talked about this. i do this all the time and i apologize because it's like. this program i mentioned is a static representation of potential execution. it's built by the compiler and it's in the file system, right? if i want ask you where a dot out is when you write your programming projects, they're in a folder somewhere, right? so they're on disk. we have n't talked about file systems yet. we'll get there and 100 and understand what a folder and a file here is, but it's on disk. this is the process's memory address space, right? it's kind of be somewhere the birth of page table. it's got ta be somewhere. all we did talk about the page table residing in operating system land. this address space. had be somewhere, right?"
"""OpSys_Memory_Fakeout_Transcript.txt""","if i want ask you where a dot out is when you write your programming projects, they're in a folder somewhere, right? so they're on disk. we have n't talked about file systems yet. we'll get there and 100 and understand what a folder and a file here is, but it's on disk. this is the process's memory address space, right? it's kind of be somewhere the birth of page table. it's got ta be somewhere. all we did talk about the page table residing in operating system land. this address space. had be somewhere, right? so where is it? can it be a memory? well, we have n't loaded it in memory. we do n't wanna load it all in memory because the process could record, could request up 17 billion gigabytes. so we do n't have fill up all of our memory with the memory space of 1 process, right? right. i also really do n't want fill up disk. i my districts are pretty big, all these mine my disk drives in general are pretty big. i do n't personally have a disk drive that's 17 billion gigabytes, you guys. now that's just for one process too, by the way. right. how many process can we brought in our system? potentially hundreds. so now i have multiply 17 billion gigabytes by hundreds. that's a lot of storage, so when it comes a process address space, the operating system represents it in multiple different states. every single page will either be in memory. some place yet be determined we have talked about later, and unconstructed meaning unused has n't been built yet. when i look at this unused space in here, a presence bike request, something in this unused space, that page has n't been built yet, right? so when the operating system, once the build the process, it knows some things already, it knows the text, it knows the instructions execute, it knows the contents of the global data, right? it does n't really help with stuff like even zach. what's gon na be on there until the process of actually starts, like securing. well, these types of things, the operating system has the ability create on the fly. and so being look at that now and in terms of 17 billion gigabytes, now we have a lot less space that the operating system has account for. it really do n't have worry about text and data now."
"""OpSys_Memory_Fakeout_Transcript.txt""","so when the operating system, once the build the process, it knows some things already, it knows the text, it knows the instructions execute, it knows the contents of the global data, right? it does n't really help with stuff like even zach. what's gon na be on there until the process of actually starts, like securing. well, these types of things, the operating system has the ability create on the fly. and so being look at that now and in terms of 17 billion gigabytes, now we have a lot less space that the operating system has account for. it really do n't have worry about text and data now. maybe it's getting initialize the stack because there's actually a set size most important processes as far as how big stack can be do we can create a space for that get started, so we at least need the frame for main cause mains got ta run stacked brain for all that stuff we can figure out what that is, but it's a finite about size right? i'll big is our text. i mean, some programs are pretty big, but it's gon na be limited staff suddenly not 17 billion gigabytes. ok, so the object is mostly billy pre creates on these pages, so i'm gon na just leaves blank not even created ever. so now where is it gon na put this stuff that they're not actually being used? what are you guys thinking? what do we have in our computer that we can use store data? we have the cpu, right? we can bring data into the cpu. that's really limited as far as how much we can store there. it's kind of only what we're actively working on. we're memory. is a little bit bigger, but i just motivated that we only want load the pages that we need in memory so we can save memory. what's the next step down as far as like access and and storage? you know, computer, what does that? what ram is memory? that's random access memory, right? that's what ram stands for. what else? what else can we store stuff? i some words. ok. yeah. distraught. and that's we'll do it right. that's we're storing our program and so what our operating system is going do is this gon na carve out the section of our disk drive called paging space. ok. and what it's going do is it's going utilize that as a storage location for memory agents for processes."
"""OpSys_Memory_Fakeout_Transcript.txt""","that's random access memory, right? that's what ram stands for. what else? what else can we store stuff? i some words. ok. yeah. distraught. and that's we'll do it right. that's we're storing our program and so what our operating system is going do is this gon na carve out the section of our disk drive called paging space. ok. and what it's going do is it's going utilize that as a storage location for memory agents for processes. so the page does not exist in memory. it's either gon na be unconstructed or it's gon na be on disk in the paging space. nowling, sense so. that's why. inside here. the notes say. when we need load a page in a memory, we determine the praying for the page a free frame if available, or choose a victim page send disk if not. now the example i gave showed a pretty open memory. well, we had lots and lots and lots and lots of free frames, right? and in that particular case, we just load the page into a free frame. but if i have not a whole lot of memory that nostalgic. ok, i'm gon na go back my very first computer that i took college at 64 megs of memory. ok, so i'm not trying say that because i'm big and bad, it just i needed a number that was small. so 64 bags say only at 64 bags of memory and i wanted load a whole bunch of processes. the amount of free space that i have in memory is going fill up pretty quick. because i have a lot fewer brains than in my computer now where i have 16 gigs of memory or 32 gigs or even more. right. so we have get here try and figure out what we're gon na do or what the operating system is gon na do when our process requests a page and there's no place put it. because it, well, what do you wanna do? what could we do? right, let's talk philosophically here. what could the operating system do if there was no free place put a page? yeah, bob, some did. you think it drops the pages on the table, right? i liked it. i do n't remember. i do n't know why this came in my mind, but when i was a kid we used play the game. chubby bunny?"
"""OpSys_Memory_Fakeout_Transcript.txt""","so we have get here try and figure out what we're gon na do or what the operating system is gon na do when our process requests a page and there's no place put it. because it, well, what do you wanna do? what could we do? right, let's talk philosophically here. what could the operating system do if there was no free place put a page? yeah, bob, some did. you think it drops the pages on the table, right? i liked it. i do n't remember. i do n't know why this came in my mind, but when i was a kid we used play the game. chubby bunny? where you'd like judge jim has many marshmallows as you can in your mouth, and then you try say some word, and ultimately you end up spinning them out, right? because you right? that's the same way right is where you ca n't fit anymore pages in your mouth. you're out of rd. you drop on the floor. well, if you drop on the floor, you have throw them away. maybe right. and that's one option is say, you know what, i have an operating system and i have a process that's requesting data. i have no place put it in memory, so i'm just gon na say i'm sorry. process. you ca n't do this. i'm going terminate you. not fair. ok. the operating system could say alright you need this page. this other process that's stuck here waiting on io. i'm going just terminate you free up memory for your pages, but i've been there that's that there. that process was sitting over there being very, very happy and somebody else said, you know what, because somebody else was a memory hog. you're terminating me? that's unfair. so we're gon na figure this out and realize that this stuff. this is where this idea of memory being finite. hopefully becomes a little bit clearer, so let's take a look at this page replacement. ok, so let's drop picture. now that we can understand this idea of pages, frames and a disk drive, here is physical memory. here is our frames for operating system 012 and like i said, it's not always three, but that's just what i got. here are three frames. 456789 k and so on right now. we had this drive, so let's allocate some frames for os and let's create some processes."
"""OpSys_Memory_Fakeout_Transcript.txt""","hopefully becomes a little bit clearer, so let's take a look at this page replacement. ok, so let's drop picture. now that we can understand this idea of pages, frames and a disk drive, here is physical memory. here is our frames for operating system 012 and like i said, it's not always three, but that's just what i got. here are three frames. 456789 k and so on right now. we had this drive, so let's allocate some frames for os and let's create some processes. let's make process p0, is in red. we have p1 is in green and i'll do p2 is in blue. ok, we're gon na put page 01 and two for p. uh0 here. we're going put page 01 and there for that one and then page 0 will go in frame nine and actually let's not draw these dots. let's limit memory forgot. ok, great. that means 4. p0 it's page table. says that. 01. three, that that, that all the way up the end. see page 0 is in frame four. page 1 is in frame five, page 2 is in frame eight. page 3 is not present, so i'll indicate 0 for a valid bit. we'll put a valid bit one here, one here and one here and all the way down here. those are all zero. or process one. 0123 all the way up ann. see page 6. no page 0 is in frame six. page 7 is in frame, page one is in frame seven. it has a valid bit of one and one page 2 is not present in memory nor is page 3 all the way up page n and now let's draw the page table for process 2. and we have the end that's not in memory and only one only page we have in memory is page 0 is in frame nine with a valid bit 1/2 and three are not in memory. check with me there. ok. process he two runs and it needs access and address that maps page 1. thank as a result, process p2 is running an instruction, it tries issue a load percentage one or a store. the mu does what? it issues a page fault. why does n't issue a page fault? the mmu is using the translation. look aside, buffer the tlb has been prepopulated with the page table entries for process p2. and why are his?"
"""OpSys_Memory_Fakeout_Transcript.txt""","and we have the end that's not in memory and only one only page we have in memory is page 0 is in frame nine with a valid bit 1/2 and three are not in memory. check with me there. ok. process he two runs and it needs access and address that maps page 1. thank as a result, process p2 is running an instruction, it tries issue a load percentage one or a store. the mu does what? it issues a page fault. why does n't issue a page fault? the mmu is using the translation. look aside, buffer the tlb has been prepopulated with the page table entries for process p2. and why are his? what is the value of the valid bit for page 1? 00 means it's not present in memory, so it issues a page fault the cpu. cpu loads the operating system say operating system process p2. you know what the cpu does n't even know that this may be 1 does not know what process is actually getting. it just says that the current executing process had a page fault form page one and the operating system now is got ta figure what do with this. and so it's gon na pick a place put it. it's not gon na terminate p2. that will be not fair, but the operating system recognizes that is this wonderful disk drive over here and on this is the file system for all of our physical files. they'd like that, but there's also a carved out region in here for paging space. so inside here there's kind of like a a file or a directory, or just a chunk of this thing that's reserved for paging space. some operating systems refer this as swap space. and windows that refers it as the page file. on linux it usually uses swap space. why is it called swap? because we're gon na be doing is, we're gon na be taking pages out of memory and swapping them for pages that might be on disk somewhere. so we have a swap or swapping it around. ok. and here are the operating system is gon na do. it's gon na use one of the several algorithms that we will talk about, maybe not that we will get it today and figure out a victim page because we're not going terminate p2 and we know that ptu needs access page one. that is a requirement of accessing this instruction load or store and paid one. we need access that number so in order access memory it needs actually be in memory."
"""OpSys_Memory_Fakeout_Transcript.txt""","so we have a swap or swapping it around. ok. and here are the operating system is gon na do. it's gon na use one of the several algorithms that we will talk about, maybe not that we will get it today and figure out a victim page because we're not going terminate p2 and we know that ptu needs access page one. that is a requirement of accessing this instruction load or store and paid one. we need access that number so in order access memory it needs actually be in memory. but here's the cool thing about this. process is running? like actually executing on the cpu pedro is running. what is the state of p0 and p1 at this point? well, that's that's let's ask it in a negative way. what is not the state of p0 or p1? that's a bad way say that they're not running. it's not just. i'll give you the answer. i think i figured out a way answer that question. if he too is running on the cpu, he is 0 and he won or not. so they are either ready run or they're blocked on some io and some other state, or they're blocked on a mutex or some of our, but they're not actually running instructions on the cpu. alright, so because they're not actually running instructions on the cpu, they are not accessing memory right? it sounds weird like that. do n't you get on looking? but it's true, i'm getting there. i promise. when we look at this, it's here one and these zero are not actually running on the cpu and not actually accessing memory. pages do n't necessarily need be in any frame, right? because they're not running. so from one perspective, at least from the perspective of p2p2 does not know they exist and p2 does n't think you need be there for site, right? so what the operating system could do is they could pick one of these unused frames and say you know what, you're not being used right now because p2 is using them. so it just picks one get rid of, and there's different strategies for one pick. one of those strategies is first in first out say whichever was the 1st frame that was populated. that's the first one i'm going get rid of now. i'm not gon na get rid of it forever, right? think about that note rather example."
"""OpSys_Memory_Fakeout_Transcript.txt""","so what the operating system could do is they could pick one of these unused frames and say you know what, you're not being used right now because p2 is using them. so it just picks one get rid of, and there's different strategies for one pick. one of those strategies is first in first out say whichever was the 1st frame that was populated. that's the first one i'm going get rid of now. i'm not gon na get rid of it forever, right? think about that note rather example. i'm like bread, eggs, cereal, milk notes in my pocket, bread, eggs, cereal, milk notes in my pocket. right. we're not going get rid of stuff. we're gon na put it on a note. stick them in our pocket. during the swap space. so in this case the service, this page fault, the operating system has no free frame. it's gon na pick one. say it picks this guy. and it will say i'm gon na issue an io request take this page. send it over here and store it in the swap space. red zero, meaning it's the page for process zero, page 0. and by doing that. guess what? now i have a free frame and i can finish servicing my page fault and say ohh you needed this. i'm gon na now load the blue page one in here. i'm sorry, i did n't realize how much all out of focus this was. and when i do that now i can update this and set the valid bit for this be one what frame is page one and now. or. and now i could let process p2 continue now when they have a new attempts access the the the the page tables for process p2, it now sees that page one is in frame 4 and it can now access that memory. that is n't anything. ohh do n't luke. that's right, do n't answer. do n't ask. yes, no questions. what did i miss or what did the operating system miss when it was doing its updating? yeah. well, yeah, go ahead, right. yeah, i drew like this on purpose. not that i'm trying like this stuff. never put you back the audience, right? and you're like, this is not purpose. where all the page tables are like right next each other, right? or isolation and protection reasons. no2 processes should ever have pages loaded in the same frame."
"""OpSys_Memory_Fakeout_Transcript.txt""","yes, no questions. what did i miss or what did the operating system miss when it was doing its updating? yeah. well, yeah, go ahead, right. yeah, i drew like this on purpose. not that i'm trying like this stuff. never put you back the audience, right? and you're like, this is not purpose. where all the page tables are like right next each other, right? or isolation and protection reasons. no2 processes should ever have pages loaded in the same frame. i because now they're axes in the same page, the same frame for data. guess what? process p2 says ohh yeah, i got a page in frame 4. process p0 says oh yeah, i got a page in frame four. no, you do n't. we just got rid of you. for consistency sake, i got ta update this page table say this is no longer valid and you know i do n't necessarily even need erase the number because the mu is gon na look at that ballot bit and see zero. and say i ca n't trust that number, but just for the sake of example, we'll just get rid of that. ok, now we let p2go anytime. we days intel process p0 comes along and it says you know what i need access. uh. a memory address. you do a load the store. guess what? then you says. alright, that's gon na map the page zero. ok, what's gon na happen? the process p0 is running and it needs access page 0. we have other great falls, so now we have picked another victim because page 0 is not in memory, so the operating system's gon na pick up victim. if we truly are using a first come first, a first in first out algorithm, we have essentially figure out one was the next one that we brought in the memory. it might have been this one. it might have been this one might have been this one, but if we're just going straight down the line just for simplicity sake, we can just get rid of this one and you can say wait a second though, is n't that a page for process p0? do n't wanna not get rid of process p zeros pages. well, most likely yes, but we know that a process p0 is accessing page 0. it's not accessing page 1 right now, so we give it it. right."
"""OpSys_Memory_Fakeout_Transcript.txt""","it might have been this one might have been this one, but if we're just going straight down the line just for simplicity sake, we can just get rid of this one and you can say wait a second though, is n't that a page for process p0? do n't wanna not get rid of process p zeros pages. well, most likely yes, but we know that a process p0 is accessing page 0. it's not accessing page 1 right now, so we give it it. right. we're only executing 1 instruction at a time, and that one instruction it's only gon na ever access data on one page. so if we get rid of this one, maybe we'll have bring it right back into memory later on. but for now, it's like i'm hurting them. so let's just try that. we'll just say, you know what? i got ta bring zero in. so what i'm gon na do is take one right that one a disk. for here, now this guy is gone. i can bring 0 back in. and then i got ta update this guys page table. this thing is no longer valid and this one now is valid and it is now in frame 5. with me. page faults, so now we have yet another thing worry about. ok, we solved a couple of things. problems. i like this because now, so long as i have enough swap space, i can have essentially an unlimited amount of memory. that's not really unlimited amount of memory because my swap space is only so big, but this most likely is going be big enough store whenever processes need, when, when. if i have, i'm running out of memory. so like we use this slop stuff out this when needed, update the page tables takes a little while, but it's doable, right? we've got start with feasibility. it's got ta work. and they'll work. i'm making him more efficient but swapping, but i added a new problem. who am i gon na choose? am i gon na choose my victim? i do n't like the victims on this kind of me. that was the way i learned, right? how do i gon na choose page i'm gon na kick out of memory in order write this i just mentioned first and first out have nice right? like first come, first serve for for schedule really quick. is always efficient well. do n't know."
"""OpSys_Memory_Fakeout_Transcript.txt""","i'm making him more efficient but swapping, but i added a new problem. who am i gon na choose? am i gon na choose my victim? i do n't like the victims on this kind of me. that was the way i learned, right? how do i gon na choose page i'm gon na kick out of memory in order write this i just mentioned first and first out have nice right? like first come, first serve for for schedule really quick. is always efficient well. do n't know. so let's go back and review our notes here, and then we'll see where go next. so go back over here, ok? all right, find a free frame, alright? next thing is i got ta figure out here it says if there is no free, if there's a free frame, use it. we're always gon na use a free frame if there's one right we do n't wanna kick out another processes frame. page, we do n't have because chances are that process is going run later on and it's just gon na need bring up right back into memory. so do n't take it out unless we have. alright, if there is no free frame, we have these replaced page replacement policy or algorithm select the victim. then this point i forgot mentioned, i'll mention in now is when i go back and review my notes here it says write the victim frame this if dirty. dirty. what does it mean be dirty? not clean. yes, cleaned up if it's dirty. in this example, when i was kicking out pages and writing them disk, i was actually writing them this right. i brought back pay. i brought out page 0 the swap space and then they brought it back into memory later on, right when the process needed it right. would have this page was only used for reading, say contained instructions with all. we have a we need it read from it. i guess we do n't write it right? this is 4096 bytes worth of data, right? that's the page in break size, right? and i'm just using this for reading and later on another process runs and ultimately the come back around and we have decide that this page is the victim. who is only used for reading? sorry, you're saying that what is or brothers and think this is there a difference between this page and memory and this page in the slot space. if i only ever used it for me. i see handshakes. awesome."
"""OpSys_Memory_Fakeout_Transcript.txt""","this is 4096 bytes worth of data, right? that's the page in break size, right? and i'm just using this for reading and later on another process runs and ultimately the come back around and we have decide that this page is the victim. who is only used for reading? sorry, you're saying that what is or brothers and think this is there a difference between this page and memory and this page in the slot space. if i only ever used it for me. i see handshakes. awesome. the answer is no, there is no difference. so this is what i mean about dirty is that when i need describe where i say feasibility now efficiency. if this thing is only ever used for reading and it's identical for what's currently in our swap space, the operating system does n't need write that back the this drive, right? but think about let's talk about timing, right? how long a page 12 takes the handle a cpu is spinning all in terms of nanoseconds, right? gigahertz memory. i keep getting it's getting faster but it's not nearly that fast. ok. flash memory also quite fast, but i will tell probably again i should looked up these numbers not nearly as fast as memory. so if i can avoid having write things this, that's awesome. i could say a lot of the time, especially not do this a lot so. another bit in the page table up here right? that bit that i drew up there is called the valid bit or the present bit, or whether or not he just valid. and remember, there's another bit that the operating system visualizes and the cpu utilizes and m uses called the dirty bit. where it says any time i write data a page in memory, that page is dirty and that it does not match what's in the swap space. so if it ever needs be written or ever ever needs be replaced, we have make sure that we write it back disk and the mu is pretty cool. is that it handles all of that for us in marking page table entries. dirt. how does it know mark them dirty? how do we write memory? what do we do? yeah. well, you know wright, system calls actually writing back in storage like a file. in a in an architecture like this, we have a load store architecture, so it's a read from memory. we issue a load and write memory we issue a store. now i think i'm x86."
"""OpSys_Memory_Fakeout_Transcript.txt""","so if it ever needs be written or ever ever needs be replaced, we have make sure that we write it back disk and the mu is pretty cool. is that it handles all of that for us in marking page table entries. dirt. how does it know mark them dirty? how do we write memory? what do we do? yeah. well, you know wright, system calls actually writing back in storage like a file. in a in an architecture like this, we have a load store architecture, so it's a read from memory. we issue a load and write memory we issue a store. now i think i'm x86. it's actually a move instruction by we're moving things around, but there is a set number of instructions that we're gon na use write memory. the mu knows where those instructions are, and we'll immediately flip the dirty bit. any time in access as of right the store something. ok. questions. so the operating system does not always have the right pages back the swap space, only has write them if they're. ok. then we bring in the new frame, the new page into the frame. the newly freed frame we update the page tables page tables plural right? that was the the mistake. i made an initial part where i updated process p2's page table but not process p0 and we had two frames that 2 pages that were in the same frame was not possible. so page tables and then we continue. by restarting what we left on, so we may have left the two page transfers, we have write a dirty page back bring new one in two operations, but that's how we're going service the page fault. questions. yeah. or my all right. 10 minutes left. this is a picture from one of the books that talked about talks about victim pages. the last topic for today is the elephant and the stop talking about idiots. i have make good on a on a another one of my lies. it's not a lie is n't telling the full the full truth. and that's fork and i i even like. i could feel like shivers running up and down my spine when i send this because i knew it was n't telling the truth. now i'm gon na make it right. ok, so i'm sorry, but this is the right alright, copy on write. before we get there, let's talk about fork again. here's my parent address space."
"""OpSys_Memory_Fakeout_Transcript.txt""","i have make good on a on a another one of my lies. it's not a lie is n't telling the full the full truth. and that's fork and i i even like. i could feel like shivers running up and down my spine when i send this because i knew it was n't telling the truth. now i'm gon na make it right. ok, so i'm sorry, but this is the right alright, copy on write. before we get there, let's talk about fork again. here's my parent address space. i said, and i drew a picture of this. if a parent process issues a fork, we get a new child process that is a copy of the parent copy of parent. right. and i said this over and over and over and over again. right. the child processes the copy of a parent. parent does not share share anything with the child. child does not share anything with the parent unless we explicitly share memory with the shared memory segment. blah blah blah, right? right. well, wrong, sorry. the copy and address space. it's takes too much time, right? ok, so take my word part right. it's all this memory operations. the objects got ta get involved and do this. copying all this memory, i could have potentially whenever 16 gigs or whatever memory i got a copy from one parent another. i got ta do all the stuff i need copy pages that have been swapped out disk between parent, child and all this. it's a lot of work, so the operating system says is, you know what at the point of the fork, the parent and the child should be exact copies of each other, right? so here's i'm gon na do. i know that the parent now has a page table. right. and the child is a page table. so the operating system can say, you know what, if the data that's associated with this address space is identical between parent and child, they do n't understand you. i'm just gon na copy the page table. wait, what? i'll just make a brand new process, not actually copy memory, but just copy the page table. what are they? what is that gon na do when the child needs access something, say it goes later on, does n't read if it is exact same copy. so say for example we've got this and it says that 0123 and 40123 and four."
"""OpSys_Memory_Fakeout_Transcript.txt""","so the operating system can say, you know what, if the data that's associated with this address space is identical between parent and child, they do n't understand you. i'm just gon na copy the page table. wait, what? i'll just make a brand new process, not actually copy memory, but just copy the page table. what are they? what is that gon na do when the child needs access something, say it goes later on, does n't read if it is exact same copy. so say for example we've got this and it says that 0123 and 40123 and four. this says that maybe page 0 is in frame six, page one is in frame 10. this guy's gon na be in frame 5, three and two. this will have the exact same numbers. it's now about child wants do a read. what brand is it going read from? i read saying i read from page 0. or frame is going access six. who owns page 6 of frame 6? the parent? that's ok, cause they're supposed be copies of each other, right? so instead of actually being copies, though now brings is like. i do n't wanna waste memory, but we're just doing reads. they can just share the same pages and it's. in jail, one of them decides it's time do a right, right? because i said there's supposed be copies, so if a child does n't write. say here a child issues a. right page 3, right? alright, so we know this. if a child does a read from page 0, this is ok, right? we are going share the page, share the frame that says frank. if a child does a right, the page 3 three is in brain three, but this frame is owned by the parent. if the child is actually allowed update that brain, now the parents going see changes, right? and we're isolation and protection. we ca n't do that, period. the child should be isolated from each other, so this is what i mean by copy on write or column. is that the operating system now? can you realize another bit and say whether or not this frame is shared and it needs be copied on right? and get involved here say, ah, this child is sharing memory with the parents right now, but the child is a right and it's supposed give the appearance that they're not sharing."
"""OpSys_Memory_Fakeout_Transcript.txt""","and we're isolation and protection. we ca n't do that, period. the child should be isolated from each other, so this is what i mean by copy on write or column. is that the operating system now? can you realize another bit and say whether or not this frame is shared and it needs be copied on right? and get involved here say, ah, this child is sharing memory with the parents right now, but the child is a right and it's supposed give the appearance that they're not sharing. so what we're going do is as soon as the child issues that right, we need copy this page. so now when we issue a right page 3, we need copy. parents page 32 new frame. step one. we issue the copy. this means that now the child is not going access a page in frame three. we're going copy it a new frame. this might involve a page fault. we might have kick out a victim page, cause we got ta get this page into memory. we're gon na make a copy and put this in here. maybe now it gets put in frame 11. we'll update the page table. update child. page table and then. let the right. proceed. now we're allowed do this, right? because the child now has a copy of it, we're still sharing everything else, is nice because we're not wasting memory. we're only sharing this stuff now. well, if we're not sharing, but what we're giving the child rather the appearance that we're not sharing right. so they happy and wright, question how does the because it's the mmu that would be dealing with this? how does it know that? that specific page table is 1. bad is shared with. yeah, there's an actually right, because we have 12 bits. new question, right? and so i mentioned that we're gon na use the present bit. we have the dirty bit. well, actually there's a couple of bits that we can that will be used signify. essentially, when this page was brought into memory that we can use for page replacement algorithms and some of these other ones is a copy i'm write bit say whether or not this bit needs be copied whenever it's written the kind of issues in a way, kind of like a page fault at that point. so we can utilize. we have 12 bits, right? we are like, oh, what can we store 12 bits?"
"""OpSys_Memory_Fakeout_Transcript.txt""","well, actually there's a couple of bits that we can that will be used signify. essentially, when this page was brought into memory that we can use for page replacement algorithms and some of these other ones is a copy i'm write bit say whether or not this bit needs be copied whenever it's written the kind of issues in a way, kind of like a page fault at that point. so we can utilize. we have 12 bits, right? we are like, oh, what can we store 12 bits? we can store fair amount of information. 12 bits? yeah. the question other questions i got one more example here and they'll be done so we know we have copy when the child writes. but here's the other the other kicker apparent does n't write over here. the parents going do a right. page uh-4. if we were just issue that right, the page 4, that's gon na update frame two. guess what? the child is currently sharing frame two with the parent. you ca n't do that. we have make the parent the child appear like it's a copy of the parent. so anytime the parent does a right, we also have. copy the parent page. the child, we also have update the child page table. and then continue. so in this case, this page needs get copied, not gon na be copied and update. we're not gon na update the page table in the parent. we'll update the child cause it's not actually running, cause the parents running. what? copy this. we'll update it some other number like frame 4. one thing we can also do is. we could just issue a copy and then not put that frame any. put that page in a - frame because a child is not currently running. if the child needed execute or access that that page later on, really it brought in via page fault, we could just invalidate the page. do you? i'm coming from there. yeah. question. yep. right. so we could make a copy of this and immediately connect the copy into the swap sticks and not actually put it in, because on the child that they did n't act as that, it will bring it in. i think a lot of talk. sorry. so i'm one minute over, so thanks for coming. that is copy on write. we'll continue with this next time. thank you. lembke, james stopped transcription"
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","meeting in _ general_-20240408_130132 - meeting recording april 8, 2024, 6:01pm 48 m 27s lembke, james 0:08 hello. hello. great. alright, so we got the recording going. that's great. so what's going on? this week we're in the middle of memory management, so last week we did process scheduling, was a pretty cool topic in that it really was n't all that long and it was just kind of added on the stuff we already talked about with processes. and so with that, we did a bunch of stuff with the arithmetic and the math for how compute the different statistics for processes. that kind of stuff, the different scheduling algorithms, some of them are abstract and hypothetical and that we do n't really know exactly how much cpu would process needs. all that kind of stuff. so that is going be subject for the quiz on friday. so that's why announcement that there will be a quiz on friday, so be ready for that. we have process scheduling, so the stuff we covered in class last week, so that's that two process simulator i'd mentioned and talked about that on friday. so that's out there, flagger had was due on friday, so hopefully that went. yeah, i'm gon na. be kind me on the course evaluations. do n't say ohh good class flag our head right if you want though. be truthful though, right? be 100 % truthful. you guys do n't like flagger head. let me know because i will. i will. i will do my darndest. maybe try and things weekly now that what actually gets match, but it had no. here's the thing though. it's not gon na match exactly because threads are nondeterministic, right? right. so you're not always going get the exact output that i get now. i was thinking in the process schedule, probably the process simulator is is deterministic, right? because it's the screen events, so that should be. you should be able duplicate the output for that one, but for the threads it's like you have no exact control over when those threads are gon na run. so if cartoon goes through the thing before car one, it's just the way they arrived. and so we have that. that's that's the the way the threads lie. but what the big thing is, it should be coherent in that if the flagger is indicating that it's safe drive from left right, you should n't have someone coming in from right left."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","you should be able duplicate the output for that one, but for the threads it's like you have no exact control over when those threads are gon na run. so if cartoon goes through the thing before car one, it's just the way they arrived. and so we have that. that's that's the the way the threads lie. but what the big thing is, it should be coherent in that if the flagger is indicating that it's safe drive from left right, you should n't have someone coming in from right left. that's not safe, but ok, that's that flag. are we got the process simulator out there? we're talking about memory management. i got the notes out here and what i wanna do is just review a little bit about memory management because it's been a weekend and then go on deeper into memory management and talk about why it's so cool. well, we're gon na keep talking about that. so where were we? were talking about memory management in memory allocation in that we have a sort of a situation where we need allocate memory multiple processes, right? because we're doing the operating system created this idea of a process. each process has an address space that needs be contiguous from start finish. it's gon na have text, data, heap and stack, and we got ta find a place put it. and so we talked about two sort of mechanisms for that. one was fixed partitions where the operating system just says alright. we got all this memory. i've got all these processes that wanna use this memory. i'm just going divide up memory into blocks. i want process comes along. i'm just gon na give it a block. ok. and those block sizes should be equal size or unequal size, but still they're fixed, right? the block that's here is always going be 12 meg. we're never gon na make it dynamic or change it. and in short, one is pretty cool about this. is that the math is pretty easy under the assumption that we actually make our blocks if a multiple of the amount of memory or the visible evenly divisible size of the amount of memory. so since our memory is typically in units of gigabytes, we should make it. we divide it out, whether that's like extra like i creating something that's like 3 meg is n't really gon na come out right in terms of math. so we should just make it come out right in terms of math."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","and in short, one is pretty cool about this. is that the math is pretty easy under the assumption that we actually make our blocks if a multiple of the amount of memory or the visible evenly divisible size of the amount of memory. so since our memory is typically in units of gigabytes, we should make it. we divide it out, whether that's like extra like i creating something that's like 3 meg is n't really gon na come out right in terms of math. so we should just make it come out right in terms of math. and so that's the first thing. all of that's pretty easy. we could use a bit map determine ones are free and ones are allocated a process. inside the process control block, for each process we just tell it what block it's using, so it needs reference memory it knows how start and it can just go ahead and run. we entered a couple of problems with this was well, if a process does n't need this much memory like 8 nights or just example, well wasting space and that's internal fragmentation. this is important these words because it's big, internal fragmentation is wasted space inside of a process allocation, right? this is allocating more space than it needs. internal. we could do something like this where we have unequal size blocks, but still we still have choose. we have save process, we're going put you in one of these and it might, you know, mostly always get it exactly right. chances are pretty low, but still gon na have some sort of internal fragmentation. the other problem was the other end of the picture was. if we get it exactly right, that's awesome. if we did it where the process does n't need as much with internal fragmentation, and if we get it where the process needs more memory than what's needed, well, we're stocks because we have no place put it. ok, then that led alright. it fixed sizes, has good and bad. then the let's look at dynamic sizes, where instead of just dividing up all of memory into just locks, we'll just divide memory up, where as we need it, and so we start out with all of memory free and as we need allocate space process, we just put it where it needs go, where as much memory as it needs. and that's great. antil, of course a process terminates and we end up with holes in memory. it's not that great. so now we have additional management."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","then the let's look at dynamic sizes, where instead of just dividing up all of memory into just locks, we'll just divide memory up, where as we need it, and so we start out with all of memory free and as we need allocate space process, we just put it where it needs go, where as much memory as it needs. and that's great. antil, of course a process terminates and we end up with holes in memory. it's not that great. so now we have additional management. we ca n't just use a bit map determine of all of the freeholds, because we have a dynamically dynamic number of holes we have no way of knowing how many we have, and the other thing is the whole here. i've always this is gon na be nothing. that not it's not only the fact that they're not gon na be the same size, but they change as the as the processes come and go and the more processes that we have coming and going, we see that the number of polls we have gets bigger. that's great because we end up with this situation where we have public free memory and the bottom right here at all this on its memory is free. if you could read that the slide is n't the unclear as far as it's still fuzzy. we have six bag plus six 9 + 4 bag, right? what does that have? a 60 minute right and if i want run a process that requires 10 meg worth of memory conceptually in terms of the amount of free memory i have. i should be able find a place put that right because i have 16 freed 16 -, 10, six. it's greater than zero, but can i run that process? no, because there's no place for it pay. this is called external fragmentation. it is racing memory or calls gaps in memory outside of a process's allocation, right? so from there we talked about four different mechanisms we talked about. first set next set, best set and worst fit for finding where a process will fit in memory. that's why it's called fit. you're trying play the place for this process, the bit and these different allocation algorithms or scenes process of whatever you want. point has attempts organize umm memory too. they get so that we can always have a place put a process, but because of external fragmentation and the behavior of processes coming and going, that is not always going be the case."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","so from there we talked about four different mechanisms we talked about. first set next set, best set and worst fit for finding where a process will fit in memory. that's why it's called fit. you're trying play the place for this process, the bit and these different allocation algorithms or scenes process of whatever you want. point has attempts organize umm memory too. they get so that we can always have a place put a process, but because of external fragmentation and the behavior of processes coming and going, that is not always going be the case. but alas, first that says it's nice and easy. we start at the beginning of memory, find a whole for the buses, put it there, allocated next. bit says we're gon na essentially do first fits what we go through all the holes in order, but we keep track of where we allocated the last process and we just continue where we left off. and then there is, we will visit all of the holes, sort of an equal number of times versus first fit. we always visit the first first poll a lot like that. the first one amendment best fits as look at all of the holes by the one that creates the fewest amount of of the smallest fragment, right? so in this so the case where we have three different sizes here 29, six -, 4 meg. if we have a four meg process first, it says what it here. best fit says put it at the end and that's the idea there is keep the fragments as big as possible so that if a big process comes around later on, we'll place put it and then worst fit is the other way around where we would n't be in the biggest one and worse fits goal is try and keep all the gaps about the same size. right. and i do n't motivated that. really there is like no magic bullet. there is no perfect algorithm here. there is so we could always sum up with an example in one of these does n't do well when it comes a process set of processes of arrival with memory allocation. all right, so i added this. i will post this in the slides. i added this sort of summary slide here as a review that in vix allocation, whether they be equal or unequal sized partitions, it's cool because it's easy manage as far as how quickly we can, we can allocate a new memory block, right? we find the first free bit now."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","there is so we could always sum up with an example in one of these does n't do well when it comes a process set of processes of arrival with memory allocation. all right, so i added this. i will post this in the slides. i added this sort of summary slide here as a review that in vix allocation, whether they be equal or unequal sized partitions, it's cool because it's easy manage as far as how quickly we can, we can allocate a new memory block, right? we find the first free bit now. ultimately, if would say, well, that's still order n, but as far as like freeing processes allocation, umm it's not that hard. we just take the block that that process was using, flip the bit, maybe zero it out so that the future process that use that do n't get old data, but it's pretty quick free a process of allocation. the bad internal fragmentation. if a process is through small and just the inability allocate a process, if the process needs too much right, then anemic good is that it's very volume in terms of the allocation we can so long as a process does n't need more than the amount of memory that we actually have, right? ca n't do a whole lot about that, right? if i've got 16 gigs of memory and the os needs a certain amount and a process comes by and says dude, i need 32 gigs. i i do n't know. i do n't know. we're done, right? it's like physics, right? i ca n't make something right. i go the store. i wanna buy something and i do n't have enough money buy it. i ca n't buy it. it's not like i got ta go target billing. i you ca n't make a memory loan, it does n't work that way and you situation, right? so all right, that's the good. the bad is external fragmentation. please holes and i did n't really talk about this, but the management we talked about management of finding a free place put it right. but the management of what happens when a process frees itself or no longer is no longer needed requires a couple of steps. if we go back this picture. difficult implementations of this use essentially a linked list of files, because we have an undetermined number of holes that we might have manage as time goes on."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","so all right, that's the good. the bad is external fragmentation. please holes and i did n't really talk about this, but the management we talked about management of finding a free place put it right. but the management of what happens when a process frees itself or no longer is no longer needed requires a couple of steps. if we go back this picture. difficult implementations of this use essentially a linked list of files, because we have an undetermined number of holes that we might have manage as time goes on. so on the operating systems, often will do is they'll just create a linked list of entries and every single time that there's a new hole in and the entry into the linked list and records the starting and ending address of the whole. so then later on when it needs allocate a process, it just spins through that linked list, whether it's using whichever the 5th algorithm is, and then finds the hole, and then wherever that puts it inside the linked list entry for the whole, it just reduces that holes size right? and it's starting and ending address and they just extracted it. the funny thing about this is when process let's do this example when when process one ends we have a new home, right? but we just need make a new entry go in place. when process four ends, it's adjacent a whole that's already there, so we ca n't just say we're just gon na make a new hole, because now we have two empty holes next each other. now you could say, well, that's not really a problem because we could just spin through it. but in terms of efficiency is concerned, i'd like keep the entries in the linked list as you as possible, because the more holes i have, the longer it's gon na take for me search through that list, right? yes, that go right. yes, right. ok so whenever i need free something i have look and see if it's adjacent an existing whole and not just add a new entry for it, but expand an existing home. ok. that's fine. great. that's a process for terminates in this step, but a process for terminates at. set gene here on this vector. now it's jason, the tools. so not only do i have increase this, add this this whole, but i ca n't."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","yes, that go right. yes, right. ok so whenever i need free something i have look and see if it's adjacent an existing whole and not just add a new entry for it, but expand an existing home. ok. that's fine. great. that's a process for terminates in this step, but a process for terminates at. set gene here on this vector. now it's jason, the tools. so not only do i have increase this, add this this whole, but i ca n't. i have merge existing walls together and every every so that this is called coalescent and we have take these holes and coalesce them and make one large bowl for all of them questions. ok. so that makes management a little bit more tricky because with the fixed ones i did n't have do that. i just storm into bitmap and just flip the bit. i do n't have coalesce anything. all right. so that's what i mean about management requires freeing and coalescing memory when processes end. ok. i guess you could probably say coalescing. free memory. right. all right, so. let's throw another set of problems in here, and we'll just let me just throw everything in the situation and then talk about how we're gon na fix it, because i keep beating around the bush here. so let's just throw a couple of other things in here. let's bring back these iterations from before, right? i kept saying this. i ca n't loan memory because processes. if you need 32 gigs and i do n't have it, sorry, you ca n't run. i wanna fix that. i wanna be able run processes that are bigger than the size of memory. right, memory is finite. ok. we'll talk about that. i'd like be able do this. i also would like allocate multiple programs and when i run them having said. yeah, i mentioned the idea of moving things around that processes should n't be moved. why not? i wanna be able move around. why ca n't they be moved around now? why? while when i propose that limitation. was that? say it again. there's a lot of his right. the point is pointing up. yeah. yeah, when i wanna allocate or not allocate what i wanna access memory. i want be a pointer like i wanna be. i wanna be able take like the address of a number, right? the address of the variable or dereference of pointer, right?"
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","why not? i wanna be able move around. why ca n't they be moved around now? why? while when i propose that limitation. was that? say it again. there's a lot of his right. the point is pointing up. yeah. yeah, when i wanna allocate or not allocate what i wanna access memory. i want be a pointer like i wanna be. i wanna be able take like the address of a number, right? the address of the variable or dereference of pointer, right? and if i have that. this process and face is in memory somewhere. if i have the text instruction here that wants take the address of a variable that is allocated on the stack, i'm gon na get some number back. if this memory block moved around, the address of is stored in a variable somewhere, and at this whole thing moved. now that number is long, right? because this location on the stack is now in a different address, so i wanna be able handle this idea of program relocation. maybe not necessarily in real time, but the idea that when a program runs, i might have multiple processes that are all created from the same program, right? and they're all going be in a different place in memory. that's really weird because if i've got a program that's accessing a variable and it's had multiple copies of it in memory, even if they just parent and child, when we do a fourth. apparently the 4a4 you'd say. well, no. the parent, the child wo n't share anything, but we're kind of. do you remember it? so it's up you. think about this right. life in store a variable inapparent process. that's the address of some variable on the stack. then i can form and the child process gets a copy of the parents memory. that pointer in the child is still valid. how does that work? right. if i have a parent process address space in memory, there's memory. and i have a variable i i is in memory and just for intents and purposes, let's say it's at the value 1000. ok, the parent process says i'm gon na take umm int star jqs the address of i. so the value of jj is gon na get the value of 1000, right? that's the address of i. if i do a fork. that's going copy this a child process."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","right. if i have a parent process address space in memory, there's memory. and i have a variable i i is in memory and just for intents and purposes, let's say it's at the value 1000. ok, the parent process says i'm gon na take umm int star jqs the address of i. so the value of jj is gon na get the value of 1000, right? that's the address of i. if i do a fork. that's going copy this a child process. the child gets a copy of eyes value, but it also gets a copy of jaye value. jay is the value 1000. but the child process still works in our system. how is that possible? parent and child ca n't share memory. this address should be in the parent's address space, not the child's, right? how do we do that? i wanna be able fix this. and a process should be allowed allocate and free memory over the course of its life. they say life because it's life is kind of weird system like that itself. i want be able support all these things, right? so. let's sidestep this for a second. trying figure where go next, ok. yeah, let's just sidestep here and i'll look at this. ok, so let's. look at something in the real world. ok, now this is not really the real world, but this is the best way i can draw it and so let's go the grocery store. i went the grocery store today. whether you live on campus or off campus, whether or whatever, probably you've been the grocery store before, right? right. and when you go the grocery store, you have a certain number of things typically that you wanna buy, right? maybe it's one, maybe it's two. maybe it's 20. it does not really. you've got a mother. be even be a grocery store or any other store, but there's a certain number of things that you wanna buy. so here is my picture of this. ok, i have four things that i wanna remember. orange, blue, pink and green. ok, if i have memory my own brain, that's good enough that i can remember 4 things in my active memory, right? this works right, i would say. well, i can remember orange blue here. i ca n't orange blue paint and grape or things right. happy days."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","be even be a grocery store or any other store, but there's a certain number of things that you wanna buy. so here is my picture of this. ok, i have four things that i wanna remember. orange, blue, pink and green. ok, if i have memory my own brain, that's good enough that i can remember 4 things in my active memory, right? this works right, i would say. well, i can remember orange blue here. i ca n't orange blue paint and grape or things right. happy days. all right, but my world is not perfect. often i will say i'm gon na go the grocery store. i need milk, eggs, bread and cereal, milk, eggs, bread, bread and cereal. right. i'm walking out the door and at least four things. no, they're breaking the page breaks it. like it might have, right? remembering those four things and as i'm leaving go the store, my wife said says, oh, by the way, can you get spinach too? i wanna make a salad and i said ok, what was that fifth thing? and then i get home and i never. i did n't. i go the store and i did n't buy my spinach because i could not remember that whatever happened happened. anybody. ok. even if that maybe you can see where i'm coming. ok, this is not great, right? so what can i do? this is gon na be 90, but just just bear with me. there will be a point. things. what can i do so that i do n't forget spinach? what is that added a list? ok, the school right. i've got now got it right here, right. i've got paper right? so what i can do is instead of saying, well, i'm sorry, say my wife. i'm sorry, i can only remember 4 things. i can only buy four things at the store. you know it's not gon na fit. i'm not gon na be able buy it. what should i not buy of the four things? she says no. buy all five? well, i ca n't remember them all. five, she says. fine. write them down on the list and so what i can do is even if i can only remember 4 things, i can do this. i could figure out why these are out of order. one second here."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","i can only buy four things at the store. you know it's not gon na fit. i'm not gon na be able buy it. what should i not buy of the four things? she says no. buy all five? well, i ca n't remember them all. five, she says. fine. write them down on the list and so what i can do is even if i can only remember 4 things, i can do this. i could figure out why these are out of order. one second here. i got ta figure out why these are not in the right order. or i'm missing something? here, that is. oh, no, wait, that's the right. i just skipped 2 slides. sorry my bad, i do this. i could say i could only remember 4 things. but one of those four things that i can remember is where i put my list, right? so now i can actively remember blue ink, 3 eggs, milk, cereal, and the note that contains the other things that i want buy. and all my note i could say, well, i got ta remember these three things. red milk cereal and worried for my notes. so all i know i put eggs in spanish. right now, you might say, well you write all five on the note, but the way you can remember 4 things is that only really for the answer you need write down the stuff that i do n't that i ca n't remember and just keep track of where i put my note. ohh, it's in my pocket, right? so that when i'm at the grocery store, i can walk through the grocery store, pick out. bill uh, bread and cereal put them in my cart and once there in my cart, i do n't need remember them cause they're in my cart and then i could pull up the note from my note from my pocket and be like ohh i still need buy spinach and eggs and then i go around and get those. all the two things it's gon na try contrived and made up, but it works, right? i know. i drew this like this because this is essentially what is referred as paging. we're talking about paging max, right? and it's a way that the our operating system will be able emulate this idea of storing more things than as possible in memory, as well as taking advantage of some of the good points of of the previous memory allocation. right. i really and i"
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","bill uh, bread and cereal put them in my cart and once there in my cart, i do n't need remember them cause they're in my cart and then i could pull up the note from my note from my pocket and be like ohh i still need buy spinach and eggs and then i go around and get those. all the two things it's gon na try contrived and made up, but it works, right? i know. i drew this like this because this is essentially what is referred as paging. we're talking about paging max, right? and it's a way that the our operating system will be able emulate this idea of storing more things than as possible in memory, as well as taking advantage of some of the good points of of the previous memory allocation. right. i really and i and i say this, and i will say it again when it comes a fixed allocation in the world of operating systems, as far as like bookkeeping is concerned using a bit mask like this is like awesome because you could look up a bit really, really quickly, especially with hardware and storing things like this just makes a whole lot of it's really easy. the problem that we have with this is with these fixed allocation sizes. when a process needs a lot of memory, we kind of have say, well, you really need multiple of these, but i ca n't give you multiple of them because they all be in order. end of our run out of them. i ca n't run you at all, and so the idea here is if i could take advantage of these fixed allocations, but also have this idea of a note for where things are. i did n't have a process run and i could say, you know what you need uh-24 banks, right? that's three pieces. that's three of these chunks. ok, what i can do is have a note inside the operating systems that says process that needs 24 bags. one is going get 1/3 and five and the operating system, they can keep. the bookkeeping can keep track of all these sort of chunks that the process is using, and when it needs make a memory reference, the operating system can use that book that notebook figure out. wait, what is the process mean? does n't mean spinach or eggs, and they can give it the proper block based on what it means. questions. ok. so this is that idea of the note. and now if i need access something directly like i wanna access green. great."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","one is going get 1/3 and five and the operating system, they can keep. the bookkeeping can keep track of all these sort of chunks that the process is using, and when it needs make a memory reference, the operating system can use that book that notebook figure out. wait, what is the process mean? does n't mean spinach or eggs, and they can give it the proper block based on what it means. questions. ok. so this is that idea of the note. and now if i need access something directly like i wanna access green. great. i can do that, but if i ca n't access something because it's not in my active memory, so what else i need buy? spinach thing. waiting buy spanish? i do n't know. i need access this. i can say, oh, i can look at my node and say, ah, where is spinach? spinach is on this note here that refers it. here i can only remember it if it's in my active memory. so what i kind of have do is consult my note. swap out. would you imagine if i had do this? but this is the way the computer actually has do this. i could go my note and say, you know what i was originally thinking about. green, might be eggs. ok, i'm gon na put green on my note and say uh so i can write it down and then i'm going actively remember eggs. so now spinach is ready on my on my note. what eggs is actively in my brain? we're going. yeah, and this is called swapping. but later on when i want access another one, i got ta. i got ta swap it around. ok. so in terms of memory blocks, this is essentially paging and swapping where the our operating system is going be managing all of these different pages. brooks, all blocks, pages, whatever and it is going use a note record where they're at. are they actively being thought of? are they actively in memory or are they somewhere else? questions. all right, so how do we do this? this gets back this relocation right in this world. now we're memory can move around. ok. that's essentially what i invented, a notebook and a place where we can keep where we can move memory around as well as allocate blocks a process where the blocks are not all continuous. why am i doing that?"
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","and it is going use a note record where they're at. are they actively being thought of? are they actively in memory or are they somewhere else? questions. all right, so how do we do this? this gets back this relocation right in this world. now we're memory can move around. ok. that's essentially what i invented, a notebook and a place where we can keep where we can move memory around as well as allocate blocks a process where the blocks are not all continuous. why am i doing that? because now i have this note and operating system can record where all these blocks are, right? that's one of the advantages that we did n't have before. but this is the problem right over the course of this idea here that i just showed you. we have blocks that are moving around in memory going back and forth. ok, so in the 1st place green was down there in # 3 and green got swapped out and written my note and yellow got put in greens spot. later on i wanna access green and my operating system said i'm going put green in blues spot and then put blue on the note. green just moved around, did n't it was originally in breed. now it's in love. question. yeah. so if you have swap two elements meeting already have those like. well, this case i would agree. wanna switch? have already know where your address is blue on the spot. those few things going right, so would n't you would n't swap them an extra step because you already know the address of where you do it is. right. and so i agree with you in order make this truly generic and be able put any color anywhere we have, we have keep track the operating systems gon na need keep those numbers. where have we been and where? where? where where it is currently, where it's in memory and where it is when it's not. something that we'll get translate translate platform, there is something be concerned about other questions, ok. so i mentioned that that blocks are going move around, but i do n't want disallow this for more thing. what is this? right? i've got a for loop and we have a number and green and if i wanna access the address of green 10 times throughout the course of this process's life, this green location right? this variable that's storing green michael durant, right. and in that case, though."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","something that we'll get translate translate platform, there is something be concerned about other questions, ok. so i mentioned that that blocks are going move around, but i do n't want disallow this for more thing. what is this? right? i've got a for loop and we have a number and green and if i wanna access the address of green 10 times throughout the course of this process's life, this green location right? this variable that's storing green michael durant, right. and in that case, though. but because of what ryan said earlier, the process should never see me and a very big moment we should never see memory locations moving right? not only for this reason, but also for this reason. when a parent makes a copy of itself via fork a child, the address of a variable should not change, right? so. under the assumption that for forked. we'll see that parent and child, even though they're two different processes at this point after the fork, right? we get the same number. we know that the parent and the child are different places than physical memory. we just went through this. how is this possible? and it's in a way, right. i talked about file descriptor fake out and file descriptor redirect like a file descriptor redirection. the operating system in it's like big grand scheme of isolation and protection fakes out every single process in the system and says, yeah, you're running in that memory space, right? what it does is it actually creates an indirect level of memory addresses called virtual addresses. and here's how it works. the paging system physical memory. we want the operating system have full control over it. is the operating system. it gets access everything because it's managing processes, right? that's one of its jobs. ok. it's also the scheduling them and doing a whole bunch of other stuff with io and file descriptors, but processes process management is a big thing. so on the operating system is going do, is i'm gon na say, all processes. i'm gon na give you the appearance that you get all of memory. so this picture up here that i drew where i kind of like lied you and i said. yeah, i'll process does n't really have address space zero infinity. but the operating system is going do is it's going tell every single process that you have, you are allowed access every address from zero all once."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","it's also the scheduling them and doing a whole bunch of other stuff with io and file descriptors, but processes process management is a big thing. so on the operating system is going do, is i'm gon na say, all processes. i'm gon na give you the appearance that you get all of memory. so this picture up here that i drew where i kind of like lied you and i said. yeah, i'll process does n't really have address space zero infinity. but the operating system is going do is it's going tell every single process that you have, you are allowed access every address from zero all once. ok, every single address in memory, but those are gon na be physical addresses. those are gon na be called virtual addresses. every process can have an identical amount of code, identical address space they fixed is, but the operating system is gon na put it in a different place in physical memory. i know when a when a process wants access a a place and it's address space, the operating system is gon na do what's called virtual physical address translation and change what the process thinks it's accessing into what it actually is accessing. questions. yeah, you know, why does it do that? for isolation and protection, because now any process can access an address and always think that it's its own and it will never conflict with another process. we can put processes anywhere we want in memory because they all think they're running in the same address space, and we can move processes around and they do n't know the difference. ok, so let's go on. let's move on here and talk this about this a little bit more. alright so. virtual address physical address. the virtual address is the location that the process thinks it's accessing. how does it do that? it does a load instruction. i wanna access this address ok whenever it does a load that is not the correct address, right? because. over here, we know that address 1000 might be correct in the parent, but in this case i down here is not at address 1000. it is not there. but this child process thinks that it's accessing 1001. is it actually accessing well someplace else? the operating system when it creates the copy of the parent and the child address space, will record the address space of where the new trial is using."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","i wanna access this address ok whenever it does a load that is not the correct address, right? because. over here, we know that address 1000 might be correct in the parent, but in this case i down here is not at address 1000. it is not there. but this child process thinks that it's accessing 1001. is it actually accessing well someplace else? the operating system when it creates the copy of the parent and the child address space, will record the address space of where the new trial is using. so when the trial does i wanna access 1 bells and the operating system says ok, where are you actually in the mic? let's figure out what that actual address is. physically, we'll send that the memory location get back the actual number of what is stored in the what i view reference that address. yes, the whipping i got thumbs up my head shape. now i got a couple people that are going like this. yeah. ok, we'll do an example and then we'll get there. so how do we do this? what we're going do is this. we'll take memory, ok. the os is going get a piece of memory. ok, this distance here the size is however much the os needs. the os need ok, so i'll write up here. the os has access all memory ok. then what? the os is going do is divide up the rest of memory into fixed size blocks. remember how i like fixed size blocks because they're easy manage as far as like ones were free and ones were used? i still wanna do that, so i'm going divide up all the memory into fixed size blocks. how big do i make it? the os gets pay ok? typically a typical system this number is. 4 kilobytes 4096 bytes. a lot of operating systems now will support larger ones, but that's typically the standard is do it as 4096 bytes. why make them that size? well, it's small enough because the minimum allocation that i'm gon na allocate a process is a block, and if i make these too big and wasting space, right? so wanna make them small enough for that? so i do n't waste space, but i also wanna make a big enough be relevant right? making one that's like 8 bytes, not a whole lot. i'm going store and eight bytes. i can store a bear mountain 4000 kilobytes. umm."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","why make them that size? well, it's small enough because the minimum allocation that i'm gon na allocate a process is a block, and if i make these too big and wasting space, right? so wanna make them small enough for that? so i do n't waste space, but i also wanna make a big enough be relevant right? making one that's like 8 bytes, not a whole lot. i'm going store and eight bytes. i can store a bear mountain 4000 kilobytes. umm. now, if it's a huge image or a video file, ok, maybe not, but and so there is current trends make these bigger, like 16 meg, there's a lot of processes now, just use a lot more memory. but if we make them too big, we become wasteful. so anyway, that's that. alright, so we've got a fixed size block. now what we're going do is allocate a process. so we've got text, we've got data, we've got heap, we got stack. here's my process and it's going have zero through. all apps in hex or all ones in binary for its maximum memory address ok. and then what? the operating system is going do is it's going say you are how big you're this big, you need a bunch of blocks. so i'm gon na divide you up into. 4096 byte pieces. ok, let me so far, right. and then it's gon na say i i will. you give you a number. there's block 0. here's block one here's block 2. here's block 3 right for that process. it has it. it's four blocks based on its size. ok, right. and then it's gon na say alright. i am going since i've got 4096 block spaces, 4096 block chunks, i'm going put. say i'll put zero here. i can put two here. i can put one here and i can put three there. do n't make a difference. right distribute the blocks into physical memory. and then these other ones are on output, right? i would n't be going now. the next step is i have a process that wants do a load. it wants do a load from something it's data section. ok, in order do a load. a load if i can actually spell load properly, i'm going load at."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","i can put two here. i can put one here and i can put three there. do n't make a difference. right distribute the blocks into physical memory. and then these other ones are on output, right? i would n't be going now. the next step is i have a process that wants do a load. it wants do a load from something it's data section. ok, in order do a load. a load if i can actually spell load properly, i'm going load at. i'm gon na load at address 1000, say for example, and that 1000 corresponds this spot right there in its address and it's address space, right? where is that chunk. ohh sorry. we give each block a number so the processes address space has numbers representing the chunk that the block that it's that it's divided into those blocks are gon na be loaded into memory. because what's cool about this is memory is broken up into sizes of 4096 bytes, and so i have so many flocks. if i keep my number incorrectly, this will always come out be an even block. i do n't wanna be like leftover blocks, so i might say, ok, the os you're gon na get along much memory you need. and so long as it's divisible by 4096, this will how we start on an even multiple that you came with that, that algebra there. ok, right. so let me ask that question. as if i've been that low, that 1001 thousand in this address space from zero all ones represents this location in. here it is in block of the process flat. block is it in? what? what one right. it's between these two blue lines, right? where is block one in memory green # 44k. so what i really need this excess is someplace in block 4 when i load from this. i really need load from somewhere down here. right. how do i know where that is? well, i need know 4. here's the other thing. ok. this you look at this would be like i think it's what you know mine belong, but it's true. it's it is what it is and you guys do n't look at me like doctor lundy. of course, that's the way it is. have you ever drawn a picture or not with this? but yeah, let me let me go the next piece. if one is in block form. this is here."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","well, i need know 4. here's the other thing. ok. this you look at this would be like i think it's what you know mine belong, but it's true. it's it is what it is and you guys do n't look at me like doctor lundy. of course, that's the way it is. have you ever drawn a picture or not with this? but yeah, let me let me go the next piece. if one is in block form. this is here. the offset from the beginning of blah of block one the place i wanna load is the exact same offset. from there, right? so alright. so let me go. you know what this offset is? i did n't compute what where in physical memory i need actually load by just taking the size of the blocks times the number. once the os states right? i have the offset and load from there. right. yeah, question does n't know how does it know between numbers. let me ask you this question then what is it? alice dos know the green numbers well, who's in charge of all physical memory? remember, i've in that previous example that i did with the slides. it might have been kind of contrived and made up. i had this like note of knowing where things are. the operating system has essentially can one big note for every single process, is where in the green numbers all the blue numbers are. ok. so question, yeah, i guess when it's not following like if there's multiple processes. like it's. no, no. ask can we? we're, we're we. we got time because i guess that kind of answered because i get different process. it would also have 1000 in the space for that singular piece of data, so there's another process, i guess. what i'm wondering is like the opposite of that process and the offset in other process can be exacts. yeah, exactly right. exactly right. i love this right the offset in that. in fact, in a fork situation, right. so let's just go fork where this becomes copy this address space here. this offset and the location of 1000 in a child process is going be identical another process. apparent right. well, guess what? the child is a copy of the parent, right? so it has a copy of all of these blue numbers, right? but it's a new process and a new process gets its own."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","exactly right. i love this right the offset in that. in fact, in a fork situation, right. so let's just go fork where this becomes copy this address space here. this offset and the location of 1000 in a child process is going be identical another process. apparent right. well, guess what? the child is a copy of the parent, right? so it has a copy of all of these blue numbers, right? but it's a new process and a new process gets its own. note that the operating system is keeping track of. so what the operating system is going take the parents process miss blue numbers and when them in memory, but it's also going be the same for the childs. so the child is going have a1a012 and three, but because it's a separate process, it's gon na go on a different number, a different location in the green numbers. so he wants one. is it 4? but the other process the child process is 1 might be m3. so while the offset into one is the same, the location of where that physically is in memory is different in a different process. that i confuse you? or did i make it clear? i think that makes sense. so it was only gon na be like one combination of like reading numbers offset, right? each blue is only gon na go in one green and so on. only on green can have one blue. i i ca n't put 2 blues in this. i do n't be like copying memory over the top and it does n't work that way, right? ok, so let's stop talking colors and let's talk terms, ok? in the world of operating system, you open up an operating systems book. it's not going say, and the green ones that no in a process's address space, these are called pages. these blocks are processing these divided up into. in this case, page size 4096 byte pages memory is divided up in what's referred as frames. frames of the same size of a page and a page is clicked inside of a - frame. ok, so in this case i've got 5 frames is probably not characteristic of real memory, but you could say i'm probably more than that and pages go into frames. ok. that do n't that stores what frame a page is in is referred, not as a note, but the page table. ok, we'll come back this later on."
"""OpSys_Memory_Management_and_Process_Scheduling_Transcript.txt""","in this case, page size 4096 byte pages memory is divided up in what's referred as frames. frames of the same size of a page and a page is clicked inside of a - frame. ok, so in this case i've got 5 frames is probably not characteristic of real memory, but you could say i'm probably more than that and pages go into frames. ok. that do n't that stores what frame a page is in is referred, not as a note, but the page table. ok, we'll come back this later on. we're going do exact smart examples because explaining the concept is one thing, but doing examples of the numbers. so i want do more examples next time because i'm out of time, so for now we will stop there cuz it's a good enough stop place stop as any. and i wish you a good day. we'll come back and talk about paging and page tables on thursday. do n't forget this. thanks for coming. lembke, james stopped transcription"
"""OpSys_Mutual_Exclusion_Transcript.txt""","meeting in _ general_-20240321_130210 - meeting recording march 21, 2024, 6:02pm 45 m 22s lembke, james 0:10 hello. hello. jeez, wait. something went wrong. please try seems be working ok. alas, anyway. alright. so welcome operating systems isolation and protection. abstractions are cool. we were talking threads and on monday if you remember from that long ago, i was motivating that threads are awesome, but they also bring about some concerns what we call it concerns there are potential problems. they're not absolute going be a problem, but because if they were a problem, we just would n't allow threads. but threads are cool in that we can have multiple sort of streams of execution all operating on the same data. they share data by default, but because of this, because of that, if they're sharing data by default, there might be a situation in we do n't want have more than one thread executing at the same time on a particular piece of code. so i mentioned critical sections and really talked about not here. this idea of motivating mutual exclusion and then we talked about mutual exclusion mechanisms. and we started talking about some of hours and then i said this wonderful. i thought it was wonderful because i'm biased of my childhood. when i was a kid and my dad dragging me all of the train museums and riding all of the trains right and drew this picture. there's idea here that this should not autofocus is that i locked it. there. that in certain situations we do n't in the real world do n't want allow multiple things be in a particular region at a time in general, is it a problem? no, but it could cause a problem. so in here with the train, we've got this section of track where it's not implicitly a problem with more than one train is inside this blue region at a time, but it certainly could be a problem in that if they got too close each other, that might bump into each other, or they might break track. they might actually like trash, is not good, so a subpar in a train world is a little electrical like why i guess, for lack of a better word, that when one train comes in and crosses the line it crosses this part of the track."
"""OpSys_Mutual_Exclusion_Transcript.txt""","so in here with the train, we've got this section of track where it's not implicitly a problem with more than one train is inside this blue region at a time, but it certainly could be a problem in that if they got too close each other, that might bump into each other, or they might break track. they might actually like trash, is not good, so a subpar in a train world is a little electrical like why i guess, for lack of a better word, that when one train comes in and crosses the line it crosses this part of the track. that little flag goes up and all of the corresponding flags also go up, until anybody else that there is a trained inside this region and it does n't go down until that train clicks on one of these other buttons that detached the track and then they all flip down. we'll we'll tell any other train that's coming in like this red train. do not enter this region because there is another train in here and could cause problems. in the world of computing and execution that led the example that we have here that really the similar idea that is. whoa. here where? while i have multiple threads that i want execute concurrently, absolutely that's what i want these threads do. i want them work together on these variables, but when it comes line 35 and 36 i do not want them be accessing these variables at the same time because correctness. well, lighting them do that is fast. if they all access all the variables and all the data at the same time, it's awesome because it's really quick. we have multiple threads of execution already always accessing this great, but it makes the values incorrect and correctness must come first. efficiency then comes second, right so. some of ours and code and i mentioned that in coding some of four involved and i drew this picture over here, this idea of a value and account and with the operating system is going do is it is going set the value based on what we initialize it and if a thread does a weight on that like a train rolling across that switch on the track, the operating system in code now stores the reference these values for us. and then i'll wait on the summer bar causes the count be decremented and if the count ever goes 0, the thread that's waiting on there then gets weighted on a wait queue, right?"
"""OpSys_Mutual_Exclusion_Transcript.txt""","some of ours and code and i mentioned that in coding some of four involved and i drew this picture over here, this idea of a value and account and with the operating system is going do is it is going set the value based on what we initialize it and if a thread does a weight on that like a train rolling across that switch on the track, the operating system in code now stores the reference these values for us. and then i'll wait on the summer bar causes the count be decremented and if the count ever goes 0, the thread that's waiting on there then gets weighted on a wait queue, right? so if the thread, i'm sorry if the count is initially one and the thread comes across the way or train goes across the switch on the track, it gets proceed through because the count is not zero. anybody else coming in that does a weight has wait until later on. there's a signal that's made increments the count allow somebody who's waiting proceed, right? so we use this account kind of as a gate allow only so many threads through the count essentially establishes the number of threads that we will allow past the wait call. like do n't. how does this look like in code? well, with any object in our operating system, i'm not any object, but with a lot of the objects we talked about in our operating systems, we have create them. we have use them and then we have release them. we wanna allocate memory. we malic, we use the memory, we free it. we wanna use a file. we open the file, we get a file descriptor. the actual like object for the file is stored inside the operating systems address space for our process, and we're given a handle in index of value for the file descriptor. use the file. when we're done, we close it. we wanna use a queue. we open the queue, we use it, we close it. we wanna use shared memory. we have essentially open with shm open open the shared memory segment. then we'll use it if we close it. if we and map something we have unwrap it, right? these operations go hand in hand, so when the summer before this is an operating system object that's gon na keep track of this count and this weight queue for us. so we have initialize it. what do we do? we call 7/8."
"""OpSys_Mutual_Exclusion_Transcript.txt""","we open the queue, we use it, we close it. we wanna use shared memory. we have essentially open with shm open open the shared memory segment. then we'll use it if we close it. if we and map something we have unwrap it, right? these operations go hand in hand, so when the summer before this is an operating system object that's gon na keep track of this count and this weight queue for us. so we have initialize it. what do we do? we call 7/8. something it takes 3 values parameters, the actual sum of four that we're gon na initialize, is good because we have initialize that object. the second variable is kind of kind of weird, so i'll come back that and then the third parameter is the initial value enough. so what's the second value? 7 fours are pretty cool because while i wanna use them and show you an example of how we can use semaphores essentially control code or control access a critical section in threads. some of course, can actually be used control access a critical section across processes as well. guard so i could have two processes with independent code. that is all gon na access this semaphore, and maybe they're gon na be coordinating. who's gon na execute a certain operation, and they need some way communicate with that. we can use the semaphore for that. that's what the second parameter says. it says whether or not the semaphore is going be shared between processes, and you might look at that and say if i've got a pointer where that semaphore is, how do i share it between processes? we have an idea. we could use. we've already learned it. that's something new. yeah you q. ok, that's a slight different thing. we could synchronize processes by having one like send a message a queue and have another one wait on that. but this is specifically with the semaphore and how semaphore itself is stored in memory. maybe. i asked that question maybe maybe. yeah. and weird like. yeah, i've had a shared memory file. yeah, we could exactly create a shared memory segment. happy the semaphore inside that shared memory segment have the operating system initialized. that semaphore inside shared memory and then we can share between processes because processes can share memory using a shared memory segment. ok, do n't for these examples."
"""OpSys_Mutual_Exclusion_Transcript.txt""","we could synchronize processes by having one like send a message a queue and have another one wait on that. but this is specifically with the semaphore and how semaphore itself is stored in memory. maybe. i asked that question maybe maybe. yeah. and weird like. yeah, i've had a shared memory file. yeah, we could exactly create a shared memory segment. happy the semaphore inside that shared memory segment have the operating system initialized. that semaphore inside shared memory and then we can share between processes because processes can share memory using a shared memory segment. ok, do n't for these examples. i'm going be using threads and i'm only gon na have one process, so i'm going leave that at zero say it's not going be shared if it's a value other than zero, it says that the sum of four is shared between processes that needs get stored in shared memory somewhere. ok, so that's shared. 78 k once we initialize the semaphore, we have destroy it when we're done. we want wait up. sorry, on a summer four that we're entering the critical section, we do some weight that does that operation at decrements the value by one and if the value is 0, it it, it holds up a thread. we also have some other flavors of of some weight, kind of like with our cues or we had blocking and nonblocking weights. we can try weight, says i would like wait on the semaphore, but if the value is 0 and therefore would cause me block i'm i do n't actually want block, i just want the operating system return an error and let me continue. ok, let's try wait and then time wait. because i would be ok waiting, but only so much time. and so there's a time specification structure where you can tell the operating system just hold up my process for only so long. and so maybe you only wanna wait for half a second or something like that get into the critical section. umm. and so we got ta be clear about that, because for a timed wait, if we do only wait for so long, we really have make sure that we really only walk one thread be inside that critical section at a time. and wright, might not be what we're looking for. we really would want use it for some other purpose than that. ok, that's wait. umm, the signal actually is called post. i used the word signal. sorry, that was why i learned it in posix."
"""OpSys_Mutual_Exclusion_Transcript.txt""","and so we got ta be clear about that, because for a timed wait, if we do only wait for so long, we really have make sure that we really only walk one thread be inside that critical section at a time. and wright, might not be what we're looking for. we really would want use it for some other purpose than that. ok, that's wait. umm, the signal actually is called post. i used the word signal. sorry, that was why i learned it in posix. the actual word is set post signal. as some of our increment the value and release release the thread. and then destroy is destroy. this kind of like free free them. aleks, right. we're going destroy this some form, right? so let's let's just do an example. so here is my code that i wanna synchronize and if i compile it p thread mutex race, if i run it again we see that problem where we really want get 10 threads running 100,000 times. these two values should both be a million. they're not, so we got ta fix that. so i'm going just copy this code. summer four, and actually then augment it with semaphores. so for that we need include another header file, need include some of 4h and then i need. create a semaphore store. so because we have multiple threads that are all going be sharing the semaphore, i could create it in main stack space or i could n't create it on the heap. for this example, i'm just going create a global global memory. i know you can argue with me about that. whether that's a good idea or not later, but we'll just do that. so i'll just call it flag. it's not initialized. this just allocates storage for it later on. we're gon na ask the operating system initialize it for us. down here. and that's going be semi in it. and i'm going initialize the flag. acquires a pointer it, so the operating note system knows what memory initialize, and then i need specify whether or not it's shared or not. in this case, it's not going be shared between processes. it will be implicitly shared between threads because all of threads share memory here, so we're not going worry about the thread sharing. we automatically get that and i'll set the initial value of 1 say i only want one thread go through at a time. then i'll start it"
"""OpSys_Mutual_Exclusion_Transcript.txt""","and i'm going initialize the flag. acquires a pointer it, so the operating note system knows what memory initialize, and then i need specify whether or not it's shared or not. in this case, it's not going be shared between processes. it will be implicitly shared between threads because all of threads share memory here, so we're not going worry about the thread sharing. we automatically get that and i'll set the initial value of 1 say i only want one thread go through at a time. then i'll start it and then when i'm done, i need destroy this up before. ok. and then in here before i access the critical section, i need like drive across that section of track and so i need do a some weight. my spell flag right and then i need do a sam post when i'm done. if i do n't post, that's like the train where just like drive into the middle of the track and then stop. or if we were like drive in, try and leave the blue zone without driving across this line here but kind of found a way go around it, right? what i'm make sure that we post or signal when we're done. questions. right. so here's the cool thing. oops, that's the wrong file. that's it. not all that. i mean, i wish that there was more it. i wish it was more complicated, but that's all we get. one. the only other thing that i can mention here is that it's hard say. see, it's subtle. this ran a lot faster than this. if you actually run it, you'll see it. there's a slight delay, just barely because of all this extra weighting that these threads have do, and the calls and the system calls the operating system, all the extra traps and stuff we have run. but like i said before, correctness has come first, then we get efficiency, all right. ok, so some caveats. as we always say, there's always something say about this, ok? we have some of ours, right, some of ours are signaling mechanisms, right? what i like think of this as is like i'm locking out this critical section, but as some before is not a lot, no one owns the semaphore. it really only signals other threads that somebody is currently using it."
"""OpSys_Mutual_Exclusion_Transcript.txt""","but like i said before, correctness has come first, then we get efficiency, all right. ok, so some caveats. as we always say, there's always something say about this, ok? we have some of ours, right, some of ours are signaling mechanisms, right? what i like think of this as is like i'm locking out this critical section, but as some before is not a lot, no one owns the semaphore. it really only signals other threads that somebody is currently using it. it does n't say who, and so right with the semaphore in the track, there's a train in there. i do n't know who's in there, but there's some train in there. so when it comes something like this, if i have a code bug. this is allow the operating system is not gon na have a problem with this and it's just gon na do it's action. and remember, the sum of four and it sets the initial count. it does not set the max count or something like that. it is the initial count i can post a summer for 100 times and if i initialize the count 1 and i post 100 times, the count now becomes 101, right? so there's no limit there. now, ok there is a limit because this is a finite computer and variables are only so big. so the count of a semaphore can only grow so high, and because it's initialized with an integer value, it's probably like the max value of an integer. so and i'm not quite sure what the behavior is. if i try signal or post assemble where the value is currently the max value of an integer. if it's gon na like rap negative or something like that. so ok, there is a limit, but it's pretty big, right? so by setting this be one, that does n't mean that the max value is 1, but at the initial value is 1. so if i do this and recompile this and run it, i get the incorrect answer or gran because one thread now signaled the semaphore twice and now multiple threads can get into the critical section cause the value got incremented two. ok. so gotcha. the other gotcha if this is if i can do this, can i do this? and the answer is yes. and what happens there is the operating system does n't know who signaled the summer before. it just knew that someone signal or waited."
"""OpSys_Mutual_Exclusion_Transcript.txt""","so by setting this be one, that does n't mean that the max value is 1, but at the initial value is 1. so if i do this and recompile this and run it, i get the incorrect answer or gran because one thread now signaled the semaphore twice and now multiple threads can get into the critical section cause the value got incremented two. ok. so gotcha. the other gotcha if this is if i can do this, can i do this? and the answer is yes. and what happens there is the operating system does n't know who signaled the summer before. it just knew that someone signal or waited. sorry, somebody waited on the semaphore, so if you wait twice, it's just gon na do the behavior and say what's the value of the semaphore? it's 1 decremented 0. great. it's not negative. you get go through wait again once the value the sun before it's zero. you need wait. you're stuck on the queue question. yeah. so like the reason why they're leader is different is because posted twice about like opened up that opened up a2 spaces in the sun before. so then the incremented the count be two, yeah, and so then at that.2, waiters would be allowed go through cause after i incremented it the first time the count went from zero 1, and then we like when i signaled it again or posted it again, the count would have gone from one two after my initial signal. my initial post where it was one anyone that was waiting could have been woken up from weight and then decremented it back zero. but when i signed it again, that would have been incremented it from zero one. i do n't know control over the exact order in things happen, but ultimately it's essentially letting conceptually letting 2 threads through, but it's really based on the account there. makes sense. do n't. conversely, though, with the weight though, if the value is 1 and i do a weight that will decrement it's zero, i'll be allowed go through. i'll decrement it again and it always say wait the value is already zero. i'm not gon na let it go below 0. instead, i'm gon na block that thread, so here runs into a similar situation that we ran into before. whoops, there we go. yeah, i tried run it. i get nothing. why?"
"""OpSys_Mutual_Exclusion_Transcript.txt""","conversely, though, with the weight though, if the value is 1 and i do a weight that will decrement it's zero, i'll be allowed go through. i'll decrement it again and it always say wait the value is already zero. i'm not gon na let it go below 0. instead, i'm gon na block that thread, so here runs into a similar situation that we ran into before. whoops, there we go. yeah, i tried run it. i get nothing. why? because the first thread that got in there is stuck, every other thread now is also stuck because the count is also zero. was a problem. this is essentially a very similar what we ended up with pipes. if it did n't close the pipe ends. this is called deadlock. in this case, the process is waiting or the thread is waiting for itself. but now? well, just like with pipes, have you got a child process that's waiting for a parent process send the data down the pipe, but the parent process forgot close the right end of the pipe and now it's waiting for the child? now we have a parent waiting for a child and a child waiting for a parent, and nobody's get any work done. here we have a thread waiting for itself and no one's gon na signal this semaphore, so we're just sitting and waiting. ok. so things think about. can we fix this? well, couple of things that i i think i i i love some of ours, but i i'd like have them be a little bit different in that i kind of like the idea of ownership, right. somebody is in this critical section and it kind of like say at the current amount of time or current instance, one of the threads owns lines 39 and 40. they're the one that sort of owning this resource access it. some of us do n't do that right. some of us also have are counting in that they can be incremented continually and when it comes something like this and i wanna lock something out, i kind of wanna think about like taking these two lines of code and like locking them in a safe say i'm the only one that can get that because i'm the one that locked the save. then when i could release it, you know i can unlock it."
"""OpSys_Mutual_Exclusion_Transcript.txt""","they're the one that sort of owning this resource access it. some of us do n't do that right. some of us also have are counting in that they can be incremented continually and when it comes something like this and i wanna lock something out, i kind of wanna think about like taking these two lines of code and like locking them in a safe say i'm the only one that can get that because i'm the one that locked the save. then when i could release it, you know i can unlock it. and another situation of like if i unlock the safe and then i unlock it again, that might not be the most efficient thing in the world, but i do n't really want have it cause a problem. whereas if i pulse a sub before more than once, it might kind of cause a problem. ok, i do n't that might be a lane motivation, but that's my motivation. you guys could think of it differently, but anyway, leads us the second mutual exclusion mechanism, is a lock and i do n't have a really cool like fancy picture consider like like a train. uh, i guess you could think of it as a lock on the door or a safe or something like that. but a lock is that it is we take this idea episode before and i like the idea of holding up processes on a queue. that's great. i like the idea of this condition of whether it's being sort of what i kind of like the countdown and semaphore being it locked or unlocked, but it really only wanna have just that two states locked unlocked. i do n't wanna have accounts later on, i'm gon na do an example of where semaphores and using semaphores for account is awesome, but for now it's kind of cloudy. no, i like it be able be locked or unlocked. i'd like be able know who owns it. and and make my operation simple. so that's what a thread like is. we have a lock we have two operations we can do. we can lock our unlock. have it recorded the ownership. and then i'm gon na mention these now. only the owner can unlock it. ok. that makes sense, right? if i have more than one thread that that's locking that's got this. that's had a nice right. i do n't wanna have let somebody else unlock it, but some other things concern that kind of concern."
"""OpSys_Mutual_Exclusion_Transcript.txt""","so that's what a thread like is. we have a lock we have two operations we can do. we can lock our unlock. have it recorded the ownership. and then i'm gon na mention these now. only the owner can unlock it. ok. that makes sense, right? if i have more than one thread that that's locking that's got this. that's had a nice right. i do n't wanna have let somebody else unlock it, but some other things concern that kind of concern. me, but i'd like just kind of keep in the back of our brain and then we can come back and address them in a minute. the first concern is what if the owner locks the mutex more than once, but the sum of four about if the process if a process waits on the semaphore more than once, we know what happens there. we have deadlock because we do n't have a we do n't have an understanding of ownership, but with a mutex lock. we might have that situation. what do you want do? what if the owner unlocks the mutex more than once? what do you want do? and what if the owner terminates without unlocking the new text with the sum of our? we do n't have ownership, so we've just do n't do anything. i just operating systems like i. i'm just gon na leave the count where it's at. let the waiters where they're at, where the lock we have more understanding of things we can do so anybody and just think about something that they might wanna do address this. what do you guys think? if an owner locks and mutex more than once, what do you wanna do? right. deadlock. you wanna return an error? i see back how people say i do n't want do anything. ok, might be an option. we'll find that in the posix world, there's a bunch of different flavors of a mutex lock, and there are some that say we're gon na deadlock just like kind of like a some before. there are some options that say do n't do anything. there is one option i find is awesome but also very scary is a recursive lock. it says if you wanna lock this more than once, it's kind of like great. you lock it once you put your critical section in a safe and lock it. now when you lock it more than once, you take that whole safe and you put it in another state and lock it."
"""OpSys_Mutual_Exclusion_Transcript.txt""","we'll find that in the posix world, there's a bunch of different flavors of a mutex lock, and there are some that say we're gon na deadlock just like kind of like a some before. there are some options that say do n't do anything. there is one option i find is awesome but also very scary is a recursive lock. it says if you wanna lock this more than once, it's kind of like great. you lock it once you put your critical section in a safe and lock it. now when you lock it more than once, you take that whole safe and you put it in another state and lock it. and if you lock it a third time, you take that whole safe that was inside of a safe, and that was inside and put that in a safe and lock it. it's called a recursive lock where it says if you want actually then ultimately unlock this, you have unlock it the same number of times that you locked it. is that good? is that bad? it is what it is. they give you that option, right? so what if it unlocks it more than once? ok, say my idea you might say, but unlocks it more than once. you can do nothing or return an error. umm, there were no much else you could do about that, right? like if you have a recursive lock turned on then you have unlock it that many times or like should be unlocked and the one of the owner terminates is not unlocking the mutex. what do you wanna do? this is weird. you wanna just say you know what? i'm just gon na implicitly unlock it. are you just going say i'm not gon na do anything? it kind of depends on your situation. often again, i'm reason i mentioned this is because it's something that we have think about. for me personally, i find that if this happens, it's probably a bug. i probably should have unlocked it before i terminated, no. but anyway, i just want throw that out there. ok, so let's go up over here. incidentally, another one of these weird, i would say deep thoughts. some destroy right destroys or something for what if we destroy some before when someone's waiting? what do you want do there? yeah, that's that, that box, though, deadlocks them. do n't release them. that's one option. another option might be just release everybody that's waiting. is that a good idea?"
"""OpSys_Mutual_Exclusion_Transcript.txt""","but anyway, i just want throw that out there. ok, so let's go up over here. incidentally, another one of these weird, i would say deep thoughts. some destroy right destroys or something for what if we destroy some before when someone's waiting? what do you want do there? yeah, that's that, that box, though, deadlocks them. do n't release them. that's one option. another option might be just release everybody that's waiting. is that a good idea? why is it not a good idea? well, it could be an ok idea in this situation if i destroyed the semaphore while it was threads awaiting all the threads would be released and then they would all access these double values at the same time and where no better off than without using some of ours in the first place. again, something else think about. ok, let's go on. because i'm. i'm. i'm. i'm so what is? sorry, i do want mention this. what is posix? say the posix says the string is some before that other processes or threads are currently blocked on produces undefined behavior. this is i feel like a cop out. that's is that the right way say that? is that not appropriate for work like this is kind of a lame decision, but i will tell you this in this essentially means undefined means it's not specified in the posix specification what is going happen. i will tell you that if we look at the linux kernel code and i'm not gon na do that because it it plus it's not code there. there is defined behavior. the linux kernel does do something in this situation. what it's saying is, is that if you as a programmer do this, it's really up the operating system decide, and we're not really gon na tell you. so essentially it says do n't do that. that's again. that's why i say it's kind of a lame answer, but you'll see situations in here where it says undefined behavior and it's meaning deposits really does not have a i have a a detailed description of what do. it's up the operating system. i do n't necessarily look at the linux kernel code figure out what happens. so anyway, let's move on. talk about mutexes. so in mutex world we have mutex locks. so just like whether summer four, we have initialize the mutex we have lock the mutex and unlock it and then we have destroy it."
"""OpSys_Mutual_Exclusion_Transcript.txt""","that's why i say it's kind of a lame answer, but you'll see situations in here where it says undefined behavior and it's meaning deposits really does not have a i have a a detailed description of what do. it's up the operating system. i do n't necessarily look at the linux kernel code figure out what happens. so anyway, let's move on. talk about mutexes. so in mutex world we have mutex locks. so just like whether summer four, we have initialize the mutex we have lock the mutex and unlock it and then we have destroy it. so another operating system object where we have create it and delete it when we're done, and then we can unlock it and lock it when we're using it. so some in it and some destroy. here's simonette utex in it, where we initialize the mutex. mutex is defined as a mutex type. we specify a pointer that new text, and then we have another optional parameter called attributes allows us customize how this mutex works. i mentioned these questions over here. what do we do if the owner locks the mutex more than once? what do we do if the owner unlocks the mutex more than once? what behavior do you want? hosek says that is through the attributes that are specified and in here, if we were look at. of where is it? yep, that's the wrong thing. sorry if we were look at. there it is. this the page i was looking at. posix provides several different attributes for mutex lock. you can create a normal. you can do an error check. you can do a recursive or use the default and then there's this table that specifies what happens if somebody for example, tries relock such a lock. the mutex that they already own. so for a normal mutex it deadlocks for the default behavior is undefined behavior and error checking. mutex returns an error and a recursive mutex does that recursive block where you have unlock it the same number of times that you lock. it makes sense, ok. this robustness has deal with on what happens when a thread, umm, unlock our thread terminates while having control of the mutex lock. so robust mutexes will release the processes nonrobust essentially as an undefined behavior. ok. questions. all right, so this is important know. am i gon na quiz you on this? no, i think it's important know that this is where you can do look this stuff up based on your application that you have options available you."
"""OpSys_Mutual_Exclusion_Transcript.txt""","mutex returns an error and a recursive mutex does that recursive block where you have unlock it the same number of times that you lock. it makes sense, ok. this robustness has deal with on what happens when a thread, umm, unlock our thread terminates while having control of the mutex lock. so robust mutexes will release the processes nonrobust essentially as an undefined behavior. ok. questions. all right, so this is important know. am i gon na quiz you on this? no, i think it's important know that this is where you can do look this stuff up based on your application that you have options available you. the big important thing about mutexes that i want you want you take away from this is they maintain ownership and binary. they're either on or off. they're locked or unlocked. ok. as well as how they're used. ok, so we have in it and then we have the corresponding detroit destroy. if we want create a new text with the default behaviors, the header file mp3 dot h provides this pthread mutex initializer. it's like a pound find initialize it. so you can initialize the mutex all in one line of code. it just for convenience. all right. why does n't the semaphore have that? well, as some of our requires that initial value and so we have initialize it, we have that extra parameter pass when the mutex the initial value is, it's created unlocked and that's it. they do n't really. the only other options we have on these attributes and so there's a pthread mutex that initializer for the default. i think there's a pthread recursive initializer if you want create a recursive lock, things like that. so ok, let's move on. done. and so then the other part of this is. this we have lock try lock and unlock. we do n't have a time block. we have a lot try lock where it says try lock the the the new text and if somebody else has n't locked, return an error immediately. then there's lock, says lock the mutex, and if somebody else has it locked, just block me and then there's unlock, unlocks the mutex. if i'm not the owner of the mutex, then that gets into the on the unowned behavior of. what happens that lock? do i get an error? is the behavior undefined? so on so after that, we got ta look at how we created our lock, is down here unlock when not owner."
"""OpSys_Mutual_Exclusion_Transcript.txt""","we have a lot try lock where it says try lock the the the new text and if somebody else has n't locked, return an error immediately. then there's lock, says lock the mutex, and if somebody else has it locked, just block me and then there's unlock, unlocks the mutex. if i'm not the owner of the mutex, then that gets into the on the unowned behavior of. what happens that lock? do i get an error? is the behavior undefined? so on so after that, we got ta look at how we created our lock, is down here unlock when not owner. so for the default behavior is an error is returned and so on. so. so let's take this take our semaphore example and justice convert this into the into a mutex example. so for this i'm going i do n't need 7 four dot edge case. i'm not using a sema 4. i'm gon na create a pthread mutex lock lock, call it flag, and i'm going use this pthread mutex initializer. just initialize it that way i do n't need actually initialize it down here. what i do need destroy it when i'm done. ok. and then up here, i'm not gon na wait whoopsies. i'm going lock. and then i'm going unlock. that's it. it's been a lot more time talking about it than coding it need for that. you're right. thank you. and i must have forgot something else. pthread mutex. that i spell it wrong, it says. ok. ah. and define my variable pipe wrong. pthread mutex t. yeah. ok there done. questions. ok, locks are cool. so i'm not going demonstrate it, but you'll see that if i was try and unlock it more than once because of me in the default behavior, that's not gon na cause a problem. if i try lock it more than once, i do n't remember what the default is. is probably undefined behavior, but up it hurts when i do that, so do n't do that. that's a lame way of saying that, but questions. ok, so that is pthread mutex locks and that's semaphores. so when would i wanna use one over the other? well, i got this handy dandy table here. this is not a definitive list of one way or the other, but it is something keep in mind. and so for your programming projects, the next one specifically you welcome use whatever you want."
"""OpSys_Mutual_Exclusion_Transcript.txt""","if i try lock it more than once, i do n't remember what the default is. is probably undefined behavior, but up it hurts when i do that, so do n't do that. that's a lame way of saying that, but questions. ok, so that is pthread mutex locks and that's semaphores. so when would i wanna use one over the other? well, i got this handy dandy table here. this is not a definitive list of one way or the other, but it is something keep in mind. and so for your programming projects, the next one specifically you welcome use whatever you want. that makes the most sense you, provided it works, but here are just some things think about. mutex locks. they can only use the synchronized threads. we ca n't share them amongst processes. well, for your for your programming project, at least the next one, you're only gon na be using threads, so that's kind of a wash whether you use some more or thread. and i should say ohh for the next programming project you'll need use multiple of these, so you're not just gon na be using us summer for or omnivex for my examples i did just use one, but when the program project they have use multiple on them, so that's the first one. new text lock is binary only if there's a situation where we might wanna signal our log multiple threads in. we're all. that's musics lock might not be the one. the best one we need for that we use can use some of what music slot can only be unlocked by the owner. any processor thread can single uniform. there is advantages that, you might say, well, is n't this is n't that great? would n't i only ever wanna do that? or they might be a situation where i want somebody else signal the threads not just the owner and the new text lock is a locking mechanism. and i said before is a signaling mechanisms. it's more meant indicate others that something is going on right? it's kind of like you're pushing information others. i'm letting you know what's going on. signaling versus alloc is kind of more of an inward say things like i am the one that's taking control of. this makes sense. ok, there are probably other differences in advantages, but that's all i'm going talk about now. so the next concurrent mechanic concurrency mechanism is conditions and i do n't have time probably get through all of that."
"""OpSys_Mutual_Exclusion_Transcript.txt""","it's more meant indicate others that something is going on right? it's kind of like you're pushing information others. i'm letting you know what's going on. signaling versus alloc is kind of more of an inward say things like i am the one that's taking control of. this makes sense. ok, there are probably other differences in advantages, but that's all i'm going talk about now. so the next concurrent mechanic concurrency mechanism is conditions and i do n't have time probably get through all of that. so what i wanna do instead is talk a little bit about the next programming project and there will be done for the day. let me see. that's a flagger. ok, so now we know pthreads. now that we know semaphores and now that we know mutex locks, we'll soon no conditions. you'll have sort of three sort of tools in your toolbox for what you can use help you with this programming project. so what are you going be doing with your programming project? it's this. this is built from a frustration that i have all the time, especially when i'm driving on country roads. you've probably seen it. maybe you have n't. i do n't know, but the idea is this. you have a two lane rd. i mean, two lane as in one lane in each direction, country rd. and often when they have do road construction instead of just closing off the road completely and having a detour, what they'll do is they'll they'll just close down one lane in the work on one lane at a time. and so as a result, now we have two ways of traffic that both need go through one lane and that does n't really work very well normally. so what they do is on one end of the stretch of rd, they put a person and on the other end of the stretch of rd they put another person and that person is sitting there with a walkie talkie. probably going the other side or phone or whatever, and what you'll see there is they're holding up a sign and i'll say stop and they'll sit there usually like live bombs and maybe flip on phone and, like, on all of a sudden, the walkie talkie will make some noise. they'll go and right here you are sitting in your car with the windows up. gone. what are they talking about? right. and then they flip the sign around, and then they go. sometimes they smile, sometimes they do n't."
"""OpSys_Mutual_Exclusion_Transcript.txt""","probably going the other side or phone or whatever, and what you'll see there is they're holding up a sign and i'll say stop and they'll sit there usually like live bombs and maybe flip on phone and, like, on all of a sudden, the walkie talkie will make some noise. they'll go and right here you are sitting in your car with the windows up. gone. what are they talking about? right. and then they flip the sign around, and then they go. sometimes they smile, sometimes they do n't. and then the cars start going through, passing the person and they drive along the way. and then after certain amount of time, they flipped the sign back the other way say stop and ultimately both sides. then on the on the, on the strength of roadside stop, and they wait for the cars drain out of this sort of critical section of road. and then the cars go out and they flip it the other way, and then the cars can come the other way. ok, controlling access this shared space of room. so what i would like you do is simulate this using threads. so what? you're gon na have it be given is a bunch of cars on this side of the section and a bunch of cars on the on this side and a flagger that will be controlling the direction of flow and you have make sure that cars do n't hit each other, but they only flow one direction at a time and that there's only gon na be a. so this stretch of rd is only so big. as a result, a car only so many cars will be able fit in this at a time. so we've got a certain amount of time, but that traffic is gon na be allowed flow while it's in there. cars are gon na be inside this thing, and then when it comes, you know, the time is done, then we were not allowed enter anymore. cars in this thing, they both have say stop the cars at the drain out of this, and then it's gon na get flipped around the other way. and cars are gon na fly back the other direction or drive or flow back the other way. a car is given a parameter of whether or not it's on the left side of the right side of the of the section. and the amount of time that times it wants cross. so a car is gon na start wanting go in one of the two directions."
"""OpSys_Mutual_Exclusion_Transcript.txt""","cars in this thing, they both have say stop the cars at the drain out of this, and then it's gon na get flipped around the other way. and cars are gon na fly back the other direction or drive or flow back the other way. a car is given a parameter of whether or not it's on the left side of the right side of the of the section. and the amount of time that times it wants cross. so a car is gon na start wanting go in one of the two directions. it's gon na go the other side and then wait on this side for so many microseconds after it's done, it's going then want get back in line go the other direction. and so it's gon na cross this so many times specified in a parameter file, and then that one car is gon na go home. so you might have 10 cars over here and 10 cars over here. one of the car was lost cross once and other car maybe once cross two or three times. it does n't necessarily have cross an end or it started. it's just gon na cross so many times, ok. and so your job is simulate this using threads and so this describes what the parameter file is going be look like. and so here's an example of a parameter file indicating the number of cars on the left side of the number of cars on the right side. i think this one is ohm. the amount of time it takes for a car cross the critical or the the the, the the road construction area. this is how many microseconds traffic is allowed flow in one direction, and then three is the capacity. how many cars you can fit on the road at any given time? and so then this parameter is deals with how many times the car wants cross and then the amount of time it waits before turning back around going the other way. ok. and then it explains what that means. here i want each car be implemented as a separate thread and the flaggers must be implemented as a thread. feel free use one thread for the flaggers on either side or two threads, and we'll say it's probably easier implement both flaggers as one thread, but you welcome use two if you'd like. ok, make sure you use proper synchronization mechanisms. uh, i do n't want. i wanna make sure that cars do n't hit each other and your i want you produce output. and so i want the output make sense."
"""OpSys_Mutual_Exclusion_Transcript.txt""","here i want each car be implemented as a separate thread and the flaggers must be implemented as a thread. feel free use one thread for the flaggers on either side or two threads, and we'll say it's probably easier implement both flaggers as one thread, but you welcome use two if you'd like. ok, make sure you use proper synchronization mechanisms. uh, i do n't want. i wanna make sure that cars do n't hit each other and your i want you produce output. and so i want the output make sense. statistics tracking as well a car when it gets in line cross that section of rd is going have wait for a certain amount of time. most likely i want you keep track for every single car how long it waits total on any side as it's waiting go across the the track the the the road. the code that has you getting getting started here is whole bunch of nothing so it's up you implement just about everything. one thing i did add here is as a directory called samples for those of you that i've already cloned the repository, those files are in. here i have the the sample files here it's the zip file if you have n't cloned the repo yet, you can get it right here in the samples directory. and what i've given you is a couple of sample input files. so here's like the one that was given and then an output file from my solution. your output does not have look exactly like this, and be honest with you, because we have no control over when threads are gon na execute, chances are it's not gon na look like this, right? three is not gon na be the first card necessarily that's going be on the interact with this right could be someone different, but every car is going give an index. so the first car in the file should be index zero and so on. so this is the i print out the parameters and then i start running. so i've got the flagger indicating that that it's safe drive from left right. here are the cars that are able cross and then they exit the construction zone after a certain amount of time. the flag indicates that it's unsafe drive, but now it has wait for the cars drain. in this case, there was four cars that got in there. well, uh. and then so we'll have wait for this other car exit and then indicates that it's safe drive the other way."
"""OpSys_Mutual_Exclusion_Transcript.txt""","so this is the i print out the parameters and then i start running. so i've got the flagger indicating that that it's safe drive from left right. here are the cars that are able cross and then they exit the construction zone after a certain amount of time. the flag indicates that it's unsafe drive, but now it has wait for the cars drain. in this case, there was four cars that got in there. well, uh. and then so we'll have wait for this other car exit and then indicates that it's safe drive the other way. and so then more cars enter and leave, and ultimately at the very bottom. after everything is done, we see that the number of crossings for all the cars since decremented down nothing. the car is finished. all the crossing the plager indicate that it's safe drive, and the planter finishes when all the cars have gone home, simulation ends and we printed out the total wait time for each card. questions. ok, i got a couple other sample files in here. there's one that's a small one. or there's only one car on either on either side. and so the output for that is a lot smaller conceived and so on. so that's the programming project. otherwise it's it's. i guess we can finish early, so have a good night. i'll see you tomorrow. we'll talk. we'll talk condition variables. lembke, james stopped transcription"
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","meeting in _ general_-20240418_130208 - meeting recording april 18, 2024, 6:02pm 48 m 37s lembke, james started transcription lembke, james 0:08 hello. hello, great. all right. so that's done. and where we going this week, we have not a whole lot of these weeks and we kind of skinny canvas wise, but i do n't think a whole lot skinnier material wise that we got plenty talk about. but today i hopefully maybe a little bit. tomorrow we're gon na finish memory management. do n't be exciting. so i wanna finish that, finish those notes and then that's that. that's today, but i got the last programming project is out there process simulator was due yesterday. hopefully that went well for everybody. i've not graded it yet, but do, hopefully you get started on that soon. memory manager is out there. the last partnering project i'll talk about that tomorrow and otherwise where were we we were. did you remember all the way back monday? feels like it's hard, but we were doing this. we're going through this idea of paging and how we have process address spaces that we make it think that it has all of memory and as a result we abstract away what it's actually accessing using the memory management unit and the translation. look aside buffer buffer and these page table entries and the cpu is automatically essentially doing not automatically, but it's doing these physical virtual physical memory address translations on behalf of the process. so did a bunch of examples with that, and then i said that now that we have this ability have this indirection, this process memory fake out via the page table, we can do some pretty cool stuff with processes make them think that they're accessing own memory when really they're accessing memory that's not directly own version of it. and so one of those was made good on copy on white, and this idea of a fork or i said then of apparent forks. a child, i said. ohh, a child is a copy of the parent. it's a even this day it's still kind of feels awkward for me say that because not really when we fork the copy of parents address space apparent might have, i do n't know, thousands of pages that it's using. and do that, memory copy takes a long time. i am relative the cpu cycle, especially for a child process. this is what gets me. you look at a shout, it's going fork and then immediately turn around and run another program."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","ohh, a child is a copy of the parent. it's a even this day it's still kind of feels awkward for me say that because not really when we fork the copy of parents address space apparent might have, i do n't know, thousands of pages that it's using. and do that, memory copy takes a long time. i am relative the cpu cycle, especially for a child process. this is what gets me. you look at a shout, it's going fork and then immediately turn around and run another program. so for the operating system do an actual copy of all of the parents memory pages just for the child say yeah, thanks for doing that. oh, by the way, why do n't you go ahead and just erase them and replace them with this with this other program? that's not very efficient, so copy on write says instead of actually copying the parent the child. or you just copy the page table so the child still has its own independent page table, but instead of actually having copies of memory, if it's only gon na do reads, is the chances are when it's most likely gon na do. if it's done centrally, immediately doing exec, but we're it's gon na do reads. it could just access the parents pages, but the problem is as soon as anybody writes now we have make it appear like the child is a copy. so if the child writes, we have essentially kind of like do a page fault in the child. assume as if that child's copy was n't in memory. happier put it in memory and then update the page table its new location and if the parent writes the same thing has happen because the child has have the old version. ca n't have the parents version i copy on wright,. this is pretty cool and it's pretty i would say it's intuitive follow once you figure all the rights that have happen there and all the copies that make when the rights happen. if it's a little bit more tricky once we fork in chain. right, let's think about this for a second. thing about parents forks a child very great. that's fine. we know how do this copy on write stuff just like i just mentioned here, but if the parent forks another child. now we got ta figure out when we need do a copy. one needs the copy if a child it was n't? the two children makes a copy or makes a right."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","i would say it's intuitive follow once you figure all the rights that have happen there and all the copies that make when the rights happen. if it's a little bit more tricky once we fork in chain. right, let's think about this for a second. thing about parents forks a child very great. that's fine. we know how do this copy on write stuff just like i just mentioned here, but if the parent forks another child. now we got ta figure out when we need do a copy. one needs the copy if a child it was n't? the two children makes a copy or makes a right. we got ta copy only the one we need for that particular child. the other child over here that never did the right can still accesses the parents shared pages. if that child writes, it gets its own copy from the parent. if the parent writes now we have send a copy both children. right. what did you say? well the why does the parent that the copy? because the parent is gon na update a page in memory, there's only one page of that. the two children are sharing that page with the parent. the parent needs make an update. both children need observe the old value of those pages, so i could make one copy and have that copy be shared amongst the children. or i can copy it each shot? make that make sense, maybe. ok, that's one case. the next case is what if a parent works a child and the child forks a child, and that child forks a child and that child forks a child. all of these chained children are essentially sharing a copy of the parents page. it's hadas. so the organization of essentially what what's called reference count is we have keep track of processes are referencing pages and how many there are and where they are so that we know where we need copy them, what page tables we need update. ok. ok, that's copy and write. let's talk about another feature of page tables, are pretty awesome. now let's look at this. say we have a process p0 and a process p1. they have memory. and i talked about inner process communication and i said processes do n't communicate unless the operating system says it's ok. they're one of the operating system channels, pipes, message queues. we could use file. you could use the file system. shared memory was one of them. number i mentioned this idea of creating a shared memory segment."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","let's talk about another feature of page tables, are pretty awesome. now let's look at this. say we have a process p0 and a process p1. they have memory. and i talked about inner process communication and i said processes do n't communicate unless the operating system says it's ok. they're one of the operating system channels, pipes, message queues. we could use file. you could use the file system. shared memory was one of them. number i mentioned this idea of creating a shared memory segment. and then having that shared segment be mapped inside process address space using mmap and then a read or write that memory goes the shared memory segment. i did n't really explain how do that other than using the system call or mmap load that shared. by the way, i have a page table and we understand this idea of paging. we can figure how this works. if we were look at this. and divide this guy up into pages. divide this guy up into pages. right, this is page 012 and three, this is page 012 and three. so if we were draw physical memory. we have a section for the os. in this case, the os is just using one page and we get all these frames. ok. and then we could just map them. so say this guy is the red process and this guy is the green process. we can put page 0 here, maybe page 1 here, page 2 here and page 3. i do n't know here then this guys page table. i'll just draw it up here. 012 and three. page 0 is in frame one, page one is in frame three, page 2 is in frame 6 and page 3 is in frame 8. and now we go this guy, the green guy. maybe we've got your. page 0 is there this guy's page one maybe is here now my pots. page 2 of the green process is shared with process p0. i will argue that page 2 for process p1 because it's shared is already in a - frame. do you see where it is? ok, what's frame is processed ones page 2in. grade six, you said. well, we talked lucky. you ca n't do that because we our page table, there's already a page there, it's process ones page 2. or because these two processes are sharing memory, we can map them the same frame. and then maybe this guy's page 3 is here."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","i will argue that page 2 for process p1 because it's shared is already in a - frame. do you see where it is? ok, what's frame is processed ones page 2in. grade six, you said. well, we talked lucky. you ca n't do that because we our page table, there's already a page there, it's process ones page 2. or because these two processes are sharing memory, we can map them the same frame. and then maybe this guy's page 3 is here. so this guy's page table looks like this. 012 and three. and this guy's uh, page 0 is in frame two is page one is in page frame seven is page 2 is in frame 6 and is page 3 is in frame 8. and then we can just let this thing ride. and it will. it will work if these guys when these guys are sharing it. when this guy needs access something that's in page 2, it's going map the other page table. nothing fancy has happen. the mu is still gon na work the same way as it did before. it's gon na read that. do the virtual physical memory address translation happened page 6? this guy does n't update, say, a store a variable that's in shared memory. that's gon na get stored here. this thing can do a can do a read and it that read is gon na get mapped the page. or be frame 6 and read the value and we can share memory and was actually are doing it by sharing pages. questions. essentially, this is actually what the mmap system call is doing when you mmap and you map something shared, that's essentially asking the operating system modify your page table so that you are essentially sharing these these pages sharing this memory region, is one of the reasons why i did n't talk about it then, because it did n't really perhaps make a lot of sense then is when you're doing an mmap when you're sharing something like this, the increment of the size that you can share with a map is opaque. it'll say the minimum size the the, the the value of the address must be vitalized page size. it will say that something like that in the main page, and if you're not quite sure on virtual number works, you might scratch your head and say what what's a page size wait. it has be, you know, a multiple of 4096. that's weird right? now we know why."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","essentially, this is actually what the mmap system call is doing when you mmap and you map something shared, that's essentially asking the operating system modify your page table so that you are essentially sharing these these pages sharing this memory region, is one of the reasons why i did n't talk about it then, because it did n't really perhaps make a lot of sense then is when you're doing an mmap when you're sharing something like this, the increment of the size that you can share with a map is opaque. it'll say the minimum size the the, the the value of the address must be vitalized page size. it will say that something like that in the main page, and if you're not quite sure on virtual number works, you might scratch your head and say what what's a page size wait. it has be, you know, a multiple of 4096. that's weird right? now we know why. because it's gon na go in the page. questions against pollywogs, yeah. umm, starts with package. well, this is the normal page for that. it's that copy. i'm right because these are parents or child. they're just two independent processes. oh, they do something wrong. david, the wrong letter. oh yeah. sorry, you're right. that's that's wrong. yes. so the answer your question is that's wrong. the answer this is it should be 4. because the green process is page 4 off, page 3 is in brain four. sorry about that. yes. does that make it better? ok, ok. so let's kick it up a notch and talk about one more thing with shared memory, only the target, the physical addresses are shared. right. each process still has its own independent virtual address space, right? this guy's address space is different than this guy's address space, right? so the physical is what's shared, the frame is what's shared where this shared memory segment is mapped in the individual processes. virtual address space can be different and you could say what? yes, this works. you can even do the math and it'll still work. this arrow i pointed that it maps the same page, but it does n't have. it could be mapped here. if that is the case, then this is not correct. this is not shared. what's shared is the physical frame that uses this guy with page 3, and then this guys page 2 would go somewhere like this"
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","so the physical is what's shared, the frame is what's shared where this shared memory segment is mapped in the individual processes. virtual address space can be different and you could say what? yes, this works. you can even do the math and it'll still work. this arrow i pointed that it maps the same page, but it does n't have. it could be mapped here. if that is the case, then this is not correct. this is not shared. what's shared is the physical frame that uses this guy with page 3, and then this guys page 2 would go somewhere like this and then the page table would have page 2 is in frame four and page 3 is in frame 6. and you could say. this is do n't share virtual addresses, they share physical address, so they share frames. so in this case, frame six is shared, but it's mapped process p zeros, page 2 and process threes are one page 3. it still works, it's just virtual physical memory address translation, and in fact the chances of shared memory being mapped the exact same space in a virtual address space is probably very low unless you're doing something like a false or you actually have copies. now we can do an air quotes. back shared memory. so let's go back here now and let's go back over the notes. make sure forget it. all right, copy and write page sharing. ok, what happens on a context switch? how do we choose a victim page? we still got work on that for page out stuff. all right. i'll come back this working set thing in a second, and so let's talk about context switching and then we'll go into page replacement. i kind of joked, not joked, but kind of just hand waved around, context switching being a heavyweight operation switch one process another takes a lot of work. i first said, well, we got ta take the cpu context for the existing process. the contents of registers the program counter, all that stuff stored away and replace it with the new process. well, now we have another problem that makes context switching even more heavyweight. we've got this cpu that's utilizing the enemy of and the translation will preside bumper contains page table entries, right, either page table entries."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","i kind of joked, not joked, but kind of just hand waved around, context switching being a heavyweight operation switch one process another takes a lot of work. i first said, well, we got ta take the cpu context for the existing process. the contents of registers the program counter, all that stuff stored away and replace it with the new process. well, now we have another problem that makes context switching even more heavyweight. we've got this cpu that's utilizing the enemy of and the translation will preside bumper contains page table entries, right, either page table entries. we ca n't necessarily leave them in memory because our two memory accesses are required do one, so this happens very quickly because we can access them and we win the tlb very fast do virtual with physical memory address language. but clb has page table entries right? now when we need switch processes, if all we were do is take the cpu contacts of 1 process and replace it with the cpu context of another and do no other updating. you guys see the problem, but clb has page table entries for a different process and it's all of the pages were shared. it would be ok, but they're not right. uh thread environment. that's awesome. we can do that because threads are all part of the same process and they implicitly share everything. so we just take the cpu context of 1 thread and replaced it with the cpu context of another and then the page table entries are the same for those two threads. that's awesome. i like that, but for a process now when we switch, we have wash the tlb's essentially get rid of everything out of here and replace it with a page table entries for the new process that we're running. i could take some time. the result is more things with the operating system has do on a context switch. we have virtual memory there. doc, just another thing do, but we ca n't forget. otherwise, we're gon na start making things incorrect. hey, let me comes up, all right. next topic. page replacement i showed this picture before. i picture out. and i went through a couple of steps. so what do we do? when we do n't have enough memory like, we're not going terminate processes or anything like that. we have this ability of backing storage. secondary storage or whatever you wanna call it tertiary storage. i do n't know. whatever it is essentially persistent storage that we have plenty of."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","otherwise, we're gon na start making things incorrect. hey, let me comes up, all right. next topic. page replacement i showed this picture before. i picture out. and i went through a couple of steps. so what do we do? when we do n't have enough memory like, we're not going terminate processes or anything like that. we have this ability of backing storage. secondary storage or whatever you wanna call it tertiary storage. i do n't know. whatever it is essentially persistent storage that we have plenty of. i might only have 16 gigs of memory, but i probably have like a tb of hard drive space. maybe i do n't know. i think that stuff i do n't really know how much. maybe 256 meg, maybe something like that. it's a fair amount more than i have memory. so the operating system it's going use some of that disk drive space as overhead and it's gon na say i'm going carve out some of that on windows called the page file. on linux it's called swap. on different operating systems, they call it something different and they use that put pages when we do n't have enough memory in it and a process requests of page, it gets that something written out the page. some one of these pages are picked be the victim, written out, and then the one that the process needs is brought you, right? this is swapping. one of the things we have be able do is when we have a full memory, we have be able choose a victim. i do n't know. that word kinda sounds mean, but is a word that i'm gon na use because i ca n't think of it right. how do we pick a victim recently? page faults are costly. we have do it this title eventually. ok, i do n't want do that. so i want minimize page faults. so when it comes time pick a victim, i'd like pick a victim that wo n't cause more page faults. so if i have a process that needs access the page and it's doing it often. i do n't really want remove that page because chances are if i remove that page from memory when a process runs again, it's just gon na request that again, right? think you can say? well, what? what is it? how do i think for them? ok, executing a for loop that for loop is on a particular page, right?"
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","so when it comes time pick a victim, i'd like pick a victim that wo n't cause more page faults. so if i have a process that needs access the page and it's doing it often. i do n't really want remove that page because chances are if i remove that page from memory when a process runs again, it's just gon na request that again, right? think you can say? well, what? what is it? how do i think for them? ok, executing a for loop that for loop is on a particular page, right? there's a bunch of lines of code in there that's accessing. i i did the access eye read it so i can check whether or not i have use my exit condition on my for loop, right? i have probably increment i at the end of for loop while i'm doing plus plus or plus equals two or minus minus or something like that. so accessing i a lot, i might even be accessing i inside the iteration of that program. so if i that they're variable for i is stored somewhere on a page. i i do n't wanna get rid of that because the next time that process runs and it's gon na be iterating this for loop, it's gon na just bring that page right back in again, another disk. i do n't want do that, so there are world of memory and operating system research that's trying come up with algorithms that are efficient in terms of operating system overhead, because that's the other thing this guy always take a long time. so i wanna minimize my page faults, but the amount of cpu time that the operating system uses determine one get rid of, i do n't want that be too high because i do n't want my operating system sucking up all of my cpu cycles. similarly, i do n't want my operating system use two gigs of memory store information about memory know page get rid of, because that's a waste of memory. so we got keep that small. we got ta keep the algorithm efficient, and we also want reduce page faults. we just want it all. so we're talking like couple of page replacement algorithms, one that's i feel like fairly intuitive, but is n't always very optimal as far as reducing number of page faults. and then we're gon na talk about another one, is a little bit better, but it's harder manage as far as organization and memory and cpu usage determine what do. and then the third one, is the optimal?"
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","we got ta keep the algorithm efficient, and we also want reduce page faults. we just want it all. so we're talking like couple of page replacement algorithms, one that's i feel like fairly intuitive, but is n't always very optimal as far as reducing number of page faults. and then we're gon na talk about another one, is a little bit better, but it's harder manage as far as organization and memory and cpu usage determine what do. and then the third one, is the optimal? yeah. so first algorithm. first in, first out simple one. what we're going do is. treat every frame essentially like a linked list, and when we bring in a page of memory, we're just going put it in the first slot. we bring in another page. we're going put it in the next slot and keep going until round robin until we fill up memory and then remember this fall and we need kick out a page. we just pick the next one, right? we go back around and then we pick up the next one. we pick out the next one in terms of a linked list, like a queue. this is nice. it is essentially. constant time figure out the next one, and i have keep as far as memory overhead. i have keep track of like 1 variable that stores the frame number of the next frame kick out. and so it's it's good. it's quick. first, in, first out thoughts. you guys like that one? why do n't you like that one? it's just some shakes. it's good random one. i mean, ok, it's it's kind of random, although it's not random. random would be an interesting one. i never thought about that algorithm say when it comes time pick up a - frame get rid of, we're just gon na randomly choose one. that'll be fairly efficient depending on how fast it takes for a random number generator run. that could be more or less constant time, and the bookkeeping would be very small because we would just. we really have keep track of anything, just the seed of our random number generator. yeah. anyway, plus it's not as essentially random, it's sequential, it's ordered, but that's actually one of the downfalls of it. we're random, might actually work a little bit better is that if i have a page that i just accessed. right here 01, right."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","that'll be fairly efficient depending on how fast it takes for a random number generator run. that could be more or less constant time, and the bookkeeping would be very small because we would just. we really have keep track of anything, just the seed of our random number generator. yeah. anyway, plus it's not as essentially random, it's sequential, it's ordered, but that's actually one of the downfalls of it. we're random, might actually work a little bit better is that if i have a page that i just accessed. right here 01, right. if i kick out one because it's the next one and a process runs, the chances of it need be brought back in again are fairly hot. so we run these lot of situations with first in first out where we get rid of something and then we need bring it right back in again because we need use it right. one random item is a better chance of picking out one of these other ones, but at first and first stop. do n't let third example, i got this example here if this paper. so while i can do this. yep. first in, first out. ok. alright so here is an example of a couple of accesses. because i need utilize writing backs, i wanna keep track of what's our reads and writes. so i keep track of what pages of dirt cause dirty pages have get written back right? so we page becomes dirty when it's written, because memory then becomes the sole, like correct value for the data, not what's on disk. and if it's dirty, we got ta make sure we write it back. so here's what i got. i've got accessing for a single process. that's the only one running in the system, and here are the pages that it's gon na access and as far as what brain it's in. well, that's our choice. we're going just make this interesting. i did not put this up here. we're gon na use fifo by folke with three frames. ok, the more frames we have the the different number of page faults we're going have. but here's what we got frame 01 and two, and we have one process that's accessing these pages. so initially our memory is empty. we were going just get rid of os space just for the sake of argument here, but the matt still more or less design and we're going just do this."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","i did not put this up here. we're gon na use fifo by folke with three frames. ok, the more frames we have the the different number of page faults we're going have. but here's what we got frame 01 and two, and we have one process that's accessing these pages. so initially our memory is empty. we were going just get rid of os space just for the sake of argument here, but the matt still more or less design and we're going just do this. so access number one, we access page 0, this page 0 and memory. these are frame numbers down page numbers. page 0 is not in memory, so we got ta bring it in. we're gon na find the first free frame, frame zero. we're gon na put page 0 there. ohh yes, there is a page fault. yes, we do not have a victim page and so we do n't need write anything back. now it's good. next access is page one. page 1 is in memory, no? so we got ta bring in a. we're gon na find a free spot. we'll put it there. we do have a page fault. it is. we have no victim page because we had a free frame and so we have a right back. now we're gon na access page 2. page 2 is also not in memory. we're gon na put it in frame two. we do have a page fault. none of the victim page and we do n't need anything back. alright, now we have a read from page 3. page 3 is not in memory, right? we have 01 and two, is the first page that we brought in. 0.1 end round robins. so that's gon na be our victim. we do have a page fault. our victim page becomes page 0. page 0 was n't dirty because we just read from it, so we do n't have write it back, and now we bring in three. all right, one moving right along. the next one is. page 4 is page 4in memory, no page 4. so who's our victim? is the first one in now of the three that are in there? one. so we do have a page fault. the victim page is 11, is not dirty, so we do n't have a right back and now we're going bring in four. our operation page 4 is a right? what does that mean?"
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","page 0 was n't dirty because we just read from it, so we do n't have write it back, and now we bring in three. all right, one moving right along. the next one is. page 4 is page 4in memory, no page 4. so who's our victim? is the first one in now of the three that are in there? one. so we do have a page fault. the victim page is 11, is not dirty, so we do n't have a right back and now we're going bring in four. our operation page 4 is a right? what does that mean? where is the definitive version of page 4 now? is it on disk? no, i see some head shakes. it's in memory so far is dirty. i'm gon na circle it in red, just so we do n't forget that boris. dirty, because if we're now, if we ever remove page 4 from memory, it must be written back disk, otherwise we're going lose the data that's on there, right? alright, moving on, page 5 is page 5 in memory. no. so we have page faults. what's our victim page? what is the 1st in of the these guys? one? page 2? yep. so too is our victim and two is not dirty. so we have no right back. we get rid of two and we bring in page 55 is a right five is dirty. and now we want. and now we have an access page 2. darn. is in memory. nope. we just, we just got rid of things. you're doing all right. that's fine. we're moving. we're we're doing first in first out. so who's our victim? page down. three. right. because that's the first one in. so three is our picked up. we do have a page fault. three is our victim and is 330. no. so we're not worried back. we have a read for two, so two is not dirty. we have read for two up here. it was n't dirty. now even another read two here 2 is not dirty. alright, so now we have a right page 0. ok. is0in memory. no, sorry. we have another page fault is the first one in now. four is 4 dirty. yes. so we have write it back and we're going bring in zero and zero is a right. so it is also still dirty."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","we have a read for two, so two is not dirty. we have read for two up here. it was n't dirty. now even another read two here 2 is not dirty. alright, so now we have a right page 0. ok. is0in memory. no, sorry. we have another page fault is the first one in now. four is 4 dirty. yes. so we have write it back and we're going bring in zero and zero is a right. so it is also still dirty. all right, now we have a right two was a memory. yes. alright, so we do n't have a page fault, so we have no victim page and we do n't have a right back. but what is our operation page 2? it's right. so two is now dirty. now we have a right page 55 is in memory, so we do n't have a page fault. do n't have a right back, and because we have a right five, five is now dirty. well, five was already dirty, so we're like, we ca n't make it more dirty. i mean, you could presumably think if i work outside, i'd get more dirty than love it in the terms of paging. we do n't. we do n't only get dirty and we're done. we do n't get more dirty, or if we did get more dirty, there would be nothing else for us do with it. we still got ta write it back. so alright, now we have a reader. 55 is still in memory, sort of a page fault. no right back, but you could say ohh it's a read so five must not be dirty anymore. now a page only becomes undertail when we write it back, and so we're not gon na write this back because there's a read. and so it's still dirty. right. we have a read the page 6, page 6 is in memory no? so we paid full. who's our victim? who is the 1st in now 5 even though we just used 5a whole bunch of times, it's still the 1st in of the ones we have. so five is our victim, my gets removed from memory. but do we have write it back? yes, because it's dirty. and who are going bring in six? 6 is not dirty cause we just read it. finally, we have a read page 1, page 1 not in memory, so we do have a page fault."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","who's our victim? who is the 1st in now 5 even though we just used 5a whole bunch of times, it's still the 1st in of the ones we have. so five is our victim, my gets removed from memory. but do we have write it back? yes, because it's dirty. and who are going bring in six? 6 is not dirty cause we just read it. finally, we have a read page 1, page 1 not in memory, so we do have a page fault. our victim is the first one in is 222 is dirty. we got ta write it back and we end with one. ok. first in, first out, just round rob, just go top the bottom, top the bottom right all the way down. question. i do n't know why i did that. does n't seem like quite the right thing. the option, but anyway. ok, least recently used. but the operating system, researchers said, is that first in first out is efficient. but if you look at the usage here, here's an. here's another example that does. just takes again 3 frames, but just a bunch of memory accesses. double process is that it does n't take into consideration usages where we have situations like here where we access 3 periodically and by the time we need access three it was just removed and then we're gon na access it again. there's access patterns in a process accesses a bunch of pages, kind of in order. you know, in a must, in a way of round robin fashion. and if we get lock step like that, we might have in a situation where we remove a page and then we immediately need access that page again. and so we just access one that we just removed and we got ta bring it back in again. we end up with this slight killing of page faults. and this happens because of a term i mentioned previously that did n't really explain this idea of called a working set. so what's a working set? ok. well, we have a process that needs so many pages throughout the course of its lifetime and now this is not a statistics class. i'm not a very great statistic constructor, but if you look at the the access like counts or process and its lifetime, sara process needs 10 pages and it's gon na access all of those 10 pages sometime during its lifetime. but some of those pages, there's a subset of them it accesses most often."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","and this happens because of a term i mentioned previously that did n't really explain this idea of called a working set. so what's a working set? ok. well, we have a process that needs so many pages throughout the course of its lifetime and now this is not a statistics class. i'm not a very great statistic constructor, but if you look at the the access like counts or process and its lifetime, sara process needs 10 pages and it's gon na access all of those 10 pages sometime during its lifetime. but some of those pages, there's a subset of them it accesses most often. some processes have an access pattern when they access all of processes, all of pages on a are even among. but typically there's gon na be a subset of pages that it's gon na access more often than others. this month are parted as a working set, so if you kind of graph it out you might might look like i'm double curve or something like that. we've got some pages or might be skewed one side and got more pages at the beginning or whatever, but there's some subset of pages that process accesses more often, and if that working set is big enough that it fits this round robin set of fifo pattern where the page that we need access next in our working set is one we just got rid of, we're going run up out with a problem where we end up with love more page faults. so the goal of least recently used is say we have get rid of pages we have we ca n't just we do n't have an infinite amount of memory. but with the goal of lr knew is it's it says what we're gon na try and do is keep track statistically of what a process is working set is and not get rid of the process is working set. get rid of the other ones, the ones that it's not using as often. and sense ok. so that's essentially what it is, is we take advantage of temporal locality, working set temporal meaning time. meaning, if i need access something, there's a high chance that i'm gon na access it again soon. ok, i'm accessing i for a for loop. chances are when i'm accessing i i'm gon na need access it again pretty soon, so do n't get rid of it. that when i forwarded ends. yeah, i do n't need it anymore. but for that 100 or 100,000 loop iteration i need i a lot so do n't get rid of it."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","so that's essentially what it is, is we take advantage of temporal locality, working set temporal meaning time. meaning, if i need access something, there's a high chance that i'm gon na access it again soon. ok, i'm accessing i for a for loop. chances are when i'm accessing i i'm gon na need access it again pretty soon, so do n't get rid of it. that when i forwarded ends. yeah, i do n't need it anymore. but for that 100 or 100,000 loop iteration i need i a lot so do n't get rid of it. that also shows that a working set for a process evolves over time in a particular set of time, from executing a poor loop by working set might be this. when i jump another section or i move on a different level in my game, my working set might change. all right. how are you essentially? says the victim page has the oldest page in memory, not the first one brought in, but the oldest one in terms of access. the one that's been accessed longest in the past. ok, so let's do that example again, but use how are you? here's my example. there's that. there's my data, so still 3 frames l ru01 into ok. since i have the access history, what makes this nice about you is not gon na just look backwards find the oldest page. you look going, so let's just move through this. so i'll go a little bit quicker here. and so for the first three, yes, they're gon na be page faults. so 01 and two, we got ta bring them in in order. they're all gon na be page faults because they're not in memory at all. we do n't have a victim page because memory is empty. and we do n't write anything back because nothing is, nothing is dirty. empty pages are n't dirty. empty frames are n't dirty. ok. then we're going read in three. what's nice about this is we can go backwards in history and find the oldest page. that's not, that's in memory. and in this case, the oldest one that was accessed back is 0, so zero becomes our victim. yes, we have a of a of a page fault. no, we do n't need write 0 back. we'll bring in three."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","and we do n't write anything back because nothing is, nothing is dirty. empty pages are n't dirty. empty frames are n't dirty. ok. then we're going read in three. what's nice about this is we can go backwards in history and find the oldest page. that's not, that's in memory. and in this case, the oldest one that was accessed back is 0, so zero becomes our victim. yes, we have a of a of a page fault. no, we do n't need write 0 back. we'll bring in three. we have access four or is not in memory, so we do have a page fault in this case of the pages that are in memory 1/2 and three, we can go over here and find the oldest accessed and so of 1/2 and three, the oldest one farthest back in time is 1. one is not dirty, so we do n't write it back. so we're going get rid of this. we're gon na bring in four. four is in fact dirty, so we have write and keep track of that. now we bring in five. 5 is not in memory. we have 03 and four or sorry 2 - 3 and four. our victim page is of these 3 pages. one was accessed farthest in the past? that is 2 way way up there we get rid of that two is not dirty and now we bring in five. but five is dirty. and you could say. ohh well, we just kicked out two and now we need it. well, hello. you was n't perfect. though we ever read from 2/2 is not in memory, we've got 3/4 and five. one is the oldest of these three? we go back our history and find ohh there's five. there's four up. looks like 3 is the oldest. it's the victim. we bring in two it's a it's a read 2/2 is not dirty. we do have a page fault. the victim page is 3 and we do n't have a write back as three was n't dirty. right 0 no 0 is not in memory. yes, page fault victim page is the oldest of two, four and five. the oldest is. 4. or and it's dirty. now we can bring in zero. it's a right 0, so zero is dirty. all right, now we have a right two, not a page fault. no victim page 2 is in memory. no right back. who was dirty?"
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","the victim page is 3 and we do n't have a write back as three was n't dirty. right 0 no 0 is not in memory. yes, page fault victim page is the oldest of two, four and five. the oldest is. 4. or and it's dirty. now we can bring in zero. it's a right 0, so zero is dirty. all right, now we have a right two, not a page fault. no victim page 2 is in memory. no right back. who was dirty? ok, two now is our most recently used used one. so again, we have pick a victim. we got ta keep that in mind. now we have a right five up five is in memory. no right back. we have a redefine 5. well, 5 is not an is in memory, so we do n't have a page fault. no right back. and now we have a read six. 6 is not in memory, so we know we have a page fault and we have pages 20 and five. one is the oldest of the access we go back in time. we find beers. two years, five and two. and you're 0, so zero is our oldest page, so that one gets removed. yes, page fault zero is the victim. yes, right back, because zero is dirty. so here's where things start differ. we bring in six. six is not dirty. now we have an access for page 11 is not in memory, so we do have a page fault and amongst 2/6 and five. one is the oldest and i ca n't do that. i got ta go this way. go backwards and we find that. 255 is newer, so two is the oldest, least recently used. so two becomes our become victim and we do have a write back because it is dirty. and then we bring in one. so in this example, in terms of total number of page faults, it might not have made a whole lot of difference because we have so few frames, but at least it allows us go through the motions, right? how are you this example from this book here actually shows an ordering in lsu does produce your page faults, and in general, lu does produce fewer page faults."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","so two becomes our become victim and we do have a write back because it is dirty. and then we bring in one. so in this example, in terms of total number of page faults, it might not have made a whole lot of difference because we have so few frames, but at least it allows us go through the motions, right? how are you this example from this book here actually shows an ordering in lsu does produce your page faults, and in general, lu does produce fewer page faults. the problem with lru is, as you perhaps notice, as i was going through it, my decision or our decision for one did decide was the oldest, involved us coming go back and look at like access history and keep track of frame is the oldest or the least access. not always, but yeah, in terms of its access and keeping track of the least recently used. it takes a fair amount of work keep track of all of that. alright, i'm not actually gon na go through the algorithms of like what data structures you can use keep track of it, but the idea is you ca n't. you have keep everyone in the list or some sort of just record of the frames, but ones are the oldest and it just it takes more bookkeeping. also, iterating through it find that now you can probably order them like a heap or something, but still take some time. ok, so if we got those two, let's talk optimal. ok, there is an optimal one. ok. if first in first out is low overhead from the operating systems perspective but produces more page faults, lu takes more overhead but produces less page faults. can we do even better? the answer is yes, and it's essentially lu flipped over. if how are you is the least recently used, the one that was used most in the past? right, the optimal and you can prove it's optimal. they're not going go through. the proof is the page get rid of is the one that will be needed longest in the future. and here's an example of optimal where you do n't have nine page faults from that brooks, example. awesome. why do n't we use the optimal one all the time? then yeah, you might not know what is the prettiest. yeah, we're not clairvoyant. we do n't know what's going happen. we do n't know what page is processes are gon na access in the future."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","they're not going go through. the proof is the page get rid of is the one that will be needed longest in the future. and here's an example of optimal where you do n't have nine page faults from that brooks, example. awesome. why do n't we use the optimal one all the time? then yeah, you might not know what is the prettiest. yeah, we're not clairvoyant. we do n't know what's going happen. we do n't know what page is processes are gon na access in the future. if i knew that well, they probably be a whole lot of other cool things i can do. if i can predict the future, so that is the problem, if we do a process is access pattern or all processes access patterns we could know how plan, but we just do n't know how do that. so we ca n't plan. ok. last topic here. ah, this is a slider on trade offs. we kind of just kind of talked about this as we went. actually i do have entered one thing about trade off. there's a bunch of other things in here. enjoy the like hard drive. seek time. but the one thing that i wanna talk about with trade offs because it is currently relevant in today's computing is page size. yeah, do it here. that if we have a large page size like larger than 4 k, right? we have fewer page table entries and and having fewer page table entries is easier for the as far as operating system overhead. as far as page payment size and nice, but the downside of that trade offs is. wasted memory, right? right now, 4096 seems be the standard. it's been that way for a very, very, very long time. there's there's a trend now make them bigger, like 16 k or even making them 16 meg, making them a lot bigger, mainly because we've got a lot more memory now and even the page size bigger, it reduces the overhead of the os, but still keep in mind that if i have a process that only needs 128 bytes of memory, the minimum amount of allocation it's ever going get, you know page. so it's gon na have wasted space, internal fragmentation, wasted space that for data that we allocated the process that it did n't use. so keep that in mind for trade offs."
"""OpSys_Page_Replacement_Algorithms_Transcript.txt""","there's there's a trend now make them bigger, like 16 k or even making them 16 meg, making them a lot bigger, mainly because we've got a lot more memory now and even the page size bigger, it reduces the overhead of the os, but still keep in mind that if i have a process that only needs 128 bytes of memory, the minimum amount of allocation it's ever going get, you know page. so it's gon na have wasted space, internal fragmentation, wasted space that for data that we allocated the process that it did n't use. so keep that in mind for trade offs. the last topic here, i'll kind of just throw this slide in, is called thrashing, and maybe you've heard this word maybe, maybe not. thrashing has deal with the situation in, if we have a process that we need run and it blocks based on io, it's got ta wait. there's nothing for it do. so what we can do is add more processes the system. we've got a process waiting on io. who had another one that does n't need wait for io? well, that guy's got ta wait. prio. now we have another one because of virtual memory and our limit and the amount of memory we have, the more processes we allow enter the system ultimately reaches a point in those processes need do so much memory accesses and they need access that and the paging system and the swap space that now the ios that we're doing, we've become bounded on our page faults and as a result our senior utilization drops because we have more and more and more processes waiting on io doing paging. this is what they're requests thrashing, and there are operating systems out there that actually limit the number of processes that are allowed enter the system based on the amount of memory that you have. we're going talk about those algorithms, but i do wanna mention what this term is because it is kind of important know, ok, so i'm apologize. i went over time, but this ends our discussion of memory management. tomorrow, we're gon na talk about the men and mary, manager programming project and we'll see where we go from there. so thanks for coming. lembke, james stopped transcription"
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","meeting in _ general_-20240422_130442 - meeting recording april 22, 2024, 6:04pm 46 m 17s lembke, james 0:07 ok, hello. so happy monday. where are we at? let's scroll down here the week. it's week 14. two weeks left. he believe it now three weeks. we got finals too, but our finals until thursday. thanks. so we got, we got time. ah, so where are we at right now? we are. it's happy and sad. we're it's sad, at least me, because memory management is my favorite topic and operating systems and we're moving on a new topic. but maybe it's happy because we're moving on something new. but this week is about filesystems. next week, we'll probably also be about file systems. ah, big announcement, though, is who is on friday on memory management. since we finished memory management, so it'll be everything starting from if we can remember all the way back block allocation where we had fixed blocks versus versus variable blocks. the ideas of the different fragmentation types, internal external fragmentation, the allocation schemes, first fit next fit, best fit, worst fit and then into paging and virtual memory and page table, mmu, tlb, all those terms, what they do, what the operating system does and servicing a page fault choosing a victim. this paging and the swap space, all that stuff is fair game for the quiz. everything, even including the examples right of the traces of memory accesses. ones are page faults? ones are not right backs? dirty bits copy on write. wow, there's a lot of topics in memory management, but that's all game for the quiz driving, so we'll have that. we've got file systems going on. i do want reiterate and remind that for the final exam, we're gon na have review on the last day of the semester, that'll be friday, not this week, but obviously next week. and for your preparation mechanisms or mechanisms or methods for studying, i i will say that the final exam will be like a big quiz on paper. no tech with a with a pencil or a pen or something. you are allowed use a note sheet 8 1/2 by 11 max both sides ok handwritten prepared by you. i am not a lawyer. please do n't say, well, you did n't say we could n't do that. please, you know be if you have a question, ask."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","i do want reiterate and remind that for the final exam, we're gon na have review on the last day of the semester, that'll be friday, not this week, but obviously next week. and for your preparation mechanisms or mechanisms or methods for studying, i i will say that the final exam will be like a big quiz on paper. no tech with a with a pencil or a pen or something. you are allowed use a note sheet 8 1/2 by 11 max both sides ok handwritten prepared by you. i am not a lawyer. please do n't say, well, you did n't say we could n't do that. please, you know be if you have a question, ask. i will talk more about that as we get closer the review, so i do n't thoughts yeah study that. uh. best mechanism for studying is going be the quizzes and the quiz solutions. ohh, that reminds me. i got ta post the solution the process scheduling quiz. sorry about that. i will work on that. right, alright. so file systems, let's talk about this. so i posted these notes out here. umm. and you know what? these are out here. you can follow along with them, but what i really want do here when it comes file systems is let's go back drawing a picture here. so we can get this focus. is that pretty clear? that's not too bad. so let's look at the situation here with. file systems and really, i do n't even want talk necessarily about this from the beginning of saying ohh file systems, no right operating systems is and really a lot of stuff in computer science we look at through a lens of knowing where we are now and what i wanna do is kind of look at the world of not the world but look at io hardware a little bit when it comes persistent storage and use that as a motivation for why our file systems are kind of built the way they are and then we'll talk about. the details behind how we can design different pieces of the file system and hopefully that will all sort of progress from one the end. so let's just go back and look at hardware. i'm going draw this picture. slightly differently, though i've done in the past just kind of emphasize different parts of it so. so we have our cpu here, right? and before, when i drew the cpu, i drew it really big."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","file systems and really, i do n't even want talk necessarily about this from the beginning of saying ohh file systems, no right operating systems is and really a lot of stuff in computer science we look at through a lens of knowing where we are now and what i wanna do is kind of look at the world of not the world but look at io hardware a little bit when it comes persistent storage and use that as a motivation for why our file systems are kind of built the way they are and then we'll talk about. the details behind how we can design different pieces of the file system and hopefully that will all sort of progress from one the end. so let's just go back and look at hardware. i'm going draw this picture. slightly differently, though i've done in the past just kind of emphasize different parts of it so. so we have our cpu here, right? and before, when i drew the cpu, i drew it really big. we had the alu and the registers and the program counter and things like that, but if we take all that and we just compress it down into here, i'm now that we know more about memory management. we also have the mmu, the memory management unit that's doing that virtual physical address translation along with the tlb that's storing the page table entries. so that's all in here. and then we have memory. and normally it would drop memory as this big huge thing, but we're just gon na put memory in here and in between the cpu and memory. we actually have this bus, is that that like collection of wires where the address comes through and then memory sends back the data. so we're gon na access data now when we're writing memory, we might have an address and data. that's going into memory, so that's why i drew it both ways in here. in reality, there's actually in between the cpu and memory. there's actually a a memory controller. that's sort of the arbiter for deciding who's gon na be able use memory, and there's this really fast memory controller between memory and the cpu. this in older hardware has be called the north bridge. i do n't really know if they use that word anymore. the reason is mainly because now a lot of cpus kind of have this memory controller kind of built into it. umm but but it used be a separate like ship that was on the on the on the the motherboard and main board of your of your thing."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","that's sort of the arbiter for deciding who's gon na be able use memory, and there's this really fast memory controller between memory and the cpu. this in older hardware has be called the north bridge. i do n't really know if they use that word anymore. the reason is mainly because now a lot of cpus kind of have this memory controller kind of built into it. umm but but it used be a separate like ship that was on the on the on the the motherboard and main board of your of your thing. ok. and then we also connected memory. have oopsies not over here. that about that. forget i drew that and io controller this time is used be called the south bridge, but it's another controller here. that's another kind of arbiter for controlling. although devices on our system and so typically when we want want do something with cpu is accessing memory right, this load store architecture, it's grabbing the data that needs manipulate do math or whatever right? but we have io devices on the system like keyboards. nice things like that. and they also need work with memory and the cpu. i wanna figure out if the user is interacting with something, but it'd be the mouse or the keyboard or something that information has be taken from whatever that io device is, the mouse or the keyboard and be written some place in memory because it refers cpu do anything with our data, it has access memory. if you're look at our instruction set architecture, the cpu does math branching, accessing memory. for the most part. and so that's kind of it. and so if we want access data from an io device, it's got ta get put into memory. so these io controllers kind of help work with that. from here we've got a bunch of different input output devices. we might have. this is gon na be. maybe not the best way dry up, but it will be close enough. usb device from here we have maybe a usb hub where we have our mouse connected or maybe our keyboard is connected this other usb devices. maybe i have a camera for talking my friends over zoom or something like that. right? ok. also this io controller we have other types of io. communication channels. so when i was my first computer, i had a a parallel pata controller was this big fat ribbon cables i used connect my hard drives. now we use slightly something slightly skinnier called a serial. eta, is what's used connect a hard drives."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","usb device from here we have maybe a usb hub where we have our mouse connected or maybe our keyboard is connected this other usb devices. maybe i have a camera for talking my friends over zoom or something like that. right? ok. also this io controller we have other types of io. communication channels. so when i was my first computer, i had a a parallel pata controller was this big fat ribbon cables i used connect my hard drives. now we use slightly something slightly skinnier called a serial. eta, is what's used connect a hard drives. things like that, ok. questions. so what this devices are essentially are different communication protocols or communicating with the different io devices, right? usb universal serial bus sata stands for serial. i think it's advanced. uh tech nology attachment. i have look them up again, but anyway, so we've got different devices that we have connected our io controller. this io controller is essentially an i guess have arbiter for controlling who is gon na be able access memory get its data though. ok, so now here's what i wanna do. i want focus on this area right here. specifically, this guy right here. the idea of a disk drive. you probably have maybe, depending on what computer you have, either a hard disk drive or a solid state disk. regardless of what you have, whether it be a hard disk drive or a solid state disk, these devices, when they communicate over the io are block devices. ok, now we were. uh, when you remember all the way back maybe the first i've heard call it a programming project, but the first project we had, was the windows subsystem for linux setup. i asked him go through and learn a little bit about the different file types on a linux system, and one of those types is a block special or a character special device. ah, essentially it it refers sort of the minimum readable unit of that particular ian device. so a keyboard is a character device in that you can read at all character from it. a hard drive is a block device. it's almost in a way, kind of like virtual memory, where we're gon na read a page, we have read it in terms of a page size, 4096 bytes goes into our frames. our hard drives are blocked devices. memory is a byte addressable device, right? we can address a single byte of memory, a hard drive."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","ah, essentially it it refers sort of the minimum readable unit of that particular ian device. so a keyboard is a character device in that you can read at all character from it. a hard drive is a block device. it's almost in a way, kind of like virtual memory, where we're gon na read a page, we have read it in terms of a page size, 4096 bytes goes into our frames. our hard drives are blocked devices. memory is a byte addressable device, right? we can address a single byte of memory, a hard drive. we have access it in terms of oblock, so if you want think about a hard drive, we think about a hard drive, whether it be a solid state drive or a hard disk drive as an array, not an array of bytes. so we can sometimes think of memory as an array of bytes. so if we were access by its address address 6, that's byte 6in memory, every bite has its own address. a hard disk drive or a block device will call it. this would be something like a hard disk drive or a or a solid state disk. ssd is a block device is essentially an array of blocks. what do i mean by blocks? there are multiple byte chunks. ok, so i ca n't access one bite at a time. i have access a block at a time. how big are blocks and a hard drive or solid state disk well? it depends on how the the devices constructed. typically our block devices are 512 byte blocks. questions, yeah. yeah, that's a good question. right. good. look at that and say why 512 bytes right? that seems what's the motivation behind that size, right? and you ask the question in terms of virtual memory and paging, in that if we have 4096 byte pages and frames. when we are swapping something for memory out the disk. now we have what 8 is that right? 88 blocks that we have write for every every page, right? and the answer there is or does that and the question is really there, does that does that have io sort of? uh. efficiency overheads, speed concerns, right? yes, i'm putting words off and the answer is yes, yes and no. and the reason is because these devices allow you perfectly do blocks, writes and reads in like chunks of them. so you can actually tell the controller here read or write sequential blocks and say i would like write."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","now we have what 8 is that right? 88 blocks that we have write for every every page, right? and the answer there is or does that and the question is really there, does that does that have io sort of? uh. efficiency overheads, speed concerns, right? yes, i'm putting words off and the answer is yes, yes and no. and the reason is because these devices allow you perfectly do blocks, writes and reads in like chunks of them. so you can actually tell the controller here read or write sequential blocks and say i would like write. here is a starting address i would like you write a blocks starting at that address and then the device will actually has a mechanism where it works with this io controller directly access memory and then copy all eight blocks in order on the device. but you raise a really good point in that, and we did n't even know you were raising that point, but. if i want access memory in the cpu, i access memory from the cpu via a load instruction. so access memory. the cpu can issue a load or a store instruction. right. there is no access hard drive instruction. sticks in order access. and i o device like this, what actually has happen is you have sort of work with the io controller and send the io controller a request. so access aio device. requires a creation of an io request. but we're essentially going do is the cpu is gon na have send a mechanism, a message the io controller. say i would like issue a read or write. i'm gon na tell the io controller through one of these protocols device needs get accessed and what do so the io request might say, read these blocks from the hard drive and store them in this location in memory. the io controller, once it receives that request, we'll do the operation and store the results in memory. now in urban the cpu access that data, it can then issue a load or a storm because the data will already be in memory. that makes sense. ok. so it's a little bit different access it's a multi stage thing because these devices are behind this io controller. we have make a request copy data from the device into memory and then we can access that memory. we do not access the device directly. the cpu is not going issue a load from hard drive request load data directly into the cpu."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","now in urban the cpu access that data, it can then issue a load or a storm because the data will already be in memory. that makes sense. ok. so it's a little bit different access it's a multi stage thing because these devices are behind this io controller. we have make a request copy data from the device into memory and then we can access that memory. we do not access the device directly. the cpu is not going issue a load from hard drive request load data directly into the cpu. the first has get loaded from the io device in the memory and then the cpu can load that data from memory into a register or whatever it is. question. so it's all the i / o data stored in the frames is all the idea i odata started in practice well. that's where it's a little bit tricky, right? because the question is, yeah, where is this ultimately stored? it could be stored in operating system memory. that is not really. i mean, it is technically in that case of frame because all the memory is divided into frames. so the short answer is yes, because all of memory is divided into frames. but more specifically, whose is it? is it if a process is accessing a hard drive? well, we do n't really want have processes due direct access io because that's an isolation of protection thing, right? we do n't wanna have one process stomping on something on the hard drive or another process is accessing it, so we need our operating system also be an arbiter. we did not talk ahead of time, but this is helping motivate the idea of a file system and hoping right is we've got these hard drives are an array of blocks, but isolation protection. now i'm starting worry about what do i wanna act? have any process have direct access these io devices? also, as a programmer, i do n't want write my python script and i do n't wanna have sit there and be like, you know what? i do n't i i need. i guess i need learn how say program all works you guys are writing your python scripts. you ever learned? you ever. you ever worry about how the hard drive is connected? you worry about if it's a solid state disk or a hard drive. no, we well in python you say file whatever and you open the file and you say like with file right put that in your python script open up a file, you're opening up a file."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","have any process have direct access these io devices? also, as a programmer, i do n't want write my python script and i do n't wanna have sit there and be like, you know what? i do n't i i need. i guess i need learn how say program all works you guys are writing your python scripts. you ever learned? you ever. you ever worry about how the hard drive is connected? you worry about if it's a solid state disk or a hard drive. no, we well in python you say file whatever and you open the file and you say like with file right put that in your python script open up a file, you're opening up a file. it's not a file that's a ray of locks. so we really kind of nice be a little bit organize things a little bit, because even even if it was, everybody did have direct access the file, the, the ian device. how do you want organize this? alright, where do you want put your data? you're given an array of blocks where it says where the the hard drive would say ok gold, where do you put your data? well, you could just say, well, i got this text file. i'm just in the store it on block zero. it will ever make it needs be ok. all right. what is the next guy gon na do? even if they knew where your file is, are they gon na say ok, you take five blocks for your text file, i'll take the next 5 and then this other guy over here. this other process they get the next five. well, what if i write a bunch of text and then i wanna add more it? do i get the first five and then? well, i ca n't have the next 5 because somebody else has got them. look, i got. i got i got data that needs grow. i'm not even talking about files, just talk about data. i've got my data set that i wanna use train my model. how do i say it? organization becomes a nightmare if i have do this all by myself. so other thoughts, questions. all right. so that's one thing. connectivity. this ian request thing takes a long time. why does it take a long time while personally have do this? it's called bus arbitration, where the io controller has say i'd like write something memory"
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","i'm not even talking about files, just talk about data. i've got my data set that i wanna use train my model. how do i say it? organization becomes a nightmare if i have do this all by myself. so other thoughts, questions. all right. so that's one thing. connectivity. this ian request thing takes a long time. why does it take a long time while personally have do this? it's called bus arbitration, where the io controller has say i'd like write something memory so i ca n't let the cpu be writing the memory at the same time i am because you might step on each other's toes so that sort of arbitration and organization takes some time. the other thing is this. our cpu is operating in the world of gigahertz, so that means that it's executing instructions in terms of nanoseconds. ok, memory a little bit slower, but still perhaps in the realm of nanoseconds. ok. hard disk drives. a hard disk drive. consists of multiple platters. they're actually like magnetic discs. that are all sort of stacked on top of each other and they're spinning around. they're spinning around at like 10,000 rpm, right? that's pretty fast when you think about it, that they're spinning around. but here's the thing. they're literally spinning. that's motion. there's motors involved. there's actuators, right? anytime something actually moves, but there's there's air in there. there's friction, there's air resistance. we can. we can only like spin things around so fast before they build up so much heat that they melt themselves apart. ok, so these things are spinning, but they can only spin so fast. that's one thing. the other thing is we got read data off of here, so there's actually little like wired, not wireless. i guess you call them wires. they're called read heads that move in and out. i'm here read data off this magnetic disk. this magnetic disk, if you can think about a hard drive, is even a small form factor. hard drive might be in terms of inches. and move this thing back and forth from the center all the way the end requires a motor, and i'm not really a motor, but it requires the thing actually move. there's a spring involved in these things. move in and out. they do n't. they move so fast. if we move them too fast, they'll break."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","i'm here read data off this magnetic disk. this magnetic disk, if you can think about a hard drive, is even a small form factor. hard drive might be in terms of inches. and move this thing back and forth from the center all the way the end requires a motor, and i'm not really a motor, but it requires the thing actually move. there's a spring involved in these things. move in and out. they do n't. they move so fast. if we move them too fast, they'll break. and so we model the time it takes move from the inside. the outside is usually on the realm of milliseconds. that what it there might be like 8 or 9 or maybe 10 milliseconds, but that means we can only move this thing back and forth like 100 times. say even if it was one millisecond, that's 1000 times a second. this cpu is doing what nanoseconds, 1,000,000 billions potentially up things a second. that's a large order of magnitude different move this thing around right for think takes a long time. alright, so you can say, what about solid state disks? ssd right sd's are built off of a technology called flash. ok, i'm not gon na pretend know how flash works. i'm gon na pretend know how hard drive works. it is solid state in that there is no moving parts right here. this is not solid state because move things move. this spins these move in and out. flash drives double, but they still based on technology, operate and write in speeds of microseconds. ok, this is milliseconds. microseconds are significantly faster, but even in terms of nanoseconds, it's still crazy slow. so i will request take a while. so that's another thing we have keep in mind that when we wanna read and write stuff this disk drive anytime we're we're we're gon na write. this could take a while, so we wanna make sure that if we're gon na write this, that we really, really have what we wanna do, we have enough data written it because i do n't want write 512 bytes and then try and then do something else. and then the right 512 bytes over again, or shortly thereafter. i really want sort of in a way sue up and write big amounts of data, because this is gon na take a while. but me? all right, so motivation we have got time takes a while."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","this could take a while, so we wanna make sure that if we're gon na write this, that we really, really have what we wanna do, we have enough data written it because i do n't want write 512 bytes and then try and then do something else. and then the right 512 bytes over again, or shortly thereafter. i really want sort of in a way sue up and write big amounts of data, because this is gon na take a while. but me? all right, so motivation we have got time takes a while. we've got i all requests kind of cumbersome we've got. protocols that i do n't wanna learn, we've got an array of blocks needs be organized. and as an application developer i do n't wanna have learn any of this stuff. so operating system, what can we do? what are you guys? wonder what do you think about? ok, so unfortunately now i'm like ohh, it's through the lens, right? i wish i could, like, take the lens of a file system away and say what if you had no folders and no files and you had an array of blocks or forget this and forget this. idle and just say you wanna store data in a world where it would be persistent from an application development standard point. how do you want your data look? i do n't. unfortunately. it's like every time i think about how i want my data look, the only thing i could think of is. lights, because that's that's my lens, right? it's just i look at a text file. what is a text file? it's an array of text characters. if i look at, yeah. a i do n't know a program. it's a rare bites, so this is really what i want. i do n't want worry about a bunch of blocks. i wanna look and say i like memory. really what i'm writing and i'm writing a program i wanna access a variable i i is stored in memory. i wanna load in store for memory, so i want have. data. that i can access from position zero through position n and just. like i'm reading a piece of paper right again, i can set it. when i was i i do n't like read, i like listen audio books. but when i do read, i like read like this piece of paper here, right? across the thing top bottom, left right, whatever. right,"
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","really what i'm writing and i'm writing a program i wanna access a variable i i is stored in memory. i wanna load in store for memory, so i want have. data. that i can access from position zero through position n and just. like i'm reading a piece of paper right again, i can set it. when i was i i do n't like read, i like listen audio books. but when i do read, i like read like this piece of paper here, right? across the thing top bottom, left right, whatever. right, but that's not the way a disk drive is organized. so the operating system develops this. the people that have developed file systems have said, ok, great, this is what an application wants. an application essentially wants an array of data. non real blocks, not an array of bytes but just data. and not only that, i do n't want have one array of data, i want have it be organized categorically. i want have this. this is my file dot txt and this one over here is my grocery list dot txt and this one is my elden ring save file for my character dot whatever it needs be right. i want it be broken up so that i can access just my stuff. i do n't wanna have be able say i do n't wanna look at my text file for my grocery list and read 512 bytes out of it and then all of a sudden read another 512 bytes and never be alden. ring saved file no. i wanna read my entire grocery list, all collected together. right? right. ok, so client. check. the next piece of organization, and i know operating systems that do this. but looking through this lens, you would say, well, that seems ridiculous. but you know, they did n't know what do at the time. files great collection of data, right? we're gon na group this together. each each file gets its own independent array of bytes. let's talk about organization, though. what if you had just one place put all of your files? buying sense, but you do that. yeah, probably. and some operating systems will say we will give you this abstraction of a file, but you only have one wait and it's even hard call it a folder or a directory, because if you have one place, all files are in one big huge pile. and if you want access them, you access them by name. and that's it."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","let's talk about organization, though. what if you had just one place put all of your files? buying sense, but you do that. yeah, probably. and some operating systems will say we will give you this abstraction of a file, but you only have one wait and it's even hard call it a folder or a directory, because if you have one place, all files are in one big huge pile. and if you want access them, you access them by name. and that's it. it's doable, but if you were say physically going my office and open up my file cabinet, i've got a file cabinet in my office and i've used that store old paperwork from previous courses i've taught, right? if i only had one big draw and i had throw all of my files in there. is that gon na be very easy for me bind stuff? so what i do is i've got a i've got a file like what they call like hanging things in there, and i've got different hanging folders in there and i label each one and so i've got swe 2840 from and i put the year on that. and why talk web apps three years ago and inside there are all the quizzes that people did n't pick up. i've got them in there. i've got old exam look at stuff like that all in that file. so if i wanna go back, say, a student three years from now after they graduated, comes back and says ohh, doctor lemke like my quiz from web apps i'll be like oh sure i got that and i go my file folder and i pull out the folder and i pull out the the quiz and i say there you go. where have you been? welcome back. i would smile. so what i'm getting at is while files are good, it would be nice have stood up ok if a file is a categorized organization of bytes, right? so i've got a file that represents all the bytes for my grocery shopping list, and i've file that represents all the groupings of the my saved data for my game. if i have 100 grocery lists, i kind of be nice categorize. all those together are five. got 100 different save games while even say for a particular game i would like move all those together. so if i want a later on, find my grocery list, i do n't have look at this huge long list that includes all my saved games and stuff."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","so i've got a file that represents all the bytes for my grocery shopping list, and i've file that represents all the groupings of the my saved data for my game. if i have 100 grocery lists, i kind of be nice categorize. all those together are five. got 100 different save games while even say for a particular game i would like move all those together. so if i want a later on, find my grocery list, i do n't have look at this huge long list that includes all my saved games and stuff. i can just go my grocery list location. and the world of folder air directory. depending on what operating system you're working with, some places called them directories, some places, called them, folders ok, and so a folder or a directory is ok. grouping of files. if a file is a grouping of bites or grouping of data. a directory is a grouping of files. now windows does n't use this word. linux does, but in linux and i will argue also in windows a folder or directory is also a file. it's a file that points and contains, but how weird? how matter? but the reason i defined it that way is is so that we can ultimately have this idea of folders contained within folders in the physical world. i do n't usually do this. i do n't try and jam a folder inside of another final folder. it does n't always make sense because things have physically fit inside one another, but in a file system, having this idea of categorizing directories with inside directories kind of makes sense. i might have a directory called my games where inside there i've got a separate folder for elden, ring and for terraria and for all the other games that i've played and inside there i have the individual save files for my individual games. another folder might contain. you know my my lists and inside there i've got my do list and i've got my grocery list and i've got, you know, my christmas list or something like that. and then inside those directories i have the actual files. but perhaps are going organization? alright. now that we have this lens here of a file system and data organization. and what we know about operating system so far. what else can we see? what else do we have or do we max ask this for question. do we have other stuff that we might want store or other information about these folders or directories that we wanna worry about?"
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","you know my my lists and inside there i've got my do list and i've got my grocery list and i've got, you know, my christmas list or something like that. and then inside those directories i have the actual files. but perhaps are going organization? alright. now that we have this lens here of a file system and data organization. and what we know about operating system so far. what else can we see? what else do we have or do we max ask this for question. do we have other stuff that we might want store or other information about these folders or directories that we wanna worry about? and if so, what might they be? ok. let's talk about that. i'm going twist your words a little bit. we've got file is a grouping of bytes. we've got a fraud or or directory is a grouping of files, but let's look at this or call it file metadata. what does meta mean? not the organization that owns facebook, and probably in other companies. but what's meta? yeah, reflexive things, right? file metadata data about the data. if the file is a grouping of data, metadata is data about the file is data about the data and of a directory as a file. then you would also have data about the directories ok using that word. so one of the metadata pieces. is file size. this is getting into the idea of what's a little bit more overhead now, right with an operating system, we're gon na have overhead. we have memory overhead with the operating system consumes some of our memory. we do that in order keep track of bookkeeping about our processes. about 3 space things like that. we also have the operating system consuming cpu cycles do things like scheduling or doing some of these protocols. we're gon na have talk about for communicating with our io devices. we're willing accept that overhead now we have another source of overhead, is we've got data that needs be organized on disk, but we also want have information about that data file size. the operating systems got ta store this something, so we're gon na end up with. moreover, at but we'll get there file size, other metadata that you might wanna look might wanna have have track of keep track of. ok. creation time. other stuff. yeah. we invite. i ca n't spell. apparently today access permissions. the thoughts? yeah, that's. ok. we'll call it relationships."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","we're willing accept that overhead now we have another source of overhead, is we've got data that needs be organized on disk, but we also want have information about that data file size. the operating systems got ta store this something, so we're gon na end up with. moreover, at but we'll get there file size, other metadata that you might wanna look might wanna have have track of keep track of. ok. creation time. other stuff. yeah. we invite. i ca n't spell. apparently today access permissions. the thoughts? yeah, that's. ok. we'll call it relationships. i put words in your mouth. hopefully you're ok with it. or hierarchy. when it comes a directory, we'll we'll find that directory has point something. points what's inside it. so we have this idea of relationship a directory points files that are inside. if a directory is pointing a file that's just an array of bytes, that's just a standard file, but a directory might point other directories, right? so we've got that information that will ultimately kind of create this hierarchy or tree structure. there's another really sort of i feel like, i mean maybe kind of it's let's say obvious that it does not explicitly listen listed here, but i think we all take for granted, but it is file metadata. one other question, what the the name exactly right? it's important. we got ta give this thing a name. we got ta call it something. ok, some operating systems also make this a little bit more important than other things as well, but i'll also mention it in here is the file type. like the kind of nice know. now you could say, well, some operating systems, there are very few file types. on linux, there's six. on windows, windows likes make you believe that there's like hundreds, right? each file type has got its own extension right? that one, that three letter thing that indicates whether it's an executable or microsoft word document or something like that. right, and linux. those are all just regular files. umm, but i'm trying leave it generic but type. other thoughts? ok. well, let's take a look here and see what i got in the notes before i forget. so let's go back. alright, so file systems. alright, talked about the situation that we have a disk that is a contiguous array of bytes bytes."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","that one, that three letter thing that indicates whether it's an executable or microsoft word document or something like that. right, and linux. those are all just regular files. umm, but i'm trying leave it generic but type. other thoughts? ok. well, let's take a look here and see what i got in the notes before i forget. so let's go back. alright, so file systems. alright, talked about the situation that we have a disk that is a contiguous array of bytes bytes. we need a mechanism persistently store our data. so and the lens of the operating system, we'd say well, file systems, right? of course we have file systems. well, if we were designing this from scratch, uh, we got ta think about this stuff. so yes, talked about i all requests. here's the idea of a of a block io. so i mentioned the structure of a hard drive and the structure of an ssd. incidentally, this is a cute little article from dell talking about how flash circuitry, like if you read, you can only read and write a flash location so many times before it wears out. i'm not 100 % sure why, but you can read this find out more. so that's another thing think about. also, with magnetic disks, the more these things operate, the more that there's a higher chance failure, right? they are talking about as like the mean time failure, and even if that mean time failure is 100 years, they still will fail eventually. so if we consider the fact that hard drive and ssd, if they're physical things, they do n't last forever, so we have worry about situations where they fail. and you could say, well, well, do n't cpus and memory also fail? yes, but when it comes the world of moving parts, those typically tend fail faster than citation needed. i know 10 fail faster than things that do n't move, but so got that in there. right speed is slow and the world of file. ok, what is a file? what is the four operations? ok, so uh, that's the other thing. we'll talk about that next. ok, what is the file? that's data. what information you wanna store name? do we get them all name, type, size? the location i'm gon na throw out. the one up the conrad with the relationship kind of a thing."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","i know 10 fail faster than things that do n't move, but so got that in there. right speed is slow and the world of file. ok, what is a file? what is the four operations? ok, so uh, that's the other thing. we'll talk about that next. ok, what is the file? that's data. what information you wanna store name? do we get them all name, type, size? the location i'm gon na throw out. the one up the conrad with the relationship kind of a thing. so we got the location as what directory it's in. we'll go with that. the data obviously want store that besides the file we talked about that we talked about some of the things. let's see. we got permissions. ohh creation time. incidentally, some operating systems also store not only creation time, but time of last access as well. so you can know when somebody updated may the last update. so linux extra stories about three different statistics for time, but even so, we got that on there. that's good. yeah. so the other thing here is. while paper there are file metadata but also. file operations. since we're trying look at a client interface or a process or an application work with files, we need store stuff for that file. well, we need allow a process do things against this file operations. so from our lens of the file system, i would say that the two obvious ones are read and write. we're going be able read our data. we got ta be able write our data, but you might look at that and say, well, that's really simple and i would agree with you. but when it comes reading and writing, it gets a little bit more. yeah, it's a complicated but more fine grain say. well, how do you want allow a user read? how do you want allow a process write? do you want the process only be able read and write the entire file? all of the data all at once. you want give them the ability read and write smaller pieces, and if so, how small of a piece do you want? are you going require that they read or write in order from the beginning of the file the end, or are you gon na let them read or write in a more or less random access?"
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","well, how do you want allow a user read? how do you want allow a process write? do you want the process only be able read and write the entire file? all of the data all at once. you want give them the ability read and write smaller pieces, and if so, how small of a piece do you want? are you going require that they read or write in order from the beginning of the file the end, or are you gon na let them read or write in a more or less random access? all these things kind of affect how we're gon na design our file system, how we're gon na design, where our blocks are gon na be placed on disk because ultimately we have an array of blocks and we've got all of these different files. we've got all these different directories, all this metadata that we need store there, because as soon as the user turns the computer off, anything that's in memory or in the cpu is gone. so we ca n't just store all this stuff in memory because we can not do n't wanna lose our files. i will be honest with you as much as i like play my games. if my games let me save my character, i do n't wanna start over every time i turn my computer on. i wanted persist so other operations that you can think of that we might want do. load. say that again. what do you mean by load however? like move the data from the actual file or from the actual that move the data from the files the cpu. ok, well, all right. i like that. that's kind of read, but you did say move. that's a big one, right? if i have a file physically a piece of paper, i wanna be able move it from one folder another or just take it out so move. delete. i was waiting for that. happy. other things, yeah. yeah. rename. rename. i'll throw this one in there because there are a lot of time. change permissions. was that what? sure, view permissions. let's go my notes. create, find, read, write, delete manner. i called it manage permissions. that's like the un change. i was kind of cheap, but no wait renamed no others. there's probably others, but i think this is good a lot of time here getting divorced, but good introduction."
"""OpSys_Paging_and_Copy_On_Write_Transcript.txt""","other things, yeah. yeah. rename. rename. i'll throw this one in there because there are a lot of time. change permissions. was that what? sure, view permissions. let's go my notes. create, find, read, write, delete manner. i called it manage permissions. that's like the un change. i was kind of cheap, but no wait renamed no others. there's probably others, but i think this is good a lot of time here getting divorced, but good introduction. the next stage is now that we know what we want and i may have, so put some words in your mouth, how do we get this work in a world where all we have is io requests and block devices? so that'll be topic for next time. thanks for coming. lembke, james stopped transcription"
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","meeting in _ general_-20240411_130251 - meeting recording april 11, 2024, 6:02pm 48 m 13s lembke, james 0:09 hello. hello. great. all right. so where are we at? welcome operating systems. ohh. isolation and protection abstractions are cool. yeah. good. so what do i got for announcements? uh, yeah, not a whole lot. for this week in cannabis at least, we've got a quiz on friday, so unprocessed scheduling. so knowing your terms and your arithmetic born turn around time and wait time and. uh service time and arrival time and response ratio as well as the different algorithms preemption, not preemption and fairness, be be able be able kind of give good opinions as what is fair io intensive co cpu intensive, what that means. so that's gon na be perfect for friday quiz, same as other quizzes format wise. bigger head was due. i'm still really close being done grading on that one, so i'll post those grading as soon as they're ready and we got in the process simulator out there so fully that will be going going well. let's see. i've had several ask this question. i willing announce there will be one more programming project after the process simulator, so just be ready for that. we're not gon na have two or three or four whatever, but they'll be one more. and that as far as quizzes are concerned, not 100 % sure. will probably have at least one more after this one, probably 2, so that will give you an idea there. and then we'll have the final exam. obviously that's on thursday. ok. so what we talking about? memory management, right? and i kind of motivated this idea of the problem that we ran into with allocation and we had. this idea of memory allocation or wiki you do flip fixed or dynamic blocks and i like fixed blocks. the they're easy manage. they're bad because of internal fragmentation and not able even just figure out what process you can run. i like that dynamic allocation because it allows variable memory, but i do n't like it because we get all these external fragmentation holes that we have manage. so i'd like find a way do the best of both worlds. and so i motivate this idea of paging where we are gon na be. do i like call it the great process?"
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","this idea of memory allocation or wiki you do flip fixed or dynamic blocks and i like fixed blocks. the they're easy manage. they're bad because of internal fragmentation and not able even just figure out what process you can run. i like that dynamic allocation because it allows variable memory, but i do n't like it because we get all these external fragmentation holes that we have manage. so i'd like find a way do the best of both worlds. and so i motivate this idea of paging where we are gon na be. do i like call it the great process? memory fake out talked about file descriptor fake out or file descriptor io redirection where a process might think it's reading from standard input, is the keyboard, but we can redirect the file descriptor using doop make it appear like it's coming from somewhere else, like a file or the other end of a pipe. i'm her tsh with pipes. everybody's second or third, well, we would talk about labs are your favorite or programming projects are your favorite. we'll just say they are what they are, right? so we you redirected files and sort of faked out processes using file descriptor redirection. we're gon na do something similar that, only we're gon na use memory address redirection. ok. and so i'm motivated. this idea of a perfect world and paging and then got. this idea of swapping where if i have a note that's keeping track of the things that i ca n't actively think about, i actively thinking about blue, red, and green, and i've got a note that's keeping track of these other two where they are now. we have the ability move things around. i can take things out of memory, write them on the note and store them somewhere else. and then bring them back in later on when they're accessed, but they might move around. ok. and that's a problem. so how do i find a way allow a processes pages be moved around? and not have it cause problem in the process address processes accesses ok. furthermore, this example here. i want you make sure this works because we think about this. ok, even if we're using block allocation, right? something simple fix block allocation when a parent process here has a variable i and it barks. the child process is an exact copy as far as memory is concerned. copy of the pair in a different place in memory. they do not share anything, right?"
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","so how do i find a way allow a processes pages be moved around? and not have it cause problem in the process address processes accesses ok. furthermore, this example here. i want you make sure this works because we think about this. ok, even if we're using block allocation, right? something simple fix block allocation when a parent process here has a variable i and it barks. the child process is an exact copy as far as memory is concerned. copy of the pair in a different place in memory. they do not share anything, right? we talked about this over and over again, parent and child processes do not share memory. it must be used shared memory, but that's a whole different inner process communication method. by default they do n't share memory. there's separate copies, so i use in memory somewhere in the parents. the parent is copied a child process and so my print out the address of i. i would expect the parent process have a different value than the child because they're in a different place and memory, right? but when i run this. i do n't get that. how is this even possible? and so the answer is. the great process memory fake out, is not the actual like proper name for it, but the name i use and that's essentially called paging. and so here's what we're gon na do. ok. the operating system and some hardware help is gon na make this happen. we are going let processes live in own world. they are thinking, just like with the file descriptor fake out, right? but you might access a particular address or access a particular file descriptor for standard in, so processes are going live in the world of a virtual address world where we are going let processes give the appearance that they are accessing all of memory. we're gon na say processed. you get have all of memory access. ok. but physically, that's not actually what's going happen. ok, so we have a physical address. we have a virtual address and we're gon na let a process live in its virtual address world, ok? so how do we do that? it was this example i gave. we were dividing memory into chunks. and living a process address space into chunks and putting those chunks inside memory. so let's do an example here. here's what i want do, just make it."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","ok. but physically, that's not actually what's going happen. ok, so we have a physical address. we have a virtual address and we're gon na let a process live in its virtual address world, ok? so how do we do that? it was this example i gave. we were dividing memory into chunks. and living a process address space into chunks and putting those chunks inside memory. so let's do an example here. here's what i want do, just make it. more mathematical, let's just let's just do this example here and we'll walk through it and we'll see how well this works conceptually. and then how we can actually do it in software and hardware so. physical memory. ok. we are going set a size of a page. be a particular value. in this case, i'm going use 4096 bytes. why? because that's pretty much the de facto standard that we use for most operating systems is they use 4096 byte frames. some allow larger than that and it just makes the math actually not. not too difficult do use the same use that number. let me just focus a little bit more. so now we take all of physical memory and we divide it into chunks. remember, this is that fixed block allocation. i really liked fixed block allocation because it was simple manage. so we're gon na divide our memory up into these fixed size blocks of 4096 bytes. ok. we'll just keep going here, alright, so now we have block 01234567891011. so on and so this distance is 4096 bytes. so the address of block 0 is 0 two 4095, the address of block one is 4096 through 8191 and then the block two is 8192 whatever that is. i ca n't remember do the math in my head so right with me on that. ok, this is physical address. we're going have the operating system consume some of this, so maybe the operating system is gon na get this one, this one, this one and that one. so the os is gon na take four blocks. ok, the remainder of this of physical memory. sorry, maybe get rid of that is reserved for putting processes in moment ok. done. let's make a process. so here's a process p0, right? it's going need some memory."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","ok, this is physical address. we're going have the operating system consume some of this, so maybe the operating system is gon na get this one, this one, this one and that one. so the os is gon na take four blocks. ok, the remainder of this of physical memory. sorry, maybe get rid of that is reserved for putting processes in moment ok. done. let's make a process. so here's a process p0, right? it's going need some memory. we're going make this more generic later on, we'll processes can use an dynamic amount of memory, but for now we'll just assume that processes have specify how much memory they need. ok. so just for the sake of example, here we are going need 3 pages. so that means that p zeros address space consists of page 01 and two so. with fixed block allocation. a process can use multiple, well, nothing in in paging a process is allowed use multiple pages. multiple blocks in fixed block allocation. they were n't. it was you get a block here, you get as many pages or many blocks as you need, but you have use a multiple of blocks, a multiple of pages. you ca n't use 1 1/2 pages. so this process we're gon na need 3 pages. and so we're gon na just number them 01 and two. so now the operating system let me use green for this here, just represent p0 will be green. we'll say i need allocate this process. i'm going put page 0 in this place, page 1 here, page 2 there. they're not the next three blocks and not initially. now we're going put that there. ok, so this is the physical location of the page of the pages. the process itself thinks that it's accessing all of memory, can access all of it. now it does n't mean that much memory, so it really should only access the pages that has allocated. so this is where all of its text data even stack are all going be inside these 3 pages, right? that's what this process said it needed. ok, so now we let this process execute ok and a process when it executes on the cpu is going execute an instruction screen, right? that instructions stream will consist of mathematics and multiply and divide instructions and load and store instructions amongst any other number of the cpu instructions that are process is allowed use do computation."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","now it does n't mean that much memory, so it really should only access the pages that has allocated. so this is where all of its text data even stack are all going be inside these 3 pages, right? that's what this process said it needed. ok, so now we let this process execute ok and a process when it executes on the cpu is going execute an instruction screen, right? that instructions stream will consist of mathematics and multiply and divide instructions and load and store instructions amongst any other number of the cpu instructions that are process is allowed use do computation. things like branching for doing loops and jobs and stuff like that, but for the most part, the thing that i'm concerned about because it's the memory management topic is when that process needs access memory. so access memory we have two mechanisms we can load from memory at an address, and we can store a value in memory at an address. ok, the process lives in virtual address world. it is going access an address that it thinks that it's gon na access, so something from its data section. it's going issue something like. a fetch we want access something from the text section, so maybe we've got our text up here and we're gon na load from something like address 1024, because that's what the compiler is going generate, right? because this is hard coded. essentially, when we write our text section is in our text section of our program. the compiler generates this the the instructions that need execute the load where it's gon na load from, and so this is where it's weird because the compiler is gon na generate. i would like load from address some number fetch instruction. the program does not know where it is in physical memory. it could be put here, but later on when we run another process it might get put in a different place in physical memory. so this is where the virtual the physical address translation comes in. ok, we issue a load for 1024. question. what page is 1024 in in the process's address space? it's the first page is page # 0. how do we know that since it's within the 4096 lower than it? so right it does. if this is the process of address space and it goes from zero and uses up 3 pages but maximum address that are processed should ever access is 4096 * 3 -, 1, zero base, because of course we always start coming on zero and the smallest address. that shower access is 0."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","what page is 1024 in in the process's address space? it's the first page is page # 0. how do we know that since it's within the 4096 lower than it? so right it does. if this is the process of address space and it goes from zero and uses up 3 pages but maximum address that are processed should ever access is 4096 * 3 -, 1, zero base, because of course we always start coming on zero and the smallest address. that shower access is 0. so i was doing the loan from 1024 and 1024 exists in this page because the address range in virtual address world goes from zero 4095. it's inside this page. so this is accessing page 0. this is the. va the virtual address. oops. of that. but that that load. ok, so one way we can do this is we can know that this goes from zero 4095. the other way is use integer division. right. because if i wanted load from 6000 something something 6000 / 4096 right that that range of addresses in page one is 4096 81 thousand 8191.81 thousand 8191 or we just take it and we divide integer division by 4096 and we get page 0. question where is page 0? hold it. what block? four. ok, so we have that note. remember the note i mentioned in the example here we have a. note that is essentially an array here that indicates what frames. so these are frames. oops, i mean the wrong color. the operating system is consuming frame 012 and three and the rest of her processes. so this says that page 0 is in frame 4. this says that page one is in frame 5 and that page 2 is in frame 6. this is essentially going be the page table for the process that indicates what frame. each page is in ok, so we have frame. we have page 0 and we're gon na figure out what frame it's in. that's gon na be in frame, uh form. so now we have figure out what is the offset inside the frame that we're accessing. well, in this case the offset is 1024 mod 4096 cause it's our leftover is 1024. this is our page. this is our offset in that page. with me. because we know that when we access a location within a page, the offset in the page 1024. in this case, is the same as the offset in the frame, right? because the memory location now here is the same as, it's against."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","so now we have figure out what is the offset inside the frame that we're accessing. well, in this case the offset is 1024 mod 4096 cause it's our leftover is 1024. this is our page. this is our offset in that page. with me. because we know that when we access a location within a page, the offset in the page 1024. in this case, is the same as the offset in the frame, right? because the memory location now here is the same as, it's against. what's one order of the way into the page? ok. so then they determine the physical address. all we do is we take because the frame size and the page size of the same, we take the frame number, in this case four times the page size of 4096 and we get 16,384 and then we add the offset get down the physical address one 16384 + 1024 is what 17,000? the 408 i think. and this is the actual real address that we are gon na access invisible memory, right? all right. let's create another process now. he won. he won needs 4 pages. ok, here is we got ta make a page table for p1. 012 and three it's gon na need 4 pages, 012 and three when the operating system is going allocate using block allocation allocate a - frame, it just says alright, you get the next 4, you get 012 and three and your page table. then we'll say what page 0 is in frame. seven page one is in frame eight page 2 is in frame nine and page 10. uh sorry. page 3 is in frame 10 and now this process also issues a load 1024 ok why we say well wait, how is that possible? how can it load the same address? but p1 has text right? and the compiler, if it's using the same compiler, chances are it's going compile the text and put it in the same spot. because the the program itself that generated by the compiler has a tech section and it gets voted essentially just at the text sections, all the process and its address space, we're going let all processes assume that they're text is in the same spot in the same virtual address space. all processes get access all of memory in own virtual address world. he won. should not know of the existence of p0. i remember."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","and the compiler, if it's using the same compiler, chances are it's going compile the text and put it in the same spot. because the the program itself that generated by the compiler has a tech section and it gets voted essentially just at the text sections, all the process and its address space, we're going let all processes assume that they're text is in the same spot in the same virtual address space. all processes get access all of memory in own virtual address world. he won. should not know of the existence of p0. i remember. so our page table in this space is going protect the one from p0 and vice versa because they will be only able access own virtual address space. so doing this math a load is still page 0 and this is an offset of 1024 still ok, but the difference here is page 0 is we look up in the page table is in frame 7. so do the physical address space translation here physical address, we need take 7 * 4096 + 1024 and that's gon na get us. i did this math already 29,696 will access somewhere down here. a different place in physical memory, despite the fact that it thinks that it's accessing the same virtual address. questions. ok. let me ask you a question. these processes allocated storage say the operating system of this identity, 3 pages and four pages, right? what happens? when a process. like this tries access a virtual address like. i wanna do a load from 32,769. yeah. i'll second look and see the operating system and the processor and with whatever going on here. it's just issuing the low right in this case, like operating system is n't running, it's this client process, a client. it's the process running in user space user mode. so if we were just take this and attempt do the math that we did, this ultimately becomes. 32769 divided by 4096 is 8.000, but integer division. this is page 8. and i covered that up. so anyway, there we go. come on. there we go. so consulting our page table, first hydrate. it's nowhere so. this essentially says page 8 does not exist. process you are trying access memory that you do n't have allocated. you are essentially trying access an invalid memory address. this number, address, pointer, whatever. it's just a number."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","so if we were just take this and attempt do the math that we did, this ultimately becomes. 32769 divided by 4096 is 8.000, but integer division. this is page 8. and i covered that up. so anyway, there we go. come on. there we go. so consulting our page table, first hydrate. it's nowhere so. this essentially says page 8 does not exist. process you are trying access memory that you do n't have allocated. you are essentially trying access an invalid memory address. this number, address, pointer, whatever. it's just a number. it does n't mean anything specifically, while it means where in memory we're going access, it only means something the processor or the win. it actually uses that number. so in a time do the load, it found that it's goes page 8. if we look up at our page table, there is no page 8 and that's an invalid memory access and we get essentially segmentation fault. so something that see. ok, let's go on. kick it up a notch here. i got green dumb. process 0 terminates the operating system. says great, you're done. and we're going consume the memory for this. we're gon na take our bitmap of free pages and just put that 0. so this marks that they're free, just like mentioned for block allocation. fine. we can clean up all of this stuff he won as part of that instruction do the load. maybe that was a fork. ok, you could say. all right. well, what do we do during a fork? we copy a process of address space, so we're gon na run p3 here now. is going be a fork of p0. here's my pork. and then there's p3kp3 is gon na get a copy of p1. remember i mentioned that idea of i and the address of i in that example. i is when one of these 4 pages from p1p0 yeah p1 maybe it's in page 9, maybe it's on page 8. it does n't make a difference, but we know it's somewhere in this address space and it's virtual address is some number. maybe it's 1020, do n't know what it is. some number, ok. so let me use blue p3. it's gon na have pages 012 and three, are copies of p1. the operating systems got put them somewhere. it's going put him in a free frame."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","i is when one of these 4 pages from p1p0 yeah p1 maybe it's in page 9, maybe it's on page 8. it does n't make a difference, but we know it's somewhere in this address space and it's virtual address is some number. maybe it's 1020, do n't know what it is. some number, ok. so let me use blue p3. it's gon na have pages 012 and three, are copies of p1. the operating systems got put them somewhere. it's going put him in a free frame. we got a couple of free frames up here so we can put 01 and two and now you could say, well, we're out of space. we ca n't allocate, we ca n't fork. well, we are n't. we got more space, we got space down here. so let's put page 3 here. because, say, we ca n't do that. doctor lembke pages have be contiguous in memory. with paging and a page table, they can be in different physical frames so long as the virtual address space is contiguous. pages are contiguous. they're the table 0123. that's good. that you s012? i can make a continuous page table. 0123 there contiguous done be like and you could look at that and say wait wait that that's not correct. no, that's correct. the difference is the part that makes this cool is what frame this is in what frame is page 0 in. what frame is page one in? what frame is page it? what frame is page 3 in 11? frames do n't have be contiguous, but virtual addresses bus the. but when i'm doing the virtual physical address translation, if i want load from something like. uh, 15,000, when we do the math, loading from 15,000 is somewhere in page 3. it's this continuous right? the 012 and three those pages are contiguous. when we figure out what frame it is and do the math of frame times page size, now we get 11 * 4096 instead of what it was. but it would have been, had it been in brave 7. so my initializing the page table just do n't look up, it's just an array. the value that's stored there, we can just look it up. that's not that hard. and then when we do the math, we ultimately get a different physical address. but it's a correct value."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","when we figure out what frame it is and do the math of frame times page size, now we get 11 * 4096 instead of what it was. but it would have been, had it been in brave 7. so my initializing the page table just do n't look up, it's just an array. the value that's stored there, we can just look it up. that's not that hard. and then when we do the math, we ultimately get a different physical address. but it's a correct value. so despite the fact that pay that p3 is a fork is a copy of p1, the value of where i is physically located is in a different place because both p3 and p1 are. living in own virtual address world, they both think that i is at the same address. in this case page maybe page 3. makes sense. questions. paging. i love it. so what else do we get out of this? right. i mentioned this right? this idea, and if i try load something that is outside my address space, i get a segmentation fault. the other thing that i kind of like about this too is protection. every process can try and load from the same address, and they're only going get values. with this, there's no possible way for a process access any other process, because the soon as it tries do that, it's gon na be referencing a page that's not its right. i need know like how you would figure out a way using this math or p3 access p0p0 was still in memory our say they have p3 access p1. there's no way of getting three get access frame 7 - 8 or 9 or 10, because if we make it so that p3 ca n't access this page table in this, living in its own virtual address world and ca n't access physical memory directly. for isolation protection like isolation protection, that's core. so questions, let me make it a little more clear. maybe then, before great i like. i like numbers. i like my examples. yeah. questions. so when you're dating process, there's no like code. you can write it. is it called cover like requests and physical address spaces? you are like complete amounted what's in virtual. yeah. no end it would like. yeah, you know, i i look at those cause i'm like someone's gon na ask this question."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","so questions, let me make it a little more clear. maybe then, before great i like. i like numbers. i like my examples. yeah. questions. so when you're dating process, there's no like code. you can write it. is it called cover like requests and physical address spaces? you are like complete amounted what's in virtual. yeah. no end it would like. yeah, you know, i i look at those cause i'm like someone's gon na ask this question. like can i figure out is there a system call that will tell me where my pages are and what frames they're in? and i could n't find anything. there's some system administrator functions where you can kind of do some stuff get information about your memory dimms figure out what we are. but, but you ca n't. this is the isolation for tection thing. umm. so yeah, there is a there is a a memory map like system file that you can maybe but i it does n't give you what you want. i tried find them so at least in linux, maybe you can in windows. yeah, this is. this is new processes leave and virtual address slope. ok, alright, so let's go on here and let's let's look at the notes and make sure miss anything. ok, so mention this, this idea that we're gon na compress virtual memory that compress but make it some virtual memory is from the us. so here's an example of a two page process and the offset in the page is the same as the offset in the frame, so we set the page size equal the frame size and then the page off size is the same as the frame offset. and then here's our computation of how they're convert from a virtual address a physical address. we compute the offset, figure out what frame is in. multiplies the frame times the page size and then the offset. ok, this is just i like having the arithmetic algebra. i did n't learn mod when i learned arithmetic. i do n't like. i do n't know if you call that or. i guess it's probably from like the remainder. all right. so then here is another example. the page table is that notebook that we're using and so it's just a lookup. we figure out what the page is looking up in the in the in the page table. figure what frame it's in, and then do that now get the physical address."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","ok, this is just i like having the arithmetic algebra. i did n't learn mod when i learned arithmetic. i do n't like. i do n't know if you call that or. i guess it's probably from like the remainder. all right. so then here is another example. the page table is that notebook that we're using and so it's just a lookup. we figure out what the page is looking up in the in the in the page table. figure what frame it's in, and then do that now get the physical address. so here is my question. let's go back my picture. well, i got two questions. question one. who's doing the virtual physical memory address translation? and i mean, who makes it sound like it's a person? in this case i did it, but i'm not doing it for all of your computers. i could n't do it really fast enough. ok. so operating system can the operating system do it? ok? i like that you jumped right there because the the first initial intuition is why do n't we have the process do it? and the reason i do n't want the process do it just go there for a second is, yeah, the process is doing vertical memory. address translation. that's fine, except in order do that now the process needs have access physical memory because it's gon na need have access the page table and i do n't wanna do that because that could potentially break isolation and protection. so i do n't want the process do it and so the next answer you guys all jump. thank you. is the operating system ok? let's think about that for a second, ok? because that's a good answer. the operating system token order for the operating system run. how does that work? how do we give the operating system run assistant call right, ultimately goes through the trap mechanism and again the depending on what your cpu architecture is, you might have different mechanisms execute the trap, but we talked about using the syscall instruction and so we could do that. we could have every single load instruction where we're loading from a virtual address, invoke a trap, have the cpu switch the system mode, load the trusted operating system entry fund, and treat this load instruction like a system call. then the operating system would then essentially do the virtual and physical memory address translation, since it has access all of memory, load the actual value into the register, and then return the user process, right?"
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","how do we give the operating system run assistant call right, ultimately goes through the trap mechanism and again the depending on what your cpu architecture is, you might have different mechanisms execute the trap, but we talked about using the syscall instruction and so we could do that. we could have every single load instruction where we're loading from a virtual address, invoke a trap, have the cpu switch the system mode, load the trusted operating system entry fund, and treat this load instruction like a system call. then the operating system would then essentially do the virtual and physical memory address translation, since it has access all of memory, load the actual value into the register, and then return the user process, right? how many instructions does that? what is the overhead of doing a trap i i did n't mention like absolutely what that number is? how many microseconds are being towed? it is a non zero amount of time and just put it out. so while that is feasible, if patient see essentially what we just did is we turned executing a single load instruction into executing a lot more. ok, you could say, oh, that's fine. it's we have pay that penalty. how many times does a does a program issue a load instruction or a store instruction? if it's an iowa intensive process, well, iowa is not very likely. but if it's a memory intensive process a lot. we're moving things around between memory often so visible. yes, efficient, not great. and so the next question is can we do better? and i would n't ask you ask that if it's the answer was n't yes, but we're we're gon na cheat. ok. the the operating system and the processor designers said. we like this idea, but we do n't like the idea of the operating system doing it because, well, we do like the idea of the operating system having control over the page table now, this, this, this whole like traveling, getting out is just in iran for every single load or store, it just is gon na work even at the very least you could be like, well, we have do a load fetch instructions, and that alone is a lot of work. so here's what we're going do. how about we just have the processor do this and we make this page table thing head up part of the cpu context? so we're gon na have the hardware doing and it's it. wait with the hardware is going do all this math."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","we like this idea, but we do n't like the idea of the operating system doing it because, well, we do like the idea of the operating system having control over the page table now, this, this, this whole like traveling, getting out is just in iran for every single load or store, it just is gon na work even at the very least you could be like, well, we have do a load fetch instructions, and that alone is a lot of work. so here's what we're going do. how about we just have the processor do this and we make this page table thing head up part of the cpu context? so we're gon na have the hardware doing and it's it. wait with the hardware is going do all this math. is n't that take time? this is what's really cool. ah, it was awesome. ok, math is hard. hardware is easy. what? no, let's look at this. ok, the result, the page size equal some power of two. this is why the page size needs be power of two for this work. awesome. ok, if it was n't a power tube, you have injure division and that that it is what it is. but if it is a power of two, integer division becomes a lot easier. so what we 1096 is 212. you can take my word for it. right. the number of bits that is necessary represent this is, well, this through involve requires 12 bits. so what we can do is whenever we need translate an address. here's our 64 bit address that we're translating, doing the math, the offset into the page is the lower 12 bits. and i mentioned that we're gon na add this offset on later on once we figure out the frame number in terms of hardware, this is just routing wires. so we think about our connection of our cpu memory. we have a memory bus is a just a bunch of wires where the address that was an address line where all these wires, these zeros and ones. essentially, these signals of a higher low current or higher low voltage go into the memory controller indicate 0 or one for the offset. we can just take those lower 12 bits and wires and just shoot them right over. you're right, mode from this offset. and then the rest of the bits represent the page number and so integer division just the way it works out."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","we have a memory bus is a just a bunch of wires where the address that was an address line where all these wires, these zeros and ones. essentially, these signals of a higher low current or higher low voltage go into the memory controller indicate 0 or one for the offset. we can just take those lower 12 bits and wires and just shoot them right over. you're right, mode from this offset. and then the rest of the bits represent the page number and so integer division just the way it works out. and we can then take the page number, jam it into the page table, figure out what the frame number is and just jam it there. we do n't actually have do any math. we just reroute wires. this is why it's pretty cool do it in the hardware. so what we're going do is we're going create a special piece of hardware that will do virtual physical address translation for us and then tell the cpu the page table. and when it's running in user mode, every single time an address shoots out, where executes a load instruction, the hardware with inside the cpu will access the page table and just jam in the frame number and just access that memory location unbeknownst the process. but what's actually being sent the memory controller? makes sense. pretty cool. we can do that relatively efficiently and not have the operating system get involved. so now some terms, ok. address translation hardware. the m and you i do n't like this name, but that's what the standard is. it calls this. what does mu stand for? it stands for memory management unit and why do i not like this? because it does n't actually manage memory, i think a memory management as things like creating the page table, assigning pages frames, that's memory management, the memory management unit is the piece of hardware that translates virtual addresses physical address and. so that was member the first question i had is who's gon na do this translation? and we say now the answer is the mu does n't. the second question that i thought i was gon na get. where is the page table. where's the page table in my picture? it's in the process. well, it's, it's. it's nowhere or se, right? i said. here's memory over here. this is no. this is my notes. this is my handwritten chicken scratch right? the page table is here. this is kind of been like la la land."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","and we say now the answer is the mu does n't. the second question that i thought i was gon na get. where is the page table. where's the page table in my picture? it's in the process. well, it's, it's. it's nowhere or se, right? i said. here's memory over here. this is no. this is my notes. this is my handwritten chicken scratch right? the page table is here. this is kind of been like la la land. it's nowhere. we ca n't have a page table in lala land in our actual computer we need put it somewhere. so where do you want put it? ok. couple of things. couple of stories someone said mu. well, someone else said memory. process control block that's located in operating system numbering. i like the that nobody answered. we'll put it in the process wright, isolation of protection. we do n't want the process have access the page table so. because this is essentially dynamic incise, we do n't really know how many pages that process is gon na need until it tells us. this is going go in memory somewhere. hardware is fixed. we got ta we'll have so much hardware. so we're gon na put this in memory. why is that a bad thing? yeah, you have not only get the memory that the process transmits, but also get the memory of the table, is too slow. operations. yeah, that's great. so this picture. if the page table is in memory and i miss you in a load or store, i got ta issue though i got ta load that right cause the the user wanted do a load or store, but the access the page table at the page table is in memory. now i have access memory load the page table entry that i need in order figure out the frame number. so it can actually do the translation, so i can do the loan of the store. i've turned two one memory access into two and one memory access is slow enough. now i got ta do 2. following solve this, it's not a great way solve this. i do n't think it's awesome way solve it, but this is the way the hardware designers said. we're going, we're going make a cash. we're going put storage inside the cpu, then we're gon na use store page table entries."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","so it can actually do the translation, so i can do the loan of the store. i've turned two one memory access into two and one memory access is slow enough. now i got ta do 2. following solve this, it's not a great way solve this. i do n't think it's awesome way solve it, but this is the way the hardware designers said. we're going, we're going make a cash. we're going put storage inside the cpu, then we're gon na use store page table entries. so when a operating system goes run a process, what it's gon na do is it's gon na have load the process context. things like the program covered the contents of the registers. all that stuff and then it's going populate this cache with page table entries. a context switch is a highly enough operation, so we're gon na we're willing pay this price load all these page table entries into the cpu. it kind of as a prefetch load all those in there once they're in there, they're gon na let the cpu run and they can just access the book cache located within inside it access the page table lectures. there's little ok little cash is called the tlb, stands for translation. lookaside buffer? people often just call it the tld, and they're even really consider what it's called because i do n't really know that this name makes a lot of sense either. but that's what it's called. it's a little cash with inside the mu that stores the page table entries. so the so the person that so sabryn who has answered never, that's true. we got ta put the page table in memory because every process has own and we ca n't just. we do n't have enough room in the processor store it all, but the person who answered ryan answered. mu is also correct because mu has a tlb stores copy as a page table entries or whatever process the cpu is currently executed. the pain. where is my. i do n't like like that, so i'm gon na stop talking. idiot. i'm saying makes sense. ok, so we got that. lastly, before we talk about the next piece, is a still something that's frustrating me, i'll processes do n't know how much memory they need when they're running, when they start running, we will fix that."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","mu is also correct because mu has a tlb stores copy as a page table entries or whatever process the cpu is currently executed. the pain. where is my. i do n't like like that, so i'm gon na stop talking. idiot. i'm saying makes sense. ok, so we got that. lastly, before we talk about the next piece, is a still something that's frustrating me, i'll processes do n't know how much memory they need when they're running, when they start running, we will fix that. next is the page table entry itself in the last two minutes here, we're not going finish this, but we'll start. is a page table entry. this eventually it addressed size, so each entry in the page table is going be 64 bits. ok. but. this offset, if you remember from the virtual or physical address translation, is straight through straight sent straight through the memory controller. so these lower 12 bits, we do n't actually need the store. there's no way that we're ever gon na have a frame number that's greater than this number that can fit in 64 -, 12 bits, 6052 bits. despite how much memory we could have, you might say, well, we might have more memory than that. if i have enough memory where the frame number was bigger than the map, i'd be happy do the math and figure how much memory that would be. so let's not worry about that, so. we have 12 bits. we can use the store stock. you could say what are we gon na do in 12 minutes? protection. we have the ability now port values inside the page table gets loaded in the cpu. that allows us do additional isolation and protection. we can actually protect a process from itself and be like, wait a second and i'm going want take a process from itself. and i'll leave it with this, with the moments in time does n't process. should a process ever be allowed do a store instruction its text? should have process ever be allowed do a fetch of an instruction execute from the data section? i do n't really think executing data is a good idea from a processor perspective. everything is just a binary zeros and ones, so a particular value of a variable i = 10 could be translated as an instruction. if you look at it in a different way, i do n't want allow that happen."
"""OpSys_Paging_and_Virtual_Memory_Transcript.txt""","and i'll leave it with this, with the moments in time does n't process. should a process ever be allowed do a store instruction its text? should have process ever be allowed do a fetch of an instruction execute from the data section? i do n't really think executing data is a good idea from a processor perspective. everything is just a binary zeros and ones, so a particular value of a variable i = 10 could be translated as an instruction. if you look at it in a different way, i do n't want allow that happen. so by setting bits inside the page table, i can tell the cpu do n't ever let an instruction fetch come from this address. do n't ever let a user issue a store instruction this address. if you do like you let the operating system know, because that process did a bad thing. ok. so we'll talk about other stuff later on, but for now i'm out of time, so thanks for coming and we'll see you tomorrow. lembke, james stopped transcription"
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","meeting in _ general_-20240212_130158 - meeting recording february 12, 2024, 7:02pm 49 m 16s lembke, james 0:06 alright. thought busy week, we are going through operating systems, isolation and protection. abstractions are cool. we were talking about one well, we talked about isolation specifically in cpu mode and now we're talking about one have been talking about one sort of important piece of abstraction that the operating system creates and that's this idea of processes. and so we've been working through that and this week now a whole lot listed here in canvas. i will be adding more once i get there, but and part of it is because we're still going through the process nodes and want finish that today and then i wanna just do a bunch of examples because ultimately where we're at right now is using operating system services. and so we had know how system the calls work and how that other stuff happens under the covers. but now that we understand how that works, i know, we understand how that works, we're going quiz on friday on that. so system calls that you have a trap. how that works processes, not the stuff that we're gon na talk about today, but just the concept of processes, how they have state that five process state diagram, what's in a process, memory address layout, that kind of stuff is all fair game for the quiz. i'll be on paper close notes. no tech, just like the previous one. alright, so as far as nodes are concerned, already got that out there. the next topic is processed communication, we're gon na get once we finish processes. but there's one thing i kind of did n't really talk about yet, is process organization in a little bit more detail. cover that today and how we create processes. all this stuff about processes have been kind of hand waving in that ok there an operating system abstraction. it's created by the os. the cpu is just executing a stream and under the covers that is being manipulated by the operating system alter what the stream is give it the appearance that vulnerable processes are executing at once. but really, the cpu is brainless about what's going on about this, and they have n't. system is building these abstraction. ok, great. so as a result, we need be able create and ask the operating system, hey, i would like start a couple of processes i'd like do this right as a human. it double click on stuff, right?"
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","the cpu is just executing a stream and under the covers that is being manipulated by the operating system alter what the stream is give it the appearance that vulnerable processes are executing at once. but really, the cpu is brainless about what's going on about this, and they have n't. system is building these abstraction. ok, great. so as a result, we need be able create and ask the operating system, hey, i would like start a couple of processes i'd like do this right as a human. it double click on stuff, right? and that starts chrome that starts steam. that starts whatever right we double click on stuff and after that we get processes created. i will tell you and we looked at it ourselves, there's no system called double click. i all that stuff has happen under the covers. yeah, system call. so we're about how we create processes and because we have system calls for that, we're going do examples, ok. so with this so far, so i'm good. ok. other thoughts? so where were we with the notes? this is where we stopped. if i understand correctly, we were somewhere around not this line where somewhere around here, but we're talked about the five state model very important and then we kind of got through this idea of the process control block and that in order be able handle processes, the operating system needs do booked tweaking. this picture is not enough. sure. memory. we kind of get for free. the processes themselves are manipulating own memory, and we can use protections on memory, we'll talk about when we get the memory management prevent other processes from accessing our memory and prevent us from accessing other processes, memory and also protect the operating system from processes. so but that we get for free if for process modifies it variable, they could modify and they stay there. if a process is that executing any modifications that it may be its memory space stay there, but there's other bookkeeping stuff that we have keep track of. things like the cpu context, right, the stuff and seeing the registers. if we have chrome running and we swap out chrome and then have microsoft word running this stuff, the program counter the instruction register."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","the processes themselves are manipulating own memory, and we can use protections on memory, we'll talk about when we get the memory management prevent other processes from accessing our memory and prevent us from accessing other processes, memory and also protect the operating system from processes. so but that we get for free if for process modifies it variable, they could modify and they stay there. if a process is that executing any modifications that it may be its memory space stay there, but there's other bookkeeping stuff that we have keep track of. things like the cpu context, right, the stuff and seeing the registers. if we have chrome running and we swap out chrome and then have microsoft word running this stuff, the program counter the instruction register. these general purpose registers will still have the other processes stuck in them, so the operating system has keep track of this somewhere, and it has do bookkeeping so that it does n't lose that information, because when chrome or whatever's going get run later on, we got ta restore that information. so all that bookkeeping goes in the process control block. and we got a bunch of stuff in here, and i'm not gon na ask you memorize all of this stuff, but i do want you realize that processors have safe. we talked about the five state model that they have an identifier so that we know and that the operating system knows the difference between what process is what, umm, as well as not necessarily what the registers are. but when you group all of the registers together, it references the cpu context, right? what the cpu is currently doing, so that's things like the program counter and the registers. so cpu context, so big things are safe, cpu context, process identifier, a lot of the other stuff you can kind of consider be kind of like bells and whistles. who owns this process? ok. yeah, kind of important on a multi user system, but from my perspective for me on my laptop, the processes that are running are mine are not letting somebody else run right? no. ok. process control block and then i talked about the process table and how it links all these process control blocks together and the process control block as well as the process table are in operating system protected memory. ok, so regular process can not give this information. if we wanna get this information, the operating system does provide interfaces for us do that, but we have ask, how does a process ask the operating system for anything?"
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","yeah, kind of important on a multi user system, but from my perspective for me on my laptop, the processes that are running are mine are not letting somebody else run right? no. ok. process control block and then i talked about the process table and how it links all these process control blocks together and the process control block as well as the process table are in operating system protected memory. ok, so regular process can not give this information. if we wanna get this information, the operating system does provide interfaces for us do that, but we have ask, how does a process ask the operating system for anything? we just talked about that last week. system cost, right? so there's system calls available for get my process identifier. get pit is the name of the thing. gpid get my parents process identifier. who is my parent? does he created me? we have talked about parents. yep, that's there. the thing get peep it get process owner or get yeah get process owner get the user identifier, it's get uid right. so all these different system calls are available for retrieving that information. his process state. well, it's hard get the process started because if you're making a system call, you have be running in order actually make that call. so say what's my state? ohh no, you're state is suspended. well, you could n't ask for that because you were suspended. so that's kind of like a chicken and the egg problem. but anyway, there is a lot of system calls in there on information retrieval get information about the process all right. so along those lines in posix and also in windows, processes have hierarchy. they're the operating system is gon na get booted up by the cpu. we talked about that, that part of the the boot up process, the operating system sets up the trusted code for handling a system call. the operating systems entry routine, umm. and then once it's done doing all of the system initialization, it starts the very first process on the system. that process is in charge of creating everything else and so on. linux is depending on what? how your linux is implemented under the covers, that is either gon na be in it or system d the system damon, that's gon na control everything and that's job is do user space initialization of the system. and i'm not gon na ask you regurgitate this on a quiz or a test."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","and then once it's done doing all of the system initialization, it starts the very first process on the system. that process is in charge of creating everything else and so on. linux is depending on what? how your linux is implemented under the covers, that is either gon na be in it or system d the system damon, that's gon na control everything and that's job is do user space initialization of the system. and i'm not gon na ask you regurgitate this on a quiz or a test. no, but i do want you be aware of the fact that there are parent child relationships. every process is the parent or the child of another process. i say or they processed might be a parent and the child, so this particular case you're command shell making the child on the system initialization process. but it's also that the parent of maybe other processes ok, when we talk about the about creating processes, we have processes that create other ones. so we have this idea of a creator, the parent and the create head. the child you can only create processes from another process. the first process is special in that it's created by the operating system. at least that's the way it works in politics. but even windows has this idea of a process hierarchy. ok. but they process hierarchy still. how do we see the process hierarchy? well, how do we list processes? well on linux. we can use the ps command and you might look at that and say if the ps command is in charge, that's what it is of listing information about processes. if i just run ps and hit enter, why is it only showing two things? the reason is that by default ps only shows the processes that i am running in the current context. so this is saying that what's being run is bash, is my shell. my command shell that i can use enter commands and ps is the command you just ran, so obviously it's running when it's listing that. that's again a weird sort of chicken and an egg problem that i'm running ps list the processes, but the list of processes ps happens be one of those processes that are running, so it's gon na list itself. thanks. it's kind of weird, but it's true. so if i wanna list everything on the system and it's, i've got this in the notes."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","my command shell that i can use enter commands and ps is the command you just ran, so obviously it's running when it's listing that. that's again a weird sort of chicken and an egg problem that i'm running ps list the processes, but the list of processes ps happens be one of those processes that are running, so it's gon na list itself. thanks. it's kind of weird, but it's true. so if i wanna list everything on the system and it's, i've got this in the notes. umm there is some command line parameters you can specify at a ps list everything and that's psa ux lists everything running on my system. so this is all processes whether they run by me or another user. what? what they are the path the actual program comma. i mentioned that processes are created from a program. that's the program that created it. you can see some information about again mentioned the process identifier. it tells you how much memory and cpu these processes are currently using, and this is in a way kind of like a text based version of the windows task manager. questions like some of these other flags, statistics and start time, you can look up in the man page for what they mean pass versus ss versus ss. i do n't really know what they are, but i do know if i want see what the processes are i can see that there there's another command that i want show you, is kind of cool. it's called top. i do n't really know why it's called top, but it is what it is. this is kind of like a text based version of the task manager, only at updates in real time every so often. so you see as it's going, it updates stuff. so we see currently processes are running. you talked about a little bit about priorities that's listed here, amount of memory and system very similar the ps command, only at updates all the time, right? right. so process hierarchy. there's a command called ps3 i just wanna show you i think this is pretty cool. it does its darndest do like a text based animation of an actual tree. so you kind of have use your imagination, but this is the process tree. so on my system system, the is the system of the visualization process. and it created all of these. it's eventually you can see the tree breaking itself down the login process was running bash, is probably actually off. here we see."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","so process hierarchy. there's a command called ps3 i just wanna show you i think this is pretty cool. it does its darndest do like a text based animation of an actual tree. so you kind of have use your imagination, but this is the process tree. so on my system system, the is the system of the visualization process. and it created all of these. it's eventually you can see the tree breaking itself down the login process was running bash, is probably actually off. here we see. here is my particular shell is running process tree. ohh this this the this like this so. questions. yeah. or do you have what would happen the child processes if you talk 6? what would happen the child process if you kill a parent? on opposite, what's supposed happen is the entire subtree gets terminated. that is not necessarily the case. there is situations where you can specify a a flag on the process say do n't. do n't destroy me. you can essentially, it's called a background process runs in the background and then if the parent process is terminated, it runs in a world where you have no parent. i personally like call that an orphaned process, but on linux and posix they call it a zombie. i do n't know why it's just a word that use it, but that's kind of what happens that makes sense. other questions? ok, so that's the process tree on windows, so i've got notes on linux. on windows it's a little bit different. you can access the process list the task manager if you go over here. yes, please run the task manager and then you see the processes here. if you look at details there, this shows you the individual processes that are running. so again, i've got bazillion chrome tabs running and so on. there's a bunch of other services that are running here. again, this is the program that created the process. you can see sort of similar information. i do n't know why this is. you could see some stuff about status in here. so that's the task manager for listing processes. if you wanna see the process hierarchy, i actually had look this up. there's a special windows tool you can download here called the windows process explorer utility. i did n't know this thing existed, but if you open it up, it gives you a i think it's a kind of a nicer or kind of cooler version of the task manager."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","you can see sort of similar information. i do n't know why this is. you could see some stuff about status in here. so that's the task manager for listing processes. if you wanna see the process hierarchy, i actually had look this up. there's a special windows tool you can download here called the windows process explorer utility. i did n't know this thing existed, but if you open it up, it gives you a i think it's a kind of a nicer or kind of cooler version of the task manager. and here here is where you can see the trees. so here there's a process called win in it is creating a whole bunch of system services. ohh no. again, that's how we'll see it on windows. questions. ok. so that's that. let's see then. alright, we'll quarter after we got that. this is good. good. let's move on last two slides and then we'll get some examples. so creating a process. let me go all the way back all the way up here. sorry, sorry. i hate keep jumping back around, but there is a picture for what i put it. maybe i do n't have it in this one. but let me let me pull up the other slides because i wanna show this picture that is, this is this course, this one slides system calls. nope. not that one either. i you know what picture i wanna pull up? i want the the multiprogramming picture. here. so we have a bunch of bronzes in here. it says program, but now we know that the processes there really processes and they're combined so that the operating system is going essentially give each one a time slides. we want be able create more processes now, now that we know the processes have state, they have a program associated with them that's currently executing. they have an identifier and they have a parent, right? all four of those things are important, with can keep them in our brain. we think about creating processes, so i mentioned that we have this parent child relationship show the process tree and so in order create a process we have have a parent process. so we can write a program that we can run that will then create more processes. how does that work? well, in order run a program that we've created, i've been using the command shell. that's gon na be the parent process for the the program that i wrote."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","all four of those things are important, with can keep them in our brain. we think about creating processes, so i mentioned that we have this parent child relationship show the process tree and so in order create a process we have have a parent process. so we can write a program that we can run that will then create more processes. how does that work? well, in order run a program that we've created, i've been using the command shell. that's gon na be the parent process for the the program that i wrote. when it gets run that i can use that program create others, ok. parents create children. so how do we do that in posix and on linux specifically? enter fork ok. fork is a very important system. call. it is interesting in that it just is. it has no parameters and it looks like a function call, just like all of our system calls are abstracted away by this. by this the c library, but it is a system call and it requests that it operates that the operating system create a process. what does it do? it's kind of weird, so let's draw a picture. it says split ok so. here's what format does. i have a process. here's my process. we'll call it p1. and it is focus. about like that. ok, it's executing its instruction stream on the cpu. ok, at some point it's going execute a system call called fork fork create a process. when that happens, this process stops because it executed the trap. who gets run at the point of a system call? the os, right? so the os is gon na enter its os entry point. it's gon na look up at the system call table and say, uh, the user wanted execute four. i can do that and it invokes the functions that are necessary with inside the operating system run form creates a process once it going do well, this process has an instruction stream. it also has. in memory. it's address space. so here's the address space for p1p1 also has in operating system space a process control block right consisting of the process identifier the the process state, the cpu context, a bunch of other stuff, but all that stuff is in memory at the point of fork. now the os is going execute. it's going get the cpu because that's what the user requested. what is the os gon na do?"
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","i can do that and it invokes the functions that are necessary with inside the operating system run form creates a process once it going do well, this process has an instruction stream. it also has. in memory. it's address space. so here's the address space for p1p1 also has in operating system space a process control block right consisting of the process identifier the the process state, the cpu context, a bunch of other stuff, but all that stuff is in memory at the point of fork. now the os is going execute. it's going get the cpu because that's what the user requested. what is the os gon na do? it is gon na take this process here and split it and i do n't mean split it, i really mean copy. so i think of a fork. i do n't mean like the fork that we're gon na use eat our lunch with. i mean like a splitting of something, right? yeah, 4 great fork it around. good. see, i was looking for an example and i lost it. so yeah, fork in the road. so we were there, right? so one process, uh becomes two. so the operating system is gon na do this. it says alright, you wanted create a process. bork has no parameters, so the operating system does. the only thing that it's gon na be able do when it comes a fork or a split is a copy. it's gon na say i need make another process. we're gon na call it p2. it takes p ones memory address space. and copies it. ok, then it takes p ones process control block essentially and copies it and creates a new process from p ones process control block. it does not give it exactly the same thing because it's a new process, so the process identifier is going be different. the parent process identifier is gon na be different, but as far as like cpu context is concerned, well we got ta update the program counter because p2 is gon na have its own text section in memory. so little things like that need get updated make this guy unique from p1, but for all intents and purposes, the text, the global data and the current contents of registers is an identical copy of the previous of the parent process. ok, with me a copy of the parent. then inside the process control block for p2, so inside right we've got our process table."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","the parent process identifier is gon na be different, but as far as like cpu context is concerned, well we got ta update the program counter because p2 is gon na have its own text section in memory. so little things like that need get updated make this guy unique from p1, but for all intents and purposes, the text, the global data and the current contents of registers is an identical copy of the previous of the parent process. ok, with me a copy of the parent. then inside the process control block for p2, so inside right we've got our process table. so here is the pcb for p1 and here is the. pcb for p2 it's going set its state ready not running because p1 is currently running cause it's the one that requested the fork ok. now that the operating system, once it's done doing all that work, it's going return and this guy gets keep running. and that's it. we just created a process. the process we created is essentially a copy of the other process, but that's it. so. at some point in time and i'll use red marker here. red ink. here we have a timeout and a context switch. where the operating system will say p1, you have had your turn with the cpu. now somebody else is gon na run, ok? and it might pick me too. and then, so here's the kicker question. when p2 runs, what code is it going execute? where is it gon na be? what's it instruction stream currently doing? yeah. from where p1 left off at the fork. exactly. ok, so remember p2 at the point of fork is a copy of p1, so all the memory that was associated with p1 gets copied down the green 2. so all the global data, all the contents of the stack and the heap and all that stuff gets copied from p1p2p2, gets its own process control block, and the program tyler gets set where that fork call was inside p2 because it's own process id. if parent gets set p1 and then when it gets run p1 continue along but p2 when it goes it's gon na start wherever it program counter was at the point of the fork. it's a copy of p1, so it's going get the key back secured in two. so in a way, we get 2 processes executing the exact same thing. yeah, there are scenario where they're p2 is kind of updated compared p1. well, and this is a good question."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","so all the global data, all the contents of the stack and the heap and all that stuff gets copied from p1p2p2, gets its own process control block, and the program tyler gets set where that fork call was inside p2 because it's own process id. if parent gets set p1 and then when it gets run p1 continue along but p2 when it goes it's gon na start wherever it program counter was at the point of the fork. it's a copy of p1, so it's going get the key back secured in two. so in a way, we get 2 processes executing the exact same thing. yeah, there are scenario where they're p2 is kind of updated compared p1. well, and this is a good question. so the question was, is there a scenario where p2 become outdated? well, it all depends on what p1 is doing right and p1 is doing some computation p2 when it returns, it knows it's going do that exact same computation. so if it's doing some sort of time sensitive thing or computing some mathematical operations, me too, it's gon na do that exact same mathematical operation. it's gon na be manipulating a different location in memory, but it's gon na be doing the same thing as q1, so i hate say philosophically it's in the eye of the beholder, but it all depends on what p ones doing. later on, we'll talk about how we can make p1 actually do something different, but for now they do the same thing. good question though. so they do the same thing with one exception. ohh sorry question. what was n't? what do you mean? what? i just do n't feel like. so yeah, so can you do it? it's hard memory since our entity that copy of p1, except that he too is a child of p1 because p1 created it. it is a different process identifier and it is a different program counter because we do n't want you 2 executing program or process once instructions we wanna execute its own so that also gets updated. but for the most part, it's context as far as general purpose registers and things like that stays the same. ok, so he too will continue from here when it's it's turned run. so the question i always confuses me or at least confused me. when i first learned this was if p1 is running and v2 is running more or less, you know rotten, they're taking turns."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","it is a different process identifier and it is a different program counter because we do n't want you 2 executing program or process once instructions we wanna execute its own so that also gets updated. but for the most part, it's context as far as general purpose registers and things like that stays the same. ok, so he too will continue from here when it's it's turned run. so the question i always confuses me or at least confused me. when i first learned this was if p1 is running and v2 is running more or less, you know rotten, they're taking turns. how does one know if you are running p2 that your p2 and not p1? i think that's a weird way ask that question. yeah. when and and, but i think, yeah, yes, that's one way we can do it, right? we did all that process p1 and p2 have own process control blocks. they are different processes, so if p2 or p1, they're gon na different parents. he one is gon na be whatever his parent is and i did n't really talk about that. but p2 is parent is going be p ones so he can know a little bit more about that by looking appearance along those lines. and i'll put words in your mouth. there's a system called called git pit, right? i can use that number say what process am i right because this guy's gon na have a different process identifier than that guy. the other thing that that is kind of cool is the operating system actually has your back. we kept saying you guys were great and jumping into the back and saying that fork in the system call. so at that point the os gets invoke the invoke. the os has the ability adjust either of these processes memory, so he won and p2. i say our exact copies, but one of the things that the os does is it tricks these processes because it is the ability alter memory and so this is kind of weird. it's awesome. work has a return call i mentioned. all system calls have a return value, and it's typically zero on success or -, 1 on a failure, right? but the operating system is going do is it's going modify the memory for p1 and p2 muck with the return value because it has the power do that. the return value is going be stored in memory here on these processes. so for p1 it's gon na set the return value be."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","i say our exact copies, but one of the things that the os does is it tricks these processes because it is the ability alter memory and so this is kind of weird. it's awesome. work has a return call i mentioned. all system calls have a return value, and it's typically zero on success or -, 1 on a failure, right? but the operating system is going do is it's going modify the memory for p1 and p2 muck with the return value because it has the power do that. the return value is going be stored in memory here on these processes. so for p1 it's gon na set the return value be. a different value than the return value from this guy. so for p2 it's gon na handle the same idea. it's going say if fork returns successfully and you've been created, i'm gon na make the return value from 4b0. ok. if fork returns -, 1. that means it failed and it could n't create the child process. usually that happens when you ran out of memory or there's a system limit say i'll process is only allowed create so many children for his system resources limits. and it also could be a situation where this parent p1 just created too many child processes. yes, you can only have so many chrome tabs open at a time. it's a huge number, but anyway, alright, so that's what i'm gon na do. and what it's gon na do in the parent process p1 here is it's gon na make the return value from 4b. what process identifier from the child? so they can tell each other apart by looking at the return value from form. ok, that sounds confusing. it'll be marked more. hopefully it'll become more clear when i do exactly. sorry. so with me pork. so let's do an example. let's do a bunch of examples. new file. we'll just call it fork dot c what do we need do? we got ta figure out what the header file is for fork man, fork. you and i a std dot h very important. you and i std dot h i'm also going do printing, so i'm gon na do std io. and you know what? i might want do malik, so let's just put that in there too. so and it's simplest. i could do this. present the. i am process. the lower case p. get fit. so if we look at the man page for that."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","we got ta figure out what the header file is for fork man, fork. you and i a std dot h very important. you and i std dot h i'm also going do printing, so i'm gon na do std io. and you know what? i might want do malik, so let's just put that in there too. so and it's simplest. i could do this. present the. i am process. the lower case p. get fit. so if we look at the man page for that. it says return the process idea of the calling process done alright and it returns a type called a pid t is essentially an unsigned number. process identifiers typically start with one and just go up from there, and they're not reused. ultimately, the operating system, if your system is running for forever, you when a process is created, it usually uses the next number up and then when that process is terminates it does n't repeat. but you could consider in a world where you might run out of numbers. i'm on a 64 bit system. those that has a lot of processes before you run out, i do n't really know how many you can fit into this. anyway, we just consider it be a unique country. it's all get picked. so let's just do this and let's just not use fork. and so if i do this orc. we see the output is. i am processed 693. if i run it again, i get a different number because the operating system is not reusing process identifiers. so if i wanna run my system model process identifiers, i can just keep doing this. i got ta be here for a while, but you get the idea, right? so i said that fork, if we look at the man page for fork again the description says creates a new process by duplicating the calling process. so i did n't lie, i do n't make this stuff up. we're new browser. further, as the child, the calling process referred as the parents and then it goes and talks about a bunch of other stuff about fork. but i can simply call fork and at that point this is going say split this guy in the tube. both are gon na continue executing at the return four, so at this point i have two processes that are executing the same program. ok, this is where we can be that. yeah, very multiple processes with the same program."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","we're new browser. further, as the child, the calling process referred as the parents and then it goes and talks about a bunch of other stuff about fork. but i can simply call fork and at that point this is going say split this guy in the tube. both are gon na continue executing at the return four, so at this point i have two processes that are executing the same program. ok, this is where we can be that. yeah, very multiple processes with the same program. so at this point i'm gon na get 2 processes running. they're both executing the same program. they are not sharing address space. it duplicates a process. it does not create a process and have them share. this is weird because when you look at this and when i show you the output, it's gon na give me the appearance that they're sharing stuff they do not share memory. all they do is we're copying stuff and people they're gon na execute independently, but the same code using the same initial data because they're duplicates. and i would say two things being printed out, the parent and the child, ok. well, anna, get the parent process id. we see that great. i am processed 734. my parent is 376, is probably the process identifier for my command shell, and then we got this other 1735. my parent at 734, that's the linkage between the process that just created them, right? right. but they alright. so now let's actually do this properly. well, we should have done. was something like this. so this is where things get a little bit more tricky in that i've mentioned that the operating system has the ability manipulate its processes because it's governance system. it is all power pole as far as our computer is censored, so it's going set the return value from 4 be different based on process is running. so in this case, if fork fails, it's gon na turn -. one so the child would be -, 1 and it's gon na say forfeit. and we'll be that's not gon na happen. like i said, it should only happen if i run on a memory or my friend too many child processes. so the love that. so i'm gon na print out more failed down. just return bangalore. otherwise, if the child is, if the if the value returned from fork is 0, that's an indication that where the child."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","so in this case, if fork fails, it's gon na turn -. one so the child would be -, 1 and it's gon na say forfeit. and we'll be that's not gon na happen. like i said, it should only happen if i run on a memory or my friend too many child processes. so the love that. so i'm gon na print out more failed down. just return bangalore. otherwise, if the child is, if the if the value returned from fork is 0, that's an indication that where the child. otherwise, if the value that's returned is the process identifier of the child, is neither -, 1 nor zero, it's gon na. we can know that we're in the parent. that's the thing. so this is how we can actually now make the processes do something different based on if they're the parent or the child. let's copy this. stop 30s. i'm the parent. i'm the child. so far so good. ok. thoughts. questions charles. say that i'm the child on 746 make sure it can. i mean, it's up you expand on what you want do, right? the thing is that the child if the child tries print out the value of child. for example, if it's like, well, maybe this is it. it's not going work because the value of child in this case the return call from pork, is 0. it's just not the child's process identified. this is the way that we can determine the difference. if the child wants know its pinned, it needs call git pin. so wait for it do it. ah, what the reason it does this for the parent is there is a git pin and a get parent process id. every child has one and only one parent, but a parent can have multiple children, so there really is no system call. exactly. that's easy say. get my child because the answer is well, one do you want? right. and so like here, the parent can keep track of it using the return value from form. right. all right, so. picture. we just saw that that when forward turned, the parent keeps running, right? i'm gon na throw it up. the potential for requirement here say you know what, if the what?"
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","every child has one and only one parent, but a parent can have multiple children, so there really is no system call. exactly. that's easy say. get my child because the answer is well, one do you want? right. and so like here, the parent can keep track of it using the return value from form. right. all right, so. picture. we just saw that that when forward turned, the parent keeps running, right? i'm gon na throw it up. the potential for requirement here say you know what, if the what? if we want the child do something, finish, and then have the parents say, wait for it, right would be kind of nice, right? so i'm gon na create a child. you go do something. let me know when you're done, and then i'm gon na gon na do something else, right? we we do n't really have a mechanism right now do that, except we know that a process is an operating system construct, right? he has talked be right and i'm beating this death on purpose. right. as a result, we can ask the operating system do stuff on our behalf. that's what an operating system service is all about. so what we can call fort, we say operating system, i'd like you create a process and just just copy me and let it run ok. we can ask the operating system say, hey, you know what, i have a parent process, but i do n't have anything do right now, at least that until my child finishes. so i would just like wait and as a result there is a system called called wait we can do say operating system. just suspend me because i got nothing do when the my child process finishes. then let me know you know, let me run. and so if we look at this code here, we see that the parent got the run first. but if we really want the parent wait. we can run weight and we can actually run man. wait and it says ok. wait, all these system calls wait for state changes and children. by default, it waits for them terminate so. ah. sis weight. good. all right, so why did i need pass null in here? if you look at the man page for weight, we see that there's a status coming in here. all these system calls specifically wait. we've got one here. there's different flavors of weight."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","we can run weight and we can actually run man. wait and it says ok. wait, all these system calls wait for state changes and children. by default, it waits for them terminate so. ah. sis weight. good. all right, so why did i need pass null in here? if you look at the man page for weight, we see that there's a status coming in here. all these system calls specifically wait. we've got one here. there's different flavors of weight. what's going happen is this is going make the parent process wait for the child finish, and then it's going take a pointer and it's gon na fill in the child's exit status so that the parent can know if the child was terminated. if they exited gracefully or if they took an exception, things like that, we'll get put in here in the wait status. if if you as a parent do n't really care how the process is terminated, you can pass in null and then the operating system will say you know what the user or the parent you're wanted wait for the child, but they did n't care what the child's exit status was. so that's why i needed a wait no in there. what about compile this now and run it? now we see the child gets run first because the parents will have continued run immediately after the 4th, but it says, you know what, i got nothing do. i wanna wait for the child it can wait. then the child's gon na run, and it's gon na then print out its time. the child and then the parent will run. after that o wait. kind of a nice system call. well, it's a nice system called now that we have 4. so kind of like, well, is there another way we could have done this? probably, but if you give us fork now, we would like be able wait and do some other stuff. questions for me or all right, let's talk about something else. let's talk about variables. ok. what's the value of i that's gon na get printed on both of these statements? not if you know the answer. get good. honor. isil and context in both of these parents and the child here."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","so kind of like, well, is there another way we could have done this? probably, but if you give us fork now, we would like be able wait and do some other stuff. questions for me or all right, let's talk about something else. let's talk about variables. ok. what's the value of i that's gon na get printed on both of these statements? not if you know the answer. get good. honor. isil and context in both of these parents and the child here. and because the child is a copy of the parent, it gets and inherits the same value as i because it's a copy of the parents address space i is on the sac for main and it gets copied because all of the parents address space is copied the child. so because the stack also then gets copied, it's gon na have the same value of i. if i do something like this. globe for glasgow global this i is global is. the local. good. same thing happens again because the child is a copy of the parent. it gets all of its memory sections, copied text, even global data, as well as heap and stack. so the value of global is still the same question so. they are copies of each other at the point in time of the fork only, so that's a great question. it's like you. it's you're the question was, do they continuously be copies of each other? and how does that mean and how does it not break consistency in memory? what happens is that the parent and the children rather the child becomes a copy of the parent at the point of fork and only at that point it's a point in time copy. so as you can guess, my next statement is this. now what gets printed out? the child was pretty obvious when the child runs, it's gon na modify i and it's gon na print out. i be wait right here. we can see it right, two lines of code above it should get 123. but what is the parent gon na give? i is on the set. it's within the context of maine. once it let's let's find out. i as 123 and the child i am the parent i as 100 right and again you look at this be like doctor lucky it's obvious. well, it is n't. is n't the child is a copy of the parent a point in time? copy at the point of the fork."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","we can see it right, two lines of code above it should get 123. but what is the parent gon na give? i is on the set. it's within the context of maine. once it let's let's find out. i as 123 and the child i am the parent i as 100 right and again you look at this be like doctor lucky it's obvious. well, it is n't. is n't the child is a copy of the parent a point in time? copy at the point of the fork. they do not share anything. see might say, well, i'm gon na modify i and i is still in scope between parent and child. and so i should get updated because the parent is waiting and it's gon na run after the child executes. so i should be updated 123 but no it is not because the child updated its own address space, not the parents cause the child ca n't access the parents address space isolation and protection right? they can only access its own and it's never address space. is a copy of the parents. and then of course, because i like do this like lembke says, well, what about this? same thing, right? he got even though it's not in the sack, it's global data. and you say, well, it's global data makes no difference. it's a copy, so the parent for the child is a copy of the parent. the child can update stuff all at once, and it's gon na update it's copy. the parents copy stays the same. this is where fork. it's kind of confusing because you would say no, i'm modifying, i'm sharing you are not sharing memory. there are techniques for sharing memory, but this is not one of them. question yeah. so when it creates the copy or like programs data just say copy over and as important the same point. or does it? it will most likely. ok, so that's a good question. what do we do about pointers? it does do a deep copy and so pointers if it. if the parent tries store a the address something and then org, the child gets its own copy of even that pointer's target location. so it's gon na do enough deep copy so that the child dereferences that pointer. it's not gon na access the parents memory. it's still gon na access its own memory, but you did add an interesting point."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","ok, so that's a good question. what do we do about pointers? it does do a deep copy and so pointers if it. if the parent tries store a the address something and then org, the child gets its own copy of even that pointer's target location. so it's gon na do enough deep copy so that the child dereferences that pointer. it's not gon na access the parents memory. it's still gon na access its own memory, but you did add an interesting point. i'll try get it in the last like 3 minutes here. yes, this i love this example. this is the last. this is ohh man alright. ok oops. so yeah, global, we got this. we've got malik. eye is. and at the dereference it. ok, maliki is 12. we see that parent and child do n't share heap. they do n't share stack. they do n't share global data. everything is independent. the parents love it's own value. old value. ok, so you can dereference pointers and the operating system handles that. it says say it. it's got your back. so we're not gon na cause a problem there. here's the here's the kicker. what? ah yes. ok. question. do i have a memory leak? i have a bunch of knots. this is i love this question because sometimes like wait, go ahead and i'll see how i got one call malloc and one call free. so that's great. so i do n't memory leak. why? for those of you are nodding and smiling at me, why is there memory loop? the child does n't free the memory, only the parent does, because remember a parent and a child are copies of each other. or rather, the child is a copy of a parent, so it gets sort of inherits everything that the parent created. so in this case, there's a location on the heap that's been allocated for an integer, but the parent freed. sort of natural. yeah, behavior of the copy. the child also inherits the responsibility of having free this thing. so if you run valgrind, it will say there's a memory leak because the child got this implicit malloc and it's got a free it, so it needs free malachi free the malloc. so now it looks weird because i have two freeze but one malik. the way it goes. questions. a lot of time, so we'll stop there."
"""OpSys_Processes_and_Five_State_Model_Transcript.txt""","so in this case, there's a location on the heap that's been allocated for an integer, but the parent freed. sort of natural. yeah, behavior of the copy. the child also inherits the responsibility of having free this thing. so if you run valgrind, it will say there's a memory leak because the child got this implicit malloc and it's got a free it, so it needs free malachi free the malloc. so now it looks weird because i have two freeze but one malik. the way it goes. questions. a lot of time, so we'll stop there. we'll keep doing. we got. i got more examples. we keep doing this forever, so we'll stop here and you have a good night. see you on thursday. i will have a new programming project out, so i i wo n't be able talk about it till thursday. so please make sure you look at it in canvas. lembke, james stopped transcription"
"""OpSys_Processes_and_Fork_Transcript.txt""","meeting in _ general_-20240215_130155 - meeting recording february 15, 2024, 7:01pm 46 m 46s lembke, james started transcription lembke, james 0:10 hello. hello. ok. and that's not the. so what did i do? canvas quiz tomorrow. do n't forget about that. it'll be on system calls and processes, not the stuff we're talking about this week. so, like fork and today we're gon na talk about exec wo n't cover that stuff, but just sort of the process sort of hand waviness states process control block, process list, what processes are the fact that they're operating system created abstraction that the cpu is just executing instruction streams, system calls, traps, system called numbers. i do n't have. i'm not asking memorize. could you imagine what is system called 0 on a linux x 8664 bit system? no, not gon na happen. so you do n't have memorize the numbers. if i do want you use system call numbers, i'll give you a list. we'll just do it that way. so that's that, but otherwise it'll be closed book. i'm paper brings something the right way. we'll do tomorrow. question. what did you mention for the cd versus the the what it is and the important fields in the pcb. so process identifier was a big one. the cpu context, the content of the registers, program counter and then there was one more thing in there. that was the program that was in the pcb that i do n't want that i always forget. uh. process state? yeah, i want the state of it is right. those are the three sort of big fields. there's other stuff in there that will add as we go, but those are the big ones that we talked about. as far as examples i concerned, we have been walking and working through fork, so i made a whole bunch of different examples in here and most of them all in canada. so i got a generic pork. pork with weight. if i mentioned the weight system call, we want have a parent weight form with different aspects of accessing memory show that. memory is a copy in the child's. there's an example using malloc that the child gets a copy of the parent, so anything that the parent does with the keep the child sort of inherits that responsibility. so we have free them, alex and the child. there's an example there and four problem i'll get today, so that's some examples."
"""OpSys_Processes_and_Fork_Transcript.txt""","pork with weight. if i mentioned the weight system call, we want have a parent weight form with different aspects of accessing memory show that. memory is a copy in the child's. there's an example using malloc that the child gets a copy of the parent, so anything that the parent does with the keep the child sort of inherits that responsibility. so we have free them, alex and the child. there's an example there and four problem i'll get today, so that's some examples. we'll do some more today. programming project is out there. teeny tiny shell. i'll talk a little bit about that tomorrow, because we got ta get through one more. sort of like grouping of system calls. i know some of you have already started it. awesome. thank you. i extended the deadline. this is february 20th. i move it the 22nd mainly because we have n't gotten through exec and i wanna give you enough chance work on it. but if you get it done early, let me know if worry about it, right as everybody says. so that's there. it's all i got, so let's let's go and do a little review and then move forward with the process system calls. so real i mentioned, uh, we were talking about how create a process and this is the situation that we have with our hardware and we wanna be able do this, create multiple address spaces, right. because when i was talking about setup of system calls and the boot procedure and this idea of a process hierarchy. they said that there's a parent child relationship between processes and the only way on a posix system create a process is with fork. and while i really kind of in the notes here said that fork is a split fork in the road. what is kind of not correct about that is that when i think about a fork in the road, i think about the road being different in that they goes different places. and it's true that in fork you do have the option go different places, but the creative process is a duplication of the previous one. there, it's an independent process. so in that case it's a fork. it's two independent processes, but they both start out at the same with the same data, same registers, same cpu context, more or less. the program counter is different cause there's different address spaces and memory references that they make are different because each of own independent address spaces. but it's still the same phone."
"""OpSys_Processes_and_Fork_Transcript.txt""","and it's true that in fork you do have the option go different places, but the creative process is a duplication of the previous one. there, it's an independent process. so in that case it's a fork. it's two independent processes, but they both start out at the same with the same data, same registers, same cpu context, more or less. the program counter is different cause there's different address spaces and memory references that they make are different because each of own independent address spaces. but it's still the same phone. and by using the return code from fork, we can actually do different things. so i guess i'm kind of convinced myself by saying that it is kind of like a fork in the road. the road looks the same, but roads go off in different directions. so just put it that way at now and then it did a bunch of examples and we had this when i showed this picture. was at the point of the fork we have process p1 that's running. it executes fork, is a system call and it says in order execute any system call in the system, we have execute a trap forces the cpu load trusted os code. so at that point mediately gets executed. this guy is kind of suspended, so speak, and that's not actively running. it's the os code, it's state does n't change. it's still the problem that's running, but the os code gets go and it's going then copy this guy this guy the the the parent process into the child. what's kind of cool about that is you might say, well, i kind of think the parent is currently executing. how can we make this copy cleanly without having a whole bunch of modifications happen here? why can we do that? no one knows. everyone knows what? well, i said that the operating system is gon na copy this kind of this guy. they may create a copy of the processes address space into a new address space. but this process is still kind of has a state of running, and the reason that we can make this copy without having be concerned with values changing while it's being copied. is because while this guy is currently in a state of running, it's actually the os code that's getting its instructions like so the os has the ability access this memory and it's not gon na change while the os runs. the os can modify it because it has access all of memory."
"""OpSys_Processes_and_Fork_Transcript.txt""","they may create a copy of the processes address space into a new address space. but this process is still kind of has a state of running, and the reason that we can make this copy without having be concerned with values changing while it's being copied. is because while this guy is currently in a state of running, it's actually the os code that's getting its instructions like so the os has the ability access this memory and it's not gon na change while the os runs. the os can modify it because it has access all of memory. or is this process only has access its memory? it just makes a copy and it's a copy of the process control block in os address space and then updates the process control bot for p2. make it point kids, address space as well as setting the state ready and not actively running and so on. so it gets a different process identifier. it gets the parents set this guy, so there's some tweaks that the operating system has do in order make this process control block be different than the ones, but it starts off as a copy. so with me, yeah. so motivation question. you've used this, at least i hope you have the command shell on windows. you've double clicked on stop, i'm guessing run programs you opened up. maybe the windows commandpromptcmd.exe and run some command and it runs stop right? and so here's where four kind of breaks down and becomes a little bit frustrating in that if i say and i've said this in posix, the only way create a process is this. it's kind of frustrating because the using fork the child processes, whether it's the parent creating a child or the child creating a child from the parent of a parent, creating 16 children, it does n't matter. fork always works in the same way and the children are always a copy of the parent, so it's a child wants do something different, right? like run microsoft word, hit the parent process is chrome and you open up a new tab or something and chrome forks, but the only program that's going run is chrome's code. how do we get microsoft word rock? it's a separate program. remember the difference in a program at a process right? the program is that static representation of compiled code on disk and the process is the active execution of that program. so you want get that program that's on disk somewhere? microsoft word, elden. ring, whatever."
"""OpSys_Processes_and_Fork_Transcript.txt""","like run microsoft word, hit the parent process is chrome and you open up a new tab or something and chrome forks, but the only program that's going run is chrome's code. how do we get microsoft word rock? it's a separate program. remember the difference in a program at a process right? the program is that static representation of compiled code on disk and the process is the active execution of that program. so you want get that program that's on disk somewhere? microsoft word, elden. ring, whatever. we wanna get it into memory so it can run and with porch as is, we ca n't do that. we do n't have the ability do that. we can only run a copy of who created us and for the child. ok, no need do system call before i get there. i want show you one more example with fork. and it's it's just one that i think is worthwhile the show, because it's another gotcha. let's write this up here quick. uh-5. fork is in you and i. sdh and that is not what i wanted do. and. i'm going do i also. and std io dot h.? do n't question now that we know what fork does. how many processes are created? we got a four loop the loops five times in a parks. so simple quick answer by just looking at it and not really kind of diving any deeper into it. answers 5 right we're gon na loop 5 times. we're gon na create 5 processes, and we're gon na be done. anyway, i see a lot of shakes. why not? why is 5 not the right answer? because each time the loop execute, it creates a a new process that would also do the loop, would then also make another process that makes the loop right. remember that a child process is a copy of the parent, including everything. as far as state cpu instructions that need be executed, all of that stuff, memory contents, memory contents, copy of the parent. so at the point of fork we have eye sets initially set 0, where is i? it's in memory. it's in scope of this four loop. it's on main stack so i is in memory and so when we call fork we copy memory from the parents of the child and then both get continue executing."
"""OpSys_Processes_and_Fork_Transcript.txt""","remember that a child process is a copy of the parent, including everything. as far as state cpu instructions that need be executed, all of that stuff, memory contents, memory contents, copy of the parent. so at the point of fork we have eye sets initially set 0, where is i? it's in memory. it's in scope of this four loop. it's on main stack so i is in memory and so when we call fork we copy memory from the parents of the child and then both get continue executing. so in this case, the parent gets go and the child will go the value of i in both the parent and the child is 0, so we have two processes that are running. hopefully they'll print out. i am whatever this information and both will flip and can proceed on the next iteration of the loop. at that point, they'll update i independently, right? they use the same code, they both will update it one because what they're going do, and now we have two processes like go through and execute form. both of them call fork and they each create another process. we're creating a tree. here we have children that are creating children, but at this point now when i is 1 now, we create 4 processes because we had one that created another one. we have two processes that each create another one. so now we have four that are going down. all those four loop around and increment eye at the point of the fork. i was one. so all those other children get a copy of whatever that value of i want. so in this case it gets one, so those other children kind of skip that first iteration of the for loop, but you know they still get. i now one comes around and we have 4 processes each call fort. so now we have 8 processes that are a copy of each other, where is 2 and so on. so in this particular case, we're actually creating not five, but two the 5th processes, is like i have enough 100 and something i ca n't remember. so if i compile this. i get a whole lot of processes printed out the first one. this is the initial parent where it's parent id is the shell, but after that we see a whole lot of other child children that are making more and more processes going down and not even know how many things are getting printed out. but it's a fair number."
"""OpSys_Processes_and_Fork_Transcript.txt""","so in this particular case, we're actually creating not five, but two the 5th processes, is like i have enough 100 and something i ca n't remember. so if i compile this. i get a whole lot of processes printed out the first one. this is the initial parent where it's parent id is the shell, but after that we see a whole lot of other child children that are making more and more processes going down and not even know how many things are getting printed out. but it's a fair number. and so this is just something be aware of now that we know how check the return value from fork if we really, really really only wanted create five, we should pay attention the return code and say something like. if i'm the child, do something like this and then when we're done. we should. we should exit now. an exit is actually in. as they live, for what it's worth, correct. this causes the child run, sprint out the stuff, and then leave. we're gon na make the system call the operating system say i am done. please put me in a state of terminated so you can clean me up later. right. so now if i run this. i should only get fine. ok. fork bomb. they called a fork bomb because it kind of, i do n't know. uh. exponential growth. runaway stuff. uncontrolled, right? it is kind of controlled rolling into create so many and i mentioned this before, there are limits on the system as far as how many processes you're allowed create, so that four loop. ultimately, the forks would start failing because you're not allowed create too many more processes as we go, but it's pretty large number question when you do the exit, do you put you put the child in the parent? in that specific portal thing termination import whoever you want terminate. so if the if the parent wants terminate, you put it in the parent. if it the child wants terminate, you put it in the child. it it all depends on what you're doing. i typically will see it in that i want the parent live on and i want. i want the parent fork off a child do some work and then have the parent wait for that child terminate, and so i typically when i write it i will see i when i see it, it is usually done in the child or the parent will say child."
"""OpSys_Processes_and_Fork_Transcript.txt""","so if the if the parent wants terminate, you put it in the parent. if it the child wants terminate, you put it in the child. it it all depends on what you're doing. i typically will see it in that i want the parent live on and i want. i want the parent fork off a child do some work and then have the parent wait for that child terminate, and so i typically when i write it i will see i when i see it, it is usually done in the child or the parent will say child. i'm creating you go off and do something and the child says, ok, i'm done. so i'm gon na exit another way. you could do this in here. it's a better return in here because a return from maine is the same as it exit. it takes a while, but if you are having the child invoke some function on, you're gon na go deep down different levels of function calls and then i wanna turn the terminate way down there. then using exit makes sense because you can then move early without having jump back up on your skype. it's the same as system dot exit i think in java the same. ok. work. so i mentioned. umm. let's see. i think everything else is here. ok, sharing does not share memory. it says do sharefile descriptors. we're gon na come back and talk about file descriptors when we talk about communication. you may already know a little bit about them already. well, we'll go back. we may get them tomorrow. otherwise we will do it on monday, so just kind of keep that in your brain for now. but because there is something that's shared between parent and child and it's file descriptors, we'll talk about that when we talk about communication mechanisms. we'll utilize this idea of file descriptors a lot, so hopefully it will become ingrained in your head. but just kind of hard try connect the dots without without mentioning this first, so you're in short with fork we can send data from parent child through variables because the child gets a copy, but we ca n't send stuff back. from child parent, so the next thing was when i motivated earlier was what if? i wanted this guy here not be a copy of the parent. i wanted it be its own independent program. what can i do and with fork? i ca n't. i ca n't do anything with this. i ca n't change my instructions."
"""OpSys_Processes_and_Fork_Transcript.txt""","but just kind of hard try connect the dots without without mentioning this first, so you're in short with fork we can send data from parent child through variables because the child gets a copy, but we ca n't send stuff back. from child parent, so the next thing was when i motivated earlier was what if? i wanted this guy here not be a copy of the parent. i wanted it be its own independent program. what can i do and with fork? i ca n't. i ca n't do anything with this. i ca n't change my instructions. they're read only. i got ta i i need operating system help me out. so enter exec executing a new program. ok. i mentioned exact like a system call like this, but this is actually not not really accurate. exec. i like refer it as a system call, but it's actually a family of system calls. umm, the designers are posix said execute a program. we kind of like allow the invoker or the person that's just siding, how that program would be is be executed. some options with fork. it's nice, it's simple. you call fork, you get a copy of your process. there's no parameters. you check the return code do something special, but when it comes calling a program, there's. we'll and i'll show you the man page for it. this is some options available us. so let's separate this for a second and then go over here exec and i'll show you the various options here. there's six different flavors of exec, all of them just define essentially parameters for how information is passed the operating system. when all of a sudden done, they all do the same thing. and this is what this is what goes down. so for exec i have a process i'm going call it pk, it has. memory. so here is p's memory. there is some os section of memory as well has the. inside here the like pcb for p right, the process control block for p so if i can alter this focus. yeah. so ps memory it's executing along accessing its memory over here. this is a p and at this point right here it executes the a system called flavor of exec and there's six different options, but all of them kind of go into the same sort of semantics. ultimately, the operating system gets all the parameters that are necessary and inside exec one of the parameters is the name of a program."
"""OpSys_Processes_and_Fork_Transcript.txt""","inside here the like pcb for p right, the process control block for p so if i can alter this focus. yeah. so ps memory it's executing along accessing its memory over here. this is a p and at this point right here it executes the a system called flavor of exec and there's six different options, but all of them kind of go into the same sort of semantics. ultimately, the operating system gets all the parameters that are necessary and inside exec one of the parameters is the name of a program. and there is also the command line arguments, we'll talk about arguments in a second, but ultimately there is the program that's going be executed. the operating system is going run whenever we execute a system call. this is like absolute right. carbon installment. when we execute a trap, execute a system call, the operating system gets control. so the os is running. the process is not the operating system is it's not running because the process executed a system call, so the operating system has access its memory and its instructions, are somewhere over here. this stuff does n't change. it sucked down because no one's modifying it because it will be process only thing that should be modifying it is the process. so there was has control says you executed it exec. here's what i'm gon na do, and it's rather destructive, right? and the way you could say it's kind of mean it's going say process you were running, you called exec, you wanted invoke that program. so what i'm gon na do is i'm gon na find where this program is on disk. i remember that a program on disk is a static representation that's compiled. code consists of a lot of stuff, but the main features are the instructions for the program, the assembly instructions and really the contents of constance global data, right string constants, string literals and stuff like that are inside that program. ok. the operating system takes that program. that was asked for via exact and creates an address space for it with its initial stuff. so the address space consists of the text is the instructions. it will initialize all the global data that needs be initialized. it will initialize the heap and stack be empty and then it will find the program entry procedure. i will never main is inside the text section. figure out where that is and it will take that address space that it just created and it will say process. you know what?"
"""OpSys_Processes_and_Fork_Transcript.txt""","the operating system takes that program. that was asked for via exact and creates an address space for it with its initial stuff. so the address space consists of the text is the instructions. it will initialize all the global data that needs be initialized. it will initialize the heap and stack be empty and then it will find the program entry procedure. i will never main is inside the text section. figure out where that is and it will take that address space that it just created and it will say process. you know what? it's, you know, it's it's been, it's been real. it's been fun, though it has n't been real fun. you're gone and it says that address space that i created for this brand new program. i'm going jam it right over here and say, process. you're gon na be replaced with this brand new address space that i just created for this new program. it's then going go and the the process control block and set or so somewhere in here there is the. sorry this is should be me writing main there is the location of maine inside the the program. it's gon na take the program the the process control block. it's gon na update the program counter inside here that's stored for wherever main is, so it's going make main the program counter. in here, it's gon na point main or the entry procedure for that program. that's it. it's gon na let the program run. so here is sort of a philosophical weird thing, right? the old process still exists. it still has the same parent. it still has the same owner. it still has the same process identifier. it still has the same state. the difference here is that it has a new address space, a new program run, a new set of global variables, a new heap, a new stack, a new entry procedure, cpu context wiped away and sent its initial state. so here's the weird thing. exec could fail. physically example fail. if this program does n't exist, right? if i try execute gallego and the operating system said ohh you trying execute that program, where is it? no, sorry. do n't know where that is, right? it ca n't create an address space from something that ca n't find. there's also some permission aspect, right. if you try run a program that you do n't have permission, or if you tried tell the operating system, please execute this program."
"""OpSys_Processes_and_Fork_Transcript.txt""","exec could fail. physically example fail. if this program does n't exist, right? if i try execute gallego and the operating system said ohh you trying execute that program, where is it? no, sorry. do n't know where that is, right? it ca n't create an address space from something that ca n't find. there's also some permission aspect, right. if you try run a program that you do n't have permission, or if you tried tell the operating system, please execute this program. it's called my file dot txt and it's just a text file. it does n't actually contain a program. the operating system is going say i'm sorry i ca n't run a text file. i have have a program so those types of things causing sector fail. if it does, it follows our standard failure procedure where it says so turn -, 1, set errno accordingly, and then process. you got ta figure out what went wrong, but here's the kicker. what does exact do? what is exact return if it succeeds? philosophical world here does exact return if it's succeeds. why not? a lot. yeah, that's the answer. there's no place go. i love that answer because exact is an instruction that invokes a trap. those instructions are in the processes old address space, the return address, all that stuff was in the processes, old address space. that old address space is gone, so there's no place go. right. if you were go back my address idea of my house, right. it's a single story ranch with gray exterior 3923 k, right. if you were say exec, i want you execute a new house. it's going be a two story brown house. well, like a single story gray ranch with a what ranch for the gray exterior. they're gon na bulldoze that down and restore it and put a nice brand new house there. so how do you knock on my front door? well, my front door is gone. it's a new house. no, my house is still there. have n't gone you, so that's exact and that's it. so this guy, when he continues along now instead of executing the black thing, he's executing the new program red, ok. so this is why i say that fork and exec are two sides of a coin. you often will see them done in pairs, because if a process run and it runs exactly, it's gone."
"""OpSys_Processes_and_Fork_Transcript.txt""","well, my front door is gone. it's a new house. no, my house is still there. have n't gone you, so that's exact and that's it. so this guy, when he continues along now instead of executing the black thing, he's executing the new program red, ok. so this is why i say that fork and exec are two sides of a coin. you often will see them done in pairs, because if a process run and it runs exactly, it's gone. if you have a process that wants run another program, what it will do often is spark create another process and then that child process will call exec replace itself with a new program. that's what shells do when you wanna command ls and you enter the shell forks itself, creates a child process, and then uses the return value from fork say if i'm a child, i'm gon na run and execute ls with exec and then the parent process the shell that's still running. we'll just do a wait for ls finish and then it'll keep going. graphical user interface. they do this too. they when you double click on something, it gets an event say the user double clicked on something. that's the program that needs get run. i'm gon na fork, run the program, and i may not wait for that program finish because your graphical user interface usually wants by chrome might not finish, and so it usually then just backgrounds that and just keeps going wait for another user input. but ultimately, that's really kind of what happens. question. yeah. what about, like seeing you were like the child process actually changes, but the current process, stevie, is weird because cd actually is n't necessarily a command. that's actually internal the shell, where it's modifying an environment variable. so you actually have an environment that you're sent your programs. processes are within and i'll talk a little bit about environment variables in a second here, but your current working directory or cwd is referred in a environment variable, so cd actually says shell when you just change the environment variable a new place, and that's what the shell is doing. it's actually changing your environment so it's a little bit different than than ls, is an actual program. so you've got me start. ok, so now that we know how exact works works. now we can go back and look at the flavors of exec and then i can do an example."
"""OpSys_Processes_and_Fork_Transcript.txt""","processes are within and i'll talk a little bit about environment variables in a second here, but your current working directory or cwd is referred in a environment variable, so cd actually says shell when you just change the environment variable a new place, and that's what the shell is doing. it's actually changing your environment so it's a little bit different than than ls, is an actual program. so you've got me start. ok, so now that we know how exact works works. now we can go back and look at the flavors of exec and then i can do an example. so 6 flavors of exec. the first right we've got exact and then the first letter we've got exact l or exact v ok and then after that we have pe or nothing. it's kind of kind of combinatorics, but it does n't matter. so what does al versus b? you know what? i'm gon na skip that. i'm actually gon na go one farther. i'm gon na look at p versus non vok. so if you look at any time that there's a p here, we see the word file after it, and any types is n't appealing. we see path name. i think that that's yeah. ok, inside our process that's executing right, i like think of it as the parent, but it does n't have be. it's some process that's executing that's gon na call. exactly. we have an environment that's specified in there and as part of that environment is a variable called the path. and you may have had muck around with this on windows. i know that i've had two for some reason whenever i install intellij, i usually have muck with this. i go into my system environment variables and i set up paths something for java. when i install it, but at any rate, if you were launch the windows command prompt, cmd exe, or launch the ubuntu shell. i could type the command dir on windows wherever i did that and it prints out a directory listing in windows somewhere. i do n't know where there is a program called di r.exe lists the contents of my directory. i did n't know the type that or tell windows exactly where find that program. it just found it and the way it found it was by looking in my tap inside my path is a list of directories say operating system. i want you find this program."
"""OpSys_Processes_and_Fork_Transcript.txt""","when i install it, but at any rate, if you were launch the windows command prompt, cmd exe, or launch the ubuntu shell. i could type the command dir on windows wherever i did that and it prints out a directory listing in windows somewhere. i do n't know where there is a program called di r.exe lists the contents of my directory. i did n't know the type that or tell windows exactly where find that program. it just found it and the way it found it was by looking in my tap inside my path is a list of directories say operating system. i want you find this program. i do n't really know exactly where it is, but the system administrator has given you a bunch of places go look and so the operating system will do. is it will look in your path for a particular command. it will do that. with exact. with the p? well, that's why it says file. you do n't have specify the entire path the the program, just the file name and the operating system will figure out where that program is, and on my computer, if i do that, i can actually say echo dollar path print out my environment variable and then here is all of the directories that my system is gon na look for for commands, and they're joined together with a colon. so it's this one or that those are different directories, ok. questions. ok, so now let's go and look at this v versus l. so the only difference between v&l is essentially these parameters. after her. notice these three dots versus over here we've got things array braces for all the the versions. this l stands for list versus variable ok and so. we did n't talk about this, but you may not have talked about it and see or cs when you took that class. i know you probably got an exposed. it and we took up, if you know python, but some programming languages allow functions have a variable number of arguments they've ever seen that we you could do one or two java. i think it would be pretty explicit. i do n't know if java allowed the variable number of arguments, at least. maybe it does. now i know that i never used, but in c you can have a variable number of arguments and what this is this dot dot dot is saying is it's telling the declaration here that this function supports a variable number of arguments. what are those arguments? these arguments are the command line arguments."
"""OpSys_Processes_and_Fork_Transcript.txt""","and we took up, if you know python, but some programming languages allow functions have a variable number of arguments they've ever seen that we you could do one or two java. i think it would be pretty explicit. i do n't know if java allowed the variable number of arguments, at least. maybe it does. now i know that i never used, but in c you can have a variable number of arguments and what this is this dot dot dot is saying is it's telling the declaration here that this function supports a variable number of arguments. what are those arguments? these arguments are the command line arguments. so what's a command line argument? it's probably better off just show an example ls that's a command, right? if i run ls, it lists the contents of a directory. if i run ls - l it runs a long listing of that directory and dash l here is a string that represents a command line argument. ok, you can specify a whole bunch. we can do ls - l, is a long listing. you can do dash t gives you the output sorted by date created. so now it just reorders them in a different order and we see the files that are more recently created are on top versus bottom. atlas has a whole bunch of different parameters you could look at. the man page list without a, not. you probably notice this the compiler gcc. if you look at the man page where gcc good luck, there's a lot of different parameters and options that you can specify. on gcc, those are all specified as command line arguments, so when we run a command or command, when we run a program via exec, we need be able pass those arguments whatever program we're running, and that's what the albertson's b does is it specifies how we give those the operating system. so without we're using a variable length. out parameters with v or giving it just in array of strings that represents. the different command line arguments though with the variable length arguments we just specify them as parameters and they're variable because we might not have what we have one we might have none. we just have differing number of command line are notes, l has a different number of command line arguments than that's. all dash t right? so with me on that command that i went. yeah, no, the last bit here is an environment allows you specify a list of environment variables."
"""OpSys_Processes_and_Fork_Transcript.txt""","out parameters with v or giving it just in array of strings that represents. the different command line arguments though with the variable length arguments we just specify them as parameters and they're variable because we might not have what we have one we might have none. we just have differing number of command line are notes, l has a different number of command line arguments than that's. all dash t right? so with me on that command that i went. yeah, no, the last bit here is an environment allows you specify a list of environment variables. if you wanna customize how you want this program run, you could specify specific environment variables. these are n't usually used if you ever want sandbox a program from running prevent it from accessing certain things. so like docker containers and stuff like that might create a custom environment restrict what a program can access. one not gon na worry about that too much in the slides is kind of more of an advanced topic. not that this class is in advance, but we just do n't topic. i hate say it that, but i'd love cover it. just i'm gon na run. so we're gon na cover command line arguments and programs, ok? ok, so let's do an example here. and that will probably run the time. let's make any file. and i got ta look up where executives. you and i have std. great. awesome. umm. i'll do that for printing stuff out. so we're going exec something. so we're not gon na fork, cause we do n't need. in this case, what we're gon na do is we're gon na exactly command and have it replace a dot out with the new command or the new program. so do that, simple enough, we can just an exec exec. i'll run lp so i can just wheezing p say use the environment variable path so i do n't have specify the whole path ls. incidentally, if you want know where that is, you can use the command. looks up program. wanna know what they stand for? we could talk about that later, but not that important, but that's where it is. so we can always use. but i'm going use the lp version so i can use variable length arguments and use the system environment variable path so i can just run ls and then it says that i need specify all of the command line arguments as separate parameters in the function."
"""OpSys_Processes_and_Fork_Transcript.txt""","incidentally, if you want know where that is, you can use the command. looks up program. wanna know what they stand for? we could talk about that later, but not that important, but that's where it is. so we can always use. but i'm going use the lp version so i can use variable length arguments and use the system environment variable path so i can just run ls and then it says that i need specify all of the command line arguments as separate parameters in the function. and the way i'm gon na tell the operating system that i'm done is by specifying a null pointer. kind of nice. this is the problem we get with variable and arguments. is that just like with arrays in c they do n't know how big they are, so it's argument list does n't know how big it is and we have find some mechanism tell the calling function where where where the end is and so one option that could have been done is you could have had the first parameter being the file name of the path name, the second parameter be how many command line parameters are command line arguments. there's going be and then you can specify a number and like you would if you're gon na specify the array length and a function called, but the developer is a posix. just said, you know what? why do n't we just have you specify a like a null terminator for when the argument list does not and that was located ok little bit different in format but still works. so if i want run ls. i'll do this. and we see that it compiles, but i get a couple of warnings. what does it say? it says warning argument null where not null expected, but it's just a warning, right? but in this case it's actually a problem. and the reason i like purposely made that problem is because it's a subtle weird. i would call it an oddity of the posix environment that i just kind of had get used over my lifetime, and you're gon na fortunately have get used it too. if we look at a system call. like weight. wait says wait for a process terminate and here is an optional parameter that is a pointer some location in memory that says operating system. when that child exits, fill in the child's exit status. here some of the child terminated or it exited gracefully or took it exception."
"""OpSys_Processes_and_Fork_Transcript.txt""","and the reason i like purposely made that problem is because it's a subtle weird. i would call it an oddity of the posix environment that i just kind of had get used over my lifetime, and you're gon na fortunately have get used it too. if we look at a system call. like weight. wait says wait for a process terminate and here is an optional parameter that is a pointer some location in memory that says operating system. when that child exits, fill in the child's exit status. here some of the child terminated or it exited gracefully or took it exception. those types of things would get filled into the exit status if they do n't care what the child's names it status. is this nullable field says? just perhaps null and the operating system will just throw away the child's exit status, right? so nullable is an indicator inside the map page say yes, i'm expecting a pointer here, but if you do n't wanna use the value you could just give me null. exact does n't have it nullable. i this it says this first command line argument must be specified for these something. and this is where i'd like my scratch my head at the designer because it does n't make as much sense me. but it is what you have do. all programs, when they're run, require one at least one command line argument. there's no way specify 0. you have have at least one, and by convention that first command line argument is the name of the program that's being executed. ok. just something we have live with. so what i wrote was wrong because i said i do n't want any command line arguments passed ls. but here is the compiler saying you need something you need at least one and that convention should be the name of the program and in my case the name of the program is a ls. ok, so it looks weird. it's like if that's the way it's got ta be anyway. ca n't the operating system just do it for me? and i would say, yep, unfortunately that's the way the command and the system call was written. ok, this probably a reason for it. i just. i just have go look it up. all right. so that's that. the other thing we should probably do is, but down here. just reiterate that i'm not off my rocker, i do n't make this up. it says the exact functions return only if an error. ok."
"""OpSys_Processes_and_Fork_Transcript.txt""","ca n't the operating system just do it for me? and i would say, yep, unfortunately that's the way the command and the system call was written. ok, this probably a reason for it. i just. i just have go look it up. all right. so that's that. the other thing we should probably do is, but down here. just reiterate that i'm not off my rocker, i do n't make this up. it says the exact functions return only if an error. ok. because there's no place go and a return value of -, 1 and eranos set indicate the error. thank you. so more or less the format here for all system calls. if they fail, they return -. one error asset. the difference here is that if it succeeds normally, would return zero. if it succeeds here, we got nothing. so what we should check the error. ok then. exec fails. just show you how irina works, arena is a global variable and it's included in aronow dot h. so i wanted show you that if i wanted print out what the error number is, i can do that and it's just called error null and then that's enough. i do this here, not hit insert. i'll exit with a bad exit code otherwise. should not get here. should not get here because if exec worked, this program is gone and it's got a new memory. if exact failed, it should return -, 1 and i should have existed. so there really should n't be no reason for uniting here, right? but thank you. right, so now let's run this. hopefully no compile error. ah yes, exit is in std liver. ok, good. clear this and we see that i run eight out and eight out. run the exact. then i rubbed exact gives me alex. ok, the horses are good. if i wanted run with additional command line parameters, i could do this dash l and that this is why i like variable length arguments, because i could just keep adding stuff on here until i blew in the face. and now i get the long listing ok. if i run a command that does n't exist. i should update this for convention. i get exact fail and i get an error too. what does 2 mean? well, we got ta look it up. yes and no. this is where i think it's cool. the operating system actually has our back here."
"""OpSys_Processes_and_Fork_Transcript.txt""","if i wanted run with additional command line parameters, i could do this dash l and that this is why i like variable length arguments, because i could just keep adding stuff on here until i blew in the face. and now i get the long listing ok. if i run a command that does n't exist. i should update this for convention. i get exact fail and i get an error too. what does 2 mean? well, we got ta look it up. yes and no. this is where i think it's cool. the operating system actually has our back here. this is the error number for two that says what went wrong? it's two. if we look at the errors. may set the arnam ok anything that's here and it should say that the error. yeah. do is one of these harris. public provides an environment is too big, that search permissions are denied. if some other problem you have other here's what all but these are worth, what is actual values? these are constants that are defined in error node dot for what these variable things mean. but the thought the number so do n't saying that this is too if i wanna know like an english sort of human readable thing. for what two is, there's a really cool function out there. called str error, says if given an error number it returns a character pointer a string representing like human readable text. for what? that error is. so what i like do is whenever i'm dealing with system calls is i will often instead of printing out the error number like this because i do n't know what that means. there's also something like this. and this is actually in string dot h. well, yeah. so now if i compile this and run it, it says ohh exact bail, no such file or directory. ohh, now i know what's going on. i did n't actually. exceeded a command called. that's good, does n't exist. ok. sounds. yeah, you go over again. why we never reached should not get your princeton. ok, sure. so exactly in this space is going do one of two things. it's gon na succeed or fail. now one of two things. it's gon na do a lot of stuff. if it's succeeds, it's gon na do a lot of stuff, but from my perspective, i'm an invoker."
"""OpSys_Processes_and_Fork_Transcript.txt""","i did n't actually. exceeded a command called. that's good, does n't exist. ok. sounds. yeah, you go over again. why we never reached should not get your princeton. ok, sure. so exactly in this space is going do one of two things. it's gon na succeed or fail. now one of two things. it's gon na do a lot of stuff. if it's succeeds, it's gon na do a lot of stuff, but from my perspective, i'm an invoker. it's gon na succeed or fail if it fails, exact we'll return negative ones and set errno accordingly. so if i if i check here say the return code from exec if it's -, 1 it's going go inside the body of this if statement print out this error message and ice. so if it exits, if not gon na get here, right? if it succeeds, is the other option, the operating system is going take the entire address space for the for this process that this program was created from and get rid of it and replace it with the address space of this command. so as a result, these instructions are no longer in memory. they're gone. so i should n't get here because this should n't exist if exact speed us succeeds. good question. ok. so i got 2 minutes left, but i do n't think i have enough time go on the next thing i wanted talk about exec fee, exec tv and then do some other examples, but for now let's just stop. thanks for coming. lembke, james stopped transcription"
"""OpSys_Scheduling_and_Queues_Transcript.txt""","meeting in _ general_-20240404_130335 - meeting recording april 4, 2024, 6:03pm 47 m 44s lembke, james started transcription lembke, james 0:09 well hello alright. that's good. so what's going on? welcome operating systems today. ah, i like this. we're getting closer and closer my favorite topic and operating systems, will probably get tomorrow, but for now, where are we at right now? we're in a world right now of operating systems that is not very programming heavy and you might say, oh, that's great because we've had enough with threads and concurrency that maybe it's nice take a break from programming. so what are we doing today? hey, we're doing some math, ok? not really like discrete math, but more algebra, and so the math is really today gon na be more about umm. evaluating, scheduling and memorizing terms and relating them what that means. ultimately, it's going be subtraction and division, but what it means is although i spell fairly powerful, and so it seems weird, but you'll hopefully get it when i understand when i get it, but before i get there. what i want do is go back and just review because when a couple of days just and also show you that my notes here have slightly better pictures than what i drew. but we had talked about scheduling in kind of in practice in an operating system when we have multiple processes in the system. so i motivated that if we only have one process in the system determining what do next with it is unambiguous or it's simple. it's you wanna change the process state you change the state of the only process on the system. you wanna schedule a process run? you wanna run its instructions on the cpu? well, you have one choice. you have due process, so it's the process and the operating system. that's it. again, the cpu does n't know what's what it's doing. it knows that it's just executing an instruction stream, but it can flip flop back and forth between the os instruction stream and a process is instruction stream via traps or interrupts right? this timer that can pop with the os can say cpu. let me know what's going on after a certain amount of time and as soon as the os as soon as that happens, the cpu loads the os and now we've got this alternating instruction stream where the os runs versus the process running. but really, it's just a bunch of instructions according the cpu."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","it knows that it's just executing an instruction stream, but it can flip flop back and forth between the os instruction stream and a process is instruction stream via traps or interrupts right? this timer that can pop with the os can say cpu. let me know what's going on after a certain amount of time and as soon as the os as soon as that happens, the cpu loads the os and now we've got this alternating instruction stream where the os runs versus the process running. but really, it's just a bunch of instructions according the cpu. alright, so we talked about different characteristics of processes and then talked about fairness and fairness really is in the eye of the beholder. it fairness means whatever we think it should mean, and this is where the world of process scheduling, like publishing and papers and research, is kind of ongoing because as humans we just ca n't seem agree on what fairness means. and i do n't want us agree because as hardware changes, fairness might change. and so as the number of cpu's in the system grows and as modern memory grows and how quickly like interconnects between memory and cpus happen as we uh move around the wires and the way things work, i want us change what it means for something be fair. so we talked a little bit about what it means be fair, but again that is not the hard set rule, but the next topic that i drew out of pictures of was this was queuing when we have more than one process in the system now we got ta figure out what do with them all. we ca n't just go the process on the system and modify its state. we have go the process that's running or not running or whatever, but if we have a process that's not in this state of running, it's got ta go somewhere. now this is weird because processes do n't move around per say, right? they just are. so when i say that someone moving, it's really a record of what that process is, where it is in a queue. so if you kind of conceptually think of it as moving around, but ultimately we have these cues are represented in os memory ultimately and it's just moving data from one q another keep track of the bookkeeping for what the process is. and so the make it easier for the operating system figure out what do next with various processes, and ultimately the goal here is figure out in processes instructions screen is gon na run on the cpu."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","so when i say that someone moving, it's really a record of what that process is, where it is in a queue. so if you kind of conceptually think of it as moving around, but ultimately we have these cues are represented in os memory ultimately and it's just moving data from one q another keep track of the bookkeeping for what the process is. and so the make it easier for the operating system figure out what do next with various processes, and ultimately the goal here is figure out in processes instructions screen is gon na run on the cpu. so by utilizing a queue, now we have essentially constant time lookup for what do next, and then a process can live in the right queue. it's not blocked for any of the reason it might be blocked for a whole bunch of different reasons, and all of these different cues that are written in here and trying draw on the picture, although i think this is a little bit easier see. they they represent what a process could be waiting for. it might be waiting because it's waiting for some io operation. it might be blocked because it's suspended. it might be waiting for an io for operation and blocked and so all these different queues represent that aspect blocked, meaning something like. it's suspended from an amount of time or it was stopped because it received a single stop. umm was this picture does not include though is other reasons that it could be blocked. specifically, things like blocked on a semaphore or blocked on a mutex waiting queue. i drew that picture and i had a bunch of other cues on there. so all those are also included in there when it comes being suspended and waiting on a semaphore. that could also happen, but we end up with what we should n't end up with, a situation where process is waiting on a7 four and waiting for io in order wait for io. you actually make a system call like read, would cause you access the device. so if you're waiting on the on the semaphore, you ca n't be running make a call for i an io device, so the organization that some of these cues can be simplified. but the goal here of this picture here show you that a process is information might be on any other any number of. sorry, it might be on different queues, but a process can only ever be on one queue at a time. ok, right. so."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","you actually make a system call like read, would cause you access the device. so if you're waiting on the on the semaphore, you ca n't be running make a call for i an io device, so the organization that some of these cues can be simplified. but the goal here of this picture here show you that a process is information might be on any other any number of. sorry, it might be on different queues, but a process can only ever be on one queue at a time. ok, right. so. then we talked about priority and i said well, what we can do, this is a all the only way do it. but there's one way. this is one way we can do it is separate priorities into multiple queues where our process of a given priority is put on a queue and when it comes time figure out who's gon na run next, the operating system gon na go the queue that represents the highest priority and then see if there's any processes on there and then schedule those run on the cpu. if there's no process in the highest priority queue, it just goes the next one. why might a process not begin a high priority queue? well, if it does n't exist, that's one thing, or if it's blocked. if it's, if it's waiting for io waiting on a semaphore, or if it's suspended, for example. uh. and as far as priority is concerned, different operating systems treat priority numbers differently and linux a lower priority number means higher. just what? it's what it is. i'm still operating. systems are higher. priority number means higher. thank you. like just so it's my picture you're thinking this is, you might say id awake, kind of a scheduling algorithm helping the operating system decide who's gon na run next. yes, and i agree with that. because it's kind of a no brainer if a process is suspended or waiting for some reason it ca n't run on the cpu. done. easy decision is that really an algorithm? umm, you could say it is, but what i wanna talk about today is scheduling algorithms related processes that are ready. ok. and you might say, well, are n't just going pick the highest priority process run, ok, yes. but there are some other things that think about that i did n't really mention that i kind of want add as potential possibilities for managing this ready queue and then use that evaluate efficiency."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","because it's kind of a no brainer if a process is suspended or waiting for some reason it ca n't run on the cpu. done. easy decision is that really an algorithm? umm, you could say it is, but what i wanna talk about today is scheduling algorithms related processes that are ready. ok. and you might say, well, are n't just going pick the highest priority process run, ok, yes. but there are some other things that think about that i did n't really mention that i kind of want add as potential possibilities for managing this ready queue and then use that evaluate efficiency. so i'll talk about what it what evaluation criteria we can use evaluate new efficiency. also, keeping in track fairness as well as priority, but it's really gon na be how are you going manage this ready queue? ok, so let's go down here scheduling and i want talk about two things and then some other subcategories of that preemption versus non preemption. we i use this word before, right? where did i use this word before? there's remember. well, outside of operating systems and that world preemption, i feel like is a big word. there were no i mean, other than reading the slide. what does it mean be preempted? well, it's like in the slide, no preemption operating system. let's process run completion without interruption and preemption. operating system interrupts processes running for some reason. remember the conditions for deadlock too, doctor about preemption. and in there deadlock a condition for deadlock is no preemption, that there is no interface allow something be essentially yanked away from it. kind of a rude thing, right? no preemption in deadlock means i can hold on something, and if i wanna get rid of it, it has be my decision. i have say i am done with it. you can have it. it is my decision get rid of it. a preemption is kind of like that teacher on the playground where it says you know what you're holding on the ball, but you do n't get it anymore. i am taking it away from you right? i often pre up my daughter maybe more often than i should. if she's holding on something that i want, i'm saying no. it's. sorry, papa's time have it right. i take it away from her. the other option is no preemption where she plays with something and she goes. i'm done with this pup. i you go right."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","a preemption is kind of like that teacher on the playground where it says you know what you're holding on the ball, but you do n't get it anymore. i am taking it away from you right? i often pre up my daughter maybe more often than i should. if she's holding on something that i want, i'm saying no. it's. sorry, papa's time have it right. i take it away from her. the other option is no preemption where she plays with something and she goes. i'm done with this pup. i you go right. so when it comes the cpu, we can consider that as a resource that the operating system might preempt, and instead of a semaphore or a lock or something like that. but it's actually executing on the on the system, and so we have two options we lot of process the os could lot of process run and just say you get run until you're done. you let me know when you're done. would you just keep the go, get the cpu prevention says for some reason an operating system might say you know what you've had your turns, you are done. somebody else gets run. ok. so questions philosophically perhaps you guys like preemption or not preemption when it comes processes? would you like have a process right? because you mentioned a situation where you run a command in a command prompt and hit return and the entire system just lets that one process run. though it's done a good. why is it not good? i saw shake a head shake. what? back up everything else. good luck out. they bet that process is executing an infinite loop. the system might look like it's locked up. ok. is it good? have i think it's good? it depends. i love that. i love that answer. what is it? the patent? ok, do n't. i'll say that louder and maybe twist the words cause my my short term memory that great. but, umm, critical processes, right? we did n't really talk about this and we wo n't have time, but real time processes, processes with a deadline. there are we're there's computing systems in the world where you know, what if it takes 5 seconds for chrome load a web page? i'm gon na be upset because 5 seconds is a long time me and i wanna be able check my account balance or i wanna check my email or whatever it might be."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","i'll say that louder and maybe twist the words cause my my short term memory that great. but, umm, critical processes, right? we did n't really talk about this and we wo n't have time, but real time processes, processes with a deadline. there are we're there's computing systems in the world where you know, what if it takes 5 seconds for chrome load a web page? i'm gon na be upset because 5 seconds is a long time me and i wanna be able check my account balance or i wanna check my email or whatever it might be. i'd like that page load, but i'm not necessarily going be harmed if it takes 5 seconds or 6 seconds or something like that, right? there are things in this world where i'm using a computer compute them, where i have a certain amount of time or my computer, my system. my hardware has a certain amount of time compute something, and if it does not compute it within that deadline, something bad might happen. you could see there some things like safety car systems. i i use example, it's really crude but bear with me. the idea of military countermeasures right if there's a situation where you're under attack and your computing military countermeasures if you do n't compute the military countermeasures in a certain time before a deadline, it's not gon na make any difference that you actually do the computation in some situation. i'll let you just think about it that way. so process with a deadline. i do n't necessarily want preempt them. right. and so maybe preemption is n't always great. but we're gon na talk about that from a just 8 evaluation criteria perspective, getting away from deadlines and things like that in real time processes. certainly those event deadline and they actually on some systems are scheduled in a different way because of that reason, they're giving special privileges and as a result, you have be a pretty privileged user even run them. but that's idea of preemption versus no preemption. so with preemption and no preemption, we have two subcategories. one is this idea of time of arrival. ok. and so if we're gon na do no preemption with the process, all of us let the process run completion with time of arrival. the operating system is gon na run first come first serve. pretty simple. the first process that runs it gets that comes the system. it gets run completion."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","certainly those event deadline and they actually on some systems are scheduled in a different way because of that reason, they're giving special privileges and as a result, you have be a pretty privileged user even run them. but that's idea of preemption versus no preemption. so with preemption and no preemption, we have two subcategories. one is this idea of time of arrival. ok. and so if we're gon na do no preemption with the process, all of us let the process run completion with time of arrival. the operating system is gon na run first come first serve. pretty simple. the first process that runs it gets that comes the system. it gets run completion. nobody else gets run until that process finishes, and then the next process that we're gon na run is the next one that comes along. ok, i'm arrival the next sub category is amount of time left. ok, so we have a process that arrives at a certain amount of certain time. i i have a command at the command line hit enter. i double click on something on my user interface that causes the process start. it it issues on a fork or whatever create a new process, then an exacto execute the program, whatever it is the process runs, it arrives at a particular time. that process is going need a certain amount of runtime. you mentioned the word cpu burst, is a word that i do n't really like because it seems like burst is something that happens and then kind of fizzles out and it's gone. but burst times, essentially the amount of cpu the process needs finish its computation. ok. what was our two quantities? if we knew them both, we do n't always know them both. we can schedule based on all of those numbers, so we have preemption versus non preemption and we have arrival time and cpu need time. so that gives 4 potential scheduling out for ling algorithms, right? we pick two of two of each of them, so. with that, what are we gon na do evaluate these things? couple of things consider. cpu utilization. we wanna keep our cpu busy. we wanna keep it busy. not only do we wanna keep it utilized, but also we wanna make sure that it's not spending all of its time running os code. because while i like windows because it has a pretty neat user interface, i spent my good money for my games and everything else that i wanna run."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","we pick two of two of each of them, so. with that, what are we gon na do evaluate these things? couple of things consider. cpu utilization. we wanna keep our cpu busy. we wanna keep it busy. not only do we wanna keep it utilized, but also we wanna make sure that it's not spending all of its time running os code. because while i like windows because it has a pretty neat user interface, i spent my good money for my games and everything else that i wanna run. i would like my system run windows and steam and all those other things that i wanted do microsoft teams and so on. i do n't wanna spending all of its time running operating system code, so cpu utilization throughput, the number of processes we can run on a unit time. yes, you wanna make sure that we can do that and have that high. but that being said, if i have lots of processes, or even just a couple of processes that need a long time run, i'm less necessarily concerned about throughput. if i have processes that. have that are gon na run for a long time and have constant user interaction like my web browser. i do n't ever close my web browser. it's always there, right? so i want i can also then you consider through point be kind of related responsiveness. i do n't want my system look like it's locked up, right. and the last thing is this deadlines, then the process complete before it needed or on or before it needed. that gets back right. you can maybe a more a cleaner way say it is like a weather forecaster, right? if i have a weather forecaster that's really great, but it takes 6 days forecast the weather for tomorrow, not going be all that helpful. that's a much better example. let's go with that one. ok. that makes sense. alright, so probably know the deadline. if i'm going forecast the weather, i'm for tomorrow, i better be done by the end of today, ok? and then wo n't be relevant otherwise. all right, so these are some of these subcategories, the ones that i really want focus on is fairness. and these are the numbers that i wanna use. this is the math. these are the terms we have turn around time, is the elapsed time from the time of the process enters the system the time it leads right. this includes all the time that it spends waiting."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","if i'm going forecast the weather, i'm for tomorrow, i better be done by the end of today, ok? and then wo n't be relevant otherwise. all right, so these are some of these subcategories, the ones that i really want focus on is fairness. and these are the numbers that i wanna use. this is the math. these are the terms we have turn around time, is the elapsed time from the time of the process enters the system the time it leads right. this includes all the time that it spends waiting. i as a process, is n't necessarily going get all of the cpu that it that that it needs all the time. it might need wait for somebody this evaluation criteria. i'm only going consider cpu intensive processes because when it comes like io waiting or waiting on a semaphore, there's not a whole lot that i can do about that. if a process is waiting for io, if star trek, i ca n't change the laws of physics. if it takes 5 seconds read a disc, drive the process away for five seconds. i ca n't improve upon that based on my scheduling algorithm, so only the time waiting in the ready queue wait time. ok, the more time that spent in the ready queue response ratio is turn around time divided by service time, ok, turn around time is the amount of time real time, but the process what it's in the system service time is the amount of just cpu time, the amount of like actual time it needs execute cpu instructions. you can consider this be like just the number of cpu instructions that have process needs run as well. ok. what is response ratio? tell us it essentially takes the turn around time, is essentially like wall clock real time and divides it by the service time and tells us how much are the the ratio or percentage wise of the amount of time that it actually took run. then how much it needed so in response ratio is one. that means the process was on the cpu for all the time that it needed, and it did n't wait for anything if the turn around time was two, that means the process waited for the same amount of time as it needed cpu. if it's more than that, you could see essentially the percentage of time additional times. so speak, that the process was in the system then it really needed be. my goal in this? my goal ohh my uh."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","then how much it needed so in response ratio is one. that means the process was on the cpu for all the time that it needed, and it did n't wait for anything if the turn around time was two, that means the process waited for the same amount of time as it needed cpu. if it's more than that, you could see essentially the percentage of time additional times. so speak, that the process was in the system then it really needed be. my goal in this? my goal ohh my uh. my kidding, the goal, our goal, whatever we're gon na say, if we can for every single process in the system have a response ratio of one that would be awesome, right? is that means that nobody waited for anything? are we going get there? probably not, but if we take the average response ratio, we can use this evaluate 1 scheduling algorithm over another. because if we have one that every time produces a response ratio of 1.7 versus for the same set of processes, we have an average response ratio of 1.2, we can assume or guess that one the 1.2 is better than 1.7. with me thumbs up. ok, mac. ah, so the math is not hard. it's just the terms. just figuring out what's what makes it a little bit tricky, so let's just do an example and we'll figure out where we're going go from there. so no brianchon we can do, no preemption and schedule based on time of arrival. and we can do no preemption and schedule based on the amount of cpu needed. ok, that is first come, first serve and benjamin, is shortest job. next, where at any given time we're just gon na schedule the shortest one run ok, under the assumption that all processes of equal priority and they only need the cpu. ok, so here's my example. i have 5 processes. you might say that the numbers, but i use letters just because i'm using numbers and a lot of other places. i do n't wanna confuse anybody specifically mean when i'm sitting so example. so we have brought us that or lettered they arrived at this time. this is like you never times. you can consider it seconds, hours, minutes, whatever. it's just a number of arrival time, and then that's the third column is service time. how much cpu and the process needs run?"
"""OpSys_Scheduling_and_Queues_Transcript.txt""","you might say that the numbers, but i use letters just because i'm using numbers and a lot of other places. i do n't wanna confuse anybody specifically mean when i'm sitting so example. so we have brought us that or lettered they arrived at this time. this is like you never times. you can consider it seconds, hours, minutes, whatever. it's just a number of arrival time, and then that's the third column is service time. how much cpu and the process needs run? ok, so if we do first come first serve, we have this sort of time graph process a arrived at time zero and because it's the only process in the system, it is the first column. so it's gon na be the first serve, so it's gon na run, and it's gon na run completion. so even though process b arrived at time 2b gets thrown on the ready queue, so you get for until it's done. so i have time three. see has n't arrived yet, so it arrives at time four. so b is the next one run. it's gon na run and or it's six time units while b was running c arrived at time 4c arrived at time six. both of them are stuck in the residue in the order in they came after being finishes, we're going pull the next process off the right view and happen be see. then when see finishes, the is gon na run but b arrived while b was excluded 2 at time 8 make it thrown in the ready queue in the order in it got here, and we just gon na have this like drilled down these processes in the order in they come. hey, so far so good. first come first serve. pretty, pretty straightforward. i feel like shortest job next. this is where things get a little bit more tricky. again, hey, here's the first one get. here it is the shortest job next run because it is the only job in the system, so it's gon na run next and no preemption. it runs completion be arrived at time 2 and you might say great. b is not the shortest job. well, in total b is not the shortest job, but i'm not clairvoyant. i ca n't make me come sooner. b is the only one in the system, so it is the shortest job at this time. it gets run completion while be runs. see arrived at time 4d arrived at time 6 and e arrived at time 8."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","here it is the shortest job next run because it is the only job in the system, so it's gon na run next and no preemption. it runs completion be arrived at time 2 and you might say great. b is not the shortest job. well, in total b is not the shortest job, but i'm not clairvoyant. i ca n't make me come sooner. b is the only one in the system, so it is the shortest job at this time. it gets run completion while be runs. see arrived at time 4d arrived at time 6 and e arrived at time 8. all we'll be was running the operating system will then reorder these guys in the ready queue once they arrive based on service time and it will always pick the shortest one, not the shortest arrival time for the shortest service time. and of that all these are in the system b has the service time of 5e. sorry, c is 4 and e is 2 so it picks the smallest is e right here you get the run once you finishes while nobody else came. so we look at the ready you and say is the shortest service time that see segued thoron and then he is the only umm sorry the is the only one left so it gets run the completion but they first job next. ok. we're just reordering the ready queue based on service time, so we have figure out priority queues of service time and all that, but we ca n't like about that so. if that was the case now let's go here and. use these numbers and let's compute some stuff. let's compute our numbers. we have turn around time. we have wait time and we have. response ratio. so of our processes. if i can get this thing focus. pretty good. we have abc and dabcd&e and so for a. the turn around time is the time that ai exited the system, minus the time that it arrived. i'm like moving my mouse over here thinking i can. yeah, so. a arrives at. times 0 and a leaves. i'm gon na try and get these on. there we go. a leaves the system at time. three, right? it arrives at time zero and leaves at time three, so that is 3, -, 0 and so as a turn around time of 3b arrived at time 2 and it left at time 9 right here, right at the 9:00."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","the turn around time is the time that ai exited the system, minus the time that it arrived. i'm like moving my mouse over here thinking i can. yeah, so. a arrives at. times 0 and a leaves. i'm gon na try and get these on. there we go. a leaves the system at time. three, right? it arrives at time zero and leaves at time three, so that is 3, -, 0 and so as a turn around time of 3b arrived at time 2 and it left at time 9 right here, right at the 9:00. so you 9 -, 2 is 7 dc's turn around time c left at time looks like 13 and it arrived at time four, so that is 9 d arrives at times 6, but it left at time 18. so that is. why ca n't i do this math 12 and so e left at time 20? and arrives at time too, is a turn around time of 18. hey, turn around time. ok, wait time. wait time is essentially turn around time minus service minus service time, right? what time did it actually leave? right. what is the total time that it was in the system minus the time of the cpu that it needed? so wait time here is going be i can scoot this over here 3 minus the service time is 3. so a's wait time is 0's, wait time is 7 -, 6, it's wait time is 1. see had a turn on time of nine? it's service time is 4, so it had a wait time of five and then d had a it was 12 minus its service time of five is 7 and then e had a turn around time of 18 and it's service time is 2 gives me 16. the response ratio is essentially turn around time divided by service time, so we'll wait time is turn around time minus service time response ratio is these two numbers divided by each other. so that is i can get this on the same screen 3 / 3 is 1. this one is 7 / 6 is 1.66 or 1.166. repeating this is not a lesson in significant figures, so sorry about that. we've got 9 / 412 / 5 and 18 / 2. 9 / 4 is. one no two point is it 2 1/4? 12 / 5 is 2.2. fifths was at.4 and then 18 / 2 is 9. ok, response ratio, good, so. is that good? yeah, i'm happy."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","so that is i can get this on the same screen 3 / 3 is 1. this one is 7 / 6 is 1.66 or 1.166. repeating this is not a lesson in significant figures, so sorry about that. we've got 9 / 412 / 5 and 18 / 2. 9 / 4 is. one no two point is it 2 1/4? 12 / 5 is 2.2. fifths was at.4 and then 18 / 2 is 9. ok, response ratio, good, so. is that good? yeah, i'm happy. if i'm me personally, it took me 9 times longer than it would. it should have or what it could have had. i ran right away. he's pretty happy. but you'll see in a way the putting a wind processes arrive as we run the system, run the response ratio kind of cumulatively gets worse as we do n't, right. ok so. let's look at shortest job next. ok, turn around. time for shortest job? next, a is still 3 -, 0 b is still 9, -, 2, but now e we've got the rod. next it exited the system at 11 and so it's 11 minus its arrival time of two dc is little different. that is now 15 and it arrival time is 4 and d is 20 and it's arrival time is, uh, what's 6? so if we were do this math, we get 379 uh 12. nope. 14 and 9 ok. wait, time is still 3 -, 3 is 0 for a it's still 7 -, 6, is one for bc now is 9 -, 4 is 5. umm wait, i must have done something wrong. 15 -, 4 come on. am i going too fast? so anyway, now 11 -, 4. now, what's this seven? and now d is 20. no, wait. 14 minus it's service time of five, is that one nine. and then we have e is its turn around time minus its service time is 7. ok. is it better? i do n't know. we'll figure this out response ratio for a is still one response ratio for b is still 1.166 repeating response time for d is 11 / 4, is 2 3/4. is that right? yes, 2.7514 / 5 is. two and 4/5, is what 2.8 and then now we have 9 / 2 is 4 1/2. ok. is that better? well, average."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","and then we have e is its turn around time minus its service time is 7. ok. is it better? i do n't know. we'll figure this out response ratio for a is still one response ratio for b is still 1.166 repeating response time for d is 11 / 4, is 2 3/4. is that right? yes, 2.7514 / 5 is. two and 4/5, is what 2.8 and then now we have 9 / 2 is 4 1/2. ok. is that better? well, average. i'm not gon na do this math because my brain is already tired from doing math, so i'm just gon na do this. here is the finished times. the turn around time and then the response ratio as we just computed. apparently i needed background cause i got teaching. but it's very very got 6 here. this should be right? so i was just threw up in my mouth, but alternately we get first come, first served as an average response rate of 2.56 and shortest job. next, the average response ratio is 1.84. so from that perspective, i would say that shortest job next is better as far as efficiency is concerned and fairness processes get run a lot closer what they think they should of these access. ok, so. that's preemption. or rather, that's no preemption. let's look at. let's look at the preemption version. so with preemption we have a again still those two sub options schedule based on time of arrival and schedule based on how much time we have left. ok. so what's interesting about that we leads things like shortest remaining time and round robin shortness remaining time means that at any given time, we are gon na always right. any time a process arrives or when it executes, we're gon na look at the ready queue and at any time, we're going take the current process off the cpu and let the process run. that is the fewest number of time units left, so we're going run into situations where now in our time graph, instead of having one process runs solid, we're gon na have breaks in it or it's gon na run and then maybe it's gon na not run. and then it's gon na run again later on. ok. so in that particular case, our turn around time, our computation board, we got ta consider these other gaps versus before. it was just you arrive, you run when you get the run, you get the run completion."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","that is the fewest number of time units left, so we're going run into situations where now in our time graph, instead of having one process runs solid, we're gon na have breaks in it or it's gon na run and then maybe it's gon na not run. and then it's gon na run again later on. ok. so in that particular case, our turn around time, our computation board, we got ta consider these other gaps versus before. it was just you arrive, you run when you get the run, you get the run completion. lot easier figure out the turn around time, but for preemption it's a little bit different. so here is that's no preemption. here's the preemption version, so with round robin and shortness remaining time, ron robin is essentially scheduled based on time of arrival. but because we have preemption, what you do is you say i'm gon na give you a time. that you get run and amount of time and the operating system terminology. they use the word time quantum ok. every process gets a quantum. here i'm setting the time quantum queue be one, means every process gets run for one unit of time and after that if there's somebody else ready run, we're going let them run. what order do we pick them? we picked them on the order of arrival. right. like first come, first serve. but we used round routing break them apart. so in this case a gets a run because for the first two time units it's the only process in the system. as soon as he arrives, it is run. we suspend a with preemption a + 1 more time unit because b is the next one run a next one arrive. so it gets run and and at the end of its time unit, we alternate between a&b until another process arrives. when that happens, we alternate between every process that is in the system. a is done at this point. so only ab and c left ultimately derives, so we're gon na start rotating between bc and d until they're all done, and then ultimately he will arrive. so alternate between all three of those or four of those processes until a process finishes or any another process arrives and we add it the list. so round robin scheduler taking turns. well, how much time do we get? we get one or whatever our quantum is."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","when that happens, we alternate between every process that is in the system. a is done at this point. so only ab and c left ultimately derives, so we're gon na start rotating between bc and d until they're all done, and then ultimately he will arrive. so alternate between all three of those or four of those processes until a process finishes or any another process arrives and we add it the list. so round robin scheduler taking turns. well, how much time do we get? we get one or whatever our quantum is. if i set the time quantum be 2, this would be different as far as the graph is concerned, but you get the idea ok. jordans remaining time is. scheduled based on how much time is left. so this is what's kind of cool about this is a arrives. it's the only one left, so it gets rough at time. two will be arrives ok, but the operating system is going look at the current running process and say b is ready. a. you're running? how much time do you have left? as time too is used up, two of its service time units, so it just has one left. so because the run, because it has the shortest remaining time, he has one unit left, he has six, but he has n't run yet. at time 3, ason b is the only process in the system. it gets run for one time unit. ok. how much time year is left for me? bye by 6 -, 1 is 5 and times 4. see arrives. see as the service time before b has the remaining time of five. so c gets run because four is less than five. so pam at times six he arrived ok? d needs 5c, has two left, so two is less than five, is also less than six. so c gets run completion at this point, at eight, he arrives. he needs two time units. he needs five time units and b needs, i guess also five time units because it got the wrong one already two is less than both five and five, so he gets the run at this point. now the operating system has a choice. it always has a choice, but it is a more difficult choice. we have two processes in the system that both need two time and what they five time units. one do you pick well? either one would make it."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","so c gets run completion at this point, at eight, he arrives. he needs two time units. he needs five time units and b needs, i guess also five time units because it got the wrong one already two is less than both five and five, so he gets the run at this point. now the operating system has a choice. it always has a choice, but it is a more difficult choice. we have two processes in the system that both need two time and what they five time units. one do you pick well? either one would make it. would would be fine in this particular example, is showing that the operating system is picking the one that arrived first. looking at our evaluation criteria of turn around time, that tends make it a little bit better as far as having it wait based on when it arrived in the system. so thinking the one that arrived first is what's done here. so be good run for its last five time units. then he gets run for it's time. five time units questions. correct. so. i'm not going do the math, i'm just going show you the math, because if i'm hoping it's right. but by doing this we have this set of values for entry and exit from robin and and or shortest remaining time we've little bit difficult because the arrival time and then the end time got all these gaps. so they add up all these gaps in there like they're all in there and we end up with an average of 1 phrase. you have 2.71 for round robin and 1.594 shortest remaining time. ok, so all these four, ones best? we have 1.591 or 2.71. we have 2.56 and 1.84, so if you're using straight numbers, the answer is shortest remaining time. hey, makes sense right? i like this nice clear simple. it's not like threading where it's like we're doing a condition variable. or do i need a right? you just look at the number and that's what's best. alright, so here's my argument. we have 4 algorithms ok one is best and one is worse while shortest remaining time is best and looks like round robin is worse, right? here's my argument. here's my my my thought my my conjecture in an operating system. one is most likely most often used? round robin, why you look at that and say ron robbins the worst. why is it the? why? yeah."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","you just look at the number and that's what's best. alright, so here's my argument. we have 4 algorithms ok one is best and one is worse while shortest remaining time is best and looks like round robin is worse, right? here's my argument. here's my my my thought my my conjecture in an operating system. one is most likely most often used? round robin, why you look at that and say ron robbins the worst. why is it the? why? yeah. yeah, because with the shortage for meeting time, anything that has a long run time might not run. if you short one, but possibly together. ok, i like that. so shortest remaining time and shortest job next also suffers from this starvation. if we have a lot of short processes running my long running process is n't gon na run for a very very very long time. ok. ok. that stakes. what's it another thing about shortest remaining time and shortest job neck? yeah. ok, there's a lot of bookkeeping in the background. we got ta order the ready queue based on the shortest remaining time. that's stinks right overhead. good. i like that one. there's another one, too, that these are some of these. actually, i did n't really think about, but there's another one that i'm thinking about. it's often not possible or even impractical know what the service time of the process is, right? if i'm running a video game, i do n't know what the service time is for that, because i'm gon na play it until i'm done, right? so for the operating system schedule that video game run based on how much time it needs, it's not going know. so it might not even be possible do shortest remaining time or shortest job first, because we just do n't know. first come first serve. that's ok. that's good. it's better than rob robin slightly, but we get back the situation of if i'm only gon na run the one process that it came first till it's completion. so that means i'm gon na double click on my video game or something, and i'm never gon na get run microsoft word or chrome or any other process in the system, right? so first come first serve is also slightly impractical due system responsiveness. we wanna be able make our system looks like it's not locked up. so what are we left with? round robin. ok."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","it's better than rob robin slightly, but we get back the situation of if i'm only gon na run the one process that it came first till it's completion. so that means i'm gon na double click on my video game or something, and i'm never gon na get run microsoft word or chrome or any other process in the system, right? so first come first serve is also slightly impractical due system responsiveness. we wanna be able make our system looks like it's not locked up. so what are we left with? round robin. ok. so that being said, though, operating systems often combine raw robin with other criteria. beside, yes, we are going take turns and give these process of time quantum, but we have some additional parameters when it comes time quantum things like what is the time quantum going be? are we going use a fixed time quantum? you all processes at the same time quantum. or do we allow some processor run longer than others? is that fair right? things consider, and even within that, the overall size of the time content makes a difference, ok. in this picture i drew it like this, mainly because it's easy and it all fits on the slide together, but in reality there's more this picture that i'm not showing because this shows the context switch we're running any now we're running b right in order do a context switch. the operating system needs run. it needs read the process control block. it needs update the state. it needs do a whole bunch of stuff that makes this bar. i have a little bit of a gap in between it right or something like shortest job next or really even we if we look up here at these guys up here, right, we have 5 processes. we have 5 context switches or 4 right? i guess you could say 5 because we got ta run the first one. so anyway, 5 context switches, right? this is a pretty tight compressed grant. round robin. really i should have a gap in between every single one of these boxes. so there's that gap graph here. should really be spread out quite wide, right? we could make it skinnier by making the time quantum bigger, right? because of that case, we made the time frame and say 68 could run the completion and we'd have less context switches. b might need at the type product was. i'll say it was five."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","so anyway, 5 context switches, right? this is a pretty tight compressed grant. round robin. really i should have a gap in between every single one of these boxes. so there's that gap graph here. should really be spread out quite wide, right? we could make it skinnier by making the time quantum bigger, right? because of that case, we made the time frame and say 68 could run the completion and we'd have less context switches. b might need at the type product was. i'll say it was five. we would do 2 contexts is total execute all of b, but these processes we'd have fewer context switches, so that's kind of nice. what's the problem? of having a large time quantum. yeah, just becomes first come, first serve. it just becomes first come, first serve, yes. if the process fit with inside time quantum right, and with that was the question of system responsiveness right? with first come, first serve. we did n't like it because the system did n't look responsive. if i had a time quantum say of one second, right, pretty big, right? very few context switches. that's great. in the process lifetime. but if i have a process that's a long, long running process, like say chrome. if i had a time part about one second. if i had six chrome tabs, if you think each chrome tab is implemented as its own process right, that means that in order for me click and change chrome tab in order for that chrome tab change, it has get the cpu in order update itself. that's updates only going happen once every second, so could you imagine a situation where you click on a chrome tab and it takes a second? or actually flip? i i do n't think i would like that. i mean, maybe i would get used it after a while, but i've kind of been frustrated. it maybe my system feel like it's not responsive and be like i spent a lot of money for the cpu. what's it doing right? it should move that tab like nobody's business, right? so we have a different uh, we have a trade off between the amount of overhead that we have in the system that where the cpu is just executing os instructions change processes versus system responsiveness. low time quantum means high system responsiveness, but it also means high overhead or for operating system context switches."
"""OpSys_Scheduling_and_Queues_Transcript.txt""","it maybe my system feel like it's not responsive and be like i spent a lot of money for the cpu. what's it doing right? it should move that tab like nobody's business, right? so we have a different uh, we have a trade off between the amount of overhead that we have in the system that where the cpu is just executing os instructions change processes versus system responsiveness. low time quantum means high system responsiveness, but it also means high overhead or for operating system context switches. we'll talk about some other overhead context switches when we talk about memory management, but that's another thing consider. so when it comes through on robin, what's the use? i say and argue that it should just be. small or big, it should be as big as possible, but small enough for user interaction make the user think that the system's not locked up. what should that time quantum be? hard say. ultimately, it almost becomes a certified user experience situation. say use the system and let me know if you feel like it's responsive. right, you can send it that way, cost. could it be dependent on the number of processes running? well, obviously if you only have one process running, pretty easy make that decision. but as soon as you have two now, you almost 2345, you could say the more processes i have, you could say there's smaller. i want the time point would be not. i do n't know. it's it's. it's weird and this is where, again, it gets almost into our philosophical research statement. i will tell you that the linux scheduler uses a dynamic time quantum error try and be fair, so process that gets the cpu a lot when it finally gets run, it does n't get the run for as long as what others worry. but for long story you could research the linux scheduler goes on for a long time. it used use something called. it's called a order one scheduler, is more along lines of what we talked about and now it's all different. but anyway, i'm out of time. i ca n't talk about this now, but that ends our discussion on process scheduling. tomorrow we'll talk about memory management. thanks for coming here, it's. lembke, james stopped transcription"
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","meeting in _ general_-20240322_130417 - meeting recording march 22, 2024, 6:04pm 44 m 46s lembke, james started transcription lembke, james 0:09 hello. hello. great. alright, so. operating systems isolation and protection abstractions are cool. we were going through these notes. and working through threads and concurrency. so today i kind of want kind of finish this topic and then do some examples and then start an example that will be kind of a series of examples that will actually lead us probably into next week. so that's the plan for today and moving on. so we ended up with talking about this, some of ours, this signaling mechanism they have that counter and a queue mutex locks are locking mechanism. they have a queue and sort of this binary value of locked or unlocked right? some of ours are just counting mutexes have a lock. they have this idea of ownership and so whenever we think about ownership, then all of a sudden we have figure out well, what if the owner goes away and we had a couple of options for like recursive locks, this idea of a robust lock versus a non robust lock where for a robust lock, if the owner dies are starting terminates, it should n't say dies but terminates. a robust lock keeps its lock. i always and then the non robust version where we just kind of like release the lock when when the owner sort of terminates. what i wanna talk about today is condition variables, is a topic. that is, it took me a while feel like really kind of like figure out when i would want use a condition variable, is why i want kind of motivate it. and then show you a simple example or a couple of simple examples and then go into this more detailed example of a producer and a consumer. ok, so i think right? so. let's talk about this. let me draw pick. let me go up here, yeah. here is here is a dilemma that i'd like make up. kind of have an idea i've got. something some person, whether it be a person or a network card or i do n't know, something, some entity that is producing some value. i'm creating something. this person might be creating something and what it's gon na do is there is going be a spot. we'll just call it some sort of shared location where this person is going be producing some sort of thing and putting it on the ground. ok, putting it in a space. so we have some producer. and."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","kind of have an idea i've got. something some person, whether it be a person or a network card or i do n't know, something, some entity that is producing some value. i'm creating something. this person might be creating something and what it's gon na do is there is going be a spot. we'll just call it some sort of shared location where this person is going be producing some sort of thing and putting it on the ground. ok, putting it in a space. so we have some producer. and. what i wanna do is i have some shared location where i wanna be able produce and put this item in the shared location. ok, this is kind of like an in programming this idea of the just a variable. i've got a variable that's shared and in more than one person attempts modify the variable at the same time, we can cause corruption in the variable value, right? we try. we mentioned that with plus plus plus plus is not in the tomic operation, so if we want control access that operation, we can either use an atomic operation, we ca n't always do in all cases, or we use a lock or semaphore. right. something lock out that critical section. we have some critical resource here. ok. and then we have. that's how you draw feet one or more other people that are all trying take that resource out of its storage place at the same time. so these are consumers. ok. replace of our so knowing what we know now about threats and concurrency if we were just say this is a variable and these are all threads, this guy is going produce something. set a variable and then maybe you go sleep using the sleep function and then after so much time produce that variable again and then so he's going create stuff and put it down periodically, right? i'm, you know, drawing pictures. and i'm gon na send them on here for someone take baby. if i was just do that and then this guy was gon na, like, take values from that location, it's actually take that variable. maybe like set it 0 or something, but they're gon na be consume what's there. i do n't like contention problem right here. right. i ca n't be modified this and i ca n't be modifying it adjust the value, add modifying it remove the value at the same time i could n't have corruption in my values."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","and i'm gon na send them on here for someone take baby. if i was just do that and then this guy was gon na, like, take values from that location, it's actually take that variable. maybe like set it 0 or something, but they're gon na be consume what's there. i do n't like contention problem right here. right. i ca n't be modified this and i ca n't be modifying it adjust the value, add modifying it remove the value at the same time i could n't have corruption in my values. i tried change this so that's the problem and so i wanna synchronize this right? so i know how do that. we have locks, right? we have new text locks. i can say i want modify this the very first thing i do is i lock it and at that point no other producer or consumer is gon na access this at any given time and as a result i can put my item there and then release the the lock. i can go sleep if later on, nobody actually takes that item, i can wake up and then lock this check. if the item is there, and if there's already something there, i can say oh, there's already something there. i'm not gon na produce another one and then unlock it and go sleep again. right. these guys can make a lock and then check if something is there and if something is there they can remove it. whoever gets in because there's a lot of only one of these guys is gon na get out of it at the time and they're going grab that item and then they can either go sleep or do what they need with that item. this is kind of like in a way polling, right? we can just say you there yet you there yet you there yet and there yet there yet, right. what i do n't like about that is if there's nothing there these days over here. the doing a lot of work that's not needed i. so while this is gon na be kind of made up and could try, uh, i'd like find a way let these guys go sleep forever until there's actually something there for them consume. right. so i'd like them just starting out with one lock, is a control on this guy. i ca n't really do that because as soon as this guy gets a lock, he could say i'm gon na wait on a lock on this critical area here, right?"
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","the doing a lot of work that's not needed i. so while this is gon na be kind of made up and could try, uh, i'd like find a way let these guys go sleep forever until there's actually something there for them consume. right. so i'd like them just starting out with one lock, is a control on this guy. i ca n't really do that because as soon as this guy gets a lock, he could say i'm gon na wait on a lock on this critical area here, right? but if this guy's not producing anything and there's nothing there, this's gon na get that lock and they're gon na be like, ok, there's nothing there. what do i do with it? so i really i'm looking for an extra mechanism allow this guy or this guy or someone wait say i do n't want get up until someone gives me a call or sends me and notification say hey, there's something there for you consume. maybe you should try get it right. and this idea of a signaling mechanism, along with a lot comes up a fair amount in situations where you have what's referred us. here's the called the producer and consumer problem. we're gon na go through a more detail. well, right now this is sort of the single producer consumer problem we have. i'll producer that's producing one thing and one thing only, and then we have maybe one or more consumers that are going get that item. so the developers of concurrency mechanisms said well, alright, that's great. but what this guy really wants do is he should go sleep. but when he wakes up be told that there's something there, i only want this guy wake up grab the item. if there's something there, and if he can retrieve this lock his he ca n't get the item out of this out of this location unless they've gotten the lock right. that makes sense. so this idea of being signaled and getting a lock is almost like a merging of a semaphore and a mutex lock, right? i do n't know. it's, i guess i'm sorry if it's confusing. that's the best way i could try and explain it. maybe it becomes easier once we get the color, but that's what we're what the next concurrency mechanism has. it has essentially an ability say i am a consumer or i am a producer."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","if there's something there, and if he can retrieve this lock his he ca n't get the item out of this out of this location unless they've gotten the lock right. that makes sense. so this idea of being signaled and getting a lock is almost like a merging of a semaphore and a mutex lock, right? i do n't know. it's, i guess i'm sorry if it's confusing. that's the best way i could try and explain it. maybe it becomes easier once we get the color, but that's what we're what the next concurrency mechanism has. it has essentially an ability say i am a consumer or i am a producer. i'm gon na be producing something as a producer, i want lock this thing down so that i can put something in this spot. but then what i want do is i want release this lock and signal. anybody that wants get the item at this more or less the same time and while i'm waiting, i wanna be able wait until i'm signaled and retrieve and have an ownership of this lock. and i only want one of these consumers be able retrieve that lock by the time, so a condition variable, is what it's called. i do n't know why it's called that. i guess it it merges this idea of a signal or where you're signaling a condition say something is true or not. is there something in this spot and a mutex lock lock the spot itself and? so if we go. the docs for that. a condition variable is another incurred mechanism. so now we have some authors 17 we have pthread mutex, underscore t for mutex lock and we have a con tv or a condition. this is what's gon na store whether or not the condition is satisfied or not. so unlike a semaphore, a condition that's either satisfied or it's not satisfied. that's the first thing with the condition. we do n't have a count. all right, we initialize it and we can destroy it all. we've got this idea of this wonderful pthread of kind of initializer. alright, so that's that. the next thing i got ta find the function for it, although it's just called, i do n't wanna use. oh, there it is. ah, please read."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","so unlike a semaphore, a condition that's either satisfied or it's not satisfied. that's the first thing with the condition. we do n't have a count. all right, we initialize it and we can destroy it all. we've got this idea of this wonderful pthread of kind of initializer. alright, so that's that. the next thing i got ta find the function for it, although it's just called, i do n't wanna use. oh, there it is. ah, please read. ca n't wait if i'm a consumer and my my example here, i would like wait until the condition is met that there's something there for me consume and i could only grab the item if i have a hold of this mutex lock. so with this condition says is wait for the condition be true. when i do await right for a mutex, i do a mutex lock. mutex lock says i wait until i can retrieve and be the owner of the lock. otherwise i block if i ca n't get it. if it's unlocked, i get it immediately. if it's locked, i wait until the person who owns it unlocks it, or condition it says. i would like wait until this condition is satisfied. and if i could retrieve this mutex. right. i mentioned that a condition is yes or no was something satisfied and a lock on a particular resource. that lock is n't muted, so i create a mutex lock and say i would like wait until signal say yes, there's something there for me consume and and and retrieve this lock. so when this function call returns, the condition will be signaled and the mutex will be locked. if somebody else's holding that lock, i wo n't be able get it. i'll still wait. so both of these things have be true. it's kind of like an and combined in all one atomic operation. ok, but me, all right, signal. says i am the owner of. well, not owner, but i am a thread or producer or whatever and i wanna say yes, this condition has been met. you go ahead and use that item. so in this particular case, i can do a signal on the condition that will release the first thing, right? there's two things that have be true in our for something wake up from a condition. this is be signaled. that's one and two, they have be able retrieve the lawn."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","says i am the owner of. well, not owner, but i am a thread or producer or whatever and i wanna say yes, this condition has been met. you go ahead and use that item. so in this particular case, i can do a signal on the condition that will release the first thing, right? there's two things that have be true in our for something wake up from a condition. this is be signaled. that's one and two, they have be able retrieve the lawn. so the person that signaling this, if they're holding that mutex lock, they also have release the lock with a mutex unlock. i'll be the second thing that could be done separately, but the retrieval from a wake up from a wait happens atomically and both of those operations must be true in order wake up from the time wait or from the conduit. ok. that's it. that enough. is that clear? i i feel like i'm losing. i'm losing you if i'm losing you. like, throw a tomato or or wave your hand or something like that about losing you. or do n't throw your water, because i i wo n't be able handle that. ok, so let's look at what this looks like. ok. let me just draw an let's just do an example. that's not it. that's not it. that's it, alright. so let's take one of these, you know, let's just make a new one. just so we got it here, pthread condition. let's see. so for this i need a whole bunch of stuff. i need all one of these variables. all of these header files let's just minimize this so we can see what's going. we get thread function, so let me just go over here and grab a thread routine. and i'm going make another routine called, i do n't know, set item and signal. will set the item and then signal the the condition and then i'll make a main. ok, so what do i need for my name for my main? i'm going go through over here. i'm gon na create some threads. come run the thread routine. i need that i need join my threads when i'm done. i'm gon na use this start variable. ok. all right. and then while i'm running here. i'm going. there's something like this. i'll create my threads. i got ta."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","will set the item and then signal the the condition and then i'll make a main. ok, so what do i need for my name for my main? i'm going go through over here. i'm gon na create some threads. come run the thread routine. i need that i need join my threads when i'm done. i'm gon na use this start variable. ok. all right. and then while i'm running here. i'm going. there's something like this. i'll create my threads. i got ta. i'm gon na have him go off the races. i got ta create this and then what? i'm gon na do is. i'm gon na have this guy produce stuff, right? just like in my example, it's gon na produce an item and item it's going produce this. just gon na be some value and then then it's gon na sleep for 200 microseconds and that will produce another one, ok. right. so let's let's now fill in the rest of this. we need a volatile and start. and then what else do i need? i need some place store the value. let's just call it. yeah, we'll call it value holder. and we'll say if the value is zero, that means that the value is been used up one of the threads used it up. if this is like a network card, that means that somebody took the network packet off the network card, but something i so something that has been used on, but zero means used up and some other value means that there's something there, right? so now i need a condition. in order create a condition. i have look in the documentation because i can never remember. i'm going just create it and i'm going use the default values that there is some attributes and stuff you get set for conditions, but i'm just use the defaults so i'll make a new condition and my con will be called value exists. ok. and it's liza. and now, because i have this shared variable, i also need a mutex. not me. fixed. i called, i'll call it value lock. and i'll use the default initializer for that. ok, so now i have my condition variable will allow me signal say that something is there and a lock say that i'm using it and nobody else gets ok. so set item in signal."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","and i'm going use the default values that there is some attributes and stuff you get set for conditions, but i'm just use the defaults so i'll make a new condition and my con will be called value exists. ok. and it's liza. and now, because i have this shared variable, i also need a mutex. not me. fixed. i called, i'll call it value lock. and i'll use the default initializer for that. ok, so now i have my condition variable will allow me signal say that something is there and a lock say that i'm using it and nobody else gets ok. so set item in signal. here's what i got in order save something inside this shared region or shared variable, i got ta lock it right anytime i want access this thing, i got ta lock it. so first thing i need do is get the lock. i'm going lock this value exit value holder. ok and. and unlike it, when i'm done so, one thing i could do is just say value holder equals value, right? that'll set the value in a controlled way. i know that nobody else is gon na mock with this because i've got the lock around it. but what it does n't do is it does n't tell anybody that the values been set right. it just says, i said the valley. and unless you're actually looking at it, you're not gon na know there's a new value that you can sue. that's a problem. that's where condition variables are gon na help us. so once i do that, i can set the value and then say something like. actually spell pthread, right? he thread cond signal and i'm gon na signal the the condition is value exists. now anybody that's waiting for this will be signaled say, hey, go ahead and you wake up. and once this guy unlocks the holder, one of these threads that's waiting on that condition can not wake up and grab the valid. yeah, is valuable during that value holder is just how mutex lock. ohh value lock. sorry, i'm using the wrong thing. value holder is the value. i should n't lock the value holder mute value lock. does that mean that that answer your question or not?"
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","now anybody that's waiting for this will be signaled say, hey, go ahead and you wake up. and once this guy unlocks the holder, one of these threads that's waiting on that condition can not wake up and grab the valid. yeah, is valuable during that value holder is just how mutex lock. ohh value lock. sorry, i'm using the wrong thing. value holder is the value. i should n't lock the value holder mute value lock. does that mean that that answer your question or not? so when you when you assign the value lock value with that technique the value if value holder is the global variable that's going store the value that we're producing and the value that we're storing is just gon na be the value that's like the producing a cookie. here's the cookie that i'm storing and i'm maybe the value holder is like the table. i'm putting the cookie on right so some other thread one signal is now gon na come by. grab this lock on the table and then grab the cookie and then i'm gon na after a little while, produce another cookie. it's gon na be slightly different because i'm using an eye value, but that's just kind of made out the mistake. but yeah, that makes sense, correct? ok, so now this guy, this guy needs. essentially consume the item, but he's got wait, ok? you got ta wait for a value be there. ok, so what i'm going do here is attempt get the thing because i need if i wanna check see if there's a value there. i have have a lock on that location. i ca n't read it. i ca n't check it. i ca n't even know if i need wait on a condition cause i ca n't access this shared value unless i lock it. it's a critical value. it's a critical resource, so just like with this guy here that's going produce it, this guy that's gon na consume it needs lock that shared resource. at this point now i can check see if. the value holder does not equal 0. if it equals 0, there's nothing there, right? and so i only want consume the item if there's something there ok. i can do something like value holder. we'll zero and i can do something like maybe. i got value. let's see bread percent. you got value percent d pthread self. and then the value is value holder."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","it's a critical resource, so just like with this guy here that's going produce it, this guy that's gon na consume it needs lock that shared resource. at this point now i can check see if. the value holder does not equal 0. if it equals 0, there's nothing there, right? and so i only want consume the item if there's something there ok. i can do something like value holder. we'll zero and i can do something like maybe. i got value. let's see bread percent. you got value percent d pthread self. and then the value is value holder. does your, so i'll bring out the thread id and then value that was in the value holder and then i'll consume the value by setting it 0, right? my hope is here that by using condition variables. and locks. no thread should get the value 0 printed out. they should only get a value that actually from the value. ok, that's great. what is the value is0i here is a situation where i need wait, but here's the other thing. that kind of stinks. if the value is 0, that's great, but if it's not zero and i wanna wait. let's just do that. i have wait. i do n't know. wait on the condition, not a value exists. and. i need retrieve the lock right. the condition has be true and i have be able get this lock. so far, they might look at that and say, ok, doctor lengthy, that's all fine and dandy, but guess what? we already have the lock, right? appear we locked it up here. so we're we're in this code here because say well, we wanna wait on this condition. so the condition has be true and the lock has be set. but you could say, well, we already own the lock, so wo n't that cause deadlock? because if we're holding on the lock and we do a wait on this condition, this thread is going be held up. right until it signal well if this thread has the lock. this guy down here that's gon na produce an item is gon na try lock the lock, but this thread is already got it right. here's the beauty of pthread conditions. by making a call, the pthread cond waste, the designers of condition variables knew that that was going cause deadlock."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","but you could say, well, we already own the lock, so wo n't that cause deadlock? because if we're holding on the lock and we do a wait on this condition, this thread is going be held up. right until it signal well if this thread has the lock. this guy down here that's gon na produce an item is gon na try lock the lock, but this thread is already got it right. here's the beauty of pthread conditions. by making a call, the pthread cond waste, the designers of condition variables knew that that was going cause deadlock. so they said, if you make a call, the pthread ca n't wait, you need own this lock and we do. but as part of the weight, this is gon na implicitly unlock that lock. so by making the call here, this is gon na hold up this thread until value exists as signal, and it's also gon na release the lock. so at this point after after executing line 22, the value lock will be unlocked. that will allow this guy lock it produce something, and then do the signal. but what's neat about what the operating system does here is it says you are only going be able wake up from this weight. if you can retrieve the lock again, we're at the point of the invoking. ca n't wait. you own that lock when this function called returns and will only return, you're able lock the lock again. questions. so you own the lot going in. you will own the lot coming out, so ultimately your state as far as this lock is concerned and your ownership of this lock does n't change. so i do n't have worry about doing a pthread unlock of that lock before i called the conway, it does it as an atomic operation. questions. it's only going get. it's all early. i kick it up a notch from here, so this is where we go. so now i'm going have this lock. now what do i do? what i want do this so what i'm going do is kind of reorganize this so i can come by in the print statements. so instead of saying if value holder not equal zero, i'm gon na say if it is equal 0 then i'm gon na then i'm gon na wait on the condition. otherwise i'm going print that off. does that make more sense?"
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","i kick it up a notch from here, so this is where we go. so now i'm going have this lock. now what do i do? what i want do this so what i'm going do is kind of reorganize this so i can come by in the print statements. so instead of saying if value holder not equal zero, i'm gon na say if it is equal 0 then i'm gon na then i'm gon na wait on the condition. otherwise i'm going print that off. does that make more sense? but when i flip it around, maybe it does n't make more sense, but does it still make sense when i flip it around ok. the last thing i got do is. add my my start the race is here ok? no. and i also have define how many threads i'm going have. all of the time. and then i got ta make sure that i actually produce 10 things. yeah, ok. otherwise the threads are just gon na sit there and then never gon na. and there we go. sense questions. ok. conditions. i do n't know why this seems like a i i've still like i'm. i feel like i'm confusing myself by explaining it, but that is what condition variables are, so it ties this idea of a lock and a condition ok. couple of other things about conditions. within a sign that when a condition is signaled when a cell come back summer forest, when a cellar 4 is signaled, what happens? what happens the count? the value? yeah, looks because i'm by one, and then if there's a thread waiting, it gets released right with a signal on a condition. a signal does n't necessarily store. it's it's it's result. a signal a condition is signaled, and if there's no one waiting, it's kind of like if a tree falls in the woods and there's nobody there it, does it make a sound if a condition is signaled and there's nobody waiting, nobody wakes up. and the condition itself. does n't have any sort of value set like a semaphore kind of stores the fact that it's been signaled right. increments that count when the condition value. it is only notified or someone's only notified if they're waiting, and if nobody's waiting, nothing really gets modified in the signal. it just says go ahead. you're done. so is why we need have this additional gift check around here?"
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","a signal a condition is signaled, and if there's no one waiting, it's kind of like if a tree falls in the woods and there's nobody there it, does it make a sound if a condition is signaled and there's nobody waiting, nobody wakes up. and the condition itself. does n't have any sort of value set like a semaphore kind of stores the fact that it's been signaled right. increments that count when the condition value. it is only notified or someone's only notified if they're waiting, and if nobody's waiting, nothing really gets modified in the signal. it just says go ahead. you're done. so is why we need have this additional gift check around here? because if because there's no other way store, you know, is the condition already set right? this is saying if the condition is already set or if the value hold it right. if the value holder has some value, meaning it's not going be 0, i'm gon na skip over this altogether, right? with the semaphore, i can essentially just always blindly weight on it because of its count that's stored in there, and i know that when somebody signals that that counts gon na get bigger. here i have make a special check say yes i want wait and this condition but i only want wait on the condition if the condition is n't met. this is the case. the condition does not melt that because the value holder is 0 if the condition has been met. yes, i want just skip over that rate code altogether. questions. ok, so condition variables. i think they're pretty cool. they're useful. they're useful for doing signaling as well as locking. what else can we do with this? that is, wait, we can do a signal and then we could do this other really, really awesome function i wish i had more use for. but i do every once in a while find out question yes. alright, so good question. so here, uh, not this one, this one. how does the mutex lock get passed between threads? well, first off, the mutex lock is in global data and threads share memory and so they share the mutex implicitly by accessing just memory directly. so as far as how you access the mutex, you do n't need have any special code there because it's it's all within the same memory space and all threads share that."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","but i do every once in a while find out question yes. alright, so good question. so here, uh, not this one, this one. how does the mutex lock get passed between threads? well, first off, the mutex lock is in global data and threads share memory and so they share the mutex implicitly by accessing just memory directly. so as far as how you access the mutex, you do n't need have any special code there because it's it's all within the same memory space and all threads share that. umm, so as far as if i have 6 threads that are all gon na be waiting on this condition, who gets who's gon na get the wake up? that's the rest should not be question well. ultimately, there's a queue on here. that's associated with it. so the operating system will set one of those threads. the first one in the queue for its state be ready, and that's the one that's gon na run. so let's sydney gets sent the. that's right. and we do a con signal. the cartwright, i did n't create a waiting queue when i created this mutex or when i created the condition right? i did n't create that, sue. i do n't really even know how create a waiting queue. it's an operating system object as far as cause it's nice get down like thread management and process management. probably operating system can use that, we'll talk about that in a little while, but i just created the mutex so i created the condition variable so the invocation of peter and ca n't wait ultimately invokes the system call and the operating system says ohh you thread would like wait on this condition. i'm going put you in the waiting queue for that condition until it's met. i'm gon na search a thread state not being ready or running or such a thread state waiting and then put you on the waiting queue for this condition and then pick somebody else run and do a context switch that. when this thread does n't con signal, if you notice i have pass in the address of the condition variable. this condition variable is where that waiting queue is and so the operating system then can look at memory at that waiting queue. figure out threads are waiting, find the first one. change that thread state reading and then put it on the on the ready here."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","i'm gon na search a thread state not being ready or running or such a thread state waiting and then put you on the waiting queue for this condition and then pick somebody else run and do a context switch that. when this thread does n't con signal, if you notice i have pass in the address of the condition variable. this condition variable is where that waiting queue is and so the operating system then can look at memory at that waiting queue. figure out threads are waiting, find the first one. change that thread state reading and then put it on the on the ready here. now that's that thread, for what it's worth, because it has wake up from the conduit implicitly needs retrieve this lock, so as soon as that thread state becomes ready, it will also then immediately become waiting, because it's gon na move from the waiting queue on the condition the waiting queue of the mutex lock. so they can get that and when this guy unlocks that lock, you specify as the address for that lock. the operating system looks at the waiting queue for the mutex lock and then sets the threads state ready and then lots of acquire the lock. at that point it will return from the system call for conduit. are n't you glad you asked when we get queueing, it'll hopefully become a lot more clearer that there's queues all over the place that a process can be on. what makes it confusing is that there's lots of different cues that are that are thread could be waiting on. what makes it less confusing is when you realize that arthritic can only ever be on one queue at a time. i guess if you're waiting on something on a queue, you ca n't wake up move yourself another queue and does n't make sense. you're only be waiting on one thing at a time. that's good question though i like it. ok, i'll draw a bunch of pictures of boxes and queues and a couple of weeks when we get the queuing. ohh great. alright, let's move on here. ohh kind signal. signals and releases are thread. it says if there is a a thread waiting on this hey, that thread can wait up. if there's three threads waiting on it, one of them wipes up. i'm signaling one thread and like a signaling me of a of a semaphore, i'm signaling once. if i wanna signal the thing six times, signal mutex, i have use a a signal."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","ok, i'll draw a bunch of pictures of boxes and queues and a couple of weeks when we get the queuing. ohh great. alright, let's move on here. ohh kind signal. signals and releases are thread. it says if there is a a thread waiting on this hey, that thread can wait up. if there's three threads waiting on it, one of them wipes up. i'm signaling one thread and like a signaling me of a of a semaphore, i'm signaling once. if i wanna signal the thing six times, signal mutex, i have use a a signal. a semaphore i have loop whatever a bunch of times and signal con broadcast. what does con broadcast do? it says alright these shall unblock threads waiting and condition variable p thread con broadcast shall unblock all threads currently blocked on the condition variable. that's kind of cool, right? so there might be a situation, say for example. in a flag or a head program, or have a bunch of threads, cars that are all waiting enter and retrieve some. some access shared resource. the controlled growth i might be a thread, a flagger that is twisting the stop sign say ah, it is now safe drive in a particular direction. but i wanna let all the cars on the other side of the road know that it's ok travel. those cars might be waiting on a condition is the stop sign in the right order, right? my condition for safe cross. i can broadcast all of the waiting threads, but they're able proceed. right, so what does this look like? this one what i'm going do is i'm gon na go my prebuilt example because i do n't want screw this up. so. what's different about this example than the previous example is. i still have my condition variable and my flag along the text. i call them slightly different. i have my global value. ok, i got my start thing. i've got some problem defines for values here. ok. what's gon na be different here is instead of producing auth thing. what i'm gon na do is i'm going tell by global value produce a bunch of stuff. so instead of a thread consuming the one value that's there, it's just gon na decrement this consume one of the things."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","i still have my condition variable and my flag along the text. i call them slightly different. i have my global value. ok, i got my start thing. i've got some problem defines for values here. ok. what's gon na be different here is instead of producing auth thing. what i'm gon na do is i'm going tell by global value produce a bunch of stuff. so instead of a thread consuming the one value that's there, it's just gon na decrement this consume one of the things. ok, so this number will essentially say how many things that i just produced -, 1 being or zero or -, 1 being that there's nothing there, and then they'll be account specify how many items are there. what i'm going do is have my main friend produce a bunch of items and then broadcast every thread out there that there's items consume, and then those threads in keep consuming items until they're gone, and then they have go back sleep. that's. alright, so let's go the easy part. i'm going add a resource and broadcast. in this case i'm doing iteration count times 2 just produce some value, and then i'm going sleep for 100 milliseconds. this code here very similar the previous one. i'm actually now printing out some status information that i'm adding stuff a mobile value, but i'm just gon na increment that global value. things that i produce and then instead of a signal, i'm going broadcast all threads and the reason i'm using a broadcast instead of a signal here is because i produced a whole bunch of items. i wanna let all of the threads know that they can consume them as opposed before, or i produced all thing and i just wanna let one thread know that there's something there. ok, here i got a lot of stuff that i produced. how many i i do n't i do n't know. but i want all of the threads wake up so they can all check. and then i'm gon na unlock the mutex. what does the thread do? well, it's gon na do this. it's going iterate a bunch of times. again. try lock them musics and then try see if there's something there ok. it's going check see before. i just had a single if statement but here i have a while loop. you might look at that said. well, why do n't you use a while loop instead of just statement?"
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","but i want all of the threads wake up so they can all check. and then i'm gon na unlock the mutex. what does the thread do? well, it's gon na do this. it's going iterate a bunch of times. again. try lock them musics and then try see if there's something there ok. it's going check see before. i just had a single if statement but here i have a while loop. you might look at that said. well, why do n't you use a while loop instead of just statement? and the reason is i'm doing a broadcast of the signaling. i'm gon na have all the threads wake up if i produce. somebody produce 100 things and i've got 10 threads. i could he grabbing lunch more stuff so i do n't need wait for one thing. i could just keep grabbing stuff and keep producing, keep consuming, keep consuming until they're gone. so what this is gon na do is it's gon na keep waiting here say, well, maybe i got woken up. ok, maybe i'm a thread that got woken up again. but i was n't the one that got the that got the lock. some other thread did, and they've been tuned the item. if i got later on, i'm able retrieve this and get the lock. i'm gon na wake up and come back around here and say wait in the time that the condition was signaled for the time that is now where i'm actually the one that can use could actually consume the thing somebody else might have consumed them. and if somebody else consumed them, i wanna go back sleep and wait questions. ok, so that's what allowed was there. so we wait until there's something there and then we grab a value and then we unlock the mutex let somebody else grab it, and then we go back around and try and do it again. so in this case, each thread is gon na try consume 5 things. and so by utilizing condition broadcast i could notify all of the threads that the condition was met. here's the kicker though. and weight still must be met. as far as its behavior, even though i might have 10 threads waiting on that condition and i broadcasted the condition all of them every last one of those threads will be removed from the waiting queue on this condition, right? but they will all get booed the waiting queue of that mutex line. once the sender or the signaler. unlocks that mutex."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","and so by utilizing condition broadcast i could notify all of the threads that the condition was met. here's the kicker though. and weight still must be met. as far as its behavior, even though i might have 10 threads waiting on that condition and i broadcasted the condition all of them every last one of those threads will be removed from the waiting queue on this condition, right? but they will all get booed the waiting queue of that mutex line. once the sender or the signaler. unlocks that mutex. on thread will only wake up if it is able get the mutex. so only one thread will actually wake up from the condition, despite the fact that they were all signaled because they have be able get this lock on the mutex before they wake up. they might say, well, that's limiting. yeah, but it's it's cool because i can signal the all threads of the condition has been met, but still only have 1x feet in the critical section, is really what i want because i only want one thread decrement this value at a time. you do n't want them all do it. if they all woke up, i would have have another view text lot around this. i i do n't. i do n't need it because i've got the mutex lock tied the condition. box questions, ok. in the last little bit of time here, what i wanna do is. add a clarification here. i updated the sample output for the flagger i had. in the previous one, it actually printed out that a car was entering the construction zone and a car was leaving the construction zone. and as it turned out by i'll put was wrong, it was n't because my solution was wrong. at least i do n't think so. the problem i ran into was essentially a race condition and it was n't a race condition. accessing a variable like we've been doing it now, it was actually a race condition. accessing the terminal output alright into a situation where in this particular case car one entered, then three, then zero, then two and what it would do was depending on this test case it would say like car 1 entered and then it would say like car 2 exit or car 0 exited could say that should n't be the case cause car one should have exited before car zero. what happened was i actually was using a locking mechanism control when a car entered or exited the the the the zone."
"""OpSys_Semaphores_and_Mutex_Locks_Transcript.txt""","accessing a variable like we've been doing it now, it was actually a race condition. accessing the terminal output alright into a situation where in this particular case car one entered, then three, then zero, then two and what it would do was depending on this test case it would say like car 1 entered and then it would say like car 2 exit or car 0 exited could say that should n't be the case cause car one should have exited before car zero. what happened was i actually was using a locking mechanism control when a car entered or exited the the the the zone. but once the car exited, a release that lock and so that i had a race condition situation accessing the print buffer with print that and so while one executive first it did n't get run in zero, got run next and it printed out that exited first is really not the case. fix that and actually synchronize access the printout buffer is a nontrivial place, and i do n't want you spend the amount of time it takes figure that out on your project. so i removed that from the requirement, so i only necessarily you can print out when they leave. if you can get it working right, i only want you print out when they enter. ok, so these have been updated in github. the examples in canvas have been updated if you already cloned the repo, you might have an old version, so please make sure you reference the correct version grab from canvas if you need and they should be correct, right? that's all i got. so we could stop there. these examples should be posted in canvas as well, and next week we'll start producer consumer. thanks for coming. lembke, james stopped transcription"
"""OpSys_Shared_Memory_Transcript.txt""","meeting in _ general_-20240307_130410 - meeting recording march 7, 2024, 7:04pm 46 m 1s lembke, james started transcription lembke, james 0:07 hello awesome. alright. there's been missed this. ok. so welcome operating systems isolation and protection. abstractions are cool. so where are we at? welcome. it is week eight. can you believe it? we're halfway through the term. alright, so actually we're one day cause thursday. we're one day passed. it did n't matter. ok, so announcements quiz. friday, i messaged cues and signals on paper. same as as standard drill for all the other servers notes for threads of concurrency, we're gon na start threads today. i got that out there and i got a bunch of samples. the one the only one that's gone through so far has been sharing memory. these i have gon na build today, so i just thought i'd throw it out there in case they have done already. it's a. so i got for that. so where we've been and where we're gon na go next. so since we have a new topic here, i kind of want. can not see where we've gone. we've kind of built up a lot of stuff in operating systems so far this semester, so obviously we started with our c review and then talked about os motivation and then started talk about this hardware versus software abstractions and why we kind of take for granted. at least i do that processes are an invented thing. it's not like something that the hardware provides for us. there is n't a process inside this hardware thing, and so with that, if we want invent a process, we have start think about all the things that are process needs, all the bookkeeping we have keep track of. and so we have this address space, is kind of a place store stuff temporarily. we got ta keep track of that. we got ta keep track of process control blocks and ohh information about the process, process, contacts for when it's not actively running on the cpu, right and that then brought about our topic on. ok, if we have multiple processes and we like this idea of isolation and protection, so the processes do n't like access each other's memory and grab each other's data and change each other's data and try and crash stuff and we have them communicate and the operating system says great. you wanna have these processes communicate? i made them up so the operating system says,"
"""OpSys_Shared_Memory_Transcript.txt""","we got ta keep track of process control blocks and ohh information about the process, process, contacts for when it's not actively running on the cpu, right and that then brought about our topic on. ok, if we have multiple processes and we like this idea of isolation and protection, so the processes do n't like access each other's memory and grab each other's data and change each other's data and try and crash stuff and we have them communicate and the operating system says great. you wanna have these processes communicate? i made them up so the operating system says, yeah, you can let them communicate, but because of i do n't want, i do n't want violate or you wo n't want you violate isolation and production. i'm gon na force you communicate on my terms, so i'll give you file descriptors. i'll give you a pipes. incidentally, programming project right? guess you're not gon na think about a water hose in the same way. right pipes, your favorite thing. anyway, ok, so inter process communication. we're talking about all those and kind of a progression from file descriptors, through pipes, through message queues, finally shared memory where the operating system wo n't let a process share everything with its with another process, but only a select region of memory that it has ask the operating system manage. and now here we are today, where? ok, now that we know what we know between file descriptors and process communication and just processes and general. now we can maybe play operating system designer. that's kind of what i want do today, because what we're going ultimately get through is, uh, a constructor, a concept that's also created about the operating system called threads, are like processes, very similar processes, but they kind of are created with sharing in mind first. so when you think about processes, processes were kind of created in a way allow us do multiprogramming where sharing is not really considered right? we can run a process and be honest with you, often we do or a process just does n't use any ipc mechanism at all. it just runs that stop, does n't talk anybody else. that's great. well, except it's not great for some situations, and so it's kind of motivating in this. well, if we wanted create a situation in parents and child or in you know even forget parent and child 2 processes independently created from own program. if they wanted communicate and work and talk each other and share by default."
"""OpSys_Shared_Memory_Transcript.txt""","we can run a process and be honest with you, often we do or a process just does n't use any ipc mechanism at all. it just runs that stop, does n't talk anybody else. that's great. well, except it's not great for some situations, and so it's kind of motivating in this. well, if we wanted create a situation in parents and child or in you know even forget parent and child 2 processes independently created from own program. if they wanted communicate and work and talk each other and share by default. well, it's worthwhile share, right? we look at address space share. they said that with a fork we do n't share anything child kinda share something with his parent because it gets a copy of the parent stuff. so the parent can send stuff downstream prior four, but after the fork forestock we ca n't go backwards. shared memory fixed a little bit about that, but it was kind of we had set it up so if we could share by default and the sky is the limit, what do you guys think we'll be worthwhile share? we could share memory. what would be good and bad about sharing memory? that's so what i want do is just kind of take it one section at a time. sharing text. there's of a problem with sharing text. ok, i see some some some head shakes. no problem with text. why? yeah, it's taxed. it's static data that we're voting into the programs we unless we might want the child have it. sure. ok, it's static. i like that it does not change. ok, that's one thing, right? it's only readable. ok, so we have a program and both of these processes are executing the same program with four. for example, right 4 copies the address space and they wo n't run the same program. the child and the parent both execute at the return from 4th. they execute the same code, so if they're gon na execute the same code, why do n't they just share it? seems ok me. they've space. we're not gon na let them write it. it seems kind of weird change your program. change your text. i know you could say that if i'm an ai that's evolving over time and it's gon na write its own, let's not go there, right? let's just stick with programs that we write and compile and run ok local data. think about that."
"""OpSys_Shared_Memory_Transcript.txt""","they execute the same code, so if they're gon na execute the same code, why do n't they just share it? seems ok me. they've space. we're not gon na let them write it. it seems kind of weird change your program. change your text. i know you could say that if i'm an ai that's evolving over time and it's gon na write its own, let's not go there, right? let's just stick with programs that we write and compile and run ok local data. think about that. ok, what does that mean? we have maybe like an integer or an array or something like that, and we have two processes that both need manipulate that. not a problem share that. yeah. thing i see couple headshake hue processes that might be running at different times. you ca n't guarantee sometimes that a global variable variable because it can be changed by something or something. ok. so i like that concern. so i would say and i see a couple of other head shakes here that sharing global variables. is it necessarily a problem? but it could be a problem as i tell my wife it's not a problem until it's a problem. we'll get there. right. because we have some situations where if one process was change global data, if the other process had access that, it was also trying change it at the same time, we could have some problems or both. the kind of you know, play with the same toy and we're both the yanking on it. so that could be a problem. so we have some concerns there. but in general, if i wanna store something in a variable and i wanna give it a child, preparing the child wanna communicate. the parent could write some data that that variable, and the child could read it and it would get it later on. the child could write that global data, but the parent then could could then read that and so long as we are collaborating on well, i'm gon na write the data. and now you can read it ok, will get as far as like actual like corruption of the execution of the program so long as we play nice. ok, i think i think we could we could we could work with that. does n't this next sort of blue section deep and stack? that might be a lame answer your question. i promise you wo n't get there. yeah, different sad. let's talk about health. ok. what is heather?"
"""OpSys_Shared_Memory_Transcript.txt""","the child could write that global data, but the parent then could could then read that and so long as we are collaborating on well, i'm gon na write the data. and now you can read it ok, will get as far as like actual like corruption of the execution of the program so long as we play nice. ok, i think i think we could we could we could work with that. does n't this next sort of blue section deep and stack? that might be a lame answer your question. i promise you wo n't get there. yeah, different sad. let's talk about health. ok. what is heather? it's dynamic memory, ok, but more specifically, what is the property of heat? well, how do we allocate heat? what are we yours? yeah. reason that please mail right. ok. like you can like, we now look with you. what's one thing about interesting thing about that now? how long does it stick around? at least bring it until it's free. ok, so it's i would like think of it as it's an explicit memory allocation and it's an explicit free pen like a file descriptor. we have open the file descriptor and then close it. we are making that decision. so what's interesting about you is while you might say yes, it's dynamic memory and it might be deleted at any time, so long as again, just like with comrades concerned, as long as we coordinate our allocation and view if apparent allocates some storage on the heap and then the child needs access it, you know, yeah, that seems be ok, because then the parent can then read that data and write it. it's very similar in idea the way we're manipulating data in the global area. we have make sure that we do n't step on each others toes, but if we do that and we coordinate with each other, that's not gon na corrupt our execution by allowing the heat be shared. yeah, yeah. then we get stafford. ok, so what's the stack? what's stored there? calls them local variables, washer calls them local variables. yep. other things. yeah, turney, dresses returning dresses. ok, i like that. so function calls local variables along with the function calls a lump in parameters. those functions cause those got skype what?"
"""OpSys_Shared_Memory_Transcript.txt""","we have make sure that we do n't step on each others toes, but if we do that and we coordinate with each other, that's not gon na corrupt our execution by allowing the heat be shared. yeah, yeah. then we get stafford. ok, so what's the stack? what's stored there? calls them local variables, washer calls them local variables. yep. other things. yeah, turney, dresses returning dresses. ok, i like that. so function calls local variables along with the function calls a lump in parameters. those functions cause those got skype what? i'm just there, so i put words in your mouth, but i knew you were gon na say that once you calls parameters return values, local variables and return addresses. so let's talk about sharing the stack. what does that really need? it's weird if we have two american child independent classes that are both sharing the stack. if we let that happen, a child might change your return address for a parent and as a result. that's going affect what the parent does, where the parent goes and its execution. and so while it might seem safe under the assumption that we we coordinated with data manipulation, we can share heap, we can share data, text no problem when it comes the stack. because we have this sort of independent execution of what we're currently doing, we have our own contacts. what we're currently executing between parent and child or any other process and so as a result, i do n't really think that sharing stack is a great idea because if we do that then when one child returns and we have a stack frame and it parent a child with all the accessing that this parent might still be in that function and if the stack frame was popped now the parent lost access its local data and that can corrupt its execution. that makes sense. so that's where we're at with shared. so enter the world of threads. ok, we ca n't share stack. so what do we do? we have this. a thread is essentially a piece of a process. i do n't like refer it as like that. i guess it's not, but not very good way say it, but it's under it. this way a thread is a process that shares by default. not really a process. i put it in air quotes because it essentially contains things that are process would have that it has its own set, but it's shares all text data and heap with every other thread."
"""OpSys_Shared_Memory_Transcript.txt""","so what do we do? we have this. a thread is essentially a piece of a process. i do n't like refer it as like that. i guess it's not, but not very good way say it, but it's under it. this way a thread is a process that shares by default. not really a process. i put it in air quotes because it essentially contains things that are process would have that it has its own set, but it's shares all text data and heap with every other thread. guide so what i want do now is leave this picture up here. and make good on another line that i told you. i will have doing is lying in this class, but we got ta start somewhere. it's like i ca n't explain everything because then it's like, could you imagine it day one like and file descriptor table and signal handler table and process control lock and eric, right. we got ta start somewhere, and then we're refining it. so take our idea of a process in the posix and in linux and what i want do is change it a little bit a process as i drew before consist of an address space, ok memory and process control block had cpu context in it. or like what the current program congress. you got ta go back that very first picture that we had, right? this is not exactly that picture, but right. we have store the cpu context, the context of a register as the program caller, the instruction register, all that stuff in the in the process control block, right? but now let's think of it differently. think of a process now as a collection of one or more threads. ok, it's still in a way a similar idea. we still have tax data, heap and sack, but now we have the potential have multiple threads and multiple stacks that all are working on the same text, data and heap, but each have own staff. so our new definition of a process is gon na consist of memory. and one or more threats. so the threads themselves now will all will have own cpu context. this thread is stack is gon na look potentially different than this thread and might look potentially different than this thread. they might be invoking different functions. they might have a different program counter, right? but all of snacks. are in memory and so they have own contacts. they have own sort of control block."
"""OpSys_Shared_Memory_Transcript.txt""","we still have tax data, heap and sack, but now we have the potential have multiple threads and multiple stacks that all are working on the same text, data and heap, but each have own staff. so our new definition of a process is gon na consist of memory. and one or more threats. so the threads themselves now will all will have own cpu context. this thread is stack is gon na look potentially different than this thread and might look potentially different than this thread. they might be invoking different functions. they might have a different program counter, right? but all of snacks. are in memory and so they have own contacts. they have own sort of control block. for what they're doing, but they it is separated from the process control block, so we have this sort of larger idea of a process has a process control block and has a process identifier as a parent process identifier as a file descriptor table has a signal handler table and all the stuff that we talked about before. all of that stuff will be shared amongst its threads and then the threads themselves have the stuff that's specific what they need. specifically, things like the cpu context, the contents of the registers and references stacks. that's not a whole lot different than a process, but a little bit more refined, ok. and that's what we get. we have access all of our resources. uh, i hope file systems these the things like the file descriptor table, signal handler table, address space is the address space for the process image. this is the text of global data and then we have trying stop ok implicit sharing of all keep all data and all text. ok. so that's what we're going use in our sort of our definition of threats. bad news, conrad's concern data races. when we have this situation where we have essentially multiple processes that all have access global data and heap, we could run into situations now where if both people are trying write something at the same time so somebody's got ta win and we have, we have essentially a race the finish, ok. questions. pause for error here, ok. more notes stuff. ok, i'm gon na mention this because you might see these terms if you happen look at operating system material or read documentation, but i'm not going spend a whole lot of time on it because yeah, it is what it is. these slides are actually out of order. i got ta fix that. it limitation of threats, ok."
"""OpSys_Shared_Memory_Transcript.txt""","when we have this situation where we have essentially multiple processes that all have access global data and heap, we could run into situations now where if both people are trying write something at the same time so somebody's got ta win and we have, we have essentially a race the finish, ok. questions. pause for error here, ok. more notes stuff. ok, i'm gon na mention this because you might see these terms if you happen look at operating system material or read documentation, but i'm not going spend a whole lot of time on it because yeah, it is what it is. these slides are actually out of order. i got ta fix that. it limitation of threats, ok. first implementation was we're gon na do this in in the user level. we're gon na write a library where we have one process where this process itself is going try and emulate multiple threads. and so there's some library here that manipulating different sets of instructions streams different function calls try and give the appearance of multiple threads executing at the same time all accessing the same data. this is n't really done before done anymore. the reason why it's not done anymore is because of efficiency. this process that's emulating multiple threads of execution. if any one of these threads attempts do some sort of operation and ask the operating system do something that would cause it block, like read from a disk drive, this guy might wanna read from the disk drive or read from user input. with these two guys might be able do other stuff. as a result, the operating system could block everything because this is 1 process, it's all the operating system knows about. the way things are typically implemented now is we actually have a series of system calls for manipulating threads or the operating system is managing the process and the subnet. the process needs as a whole and then managing also each of the threads within inside that process. this is referred as colonel management or kernel level threads, no? i just want mention those terms exist. so one more slide here before we get examples will take us the rest of the rest of the rest of the the the day today. so how do we create threads where you system calls? how do we do anything with our operating system? we have ask it, how do we ask the operating system for anything? yes, system call. so be threats, posix threats."
"""OpSys_Shared_Memory_Transcript.txt""","the process needs as a whole and then managing also each of the threads within inside that process. this is referred as colonel management or kernel level threads, no? i just want mention those terms exist. so one more slide here before we get examples will take us the rest of the rest of the rest of the the the day today. so how do we create threads where you system calls? how do we do anything with our operating system? we have ask it, how do we ask the operating system for anything? yes, system call. so be threats, posix threats. they are implemented as functions just like any other wrapper around system calls colonel operations, colonel system calls, and so we have sort of duals, similar things for creating threads for this, creating processes create a process will use four the create a thread, we use pthread create. these function calls again. i feel like this makes more sense me than this pork is not. it's not. it's kind of a fork, but it's not, you know, right? what it does? whatever you wanna call it, we just did n't understand what it does. this creates a threat. pthread. we wanna wait. well, like for a parent, a parent process can wait using the weight call. if we want a one thread wait for another thread, we use pthread join. i do n't know why the word is joining because and if they were gon na use join, why did they call it p thread fork right? we're forking in the road, then we're joining back up anyway. that's what he tried create. he tried join that essentially says wait for a friend finish. we have exit and the equivalent is pthread exit. we wanna try terminate. this will terminate the process if the last thread of the process that runs called pthread exit. if we call exit, that causes all threads exit because the entire process exits. ok. umm, we've also will find that there is an implicit exit, just like the implicit exit of of a process when you return from main. that causes the process terminate, pthread exit. a thread will also terminate implicitly on a return as well. correct questions. that's, you know, be honest with you, when it comes threads that create wait, there's some other like weird tweaks that we can do and weird is n't the right way. there's some other tweaks we can do with them, but that's really it."
"""OpSys_Shared_Memory_Transcript.txt""","umm, we've also will find that there is an implicit exit, just like the implicit exit of of a process when you return from main. that causes the process terminate, pthread exit. a thread will also terminate implicitly on a return as well. correct questions. that's, you know, be honest with you, when it comes threads that create wait, there's some other like weird tweaks that we can do and weird is n't the right way. there's some other tweaks we can do with them, but that's really it. just that and the knowledge that they share pretty much everything, is it? so the other thing i want mention is that they share the process identifier, but they do have own individual identifier. every thread on the system has a thread identifier as well as a process identifier. all threads of the same pid. all threads do not have the same thread thread identifier. that's not really word. i just made that up. ok, so. man page manpage manpage. man page for pthread section 7. that's the overview page, the overview of threads. this is the documentation here and i just wanted go over a couple of things before i get an example and just talk about what the text here is. this is really just another way of saying the same things i just said. maybe it's better. maybe it's works, but it is what it is. it's it's the posix. specify the set of interfaces for threaded programming. counting those posix threads, a single process can contain multiple threads, all of are executing the same program. ok. we did that, talk about that threads share same global data and data with the thread has its own stack. ok, right. uh. and they also share a range of other attributes, so threads also share and a lot of these we talked about some of these we did not or we will talk about in the future. the process id parent process id talked about that control and terminal. we did n't really quite talk about that kind of maybe when talked about pipes, open file descriptors, yep, threads share open file descriptors, so that's another thing. record locks. again this year, we have talked about file locking it when we talked about file systems, we'll get there signal this positions. this is another word for the signal handler table. the threads share that and some other stuff deal with our environment. nice value."
"""OpSys_Shared_Memory_Transcript.txt""","the process id parent process id talked about that control and terminal. we did n't really quite talk about that kind of maybe when talked about pipes, open file descriptors, yep, threads share open file descriptors, so that's another thing. record locks. again this year, we have talked about file locking it when we talked about file systems, we'll get there signal this positions. this is another word for the signal handler table. the threads share that and some other stuff deal with our environment. nice value. we'll talk about that when we talk about process scheduling and resource limits, things like the maximum amount of memory you can allocate or the maximum number of file descriptors you can have open. those are all shared by threads. ok, now that right. ok, pretty, pretty, pretty. i would say not necessarily straightforward, but from what we talked about, ok, that makes sense. yeah. so. how do we create a threat? so let's do some example. let's do an example, some examples. how do we create a thread? we use it, we do pthread create. one thing we see with pthread create that's different than fork is there action parameters feed thread create versus fork just was did you call fork worked at a lot of stuff, but the key there was fork is while it copied the parent into the copy the parents memory into the child process. both processes that were created continue executing where. what was that? right wherever fork was called. or another way say that is, as at the return from form, the next instruction after the invocation of the fork system call bolt processes will continue. v3 create does not do that. pthread create takes a bunch of parameters. first one is this range. we're gon na worry about that. is this second one is attribute the third one here is a start routine and the 4th one is an art. threads are very a little bit different than fork and then they're when they're creating. is that what this will do? is it will create another thread it immediately start running, but that thread that runs will not run at the return from pthread create. unlike a process runs at the return from 4, the thread will run this function. you pass in a function pointer. a pointer is a number, right?"
"""OpSys_Shared_Memory_Transcript.txt""","is this second one is attribute the third one here is a start routine and the 4th one is an art. threads are very a little bit different than fork and then they're when they're creating. is that what this will do? is it will create another thread it immediately start running, but that thread that runs will not run at the return from pthread create. unlike a process runs at the return from 4, the thread will run this function. you pass in a function pointer. a pointer is a number, right? this number that we're passing into the into the system call will tell the operating system and address of where more or less set the program counter inside the thread control block for the new thread be created. when that thread runs, its program counter will get set whatever this routine is, and it will execute that function as if the function had just been invoked. just been called. ok, it's different than four. we actually pass a function pointer it. this me actually makes more sense. it just seems easier for me organize it in my brain that you just define a routine for the thread run. that thread runs the routine, and when that routine returns, the thread finishes. that's it. it's kind of nice. one isolated location for that thread run. this argue here this pointer here is an actual argument that we give the thread routine. all thread routines take one parameter and one parameter only, and that's a pointer some data that the thread can use. ok, all thread routines return a pointer indicating the result of what the thread did. he does n't have actually use that, but it has that option. ok, what else we get thread. fork returns the process identifier of the child the parent. it returns zero the child at -, 1 on error, right pthread create. returns zero on success and a negative number on error, or an error on. sorry and then error number on error. ok, it does not return. the thread identifier versus fork. did it returns an error number on an error and so if we wanna get the thread identifier what this says is? if you want know what the thread id is, you have pass in a pointer a thread id variable. this is a a defined type definition for some number representing the thread identifier."
"""OpSys_Shared_Memory_Transcript.txt""","it returns zero the child at -, 1 on error, right pthread create. returns zero on success and a negative number on error, or an error on. sorry and then error number on error. ok, it does not return. the thread identifier versus fork. did it returns an error number on an error and so if we wanna get the thread identifier what this says is? if you want know what the thread id is, you have pass in a pointer a thread id variable. this is a a defined type definition for some number representing the thread identifier. and just like any other time when we passed a pointer a function and we had that function fill in the data, the operating system is gon na fill in the thread identifier for the thread that was created. ok, makes sense. something. alright, so that's pthread create. let's look at pthread join. pthread join takes 2 parameters. the thread that we're gon na wait for and then this is another output parameter where the thread that terminated that we're waiting for it can have an option of filling in a return value. so we do n't care about a return value from the thread, we just leave that null. no. so remember from wait, we could just say wait and what that's gon na do is cause the parent wait for a child. ok, you might look at this and say well, why do i need specify the thread identifier for p thread joint? and i have any intuition then yeah, there could be more than one child thread. ok, there could be more than one child thread. there also could be more than one child process is in a way why we have weight pit where we can wait for our child process by process identifier. the other answer for this? alright, so what caleb, the answer is correct. what? caleb said the other answer here is that threads do n't have a parent child relationship. threads are peers, so with a weight it was essentially asked the operating system. i am a parent. i would like wait for a child, but a thread. there is no child thread, they're all peers. so if you wanna wait for a thread, the operating system will says ok what friend? what peer of yours do you wanna do? you wanna wait for? ok, you have tell me because you do n't have any children."
"""OpSys_Shared_Memory_Transcript.txt""","caleb said the other answer here is that threads do n't have a parent child relationship. threads are peers, so with a weight it was essentially asked the operating system. i am a parent. i would like wait for a child, but a thread. there is no child thread, they're all peers. so if you wanna wait for a thread, the operating system will says ok what friend? what peer of yours do you wanna do? you wanna wait for? ok, you have tell me because you do n't have any children. you have peers, so while we might have a situation where we have one thread that creates another one, it's still it's peer. it's not. it's child threat. i often well think of it that way, and i might accidentally say it that way, but they really are peers, not children, right? so we always have wait for thread by id. alright, so i know for me chat chat, let's actually do some examples. so. make a file here. so what do i need in order use pthreads? i need include the pthread header file pthread dot h. i also will need include. standard io. i'll also need include ohh erno wanna do error numbers. i also need include ohm. i do n't know. i just i need collude string for dealing with str error. i should probably include std lib in case i'm gon na do malek. you know why that happened? and then just for good measure, i will use that for other system calls. it's. ok, so what i'm going do is create a thread run and print out some information. so for that i need create the thread routine. the thread routine must be a function that returns a pointer. avoid pointer. they'd routine. and it's gon na take a void pointer for its arguments. in this case, this guys not gon na return anything so but it has return something. sells return null. alright, so there's my thread routine and actually maybe i'll do something like this. ohh my thread my pid is. i e cool. cindy my thread id is. and i'll do get pid get my process identifier and then i happen know that the system called get the thread id is called pthread self. there's a problem here. well, it does n't like that, but i i promise you that as the right way do that. alright. cindy, create the through the thread."
"""OpSys_Shared_Memory_Transcript.txt""","alright, so there's my thread routine and actually maybe i'll do something like this. ohh my thread my pid is. i e cool. cindy my thread id is. and i'll do get pid get my process identifier and then i happen know that the system called get the thread id is called pthread self. there's a problem here. well, it does n't like that, but i i promise you that as the right way do that. alright. cindy, create the through the thread. i got ta call pthread create, so i need create a location for the thread id. and then i'm going call pthread create. that requires an output parameter of the thread id, so i will specify that it requires. now the second parameter, a list of attributes, and if you're curious, i'm not going spend a lot of time talking about what the attributes are, but they are all listed in here for. various things that you can set whatever it is. or some attributes about the. throughout itself. i'm not gon na worry about that. i'm just gon na use the defaults. they're in the man pages. for the attributes are, so i'll just use the defaults and if i only use the defaults i can just specify null here. the next parameter is the routine that i want run and address of that, so i need specify that and then finally the parameter value that we'll get translated into arms. i'm not giving this parameter this thread routine anything, so i'll just leave it as null. ok. pthread create returns zero on success. so if i do n't have a value of zero, that means i have an error. what it is? well, we'll ask the operating system. and we'll exit with a bad returned call. ah, this as soon as that function is involved, that thread could start running. it might not. it's the opt the operating system decide who's gon na run next. main we'll have a have a thread executing this code. it's gon na create another one. now i will have two threads running. they are both peers. they both have the same priority because i use the default attribute actually set different priorities through that and i will know that because they're in the same priority, the operating system gets decide who gets run next, and they run more or less with equal priority. it might choose run the main thread."
"""OpSys_Shared_Memory_Transcript.txt""","it's the opt the operating system decide who's gon na run next. main we'll have a have a thread executing this code. it's gon na create another one. now i will have two threads running. they are both peers. they both have the same priority because i use the default attribute actually set different priorities through that and i will know that because they're in the same priority, the operating system gets decide who gets run next, and they run more or less with equal priority. it might choose run the main thread. they might choose run this new thread we're running thread routine. i have no control over that, and so both of them are gon na be running more or less concurrently if i want main thread wait for this other guy finish, they do a pthread joined where i specify the thread id. and then an output parameter for whatever that thread returned that threads returning doll. so i do n't really care. i'm just gon na leave that blank. done. great. a thread wait questions. yeah, supposed return something if, like, leave it as a void pointer. what if i wanted it return an integer? would i do have change it an integer? is there a different way handle so that's a good question. thread routines must return a void pointer, and so if i wanna return a value what i have do is return an address of whatever that value is, so that value is going get stored somewhere in memory so that thread we'll get that, but that thread routine needs return a pointer it, just the way that the thread routine. that way the operating system set the way threads have work. all right, so let's run this. good. so nothing super interesting here. we see that we have a process identifier and we have a thread id. thread ids are big. process identifiers are not so big, but you know it does n't make a difference beyoncé that you what those values are. they just are. by everything gets its own number. ok, alright. so let's do something a little bit more interesting still. perhaps kind of uninteresting, but let's do something a little bit more. something like this? let's make an array of threads thread count. and let's do. that and when i'm grabbing the thread id, i got ta use the array ok and when i'm waiting. i will wait for everybody. no sense waiting for just one thread. turney, good there. yes, you're right."
"""OpSys_Shared_Memory_Transcript.txt""","by everything gets its own number. ok, alright. so let's do something a little bit more interesting still. perhaps kind of uninteresting, but let's do something a little bit more. something like this? let's make an array of threads thread count. and let's do. that and when i'm grabbing the thread id, i got ta use the array ok and when i'm waiting. i will wait for everybody. no sense waiting for just one thread. turney, good there. yes, you're right. and i got ta do it up here. so now i'm going create 10 threads all running the thread routine, and they're gon na run it as if they got it just invoked. so now. i have 10 threads, each with own. sorry thread id that should be different and they all share the same process id ok. so far so good. again, perhaps slightly uninteresting, but still. we see they're all working together. yeah. the reason i feel like this is uninteresting is they're not manipulating any data right? you could say, well, if i wanted share something, right, is what i wanted do, i wanted share my default. maybe we should actually use something that we're sharing and work together on something right? is the next step. so let's have these guys actually do something and do some work together. let's utilize this argument pointer. remember, this has be a pointer, so if i wanted say alright, this is the thread id, but the threatening is just some value that identifies the threat. is that really a value that the thread's gon na operate on? so if i wanna as main want these guys work with the value i go the main thread, pass a value each of the threads work with. that's got be a pointer, so let's just do that, let's say something like this. i'll cast the args a value and then say something like this. and that that's ok, so long as the pointer that i'm passing in is some valid value, i can dereference that, right? that's just like a load instruction, and they all share the same memory, so that's fine, right? so let's just do this. i'll take i, is a valid value. they're all share in memory. that's great. and so i'm gon na pass this address of into that this guy should print it out."
"""OpSys_Shared_Memory_Transcript.txt""","i'll cast the args a value and then say something like this. and that that's ok, so long as the pointer that i'm passing in is some valid value, i can dereference that, right? that's just like a load instruction, and they all share the same memory, so that's fine, right? so let's just do this. i'll take i, is a valid value. they're all share in memory. that's great. and so i'm gon na pass this address of into that this guy should print it out. so every thread should get own value, right? and what do i get? yeah. what do i get? it's weird. it's kinda you. ok, so race condition, data races. i one person saying daily with data race day race. but nobody's who's writing the eye right eye is changing, obviously, but we got some weird things in here we've got. but while i was expecting i go from zero 9 right with my 4 little, you got ta see it up there. zero thread count. i've got two threes. i've got a four. i've got two fives. i missing zero and one and two. umm. and i've got 678 and then i have 10. what? and i did n't i. so what's the problem? maybe we see it. what's this last value here? what is? what does that ampersand mean? not dereference. what does ampersand mean? address of. so where is i in memories? i is in memory in maine. ok, threads are sharing memory ok, so as far as accessing that memory, not a big deal, but. that. how many copies of i are there in memories? one, it's in maine, right? so maine is manipulating i this for loop. it is one location in memory. this address of gives us the number is where i is stored in memory. every single thread is getting the exact same value of that location, so they're all referencing the same location in memory. they're not referencing a value. they do n't get the value passed them. they get a reference where that value is. so as maine is iterating through here, it's manipulating i and the main thread. we have no control over who's gon na run when they all get run more or less at the same time."
"""OpSys_Shared_Memory_Transcript.txt""","this address of gives us the number is where i is stored in memory. every single thread is getting the exact same value of that location, so they're all referencing the same location in memory. they're not referencing a value. they do n't get the value passed them. they get a reference where that value is. so as maine is iterating through here, it's manipulating i and the main thread. we have no control over who's gon na run when they all get run more or less at the same time. so what happened was maine went created a bunch of threads, incremented i those threads did n't get run yet. finally, one of those threads got run it printed out, and it dereferenced i and it said, well, the one location that i is, i'm gon na dereference that, get its value. it just so happens be 3 at this time. great. i'll print it out and return another thread. got run before the main thread ran and it said i'm gon na dereference that location of i and i'm gon na print out whatever it's current value is. just happens be 3 again because main did n't increment it yet and then ultimately main gets run again. it's gon na increment i and we see that it's changing, so all of these threads are referencing a location, not a value. now they're dereferencing that location get the value, but there's just one location. ultimately, main finishes and it's goes into weight. eye is 10 because an incremented eye be thread count. where this break hair happened? and even though i is out of scope of this for loop, the address of i is still valid because the main stack frame still sticks around and the friend can access that and it gives the value of tag. sense. so kind of stinks, but there is a fix for this. the fix is if we want all of these threads reference a different location get a different value, all we got ta do is allocate a different location for each thread. and here's my solution. oops. now we got the data for each thread. are we see. ah, finally. now again, we have no control over when threads are gon na run. they're gon na run whenever the operating system wants schedule them, so that's great. they all have own unique value, but it's not zero through nine, it's this. and if i run it again, i get a different ordering. run it again."
"""OpSys_Shared_Memory_Transcript.txt""","the fix is if we want all of these threads reference a different location get a different value, all we got ta do is allocate a different location for each thread. and here's my solution. oops. now we got the data for each thread. are we see. ah, finally. now again, we have no control over when threads are gon na run. they're gon na run whenever the operating system wants schedule them, so that's great. they all have own unique value, but it's not zero through nine, it's this. and if i run it again, i get a different ordering. run it again. i get a different ordering right because i do n't have control over who's gon na run when, but at least they all get own value. exactly pointers elevel pointers, though we run into situations like this, one other problem. can we run into? well, let's look at this. what if i wanted return something? but i have return a pointer. i ca n't just return a result, i can multiply the value times 100, but i got ta return a pointer warning. let me see a problem with this. where is result? local memory. it's on the call stack for this particular thread. when this thread returns for its thread routine, what happens in the stack frame that that thread is using? bone. so unfortunately, if i was try do something like this. and grabbed the result from the thread. and you get a warning saying returns address of a local variable. be wary. but i get segmentation fault. not great. so the question here is i ca n't do that if a thread needs return a turn a result, i'll leave. this is a question because of mine here how do we have a thread return a result? part of it? where are we going store this memory? we ca n't store it in a local variable. remember threads share everything though could we use double? we can use the heap and i got another strategy that we'll talk about next time as well. so we'll get back. so thanks for coming. have a good day. lembke, james stopped transcription"
"""OpSys_Signals_Transcripts.txt""","meeting in _ general_-20240304_130341 - meeting recording march 4, 2024, 7:03pm 45 m 1s lembke, james started transcription lembke, james 0:06 well, hello. all right. welcome, welcome. so is operating systems again. uh, today is going be hopefully our last day talking about interprocess communication mechanisms. so we're gon na do today is talk about shared memory and then next time we're gon na start threads. roads are awesome, so some people hate them. i think they're super cool once, it just get in the right mindset, but we'll get there. so but for now shared memory, so questions. they got quiz on friday. what we've been talking about, we've been talking about enterprise communication mechanisms. if you can remember back far away from, yeah, friday we were talking, we talking about message queues last week we started out with file descriptors that moved into pipes because file descriptors in general had had uses, but they had disadvantages with the sharing thing and managing this file position pointer. so we said, ok, great operating system, give us a pipe. now you could control the file position and give us the stream of data, and then we said great a stream of data is kind of cool, but i'd like it be a little bit more structured than that. so then the operating systems like, ok, fine here, you can have some message queues where you can have structured data and then we said, alright, that's great. but what if i wanted receive like an asynchronous notification from the operating system and the operating system said ok great, i can do that. how about signals and you just tell me what function do invoke when you receive a signal, and then we talked about that whole procedure that the operating system goes through for creating a stack frame and invoking the function handle the signal. and then we talked about user send signals with the kill system call as well as system sent signals that are sent well by the system. so segmentation fault. sigint we can set with a keyboard interrupt. we can do sig alarm and it's a whole bunch of other ones. so today, now we're going say operating system. we're talking about fork and i said parent and child do not share memory. they ca n't share memory. they're copies of each other. they share open file descriptors. we later on discovered that the share open message queue descriptors."
"""OpSys_Signals_Transcripts.txt""","and then we talked about user send signals with the kill system call as well as system sent signals that are sent well by the system. so segmentation fault. sigint we can set with a keyboard interrupt. we can do sig alarm and it's a whole bunch of other ones. so today, now we're going say operating system. we're talking about fork and i said parent and child do not share memory. they ca n't share memory. they're copies of each other. they share open file descriptors. we later on discovered that the share open message queue descriptors. well, the next question is please can we just share memory all this stuff about setting up the file descriptors for those that have been working through the hopefully working through the next programming project? do n't forget do tomorrow. pipes can be kind of janky try and get them all set up properly. it takes a lot of work. can we just share memory where if a process writes i and the other process reads i you can just get that. ok. so the operating system says yes, if you really, really, really wanna share memory, i will let you. but i'm the operating system. you have do so on my terms. i'm not just gon na let you share memory willy nilly. you have ask me for memory share. you have map it accordingly and you have sort of play by my rules. ok, then you can share my. so let's talk about how that works. ok. and then i'll do an example and go through some. some of the function calls in the system calls for shared memory, so here we are shared memory. i've drawn this picture a whole bunch of times. i know you've drawn it yourself. many of you, especially on your quizzes, what is this? we have a process address space. or just like its memory space address space or memory space. and what does that we have text. data for global data we have heap and we have stack for dynamic data. stack is for like the stack frames. all of our local variables return addresses, return values. data is global data stuff we define outside of functions and text is our code right? this is usually the way i draw it, but be honest with you, the operating system, when we later on we talk about memory management gives every process and address space that is really, really quite big, right? how much memory do we have on our computers like gigs, right 81632?"
"""OpSys_Signals_Transcripts.txt""","data for global data we have heap and we have stack for dynamic data. stack is for like the stack frames. all of our local variables return addresses, return values. data is global data stuff we define outside of functions and text is our code right? this is usually the way i draw it, but be honest with you, the operating system, when we later on we talk about memory management gives every process and address space that is really, really quite big, right? how much memory do we have on our computers like gigs, right 81632? maybe even more, i say this or when i worked at an ibm, we had systems that customers would buy that had terabytes of memory. there's a lot of memory, so when it comes the address space of a process, yeah, this is really kind of like the way i draw it, but this is not necessarily drawn scale. when i think about the actual text for my program that gets get put in there, it's usually on the matter of maybe megabytes. i mean, i do n't usually think of a program that right that's really big now for those of you that are playing, umm, final fantasy 7 rebirth, that's a pretty big program. ok. so yes, it has a lot of text in it. it also probably has a lot of data. there's a lot of assets, a lot of images, a lot of textures and stuff. that's the load. but for all intensive purposes, a dot out for examples that i'm doing i really small, so this particular address space in here might be drawn like this, but in reality. reality it's probably more like this. where i've got text and data and then heap and stack with a really kind of like scrunched in there and i've given all of this address space and all this stuff right in here is unused. it's not used yet. it's essentially reserved for more dynamic data, more stack frames, more heap allocation, more stuff with malik and stuff like that. right? ok. so the operating system says, you know what, all this unused area. we have two processes want share memory. i'll let you share memory and what i but what i want you do is ask me as an operating system, i would like share memory. i would like share not only memory but so much space. i want you tell me how much memory you wanna share and then what? i will let you do is."
"""OpSys_Signals_Transcripts.txt""","it's essentially reserved for more dynamic data, more stack frames, more heap allocation, more stuff with malik and stuff like that. right? ok. so the operating system says, you know what, all this unused area. we have two processes want share memory. i'll let you share memory and what i but what i want you do is ask me as an operating system, i would like share memory. i would like share not only memory but so much space. i want you tell me how much memory you wanna share and then what? i will let you do is. i'll let you share memory in this unused region. so you can essentially take memory and map it in the here and then when you write that memory, instead of having it go your head or your stack or data, you ca n't write max data area. umm, it's gon na go a special region. that other processes can also access. ok, so essentially what we have like the operating system lets us do is create in sort of. we have our process address space here. go back the not scale. yep. back and here's our unused area. what we can do as a process, here's our process. we can ask the os create a shared memory segment. please create a shared memory. segment the os. well, allocate some memory region some amount of space. that we can map and i'm gon na do this very good job, but map it. into our address space so that another process with its memory region. and its text, data, heap and stack. you can also map that same region. into its address space shared. like this? that was supposed be blue. it did n't really quite come up all that clear. so now that we do this, the operating system create a single shared memory segment and now it looks like both of these processes have a copy of it. but where with fork, we actually did have a copy with shared memory we have one region that's in a way kind of controlled by the operating system, but the operating system with proper permissions allows a process map that region into its own address space. so when one process writes or reads from that shared region, it actually reads and writes not for its own address space or its own memory, but from this shared region, and then every other process. and i drew it with two, but we could have three. we could have four. we could have 27 processes that are all mappings."
"""OpSys_Signals_Transcripts.txt""","but where with fork, we actually did have a copy with shared memory we have one region that's in a way kind of controlled by the operating system, but the operating system with proper permissions allows a process map that region into its own address space. so when one process writes or reads from that shared region, it actually reads and writes not for its own address space or its own memory, but from this shared region, and then every other process. and i drew it with two, but we could have three. we could have four. we could have 27 processes that are all mappings. this shared memory region in memory address space and as soon as they do that, they read and write it and it goes the share of region. ok. and that's shared memory. so it seems simple and that's really because it is the setup is takes a couple of steps. we have be able create the shared memory region. we have have the proper permissions it, so when it comes this right, you can say well, this could be kind of serious if we're letting processes share memory one process now we're not letting another process corrupt or access our texts or data are heap and stack. no, we're only letting the processes share this particular map region. so that's kind of nice. we still have isolation and protection, but you know if this is sort of critical data that we're sharing, we only want allow certain processes actually map it, because if i'm gon na like, share memory and then write a credit card there, i do n't want some other random process read my shared memory region and then map it and access that information. so we have have permissions so the operating system supports that only certain processes will be allowed map it. we have be able create it. we have be able see how big this is. it's not gon na be an infinite size. sorry. and we kind of want be able clean this up when we no longer need it. ok, since we have the ability or any number of processes now, they're probably is a limit on the system for how many processes can share memory at any given time. i do n't know what it is. we also are limited by the amount of memory that we have. so that's something consider, but. these processes might come and go. right."
"""OpSys_Signals_Transcripts.txt""","it's not gon na be an infinite size. sorry. and we kind of want be able clean this up when we no longer need it. ok, since we have the ability or any number of processes now, they're probably is a limit on the system for how many processes can share memory at any given time. i do n't know what it is. we also are limited by the amount of memory that we have. so that's something consider, but. these processes might come and go. right. this process is gon na run map the shared memory region, use it, and then it's going leave another process might run and share this for a certain time, and as a result, because we have processes that come in dull and share memory, just like with the file system, this is going actually persist, seems kind of weird. it lives after processes terminate. ok, that's another property of shared miller,. questions. yeah. so it still is this, but the mapping does n't exist. what's the process, right. it's ok, good question. right. and so we're gon na create shared memory segment. we're going map it into our address space, so i'll memory we can use it and then when we terminate the operating system is gon na mark this process as terminated and then later on it's gon na clean up its entire address space and get rid of it. this shared region will be essentially unmapped from this process of address space this, entire memory is going be consumed. it wo n't be deleted. it will stick around because other processes might need use it. they might also be sharing them, but this particular process is gon na lose access that shared memory. and when all of a sudden dos, it's not a problem, goes this process does n't exist anymore anyway, right? so yeah, that's the question. the questions? yeah, when does it automatically clean up the portion of memory that process 1 dedicated the shared one process? one gerrits, right. yes. so because it's entire address space is gone this allocated. ohh address space utilization gets cleaned up now. this turned memory does not get deleted. the actual data does not get deleted, but like all of them memory allocations bye. so let's get for you. yes. yeah. and that's that's business as usual. so speak right, i say, should free them, alex, but if you do n't win, the process terminates."
"""OpSys_Signals_Transcripts.txt""","yeah, when does it automatically clean up the portion of memory that process 1 dedicated the shared one process? one gerrits, right. yes. so because it's entire address space is gone this allocated. ohh address space utilization gets cleaned up now. this turned memory does not get deleted. the actual data does not get deleted, but like all of them memory allocations bye. so let's get for you. yes. yeah. and that's that's business as usual. so speak right, i say, should free them, alex, but if you do n't win, the process terminates. it will. we get all that cleaned up now in order access shared memory, we're gon na use a system called mmap says memory map or the map shared memory into our address space. when we're done using shared memory, just like what we free the malex, we should tell the operating system i have completed using this shared memory. please unwrap it so there's an m unmap call. so just like with freeing the malex, we should unmap our memory maps, right? goes kind of hand in hand. that being said though, if we do terminate, the operating system will implicitly unwrap it. so it kind of gets on those two questions. hopefully we'll do some examples and become a little more clear other questions. yeah, we're moving right along. so we'll see how far we get here. shared memory. i love it. alright, so lots of system calls involved with shared memory. if you go the man page or shmem over you as a chap shared memory overview of it talks about all the different system calls for shared memory. there's a bunch of them. shrem, open as i, jim, open this. just like with a message queue, right, we had mq open. we have shm. open it opens a new shared memory object. this will create a shared memory object if it does n't exist under the assumption you actually provide that. just like with a message queue queue with the option create it if it does n't exist, this will open an existing one. if it does exist, remember shared memory segments are persistent. it's kind of weird. you should think of memory persisting, but because we have this ability share stuff, the operating system does n't necessarily know who's gon na use it when. so it keeps it around until it explicitly deleted, just like where the message queue a file right? my file dot txt. how long should that exist?"
"""OpSys_Signals_Transcripts.txt""","just like with a message queue queue with the option create it if it does n't exist, this will open an existing one. if it does exist, remember shared memory segments are persistent. it's kind of weird. you should think of memory persisting, but because we have this ability share stuff, the operating system does n't necessarily know who's gon na use it when. so it keeps it around until it explicitly deleted, just like where the message queue a file right? my file dot txt. how long should that exist? hard make that call, so the operating system says i'm just gon na leave my file dot txt in the file system until you user explicitly delete it. shared memory is the same way. ah, so it's very similar open. we look at that, it actually behaves very similar open. i've truncates this, sets the size of the shared memory object. remember when we create a new shared memory object, we have tell the operating system how big make it. it wo n't be. it wo n't. no, right otherwise how much shared memory should it create? you could say, well, we have the operating system. just tell us you get 100 bytes. ok, that works. but what if i want share 5000 months? then i need create what 50 shared memory segments. it's a lot deal with, so we have be ability ask the operating system please allocate so much of our shared number. this is kind of like malik. this creates a reference a shared memory segment, but does not set its size. it will create it be up size 0. truncate is what's used make it a particularly set size, and that i mentioned that this is what maps it into our address space. i'm unmapped. is essentially like free. it releases it when we're done, and finally when we're done, we should close our shared memory segment. this is what's kind of weird as they jump open, we'll return a file descriptor reference the shared memory segment. we do n't have sheetal clothes, we have mq calls. remember, because we had a message queue descriptor, not a file descriptor. is hmm opened is specific for shared memory. it creates this a run of the mill file descriptor so we can close the file descriptor when we're done with it. with close, this establishes as hmm. open establishes that contract. remember, we have explicitly unlink a shared memory segment when we no longer need it."
"""OpSys_Signals_Transcripts.txt""","this is what's kind of weird as they jump open, we'll return a file descriptor reference the shared memory segment. we do n't have sheetal clothes, we have mq calls. remember, because we had a message queue descriptor, not a file descriptor. is hmm opened is specific for shared memory. it creates this a run of the mill file descriptor so we can close the file descriptor when we're done with it. with close, this establishes as hmm. open establishes that contract. remember, we have explicitly unlink a shared memory segment when we no longer need it. if a process is using a shared memory segment, we do n't want remove it underneath them. so this is such an open establishes that contract say you get use the shared memory segment and the operating system will not delete it until everybody that wants it closes it. so we have make sure we close it when it's no longer needed. science. ok, f stat. this is for other stuff, is for getting statistics and stuff, changing permissions. not gon na really worry about that, but yeah, let's just take a look at this and see what we need then. so shmem open. all shared memory segments need a name. ok. so just like what files in the file system, they need a name. remember, pipes are anonymous. we do n't need worry about that names for that, but files need a name. message queues are also persistent, right? they need a name, shared memory segments, also persistent. they need a name. so when is our name? this might look familiar. it must begin with slash and must contain some string of characters that do not contain slash, just like with the message here. ok, that's the name. why did they pick that? good question. i know, but that's the name. so we give them a name, then we have a bunch of flags. these are gon na be the flags that will indicate what do we want use this shared memory segment for? what is our intended purpose? do we only want read data from the shared memory segment? are we someone that's just gon na grab data from another process that's writing it? do we wanna read and write it?"
"""OpSys_Signals_Transcripts.txt""","ok, that's the name. why did they pick that? good question. i know, but that's the name. so we give them a name, then we have a bunch of flags. these are gon na be the flags that will indicate what do we want use this shared memory segment for? what is our intended purpose? do we only want read data from the shared memory segment? are we someone that's just gon na grab data from another process that's writing it? do we wanna read and write it? no, we have specify that that that, that those flights mode that's just like where the message queue just like where the file if we want the operating system create the shared memory segment, if it does n't exist, we have specify what permissions we want on that shared memory segment, who do we want be able access this right? so that's in the mode, so. very similar mq open, very similar open. kind of a reason for that. kind of. once you know one, know one of them, you hopefully will know more. again, we can tell the operating system create it if it does n't exist, and a bunch of other flags in here we can tell it that we do n't want allow the the, the the code be executed when it comes shared memory. that's probably a good idea. we do n't want be able execute shared memory. it's not really intended for instructions. it's only intended for data, so we can specify flags for that. ok, the return value is, but round here unsuccess it returns a file descriptor just like open on on an error it returns -. one such error. now we all know how that works. ok, so let's create and let's do this. new while. schemm demo. ohh and what do i need? i need a bunch of stuff. let's just go over here. one of my other previous ones, we probably need all this stuff. let's just double check see what else we might need. we also need amman dot h is for memory that stands for memory management, by the way. it's not like the mail, mail, human, it's memory management and man. so we need that cause we're gon na be managing our memory. alright, so we need create a shared memory segments, so that's going give us shm file descriptor. we're gon na do shm open. umm, you guys have a good name?"
"""OpSys_Signals_Transcripts.txt""","let's just double check see what else we might need. we also need amman dot h is for memory that stands for memory management, by the way. it's not like the mail, mail, human, it's memory management and man. so we need that cause we're gon na be managing our memory. alright, so we need create a shared memory segments, so that's going give us shm file descriptor. we're gon na do shm open. umm, you guys have a good name? that's this kind of lame. those just use this one shared memory, except that's spell it right? we're going open it for reading and writing. probably is a good idea, and we're gon na create it if it does n't exist. and then if we do that, we need specify the mode, and that mode is going be reading and writing for me only because i do n't want anybody else mess with my shared memory segment. hi. so if this returns -, 1. then we have a problem. could not not open shared memory? why not? we'll let the operating system tell us. well, actually do exit -, 1 or failure. alright, good. so now we have a shared memory segment. we open it. we got ta close it. close as hmd. do n't forget anytime we exit in error we have make sure we also close it. so the next thing we got ta do is set the size. so we're going set the size, width, truncate, have truncate. we have a file descriptor is our shared memory segment and then the length. great. so how big do we want? well, figure this out. so umm, if truncate, we're going our as it mfd, we'll send it me. i do n't know. how about? how about 100 bytes? it's good amount of monitors any you know? let's try this. we're going be using this value a lot, so let's just create a constant for it. ok. that's step two. we go back our shared memory overview. step three is mmap. so now we have gone this far. we have created the shared memory segment and we've set its size. in this case, we set it be 100 bytes. the next step is this piece. we have take this shared memory segment and map it into our processes address space, and with that we have use this wonderfully."
"""OpSys_Signals_Transcripts.txt""","we're going be using this value a lot, so let's just create a constant for it. ok. that's step two. we go back our shared memory overview. step three is mmap. so now we have gone this far. we have created the shared memory segment and we've set its size. in this case, we set it be 100 bytes. the next step is this piece. we have take this shared memory segment and map it into our processes address space, and with that we have use this wonderfully. i feel like overcomplicated system call, but it works. it's called a map. it creates a new mapping of the virtual address space. we'll talk about virtual address spaces later, but for the calling process. so what does it take? takes address. kind of weird. a length. ok, length kind of makes sense for our right and how big of an area we're gon na use. we've got some improv flags into fd. ok, we have a file descriptor. that's our shared memory segment. that makes sense. we need offset. it's a lot of parameters. ok, so what we just work through it 1/1 at a time. address. what is this? the starting address for the new mapping is specified in adr. ok. this is a convenience that the operating system is giving us. it says user you would like map i shared memory segment. yes, we would if you user are knowledgeable about what exact address you would like use for this shared memory region. say, maybe you'd know that you've got a place that you have unused that you just wanna use because it's spelled or useful for it, or it's your favorite number or something like that. you can ask the operating system please map this at this particular location because i wanna i wanna use that one. if you do n't care and you want the operating system just pick a pretty good address, you can just leave that null and the operating system will just figure out a good place put it in your address space makes sense for this. i do n't really care, so i'm gon na use. no. all right, that's good. so that's good. i can use null awesome lane. that's the length of the shared memory segment. ok, we know that that's 100 bytes and prots what are what is prot? prot is pretty cool."
"""OpSys_Signals_Transcripts.txt""","if you do n't care and you want the operating system just pick a pretty good address, you can just leave that null and the operating system will just figure out a good place put it in your address space makes sense for this. i do n't really care, so i'm gon na use. no. all right, that's good. so that's good. i can use null awesome lane. that's the length of the shared memory segment. ok, we know that that's 100 bytes and prots what are what is prot? prot is pretty cool. it describes memories protection when we're mapping something into our address space, we can actually tell the operating system essentially the intended purpose. i would like you map this into my into my address space, but i would like protect that in some way. for data, i would like be able read and write those made for that. for those that memory, so i usually use these two together if i wanna be able execute it like as code you can use that does this scary me, so i do n't usually use that one. none. not exactly sure exactly why you would do that. you were essentially asking the operating system map a shared memory segment, but you do n't want use it for. but yeah, you can do that. so i wanna map it for reading and writing, so i'll keep that in mind. next thing, flags, flags are additional stuff that we're gon na ask the operating system for or. how we want this map we can map it share, we can map it private. we can actually put a lock in a way on the shared memory segment say you know what, i do n't want anyone else use it. i'm the only one that's gon na be able. not really a whole lot useful for our shared memory segment, but we can do that. i like this one. we're gon na map it. shared cause it's a shared memory segment, but we can if we want map it private. it could be useful if you want like temporarily lock out other processes from being able use that shared memory region segment, and then you could center release that, but for now, we're gon na use share. there's a bunch of other stuff in there operating system specific, but we're not gon na worry about all those. we're just mostly worried about shared or private. ok, so that's flags, afd. that's the reference the shared memory segment."
"""OpSys_Signals_Transcripts.txt""","shared cause it's a shared memory segment, but we can if we want map it private. it could be useful if you want like temporarily lock out other processes from being able use that shared memory region segment, and then you could center release that, but for now, we're gon na use share. there's a bunch of other stuff in there operating system specific, but we're not gon na worry about all those. we're just mostly worried about shared or private. ok, so that's flags, afd. that's the reference the shared memory segment. that's our file descriptor and offset. the last one is offset. we go down offset. where is it? sorry, it's in here. i know flags. protection. you know what, officer? the offset is used specify an offset into the shared memory region. so say we have a shared memory region that's 100 bytes, and we only want map the 2nd 50 bytes. we can specify a length of 50 and an offset of 50, and the operating system will only map half of the second half of that shared memory region. for us, it makes sense for this. i want the offset be 0 because i want map the whole segment. ok, great. it returns a pointer. down here, this is what's pretty cool. once we get all the way down here, it says on success and that returns a pointer the mapped area. what's the pointer? a number a number representing the address in our address space of where that shared memory segment was was met. from there we have a pointer. it's as if we called malloc centrally. we can use it just like anything after that, well within, within limits because we only specify how much memory we wanted it the now, so otherwise it returns this special value called map failed is a pointer of -, 1 essentially a number, -, 1 and so -, 1 on air. the pointer on success. so let's actually do this. so now we've got a map this so this delegates a shared memory segment. this sets the size of the shared memory. now we're going map the shared memory. we're going say mp, we're going specify null let the operating system pick address use. we're going specify the size, is memory size. then we need the protection bits, is protected. we're going read and write. and then the next thing is, uh, i was forget. the flags."
"""OpSys_Signals_Transcripts.txt""","so let's actually do this. so now we've got a map this so this delegates a shared memory segment. this sets the size of the shared memory. now we're going map the shared memory. we're going say mp, we're going specify null let the operating system pick address use. we're going specify the size, is memory size. then we need the protection bits, is protected. we're going read and write. and then the next thing is, uh, i was forget. the flags. that's right. we're gon na map this shared. and then we have the file descriptor, is the shared memory file descriptor, and then the offset 0. so like 6 or 7 parameters, but that's what we got. we've got. we're gon na let the operating system pick address it is, so we're not gon na give it an address use. we're gon na. this is the size we're going map it for reading and writing. we're gon na map it. shared here's the file descriptor use, and it's gon na be 0 offset in there. so we're gon na get the whole thing. this should return a pointer. where does she avoid pointer here? or the address. we'll just call it the shared address. or use so if map failed. then we had a failure, but not now. failure is. something that went bad. we opened the shared memory segment, we got a close it before we return. all right. shared memory. next step ok. alright, so i i do n't know exactly where in the documentation it says this, so i'm just gon na say it. parent and child originally said they do n't share anything. and then i said i got ta make. i got ta make good on a on a why or something that i told you they do share things they share, open file descriptors. then we said ohh you have they also share open memory messages? open message queue descriptors, right. right now i got another one i got ta fix parent and child process after abort share memory map regions. so while this i did n't forget anything, this is just one set of code. here the parent in this case, once i fork created an opened a shared memory segment. when that board completes, then with this is the file descriptor. parent and child share open file descriptors. great."
"""OpSys_Signals_Transcripts.txt""","i got ta make good on a on a why or something that i told you they do share things they share, open file descriptors. then we said ohh you have they also share open memory messages? open message queue descriptors, right. right now i got another one i got ta fix parent and child process after abort share memory map regions. so while this i did n't forget anything, this is just one set of code. here the parent in this case, once i fork created an opened a shared memory segment. when that board completes, then with this is the file descriptor. parent and child share open file descriptors. great. we knew that we have mapped this parented child share mett, now mapped regions, so i can just fork and now this shared address will be shared between parent and child. ok. so that's another thing that they shared. so that spork. we have a failure, could not. pork. uh, we got ta close this. and then we can exit this. else if zero, this is the child. else here we are in the parent. ok. amount we mapped a region into our address space just like we have free the maleks we have. mud map the moon maps. ok. anytime we map shared memory, we have unwrap it. what's nice about i'm unmap is it's pretty simple. we're gon na tell the operating system what address we want unmap and how big it is. well, we already have that information. so down here, before we close, we have m unmap the shared address and it's just memory size. if we have a failure, we really should do that too. now we have child and we have parent. they share shared memory. so prove that. before we had some problems where we could not. the parent. can i not send something a child by sending variable and then just the child being a copy of the parent? we could n't send anything back from child parent you memory because the child's ability. but now that we have shared memory, we can do that. we have a region. in this case, it's 100 bytes. that's all. let's send something back the parent, but it's cool about this. now is i can do something like this within ager casts. value parent equals. just cast this an end and then pointer and say alright you originally avoid pointer was an untyped address. now i'm going tell the compiler i wanna use this for an integer."
"""OpSys_Signals_Transcripts.txt""","we could n't send anything back from child parent you memory because the child's ability. but now that we have shared memory, we can do that. we have a region. in this case, it's 100 bytes. that's all. let's send something back the parent, but it's cool about this. now is i can do something like this within ager casts. value parent equals. just cast this an end and then pointer and say alright you originally avoid pointer was an untyped address. now i'm going tell the compiler i wanna use this for an integer. and i can just now dereference that. i do n't know 123. this is a dereference. it will tell the compiler generate a store and it will store 123 and that memory address. that pointer, is a number right? it will store it. that is the number that the operating system gave me for the shared memory segment. that number will then go the shared memory segment. the parent now should just be able read from that directly and get the value because it's been shared between parent and child. but before i'm done, i got ta do this. i got unwrap it. i got close it and i got exit. in this case, i'm going exit gracefully because i do n't have any errors. hey. parent is going wait for the child finish. and it can just access this. are you directly value? from child and it should do a printf parent got. but integer, we're going dereference value from child when the parent can close. and unmap, although actually tell you what? well, i'll just get rid of this here just make it consistent and then it will exit with that return. questions. with me, yeah, yeah. yeah. this map shared in that private. yeah, that's a good question. as what would happen at that point, we have try it out know exactly what what would happen there. it's a good question. that's a lame answer. other questions, though, we can come back that later. yeah. so when you when you want have a variable like share in that shared variable. sorry in that shared memory space, do you? you do n't have do anything like special it or it's just memory. so in this particular case, we're writing a primitive data type, right integer, right?"
"""OpSys_Signals_Transcripts.txt""","as what would happen at that point, we have try it out know exactly what what would happen there. it's a good question. that's a lame answer. other questions, though, we can come back that later. yeah. so when you when you want have a variable like share in that shared variable. sorry in that shared memory space, do you? you do n't have do anything like special it or it's just memory. so in this particular case, we're writing a primitive data type, right integer, right? if it's something that's more complicated, like a structure, i might have do something like a mem copy or whatever, but i can even do that. we could even we could even do this. we could say, you know what? i'm gon na make a struct. umm, i do n't know data. we have a we have 100 bytes. so long as i do n't go over 100 bytes. make it 40 bytes. i got plenty of room instead of casting it an integer. let me cast it a struct data. and then we can do this. we can say value parent value one is 123 value two parent. now you too is 144 and then we could do something like string copy into value parent text of the text hello. umm. and that will copy that text in there. you do that too, and then this. then from the trial we have cast this not an int pointer but the structure. we only need 1 pointer and then parent got percent the percent oopsies percent d percent s and it's gon na be the value from child. value one, the value from child value 2 and the value from child text. should also work. so before i get too like knee deep in this, let's just double check make sure that it does in fact actually work. and then. and i'll show you a couple other things and then we'll be done for the day, all right. let's make sure. let's see. like compile the first time. bam. parent got look at that. we shared memory and we could just access stuff directly. what do i like about shared memory? we do n't worry about setting up pipes. we have worry about. wait, what end do i gon na close at the zero or the one end? right. we have learn about message queues, but like is it blocking or nonblocking right? we just access memory. what i do n't like is."
"""OpSys_Signals_Transcripts.txt""","let's make sure. let's see. like compile the first time. bam. parent got look at that. we shared memory and we could just access stuff directly. what do i like about shared memory? we do n't worry about setting up pipes. we have worry about. wait, what end do i gon na close at the zero or the one end? right. we have learn about message queues, but like is it blocking or nonblocking right? we just access memory. what i do n't like is. all this setup where you got ta like create the shared memory segment. we got ta set it size. we got ta map it. we got make sure we remember unwrap it and close it, but you know, you get what you get, you take the good with the map. so other questions here. ok. so let me show you a couple more things i mentioned shared memory segments are persistent. ok, they have a name. what is cool about that? well, i use four, but any process that is running and created from any program, it does n't. in this case i forked, i have two processes from the same program, but even if i had another program that i wrote, if i know the name of the shared memory segment, that process can can can map it. i can have two separate programs that both access the same shared memory segment if they know the name. that's pretty cool. ok, second thing is shared memory is persistent, so you notice i did n't unlink the shared memory segment. i just wasted 100 bytes, so speak, that's still there. i did n't waste it. it's great for this example, but the data is still there. where is it? well, just like with mq, we look in the slash dev directory. there's a shun directory, shared memory directory, and if we look at that. we see there's my shared memory. here's what's also kind of cool. do you guys ever heard of this program called hex dump? oops, not what hacks dubbed does is it takes the contents of either standard input or a file, and it prints it out in hexadecimal. now, there's not a class in base conversion or hexadecimal whatever. but if we run hexdump dash, c means run it in canonical way or an action will print out the actual hexadecimal by number, but then also try translate that aski so we can kind of see what's going on."
"""OpSys_Signals_Transcripts.txt""","here's what's also kind of cool. do you guys ever heard of this program called hex dump? oops, not what hacks dubbed does is it takes the contents of either standard input or a file, and it prints it out in hexadecimal. now, there's not a class in base conversion or hexadecimal whatever. but if we run hexdump dash, c means run it in canonical way or an action will print out the actual hexadecimal by number, but then also try translate that aski so we can kind of see what's going on. we see here that inside the shared memory segment, here is the raw data that's inside that file. hey and if you were do the conversion of this 7b and 90, you would find that most likely that's gon na be whatever those numbers are that i wrote the thing. 123 and 144 sydney is a hex converter convert that the seat and i think this should be 123 and that should be 144 and base 10 and over here we've got a bunch of 48454 charlie whenever. sorry, i should n't use those things, but 4c4f and the actual translation of that into actual characters is hello. so the operating system is persisting the data that i wrote the structure in that file. so another process later on that has access this file. this shared memory segment can map it and read it, and they'll get the same data even if it's six days from now, because that shared memory segment lives until explicitly deleted. if i do n't want it around anymore, what i probably should have done is this after i closed it, do an shm on link of the name what i said was shared memory. now when i run this by compile this. still get the same stuff because that was what was hard coded. but when i do a listing of that, it's been deleted i. so. that's it. really. was shared memory. it's plenty. so we have shared memory, we have create the segment, create it size. we have map it our address space. use it. unmap it. close it, unlink it. when we're done questions. ok. well, then we're done. earlier we got 2 minutes done, so that's all i got. see you on thursday. have a good week. lembke, james stopped transcription"
"""OpSys_System_Calls_and_Processes_Transcript.txt""","meeting in _ general_-20240208_130127 - meeting recording february 8, 2024, 7:01pm 48 m 19s lembke, james 0:08 hello great. ohh, all right. welcome operating systems isolation and protection. abstractions are cool and all that. so what are we doing? i ca n't try remember here, so we have been working through this picture working through c review and last time all the way on monday it's it. it's been a while. i feel like we started talking about system calls. on a finished talking about system calls today and then relate them function calls and then talk go into the next topic will take us the end of the week. so my plan is right now we kind of been teaching or i've been kind of been going through this class kind of piecewise. cartwright, ryan joined the meeting lembke, james 0:52 they do a bunch of hand waving, draw a bunch of pictures, then do a whole bunch of examples like when we gon na do some more material and then we'll do some examples. and i kind of like follow that. so the last week we were doing see review, we did a whole bunch of examples. this week can be doing a bunch of hand waving and drawing pictures for system calls and processes. next week, we're gon na go back and do a bunch of examples. i do have a couple of examples i wanna show you today, but until we really engrain our brain with the concepts and the hand waving and the pictures, the examples might not make any sense. i could throw at you, but i i do n't wanna confuse anybody. so we'll go back with these. so system calls ever remember system calls is remember those and the problem that we ran into in that in this picture we have connected the system a bunch of other stuff right here shows the direct link between memory and the cpu where it's kind of like wired together with a bus. the system boss, the front side bus so everyone referred you would have. there's multiple names for it, but then we have a whole bunch of io devices that are connected the system in various ways, and we motivated that. maybe not the best way. it was kind of lame, but ultimately motivated. the fact that i do n't really want all of my user code access all of these io devices all of the time."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","right here shows the direct link between memory and the cpu where it's kind of like wired together with a bus. the system boss, the front side bus so everyone referred you would have. there's multiple names for it, but then we have a whole bunch of io devices that are connected the system in various ways, and we motivated that. maybe not the best way. it was kind of lame, but ultimately motivated. the fact that i do n't really want all of my user code access all of these io devices all of the time. i also do n't want processes or programs access each other, so if i have a process with instructions and memory here because of my system is doing multiprogramming and giving me the appearance of multiple things happening at once. instruction for different programs need be in memory at the same time, otherwise the system would just not work fast enough. it would just be too small, so i do n't want have this guy's code access this guy's data. it's just a security problem and also the correctness problem cause this guy mocks the something all of a sudden it's gon na get go the wrong answers. and i'd rather have the models that i train be correct, or elden ring, you know actually work properly. so we want isolate processes and we also want isolate processes from the operating system code. the operating system is instructions is providing services like accessing io devices and it is the code necessary for doing that. i do n't want have a program start mocking with operating system code. it's i want break my system. ok, so what other is on purpose or on accident? right, we can be malicious on accident. it happens. we wanna do that. so the inventors of this hardware said let's do something about that and we'll set this idea or create this idea of the flying industry and the mode bits where we can set the cpu operate in different modes. and if it's running in user mode, it can only access certain stuff. it ca n't access all of the instructions. it ca n't access all of memory and we'll have a way, a mechanism that we need put in place allow the cpu escalate its privileges get into system mode where the operating system is gon na run. and the trick of the problem that we've talked about was how do we escalate those privileges without just saying, yeah, you go ahead and just escalate your own privileges. right. the military would n't like that."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","and if it's running in user mode, it can only access certain stuff. it ca n't access all of the instructions. it ca n't access all of memory and we'll have a way, a mechanism that we need put in place allow the cpu escalate its privileges get into system mode where the operating system is gon na run. and the trick of the problem that we've talked about was how do we escalate those privileges without just saying, yeah, you go ahead and just escalate your own privileges. right. the military would n't like that. i do n't like that, right? i do n't just want have a regular person say. ohh yeah i have but i have higher problem just so i'm just gon na run and i'm gon na flip the bits be system mode and then i'm going make it in vacation into operating system code. change the program counter and start it running. conceptually that works, but in all reality, if any program was allowed escalate its privileges, then we just lost all the security that we had available us. by having these mode bits right? so any motivated the idea of, well, what if we booted the system in system mode and the only code we loaded when the system booted was operating system and we said operating system, now that you're loaded and you're running in system mode, no user programs or no user processes are running yet we still have that the screen up that says windows is loading, right? it's going set up a special routine for system point entry and then tell that the cpu and then say i am now going release my privileges. that's one thing about being privileged is i can release my privileges. i can say, you know, i just do n't want them anymore. i am taking the initiative make myself less six months or less secure, but i'm letting myself access less stuff. i ca n't get more without asking, but i can offerup and say i would like restrict myself. ok. so let's operating system sets up. it's enter routine. it then changes the mode user mode, runs the first user program, and that program runs and can not access anything other than its own stuff because it's running in user mode. if it wants access system mode, it needs ask the operating system. the only way for the cpu load operating system code will be execute this instruction called syscall, is executable and user mode, and it will flip the mode bit system mode."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","i ca n't get more without asking, but i can offerup and say i would like restrict myself. ok. so let's operating system sets up. it's enter routine. it then changes the mode user mode, runs the first user program, and that program runs and can not access anything other than its own stuff because it's running in user mode. if it wants access system mode, it needs ask the operating system. the only way for the cpu load operating system code will be execute this instruction called syscall, is executable and user mode, and it will flip the mode bit system mode. but at that point, as a side effect of calling says, code says call, it will flip the program counter only point operating system code. that way we can escalate our privileges, but we will never execute a user program when those privileges are executed, we will only execute os code, right? and that was the the idea of a track. right now i'm reviewing this and offered in the past, people like doctor longview reviews too much, but this is important. like this is like this is operating systems like if you do n't start this. if i lost you here, then the rest of operating systems is gon na be like, i do n't know what's going on. you got ta know. you got ta know trap first. so we're gon na cover multiple times. ok. questions with me? alright, so this is what it looks like hand wavy on paper. what does it look like in actual code? let's go back over here my notes. here is the picture of the syscall. we've got this trap and why i mentioned this picture shows a mode bit of 1 bit on an actual intel x86 architecture. it uses 2 bits, but we wo n't necessarily go into that in great detail. we mentioned the system called table, is how the operating system knows what service execute. the user sets a register say what i'm gon na execute or what i want the operating system execute. then when it invokes a syscall and the cpu changes the mode and loads the operating system at the same time, the operating system reads that register determine what service execute, and that's in the system call table. and so then here is an example. in actual code, it's assembly code. i know. is n't that on the subway class, but we kind of have know this a little bit in order get the rest of the stock."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","the user sets a register say what i'm gon na execute or what i want the operating system execute. then when it invokes a syscall and the cpu changes the mode and loads the operating system at the same time, the operating system reads that register determine what service execute, and that's in the system call table. and so then here is an example. in actual code, it's assembly code. i know. is n't that on the subway class, but we kind of have know this a little bit in order get the rest of the stock. so here is our high level statement. we have a system called called write allows us write a particular device and so later on we talk about io. we'll say we'll learn that all of linux really when we're when we're accessing a device, it treats a device like a file and it gives you a descriptive a number associated with that particular device. all devices have a number associated with them and so what this is saying is i would like write some characters a device. this is a buffer for how many characters i'm gon na write. this is how long that is, or how many characters i'd like you write that device, and in this case it's going be some location in memory. but in this case it's a string literal that is hello world and if you count that it's 12 characters minus the null terminator. what device are we writing or writing device # 1? all devices are given a number just like a memory addresses, a number. a device is given a number one. in this case, is the output device or standard output? every single process is given 3 device numbers automatically 01 and 20 represents standard input, is like system dot in reading from the console from the user's standard output. system out in java or c out in c and then # 2 is standard error is like something that error or c error in c for outputting the error display error display one and two typically go the console like the terminal output 0 is reading from the keyboard. later on, if you're curious, you can talk about mouse endpoint and how you get that kind of stuff, but essentially think of device. so anyway, this says right device number one those characters. how does this get translated into assembly? well, just like what we did in hand, waving only, it's straight down code."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","system out in java or c out in c and then # 2 is standard error is like something that error or c error in c for outputting the error display error display one and two typically go the console like the terminal output 0 is reading from the keyboard. later on, if you're curious, you can talk about mouse endpoint and how you get that kind of stuff, but essentially think of device. so anyway, this says right device number one those characters. how does this get translated into assembly? well, just like what we did in hand, waving only, it's straight down code. the first thing we need do is move what operation we're gon na do # 1 into the rx register, says here is the operation that i'd like the operating system perform. if we look up in the system call table i i thought i showed you, you'll find that one is the system call # 4. right. right. there's 332 ish system calls that are in that table. one is right, zero is read. i ca n't remember what the other ones are, but we can always look them up. the rest of this is setting up parameters for what tell the operating system do, and then we make assist call at this point, this program stops the cpu, so speak. does n't necessarily know that it's executing operating system code versus user process code. this really understand that it just needs an instruction stream, but it does know when it executes assist call it has change the mode system mode and load into the program counter the address of the system entry routine was set up by the operating system when the system booted. then it will execute that code and then this code down below. here is the return from the operating system. this is not like this is contain operating system code, but the operating system code would execute right in here. then the second line of coding here shows another system call. it's the actual exit system call has the value of 60, is essentially tells the operating system. i would like quit and end my program and my process ok, so this is kind of implicitly called whenever main returns. but we can explicitly call it by calling syscall 60. ok. all right. two different ways look at the same thing. alright, so now let's go an example. i want do an example of let me pull up the web browser here. you name."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","then the second line of coding here shows another system call. it's the actual exit system call has the value of 60, is essentially tells the operating system. i would like quit and end my program and my process ok, so this is kind of implicitly called whenever main returns. but we can explicitly call it by calling syscall 60. ok. all right. two different ways look at the same thing. alright, so now let's go an example. i want do an example of let me pull up the web browser here. you name. anybody familiar with you name not expecting you be familiar with you named but you and name is a system call? and what you name does is it says operating system. i'm going provide you with a pointer. once a pointer a number. yeah. bam, what does it refer? a location in memory, right? if i'm going stop saying this after a while, but i'm gon na do it one more time. if my street was representing of all memory right e yale ave address of my house 3923 is a number. it represents my house. the value that's stored there is single story ranch with a gray exterior, right? that's the value of my health in this case, we are telling the operating system here is a location in memory. what i want you fill in some stuff, so we're gon na put this in of registered tell the operating system here is a location and i'm gon na invoke the you name system call with the syscall instruction. the operating system then will read this number and fill in this buffer. this structure with a bunch of information and that information is defined down here and what it's gon na fill in is information about the system, what the operating system name is, what it's version is, what what hardware we're running on and so on. this is not something that's specific see. it's specific this system we're running out, so it already get this information. we have ask the system how do we ask the system for anything? there is a system call alright, so let's program this up and we'll take a look at how this works at what we get. so it says in the the manual page in order use the struct uts name, i got ta include sys uname dot h that's where this structure is defined."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","this is not something that's specific see. it's specific this system we're running out, so it already get this information. we have ask the system how do we ask the system for anything? there is a system call alright, so let's program this up and we'll take a look at how this works at what we get. so it says in the the manual page in order use the struct uts name, i got ta include sys uname dot h that's where this structure is defined. so i'm gon na go back my c lion and create a new file and we will call it, uh, this call call you name for like a better word. and i'll make my main routine and i'll return 0 here. but then i need include the header files, so instead i oh, i'm going do that because i'm do printing and i need include sys. sis uts name dot hok then i need create my struct is called you. it's just called rts name, right? yeah, uts name. umm os info. ok, so what? this will do as soon as i write that and i compile it. this will tell the compiler allocate storage with inside the context of vain for a structure that's big enough store all the information that the os might give us. right. ok, so now we need. now we need call it. we just call it with this, passing in a pointer is gon na be the address of where we allocated the struct. ok. one thing that i want point out here is is it sort of a theme amongst operating system system calls, at least in posix and linux is they kind of follow a standard behavior. they have parameters and they've got they've got maybe multiple parameters. ok, that's true. right. but they also have a similar behavior for how they return, and that's just how kind of is the way the syscall instruction kind of works under the covers is that if there is a success, it returns zero. if there's a failure, it returns -. 1. that's very similar and the reason why i pride in practice with this in your stacked machine ordering project was that all the functions either return zero or -, 1 for this very reason. kind of get our mind in the right mindset of 0 means success -, 1 means error. if there is a specific error that happened, there could be any number of reasons why why our system call would fail."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","but they also have a similar behavior for how they return, and that's just how kind of is the way the syscall instruction kind of works under the covers is that if there is a success, it returns zero. if there's a failure, it returns -. 1. that's very similar and the reason why i pride in practice with this in your stacked machine ordering project was that all the functions either return zero or -, 1 for this very reason. kind of get our mind in the right mindset of 0 means success -, 1 means error. if there is a specific error that happened, there could be any number of reasons why why our system call would fail. it could be because you do n't have permission something. it could be because you're out of memory. it could be. i do n't know you name it. the operating system is gon na set a special global variable called air note, so this is a special thing that's accessible by your program that's global that says specifically what that error is. you ts name is kind of special in that it only has one particular error is buff is not valid if i give it an invalid pointer, the operating system is gon na say hey dude i ca n't copy data there, that pointer is not valid. it will return -, 1 and then set error node be that there's a memory fault. uh, but other system calls will fail for other reasons. there's some that could fail for i do n't know, 50 or so different potential reasons, so i want know specifically why something failed. i can look at the global variable called errno. otherwise i just move on, so in this particular example i'm going provide all the correct information, so not gon na worry about errors, but later on i will certainly do that. so in order do this, i'm just going say call you name and pass in the address of my struct os info. now, because i just talked about error messages, i'm going surround this with an if statement say if it is, uh, and i'm gon na do doctor lemke's trick so that i do n't accidentally do an assignment operation. although in this case it would n't make a difference because i ca n't assign a value a function like that, but i'm gon na do it that way, so if this returns zero, that means i have good values."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","so in order do this, i'm just going say call you name and pass in the address of my struct os info. now, because i just talked about error messages, i'm going surround this with an if statement say if it is, uh, and i'm gon na do doctor lemke's trick so that i do n't accidentally do an assignment operation. although in this case it would n't make a difference because i ca n't assign a value a function like that, but i'm gon na do it that way, so if this returns zero, that means i have good values. that means that the system call would have executed and the contents of os info will be filled in by the operating system with the appropriate information. and now i can just print it out os name. i think that's one of the fields. nope. sludge and let's take a look here. maybe this we'll see how all this works and not too bad. ah, this name os info dot sysname, and then i'll print off the. os release will be that's i guess it's two values. there's a release and version. do that and then we'll do something like i do n't know, dash, dash, dash. os info dot release and os info dot version not bad i guess i should put our new line in here. uh, we'll call it. i do n't know hardware, i'd i do n't know. who was involved? dot machine ok. ok, but they. alright, let's build this and run it and see what we get. please boot up os. yep. this call you name dot c good. looks like it worked and i got my eight out. so when i run it i get this. this is one thing that kind of frustrates me about this. oh yeah, sorry question. did you do anything special? no, no, it's just a. it's just a header problem, just like any other, so this is telling the compiler look for this header file in with the less than greater than symbols in the system library paths, and that sys represents a directory. so somewhere there's a system library path or include files that can change the directory sys and inside there is uts name dot h and it was able find it if it was n't able find it i would have got a compiler. there's nothing magic behind that, just it knows where search for it, because it's got a search graph with the system pattern."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","it's just a header problem, just like any other, so this is telling the compiler look for this header file in with the less than greater than symbols in the system library paths, and that sys represents a directory. so somewhere there's a system library path or include files that can change the directory sys and inside there is uts name dot h and it was able find it if it was n't able find it i would have got a compiler. there's nothing magic behind that, just it knows where search for it, because it's got a search graph with the system pattern. one thing i did see is that i solved hardware wrong our ward, but you guys that that's what i was thinking. but anyway, we get the information about our system now. what kind of frustrates me about this is i'm running on windows and it's giving me information about linux, but that's because i'm running windows subsystem for linux, but it's telling me that my os name is linux, that my release information is. this is the microsoft standard wsl kernel, and then that's the version, and then this is my hardware id is x8664 makes sense question. what are you getting? so when you do gcc of of of your file you get file that file. uh also also talk after class. did you get the same problem on in like the different language? yeah, there's a forward slash, not backslash. ok. actually, we'll talk after class, i guess because i do n't i i do n't, i do n't know. but that's a good question. alright, so sorry that that aside, now let's look, ok, so this is the system call and it's being executed. obviously something is being executed. it executed the trap. they've loaded the operating system code and this information was filled in by the os, ok. well, let's take a look at this from an assembly perspective then, since that's what actually happened. we should be able compile this with the dash capital s flag get it stop after the assembler. i'm sorry, after the compiler before the assembler runs and give us assembly instructions, but let me go down here and this is not all going fit on the screen, but at least we get an idea. so above here we've got the compiler declaring storage for all of our string literals, and all of our other literal values."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","well, let's take a look at this from an assembly perspective then, since that's what actually happened. we should be able compile this with the dash capital s flag get it stop after the assembler. i'm sorry, after the compiler before the assembler runs and give us assembly instructions, but let me go down here and this is not all going fit on the screen, but at least we get an idea. so above here we've got the compiler declaring storage for all of our string literals, and all of our other literal values. so here these are the string literal values that are needed for doing the format, the printf and so that that makes sense. it's like a model is colocating that it's got ta go somewhere. then in here we have the instructions for maine, and i'm not asking you know exactly how this works, but what it is kind of doing right here is we see this like sub q or doing some sort of subtraction. this is in a way that compiler allocating storage for that os info that uts names structure and so if we were look in the header file under this option we can find it i'm not 100 % sure why. yeah. still, you're. but anyway, that's something we can find it the actual size of that structure is looks like 400 bytes. ok. and we can look it up know for sure, but i do n't know that i need and then down here we see it's doing some allocation and working with that sword get it all set up. and then right here we have a call. and ok. and you can say, well, somewhere in here there must be a syscall, because if i'm making a system call, somewhere in here must be syscall. and what i have is a call here you name and then after that i have a call print that well. so ok, somewhere between this and here, that system call had have happened because i got the data and this is where it's printing out. so it i have have had it by now, but i do n't see anywhere in here where i'm accessing the system call. so where is it? it's magic. no, it's not magic. one reason why i'm showing you this is because. given the previous example here. it took from wikibooks, by the way. that's awesome. alright. doing this setup here as a programmer, i like function calls. why do i like function calls?"
"""OpSys_System_Calls_and_Processes_Transcript.txt""","so ok, somewhere between this and here, that system call had have happened because i got the data and this is where it's printing out. so it i have have had it by now, but i do n't see anywhere in here where i'm accessing the system call. so where is it? it's magic. no, it's not magic. one reason why i'm showing you this is because. given the previous example here. it took from wikibooks, by the way. that's awesome. alright. doing this setup here as a programmer, i like function calls. why do i like function calls? because well, as a c programmer, we have data and. auctions of manipulate that data. ok, right and a function call is pretty convenient. i know how do that. i understand that it's clear, so if i'm calls are confusing and from a compilers perspective, you have have special code in order be able see the word right? like this and generate the proper assembly instructions for syscall. could be a lot of work, so what the developers of the sort of the compilers and the working with these system call said? you know if function calls are really easy handle because we know how do that by generating just a call instruction that we can do that. why do n't we just take every single system call on the system and isolate them one place so that the compiler with source code for it and i'm sort of a target organized section of its code, or handling all of the system calls, and then anytime a user wants invoke those syscalls, instead of having it invoke the system call directly, we will have it call a function instead? that way if something changes and as far as how system calls are invoked, all we have do is swap out the library that the user program is calling and we have have the user program change. so if we had like a system update say we have a new way for you call this system call instead of having all of your user programs be recompiled, all you have do is do a system update. the library gets updated and you get use the new format for for invoking a system call, but your code does n't change because it just invoked a function call. makes sense. you see, that? got some nods. some people going if you're bored, that means you got it. i i kind of want bore you, but also also do n't."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","so if we had like a system update say we have a new way for you call this system call instead of having all of your user programs be recompiled, all you have do is do a system update. the library gets updated and you get use the new format for for invoking a system call, but your code does n't change because it just invoked a function call. makes sense. you see, that? got some nods. some people going if you're bored, that means you got it. i i kind of want bore you, but also also do n't. so here's what actually happens is that system calls in order make them look like a function call, we have some library that has a file in it, and i can show it you. it is cool. i have look at it once, so i was n't getting doing my my my research, my research the file that for doing all of the system calls right there's 300 and sub system calls on linux and all of those have be wrapped in that library. there's a file or set of files for doing that, but i want make a system call. i go function call but the seed library actually does the system call on my behalf. you do the trap get into the kernel, and in linux, and that civically libc libc also exists on other operating systems g libc, the canoe lib c or library for c does that for us on windows, in case they're curious. that's done via the native api and that's located at least as of windows 10. i do n't know if they moved it in windows 11, but as a windows 10 it was called and through the l.dll does that. and that stands for the nt or the new technology. i think we're just a version of windows from a long time ago. the l stands for dynamic link library, is a library inside windows that wraps all the system calls for you, but it's still doing this. track it has. the only way you can do it under the covers questions. ok. this slide is only for reference. i'm not going cover it, but it talks about sort of the history of linux system calls and how we're still able access a single point of entry based on all the different mechanisms."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","i think we're just a version of windows from a long time ago. the l stands for dynamic link library, is a library inside windows that wraps all the system calls for you, but it's still doing this. track it has. the only way you can do it under the covers questions. ok. this slide is only for reference. i'm not going cover it, but it talks about sort of the history of linux system calls and how we're still able access a single point of entry based on all the different mechanisms. the way we invoked the system call kind of is evolved over the life cycle of x86 as it's moved from 8 bits 16 bits 32 bits and now 64 bits and under the assumption that someday they'll do 128 bits, it'll probably even change from then on. but we'll see what happens. but if you're a colonel hacker, that can give you sort of an idea of how it works. ok. so 130 the last bit of stuff are some questions that i want us keep in mind will come back some of these, some of these we already answered, but i just wanna throw them out there just keep us brainstorming. and so we do n't forget. uh, so what do we have? how do we pass data a system call and for that i did n't directly did n't directly answer that question, but if you look at the system called documentation. we'll find that the way you actually pass parameters a system call. so for example, with the right, the one that i showed you in the example it says store number one in the rx register and then here is storing the different parameters in different registers. so in the operating system code ultimately gets invoked. it just reads those registered directly get what the parameters are. this is different than a function call or an a function call. everything is passed and handled via memory. we'll talk about that when we get in the processes, but for now, we make a system call. it's done via registers. ok. and so the other system call that i believe that where that was in there was sixty was exit not hex 60, decimal 60. there it is. exit and it just has one value is the error code and you'll see that some system calls like fork will get you next week or maybe even tomorrow has no parameters, you just call. ok. that's how we pass parameters. we are registers. that's the table. let's go back down our questions."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","it's done via registers. ok. and so the other system call that i believe that where that was in there was sixty was exit not hex 60, decimal 60. there it is. exit and it just has one value is the error code and you'll see that some system calls like fork will get you next week or maybe even tomorrow has no parameters, you just call. ok. that's how we pass parameters. we are registers. that's the table. let's go back down our questions. how many system calls do we need? i love this question. how many operating system services do we need well? biggest thing 51020. there was some movie. uh, i do n't know. what was it? someone was quoting and asking something in the answer. the question was at least one more. sometimes i kind of feel like when it comes system calls, that's kind of the way it is currently on linux we have. i think there's 333 hundred 35330 somewhere ish system calls for for that. another answer that somebody in the other section gave, i really was was awesome was how many system calls do we need? ask the posix developers, because that's the standard, and that's kind of true. but ultimately, the deposit developers have say from perspective how many they need. the short answer is i do n't know or investor could say it depends. it really depends on how many services we wanna provide. we're always thinking of more services provide, maybe someday if we have like generative ai built into the operating system will have a system called for that, who knows? i do n't know. i'm making this up as i go. ah, but it's really as as many as we need depends on what services we have. different operating systems have different system calls. that's embedded systems may not have as many because they do n't have as many. they're more special purpose versus your general purpose thing, like politics or the all right. and this last question is a philosophical question we will come back later on when we talk about processes and process scheduling is what process executes a system call, not what process per se. but it also kind of a follow - up question, i should have maybe said it differently, is does the operating system ever run and what is a process and what is an operating system? and it's arguable that an operating system does n't actually execute itself. it always executes on the behalf of a user program."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","they're more special purpose versus your general purpose thing, like politics or the all right. and this last question is a philosophical question we will come back later on when we talk about processes and process scheduling is what process executes a system call, not what process per se. but it also kind of a follow - up question, i should have maybe said it differently, is does the operating system ever run and what is a process and what is an operating system? and it's arguable that an operating system does n't actually execute itself. it always executes on the behalf of a user program. others will argue that no one operating system really does run on its own, has its own processes. but again, fill this out of the question, but we will definitely come back that. talk questions. i know a lot of hand waviness, but still we got ta cover it. so that's my end of system calls. so once we do that, now let's build on that and we'll talk about processes. and i mentioned that word and i've all. i kinda almost used the word processing program interchangeably in this class and i've kind of done that on purpose. but today is where we're gon na draw the line between what's a process and what is a program? i've so. what's the process? if i have an idea, anybody know anybody worked with this idea? and windows, we have the task manager right? you never use the task manager. yeah, usually i use it for like what the heck is my system doing right and i pull up the task manager and say who is sucking up all of my memory? right. or who is using all of my cpu, right? this lists our process. windows does n't call them that. i do n't know why this is, it did n't matter. well, i guess it does. here background processes. yeah, but what's the process? what's a program? in the cliche word, let's dive in. ok, so what do we have review. dual mode operation, right user mode, kernel mode, ok, user mode, restricted mode right can only execute certain instructions. i can only access certain parts of memory, right? if you try access something that you're not allowed, you get an exception, and then your your your application will most likely crash and somebody else gets run kernel mode. supervisor mode, system mode, privilege mode."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","what's a program? in the cliche word, let's dive in. ok, so what do we have review. dual mode operation, right user mode, kernel mode, ok, user mode, restricted mode right can only execute certain instructions. i can only access certain parts of memory, right? if you try access something that you're not allowed, you get an exception, and then your your your application will most likely crash and somebody else gets run kernel mode. supervisor mode, system mode, privilege mode. you get do anything you want, access all the instructions, access all of memory, and if you crash when running in kernel mode, good luck. alright. ok, so that's that. so here is my spiel. this is not necessarily a in a book anywhere, but this is kind of partially my definition and sort of emerging killer. a bunch of stuff. i'll program a static representation of operation operations and data. ok, compiled code. the big thing here that i want you take away with this is that a program is static. one static does not change and you could say it does change, but for the most part it does not change when i install a program. when i install microsoft word or i install elden ring installed install steam unless i have like an update that program, i do n't change it, it stays put. it's there. ok, right. two, it's a file. right. it's a thing that i can represent and store on my disk drive file. it's not special, right? on linux, we you in your first programming project or lab that are going it as you identified and looked at the six file pipes on a linux system. windows is something similar that. now windows does it's darkness try and tell you that a docx file is different file typethana.exe that there's a special thing associated with it. so just files on the disk drive. ok, same thing. this is just a file, it's just data that's being stored by our operating system. it is static. ok, once a process a process is, does an instance of active execution. you can also say it's a program in execution. we might have one program, but from that we might create multiple processes of it. ok, chrome is a prime example."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","now windows does it's darkness try and tell you that a docx file is different file typethana.exe that there's a special thing associated with it. so just files on the disk drive. ok, same thing. this is just a file, it's just data that's being stored by our operating system. it is static. ok, once a process a process is, does an instance of active execution. you can also say it's a program in execution. we might have one program, but from that we might create multiple processes of it. ok, chrome is a prime example. chrome is 1 program that runs that you can run, but every single tab that you that chrome runs because of isolation and protection reasons it creates every single tab as its own process. ok, so one program, multiple processes, ok, processes have been away, a state associated with them. and i do n't necessarily mean a state of execution versus suspended, and we certainly will get that. but they have a state of like what variables you have in memory, right? you might have a four loop that is the value of i, right? i is a variable. for that reason it a variables change the variable and so i'll particular state of a program consists of what values are it variable. it's variables have so every single chrome tab might be executing the exact same program, but the variables associated with each tab will most likely be different, even if i'm loading the same web page, it's probably gon na be slightly different when each tab is doing. so here is a map of programs and memories and i kind of try and drew that on that picture before, but this shows the picture from the william stallings book that each process has a location in memory associated with it and our operating system in protected memory is keeping track of all of the processes that are currently running on the system internally in this process list, we'll talk about a little more about what goes in this process list and what the process is allowed access versus what the operating system access is. but i do want mention that it's a lot of hand waving just, but it's important. ok, so why do we need processes? why do we need processes? it's kind of a funny question. i'm imagine a lot of people ask that question. in the past, i'm not gon na necessarily spend a whole lot of time about why we need processes."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","so here is a map of programs and memories and i kind of try and drew that on that picture before, but this shows the picture from the william stallings book that each process has a location in memory associated with it and our operating system in protected memory is keeping track of all of the processes that are currently running on the system internally in this process list, we'll talk about a little more about what goes in this process list and what the process is allowed access versus what the operating system access is. but i do want mention that it's a lot of hand waving just, but it's important. ok, so why do we need processes? why do we need processes? it's kind of a funny question. i'm imagine a lot of people ask that question. in the past, i'm not gon na necessarily spend a whole lot of time about why we need processes. we do, but in short, it's allow us take advantage of our cpu. because i mentioned before, at least i tried. i hope i did that. it's really hard keep our computer processor busy. because a lot of the times our computer processor is waiting for something, and often it's waiting for us, right? if i'm playing some game, waiting for it needs wait for some user input, even if it's polling the mouse 1000 times a second. that's that seems like a lot, but the cpu can be usually doing like a billion things a second. so 1000 times a second. right. a billion is, what, 10,000? thousands. that right? right. it could be doing a lot of other stuff while it's waiting for us move our mouse around, so we want keep the cpu busy and so one of the things one of the ways we can do that is multiprogramming. if the cpu is not able do something and it has wait for something, well would do something else right? right as well, it's not doing anything anyway. it could be sitting waiting there, twiddling it's thumbs, but i can be sitting there twiddling my thumbs. or i could be studying for operating systems while waiting for my friend give me a call. right? i could sit there and be like, oh, wait, my friend call me or send me a text. i guess who calls people anymore, right? or i could study for operating systems while i'm waiting for that call, say my idea, all the program. are too is."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","it could be sitting waiting there, twiddling it's thumbs, but i can be sitting there twiddling my thumbs. or i could be studying for operating systems while waiting for my friend give me a call. right? i could sit there and be like, oh, wait, my friend call me or send me a text. i guess who calls people anymore, right? or i could study for operating systems while i'm waiting for that call, say my idea, all the program. are too is. like kind of like be able try and do more than one thing at once, right? i like have microsoft word running in the background right while i'm doing all the lots of other things. the other answer is isolation and protection. we need this idea of a process because if we're gon na do multiprogramming, we need find a way isolate programs or active programs from each other. even though chrome is 1 program, i do n't want have one of my tabs access the memory of another tab, because if i've got stuff in amazon going on, i've got credit card numbers typed in there. i do n't want somebody else's website access the tab that has amazon on it get my credit card. so isolation factor not only for security, but also for correctness. i had. so let's take a look at a program and a process, and here is where we go. so what's in a program? a program consists of stuff that does not change. ok, we have text. once our program is compiled or our code is compiled, i do n't want my instructions change if i want them change, i'll recompile it or i'll download a system update. right. steam will get updated. download a new one, but for the most part should n't change data sections, static data, global data, constants, things like that. they should n't change. they should always be the same every single time i run my program, all of the constants that are in there should be those values every single time i run them. i do n't want somebody change what the value of 10 is. the value of 10 should be 10. there are some programming languages like you still let you do that. warning. right, ok, linking information. what libraries this thing is dependent upon? the only time that should change is if i rebuild the program."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","they should n't change. they should always be the same every single time i run my program, all of the constants that are in there should be those values every single time i run them. i do n't want somebody change what the value of 10 is. the value of 10 should be 10. there are some programming languages like you still let you do that. warning. right, ok, linking information. what libraries this thing is dependent upon? the only time that should change is if i rebuild the program. so if i'm using the map library do things like square root or something like that, that's a dependence, and that does n't change. symbol table. this is english words for our symbols. this is not necessarily required in a program. ultimately, when the cpu executes stuff, it just cares about memory addresses and registers. as you've auger, i personally would like know what the value of i is by name. hi what is i? what is my variable? the zipper does n't care. i might be address 4000, but when i'm debugging my program, i'd like know that so the symbol table is a way that variable names. we can strip that off if you're curious. i can show you how plus. anyway, that's in a program. ok, that's important text data linking and symbols. what's that process? well, we have a couple of things that should n't change and you could say well, yes, text is the executable code. it should n't change. well, yes. and i would argue then you would say, well, why do i need it in memory? why do i need it be part of my process? ultimately, we're gon na find that processes get loaded into memory. they're created from a program and despite the fact that we want might have multiple copies of the text in memory at the same time, we want have fast access our instructions and the fastest place that we can put it well would be inside the cpu. but we do n't have enough space for store at all. we have space in memory, so we're gon na put that in memory, despite the fact that we do n't want this change. but we'll talk about memory and memory protection and we can actually protect this so that we ca n't change it. there's a data section. this consists of things like global data, ok, things that need exist throughout the life cycle of the process. they might change."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","they're created from a program and despite the fact that we want might have multiple copies of the text in memory at the same time, we want have fast access our instructions and the fastest place that we can put it well would be inside the cpu. but we do n't have enough space for store at all. we have space in memory, so we're gon na put that in memory, despite the fact that we do n't want this change. but we'll talk about memory and memory protection and we can actually protect this so that we ca n't change it. there's a data section. this consists of things like global data, ok, things that need exist throughout the life cycle of the process. they might change. so we're gon na put it in memory, but it has some sort of initial value and it's value stored somewhere, and that's the stick around forever. if i have a global variable called i, it's always in scope, so it ca n't ever go away. so we're gon na store it in the data section and then finally we've got these three sections down here, one called the heap and one called the staff. and this is area that's reserved or dynamic memory, things that change, things that come and go. we'll find that seth is used for temporary data for the process or things that are local function calls or things that are local essentially scoping braces, and then we'll have the heap, is memory that persists, but it does n't persist outside the life cycle of the process. it just persists until it's explicitly free. that's things that you would use the new operator for in java or c or malloc airport programming in c ok, what time is it, miller time? no. i got time now. we're moving alright so. questions all right. but here's what we have we are program and process of this essentially the format for a program. not gon na ask you memorize this, but if you're curious i've ever done this. gone wikipedia and look up the format for a java class file. it's. it's published. it's it's, it's open source, right? java's open source, so if you want know how a class file look, it's in binary and the first like couple of bytes of a class file is a magic number so that you can know that it's a class file because you ca n't really trust the extension."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","not gon na ask you memorize this, but if you're curious i've ever done this. gone wikipedia and look up the format for a java class file. it's. it's published. it's it's, it's open source, right? java's open source, so if you want know how a class file look, it's in binary and the first like couple of bytes of a class file is a magic number so that you can know that it's a class file because you ca n't really trust the extension. similar a program on our linux system uses the health format, is the executable and linkable format, and it has a header on there says that this is an out formatted program and inside there we've got all the different sections that i mentioned previously. text. is this out there? extractions read only data. that's our constants. we have changeable data that is set sort of globally but but umm for just have allocated allocatable spaces with a bunch of other sections in here, i'm not gon na ask you memorize this, but i do want mention that this is sort of the way format works and then we have a process. all processes are gon na look something like this. we have text we have. this is memory and you could talk about the address from zero infinity. processes do n't actually have an infinite amount of memory. it's limited by the amount of memory on our system, but it's usually pretty big and so they're given an address space, a spot for text, a spot for global data, bss. they actually say what it's doing for it. i never remember what it stands for. bss block started by symbol anyway, that's what stands for. what it essentially means is it's global variables that do n't have an initialization. so if i was go in here and go my sister name thing and say int x = 10 and int y. acts as initial value. it's ten that gets stored in the data section. y gets stored in the bss section. it's a section. just another place store global data. it's just the way things are created. for the most part, you can just say it's where we store global variables in that location in memory. got ta be stored somewhere. it is always in scope right where i am in this file. x&y are always in scope, so they always have be allocated someone, so we put that in memory. and then finally, we have this heap and stack ok."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","y gets stored in the bss section. it's a section. just another place store global data. it's just the way things are created. for the most part, you can just say it's where we store global variables in that location in memory. got ta be stored somewhere. it is always in scope right where i am in this file. x&y are always in scope, so they always have be allocated someone, so we put that in memory. and then finally, we have this heap and stack ok. remember the cpu. who's this? conceptually, we think about it like this, where each of these programs now we understand program versus process. each of these processes you have run a certain amount of time. the cpu says i'm executing instruction stream, so what's going happen is the operating system is going set this up that over time it's going set the program counter point the text section in memory for one of the processes that process is gon na get the run. it's gon na modify a sneak and it's sad and it's maybe it's global data. it wo n't be allowed modify its text, but then after a certain amount of time the operating system is gon na have get involved it. we'll talk about that how that happens. we talked about seeking new scheduling and then it's gon na let the other process run by altering the program counter of the cpu point the memory location of the other process. and then we let it keep going. so i've said this in the past and i'll say it again and then we'll be done for the day. when it comes process management and processes on the system, the cpu does not know the existence of processes. all it sees is a string of instructions that it executes. processes are an os construct and you might say, but no, the operating the the cpu gets run in user mode versus kernel mode. that does n't indicate whether or not it's a process that's running or the os code right. we could allow a regular user code run in system mode. i do n't recommend it. it does just a bit, just a bit. just a flag in the cpu, the cpu is just executing instructions and whether or not it's mode is set the system mode or user mode. that's something that the operating system sets up for us because it knows what it's doing."
"""OpSys_System_Calls_and_Processes_Transcript.txt""","processes are an os construct and you might say, but no, the operating the the cpu gets run in user mode versus kernel mode. that does n't indicate whether or not it's a process that's running or the os code right. we could allow a regular user code run in system mode. i do n't recommend it. it does just a bit, just a bit. just a flag in the cpu, the cpu is just executing instructions and whether or not it's mode is set the system mode or user mode. that's something that the operating system sets up for us because it knows what it's doing. and then, say, knows what it's doing, but the authors know what they're doing, and so processes are an os construct down here. os abstraction abstractions are cool. they're created by the os. they're managed entirely by the old, by the os, right? unknown hardware and a process sort of operates concurrently with other processes because of operating system managing that and they have this idea of safe state being the contents of memory that represents variables as well as the sort of the program color and what's currently being executed along with whether or not it's allowed run or if it's waiting for something it's waiting for user input, they're gon na talk about state next time. so i think a lot of time why even if i'm not, i'm gon na stop there. so questions. ok. well, thanks for coming. i'll see you tomorrow. lembke, james stopped transcription"
"""OpSys_Threads_Transcript.txt""","meeting in _ general_-20240318_130442 - meeting recording march 18, 2024, 6:04pm 42 m 58s lembke, james started transcription lembke, james 0:09 hello. great. so operating systems isolation and protection abstractions are cool. this week, week nine, we're already halfway through the semester. i ca n't believe it. we're racing the finish now. we're back and so project is posted. no quiz this week. and where is my? what happened my? that's weird. anyway, so where are we at? we are here talking about threats. this, this world where we started out with isolation and protection, and i like say it's sort of purest form where we are completely isolated and that was the world of processes where the operating system rather the cpu does n't really know what it's doing. it's just executing a whole bunch of instructions and moving things around in memory. the operating system invents this idea of a process just for organizational purposes take advantage of multiprogramming, so that we can give the cpu and appearance like it's doing multiple things at a time. but all processes are fully isolated. they do n't get touch each other. they do n't get access each other's memory. they can kind of share stuff through interprocess communication mechanisms. there are things like pipes, file descriptors, we talked about how create a process with fork and some of the things that are shared between parent and child. things like file descriptors and we'll later on talked about message queue descriptors, shared memory segments like kind of stuff, but for the most part processes are isolated. they do n't get access each other's memory or stuff for for good reason, right? because if we have a a process that's manipulating something that might be security or related, we do n't want some other process just read the memory and access credit cards or passwords or anything else that could be. security related or by compromise security. also, we do n't wanna have processes crash our system, so the operating system says i'm in control. you can execute, but you got ta execute in your own little controlled environment, kind of like a sandbox world moved us down increasing what we can share. we talked about shared memory and then later on the next thing was what if sharing was turned on by default and the operating system designers said ok, you can do that."
"""OpSys_Threads_Transcript.txt""","because if we have a a process that's manipulating something that might be security or related, we do n't want some other process just read the memory and access credit cards or passwords or anything else that could be. security related or by compromise security. also, we do n't wanna have processes crash our system, so the operating system says i'm in control. you can execute, but you got ta execute in your own little controlled environment, kind of like a sandbox world moved us down increasing what we can share. we talked about shared memory and then later on the next thing was what if sharing was turned on by default and the operating system designers said ok, you can do that. but i'm still going have isolation turned on in that everything that's gon na have this sharing by default, these threads are going be part of own process so they can share memory implicitly, but they're not gon na be able touch anybody else. and so from there, we did a bunch of examples and the examples really were threads in i like say they're purest form in that they execute stuff, they touch memory, they can access each other's global data, they can access the same uh, uh, instruction stream. where was my picture of threads. right here. but they have own stack, own call stack. but they share heap. they share data. they share text. and this led about a bunch of what i thought was kind of neat examples, but i wrote them up there. they're they're kind of made up, but certainly it was. ultimately, hopefully useful in that we have this idea of a thread function and the thread function has some caveats it. a thread function. if we want run a thread, we have create it and give it a function execute. does this kind of like it's main routine? like if we're running a process that starts with main and by the thread starts with its thread function, you can call it whatever you want, but that's the follow a certain format. it has take a single parameter, is its arguments and has return a single value, is a pointer the return value. a function in general could have all sorts of different parameters and different return types for its function."
"""OpSys_Threads_Transcript.txt""","if we want run a thread, we have create it and give it a function execute. does this kind of like it's main routine? like if we're running a process that starts with main and by the thread starts with its thread function, you can call it whatever you want, but that's the follow a certain format. it has take a single parameter, is its arguments and has return a single value, is a pointer the return value. a function in general could have all sorts of different parameters and different return types for its function. red functions must behave like this, and it stinks in certain situations, because if we wanna pass something other than a pointer, like multiple things, we end up having do something like this up here where we end up creating a structure that has multiple things built into it, and we pass a pointer that structure. also concerning the fact that this is a pointer, this has be allocated somewhere, whether it be on the stack of some other function or with the heap, or in global data somewhere, so that can be a little bit clumsy try and get it work properly. no, this was the ad. thread function where i created a couple of vectors and created the the parameters for the vectors later on created the actual threads then are given own argument what operate on and then the each thread ads using a vector addition. portion of the vector storing the result in the resultant vector and then printing that out. remember that example? yeah. ok. and then we ran into a problem with the dot product and that brought up this idea of a data race where if we have a global variable like this, what's cool about dot product, remember dot product is each thread who can operate on its own piece of the vector. but the problem here was this operation right here. this plus equals where if we look at line 40, it appears like one line of code, but it's really not one line of code in terms of what the cpu does. this ends up being multiple instructions. we have a load the value of a. we have load the value of b. we have the multiply those two together. that's another operation and store the result in a register. then we have below the value of global dots and then we have add the contents of what we just multiplied together that and then store the result back in memory. so there was like 5 or 6 operations that are all done on this one line of code and as a result."
"""OpSys_Threads_Transcript.txt""","this plus equals where if we look at line 40, it appears like one line of code, but it's really not one line of code in terms of what the cpu does. this ends up being multiple instructions. we have a load the value of a. we have load the value of b. we have the multiply those two together. that's another operation and store the result in a register. then we have below the value of global dots and then we have add the contents of what we just multiplied together that and then store the result back in memory. so there was like 5 or 6 operations that are all done on this one line of code and as a result. we do n't really know when a context switch is gon na happen. all these threads, while anyone thread and you look at rather anyone cpu can only execute one instruction stream at a time. the operating system is swapping out these threads on the cpu using a context switch, and it can happen anywhere at the end of any individual instruction. a line of code is not atomic. i like think of all of it happening all at once, but it does n't. it's generated in multiple instructions and we looked at that in the assembly code over here for the thread dot routine and we've got all these instructions that move stuff around and do the multiplication and do this addition right. this is all for that one line of code and we could have a context switch here or here or here or here or here and any number of them could cause a problem when one thread loads the value of global dot and then does n't matter again, another thread reads the value of global dot. maybe it's gon na modify it, but then when we context switch back the previous thread, it has a stale value of global dot. so. one solution for this was change this from an ordinary run of the mill integer a special type of an integer called an atomic integer, using the atomic library, and we measure a very special instruction called fetch an ad generates a fetch an ad instruction on the cpu retrieves this value from memory as the result, and stores it back in one atomic operation. right. with me. sorry, i'm reviewing a little bit, but this is this is important because the next example is showing that this really well as great as this is, it does n't work in all situations. it say oh well, wo n't work in some tracked. ok."
"""OpSys_Threads_Transcript.txt""","one solution for this was change this from an ordinary run of the mill integer a special type of an integer called an atomic integer, using the atomic library, and we measure a very special instruction called fetch an ad generates a fetch an ad instruction on the cpu retrieves this value from memory as the result, and stores it back in one atomic operation. right. with me. sorry, i'm reviewing a little bit, but this is this is important because the next example is showing that this really well as great as this is, it does n't work in all situations. it say oh well, wo n't work in some tracked. ok. well, yes, it wo n't work and subtract and it's ad, but we can add a negative number as it just turns out there actually is a patch and subtract or patch and sub. what about multiply? ok, there is atomic operations for a lot of the mathematical operations. ok, i think all of them have been in comic version. what? where does this not work? i do n't have an example written up for it, but when it comes things like moving things around in memory, there is n't like a patch in move and you can say, well, where does moving things around in memory become important? well, things like linked lists. if we have a doubly linked list and we're having something and adding an element a linked list and we have forward and back or like next and previous pointers, we want make sure that when we're moving around pointers and memory, we do them atomically. we do n't want one thread through a retrieve an element from our linked list and then move around some head and tail pointers at the same time as another thread is trying move stuff around. we're gon na end up with a linked list that ends up in a circle, or it's just completely missing elements altogether, and so this types of things do n't work, or that type of situation. so that really a mathematical operation. right. so how do we fix this guy? so let's let's simplify this, ok? what i want do is just simplify this down and go through an example here and then motivate what we can do fix it and motivate why this is really kind of a problem in the 1st place other than what i've already kind of done. so let's look at this one, ok. we've got 10 threads. we're going create and they're both."
"""OpSys_Threads_Transcript.txt""","so that really a mathematical operation. right. so how do we fix this guy? so let's let's simplify this, ok? what i want do is just simplify this down and go through an example here and then motivate what we can do fix it and motivate why this is really kind of a problem in the 1st place other than what i've already kind of done. so let's look at this one, ok. we've got 10 threads. we're going create and they're both. all the threads are going increment a global value 2 global variables ok. volatile int start. remember anybody? remember from previous class and see what volatile means. do you guys cover that keyword? ok, let's talk about volatile because when it comes threads, volatile is important. even say what? or we'll get it. alright, forget programming for a second. what does that mean for something be volatile? it's kind of a big word, unstable, unstable. i like that. other thoughts on on volatile? explosive. i love that volatile compounds, right, the volatile chemicals. yeah, i. ah, i guess that's the best way think about it. is spontaneous, right? you could say that right ever changing. you ca n't trust it in a way. it's volatile and so what this what this is telling the compiler it's actually a directive the compiler say this number this integer is hot. it's a weird i i say it that way, but that's kind of that's kind of an idiomatic breaks. it's hot, meaning you ca n't trust its value. you could sit there and going wait. if i ca n't trust its value, what what? what does that mean? well. this is not a class in compiler optimization, but if you look at assembly code that the compiler generates, especially that our gcc compiler that we have, what it tries do is it tries keep things in a register because registers are fast, right? we can access a register in the time it takes execute one cpu instruction. i and of work executing billions of cpu instructions a second. that's pretty fast. accessing memory takes a little while, like 1001 thousand perhaps for some cpu the amount of time it takes execute instruction. so cpu can literally be doing most likely 1000 other things while it's waiting for something from memory get loaded. numbers like this and i they're allocated in our processes address space inside the sack."
"""OpSys_Threads_Transcript.txt""","this is not a class in compiler optimization, but if you look at assembly code that the compiler generates, especially that our gcc compiler that we have, what it tries do is it tries keep things in a register because registers are fast, right? we can access a register in the time it takes execute one cpu instruction. i and of work executing billions of cpu instructions a second. that's pretty fast. accessing memory takes a little while, like 1001 thousand perhaps for some cpu the amount of time it takes execute instruction. so cpu can literally be doing most likely 1000 other things while it's waiting for something from memory get loaded. numbers like this and i they're allocated in our processes address space inside the sack. in this case, maybe we could allocate it on the heap, but ultimately this is in memory access the value of i the compiler needs issue a load instruction, right? that takes time when it comes something like a boot counter, especially here where a looping 100,000 times. the compiler is like you know what? i do n't really wanna load i from memory 100,000 times. that takes a long time. so what it's gon na do is it caches it in a register and it just says i need use it. i a lot, so i'm just going store it in a register so i do n't need reload it from memory every time. makes sense. it's kind of cool. what's cool about that is we can access. i really fast. what's not cool about that is if somebody else modifies i in memory, the value of i we have stored in our register is wrong. right. that's what volatile tells the compiler. it says compiler this start is located in global memory and as a result do n't cash it in a register because some other thread might be modifying its value. so it says anytime you wanna access start you have load it from memory every single time. i know. i'm sorry. it's gon na take a while, but we need do that maintain correctness. ok, so when working with threads, if there's a variable that you have a a multiple threads modifying often if you define it volatile, that tells the compiler the always loaded from memory. i all right. so here is the thread routine that we've got. i'll show you where i'm using start right here. this is pretty cool."
"""OpSys_Threads_Transcript.txt""","so it says anytime you wanna access start you have load it from memory every single time. i know. i'm sorry. it's gon na take a while, but we need do that maintain correctness. ok, so when working with threads, if there's a variable that you have a a multiple threads modifying often if you define it volatile, that tells the compiler the always loaded from memory. i all right. so here is the thread routine that we've got. i'll show you where i'm using start right here. this is pretty cool. he thread create alright, let's just go back and refresh our memory on pthread create that creates a thread run a particular thread routine and gives it parameters and then return and then sets the thread id as a. not really a return value, but inside one of the parameters, right? that thread executes immediately. kind of like fork. it schedules the new process run immediately. we do n't have a control or any way say operating system. i want you create this thread, but i do n't want you start it until i tell you. it's it's just rode automatic labs that automatically, but it runs as part of pthread create. so if i wanna have a bunch of threads start but not actually do any work yet, i kinda have like get them all the like line up at the race like i'm like a minute, you know, launch a gun for a track meet. right, everybody lines up on the starting line. maybe they they bend over and they put feet in the blocks get ready go. i do n't want anybody start yet. so what i did here is created a volatile integer called start and said while start is 0 sit there. so i can create in this case 10 or 100 different threads and they're all going start immediately, but they're going get right here and they're all going stop because they're gon na just spin in that loop forever. does that not that semicolon there, and you might say that's useless put that there and under normal circumstances, yes, it just causes an infinite loop and causes my process sit there and do nothing. but in this case i'll have one bunch of threads that are all gon na wait right here, and then another thread can flip that bit like launching the gun and that would become one, and then everybody else will just start running all at the same time. incense. ok. so then i've got a loop that's gon na run 100,000 times."
"""OpSys_Threads_Transcript.txt""","does that not that semicolon there, and you might say that's useless put that there and under normal circumstances, yes, it just causes an infinite loop and causes my process sit there and do nothing. but in this case i'll have one bunch of threads that are all gon na wait right here, and then another thread can flip that bit like launching the gun and that would become one, and then everybody else will just start running all at the same time. incense. ok. so then i've got a loop that's gon na run 100,000 times. and increment some values. this is unprotected, so all of these threads are essentially going run concurrently, and then we're going return null. what do you guys think is gon na happen? what are the expected value? ok. so, well, let's just go down and look at the main routine. i'm going create 10 threads all execute this routine. they're all gon na line up at the start line. i'm gon na set start be one as soon as that happens. then they're gon na start reading the value and say ohh start as one and or break out of that while loop. continue on. we're gon na wait for them all join. and then when i print out the value of the global values, i would expect the global values be 10. times. 100,000 so that's a million, right. you expect them be in the because each one is. each thread is incrementing it by one 100,000 times. i got 10 threads so that should be 100,000 * 10 or 1,000,000 right for each value. but we know that this plus plus is not an atomic operation, right? it's a load, an increment and store 3 instructions because our context switch anywhere. so i will tell you this is not what's gon na happen. we get. nowhere near 1,000,000. and not only that. the values are n't the same, right? this is a problem. this is essentially, it's called the race condition, right? we talked about that already, right with our vector dot products in that we can maybe fix this with global apps. i've got a atomic acts. we have atomic fetch and now we have one that. ok, sure, that would fix it for the final value, but what if we wanted these be incremented in lockstep? and i've always be the same value if we use that tomic bench and add this guy could n't get added."
"""OpSys_Threads_Transcript.txt""","this is essentially, it's called the race condition, right? we talked about that already, right with our vector dot products in that we can maybe fix this with global apps. i've got a atomic acts. we have atomic fetch and now we have one that. ok, sure, that would fix it for the final value, but what if we wanted these be incremented in lockstep? and i've always be the same value if we use that tomic bench and add this guy could n't get added. and an atomic way and incremented and this guy would be we could have a context switch in between lines 35 and 36 if we wanted these now variables be incremented together in lockstep. you need another way. we ca n't catch an increment 2 values at the same time. it does n't work that way, but instruction just does n't work that way. so i got ta ask the operating system for help. done what we ultimately have here is. after the pthread slide. here's p threads. the world of concurrency, ok, and the problem that we have here is that we have multiple threads that are all executing concurrently and you could say well, doctor lembke, know they're not because the cpu can only do one thing at a time. and i would say yes, that is true. but because we do n't have any direct control over thread gets run when the operating system is gon na essentially emulate them all executing at the same time. and so we have no control over thread is gon na increment when, is gon na execute and grab a very various values out of memory. we we just do n't have control over that. and so the world of concurrency brings about, you know, some frustrations. and we really, be honest with you, i really like come up with a way fix this, right. in currency means multiple things executing in parallel together, right and current and. but what i really want here is during this for loop i want lines 35 and 36 not be concurrent. i only want one thread execute those at a time, right? and so this is referred as a critical section. i do n't really know why they call it that like it's critical, but that's just the term that's used. and so i'll continue use like as i ca n't think of anything better."
"""OpSys_Threads_Transcript.txt""","in currency means multiple things executing in parallel together, right and current and. but what i really want here is during this for loop i want lines 35 and 36 not be concurrent. i only want one thread execute those at a time, right? and so this is referred as a critical section. i do n't really know why they call it that like it's critical, but that's just the term that's used. and so i'll continue use like as i ca n't think of anything better. there's a section of code that, while we want because we're using threads and they're sharing everything we want them run concurrently, but every once in a while there are certain lines of code that we only want one thread that execute at a time and that's referred as a critical section. so what we have try and do is can we figure out a way log out everybody else into one thread executes this code and then somebody else can use it? that's kind of like everybody's saying, sorry, go back kids. i would talk my daughter a play twice this morning, right? all these kids are playing around with stuff and they're all they're all these toys and everything happening concurrently. and then there's that one toy that everybody else wants, right? or they have kids are not. maybe you've seen it in nephews or nieces or relatives or whatever, or that comes the point where it's like, no, i want. it's not that i want a ball. i want that ball right, that one ball. and so all these kids, they're they're running around, they're trying grab this ball, maybe they're gon na rip it pieces. but what do you have every once in a while you get lucky and you get the teacher or the daycare provider or the person that's managing the room where they walk up the kids and they say. why do n't you let alice have a turn and then let john have a turn right? taking turrets, we need find a way for all of these threads say you know what i wanna increment the value. you. no, no, i wanna increment the value. you know i wanna increment the value. somebody say? wait, why do n't you let red one increment the value and then it'll be threads 2's turn, right? so. back too. concurrency well, like call."
"""OpSys_Threads_Transcript.txt""","but what do you have every once in a while you get lucky and you get the teacher or the daycare provider or the person that's managing the room where they walk up the kids and they say. why do n't you let alice have a turn and then let john have a turn right? taking turrets, we need find a way for all of these threads say you know what i wanna increment the value. you. no, no, i wanna increment the value. you know i wanna increment the value. somebody say? wait, why do n't you let red one increment the value and then it'll be threads 2's turn, right? so. back too. concurrency well, like call. that is the term that we use for that in programming is not necessarily taking turns as fun as it would be say that it's called mutual exclusion. we wanna have mutual one access something, do some critical section, right. but if we do that, we have consider a couple of other things. mutual exclusion is awesome and we will talk about how the operating system is going help us out because the operating system is managing our threads for us, it's going be able provide some other features allow us perform mutual exclusion. that is awesome, but that's there. the other thing though that i wanna be concerned about, though, is going back the kids on the playground or the kids in the room fighting over the ball is we have make sure that we have progress, right and wanted say about progress is as if no process is executing in the critical section and there exists some process that wish enter the clinical section, then the selection of the process that will enter the critical section can not be postponed indefinitely. what? this is the term from from one of the books that that was sort of an optional reading. what does progress mean? it says we have a ball that the kids wanna play with, right? i got five kids that wanna play with the ball. i've got the teacher in the room that's having the kids take turns. right. we've got john. we've got alice, we've got bill and we've got. that's what we've got, wesley. great. wesley. wesley, right. wesley wants the ball. these other three guys, i ca n't remember names are, do n't want the ball. you know what the the teacher ca n't? ca n't exclude wesley, and wesley wants the ball. he's got ta get it eventually, right?"
"""OpSys_Threads_Transcript.txt""","i've got the teacher in the room that's having the kids take turns. right. we've got john. we've got alice, we've got bill and we've got. that's what we've got, wesley. great. wesley. wesley, right. wesley wants the ball. these other three guys, i ca n't remember names are, do n't want the ball. you know what the the teacher ca n't? ca n't exclude wesley, and wesley wants the ball. he's got ta get it eventually, right? that's what this is saying. you want the ball. you get it eventually. that's progress, right? if you want execute in the critical section, you might not be able execute in the critical section now, but you will be able eventually. that's what progress is, right, right? founded way starvation, freedom and fairness, it says abound exists in the number of processes that are logged into the critical section. that will ok another long winded definition founded way essentially means that if you want enter the critical section, you might not get yet. you might not think it, too. after everybody else runs, but you will be able get it eventually, there's a bounded amount of time that you will be able that you will have wait. and what you will get in eventually. right, so mutual exclusion or wanna make sure that we make forward progress. everybody that wants it gets it and everybody that wants it will get it eventually under a certain amount of time and they want it wait forever. hi progress. founded. wait. mutual exclusion. a little bit more in progress before we talk about mutual exclusion mechanisms. i will refer these terms and we'll come back them too later on. but i just wanted mention them. i've probably already mentioned it once already, especially when we came and talked about pipes and what might happen when you do n't close all of the ends of your pipes. so deadlock aggressive holding of resource resources. this is the problem on the playground right where i i ran into this when i was a kid. right bunch of kids are playing on the playground. they're playing basketball and use this example all the time. so you probably heard me say it already. the playing basketball, they having a wonderful time. finally, one kid gets upset and he says i'm going home and i'm taking the ball with me, right?"
"""OpSys_Threads_Transcript.txt""","i've probably already mentioned it once already, especially when we came and talked about pipes and what might happen when you do n't close all of the ends of your pipes. so deadlock aggressive holding of resource resources. this is the problem on the playground right where i i ran into this when i was a kid. right bunch of kids are playing on the playground. they're playing basketball and use this example all the time. so you probably heard me say it already. the playing basketball, they having a wonderful time. finally, one kid gets upset and he says i'm going home and i'm taking the ball with me, right? he wants prevent the others from having the ball and then some other kid on the playground says fine. then i'm taking your bike, right? the kid ca n't ride his bike home, but he's holding on the vault, so he's not. he's not riding home and he's also not playing basketball. everybody sitting there staring each other. it's called deadlock, ok? process a is executing in the critical section waiting for process b and process b is executing its critical section and it's waiting for process a i said critical section is in a section of code that we only want one thread execute in at a time, but there might be more than one of those. so in a is in a critical, is in a critical section, and it's holding on a resource that be needs and b is in a critical section and it's holding onto a resource that a needs. now we have a situation where nobody is able execute at all because eight is waiting for b&b is waiting for a and we're stuck there doing nothing. so that one, ok, it looks like nothing's happening because nothing's happening. we will look at the cpu utilization process a or thread a is not running. either is either a thread b because they're both waiting for something. double live on. there's another one. ok, maybe i feel i feel like explain this a lot, but anyway livelock maybe i've heard this story as well. process 8 releases a resource that process speaking continue. process b must wait be done, but ok. what is livelock mean? there's a lot of words here. i find that it's much easier explain in in a way when i was in college because i did this all the time and advanced with you, i still did this with my wife."
"""OpSys_Threads_Transcript.txt""","there's another one. ok, maybe i feel i feel like explain this a lot, but anyway livelock maybe i've heard this story as well. process 8 releases a resource that process speaking continue. process b must wait be done, but ok. what is livelock mean? there's a lot of words here. i find that it's much easier explain in in a way when i was in college because i did this all the time and advanced with you, i still did this with my wife. we walk into the room and my bunch of my friends and we look at each other and we say what's on what's for dinner in the cafeteria. and we look at that, look at our watch. we look at the at the menu online or like now do you invest? and so i look at my friend and i say let's go out dinner. they say great. where do you wanna go? and i say i do n't know where do you wanna go. and they look at me and they say i do n't know, where do you wanna go? and i say i do n't know where do you wanna go? right, right. would do that. run that situation, or maybe something similar that. this is livelock. it's socially almost in a way, in aggressive releasing of resources. process a says no no process b where b you go in the critical section and process b says no, no, no, no. hey, you go into critical section and they go back and forth and back and forth. nobody enters the critical section because they're all releasing resources almost aggressively. and what sucks about? sorry, what stinks about livelock is if you look at the cpu utilization, it looks like the processor is doing a lot of stuff, but nothing but no work is getting done right. if you're sitting in your dorm room saying, i do n't know why do you wanna go? i do n't know where do you wanna go. you're saying a lot of words, but you're not actually doing anything. you're not actually going through the the restroom. ok, so that's livelock. nobody can continue here. nobody can continue a deadlock either, so our goal here with progress is we do n't want have live blocker deadlock. questions, right? so let's talk about mutual exclusion mechanisms. there's three."
"""OpSys_Threads_Transcript.txt""","if you're sitting in your dorm room saying, i do n't know why do you wanna go? i do n't know where do you wanna go. you're saying a lot of words, but you're not actually doing anything. you're not actually going through the the restroom. ok, so that's livelock. nobody can continue here. nobody can continue a deadlock either, so our goal here with progress is we do n't want have live blocker deadlock. questions, right? so let's talk about mutual exclusion mechanisms. there's three. we're going talk about there's a bunch of other ones out there, but these are the three that i kind of feel like i use most often and i kind of want you know. so we have several floors, we have mutex locks and we have condition variables. ok. so some before. let's talk trains, ok? there's a ride on a train. you know, i feel like in europe they do that more often, but anyway this is not a this is not a transportation class, but i will try and draw this picture. so trains. trains. we have a track and we've got like railroad ties that are joining the track together. ok, you might be wondering where trains come in with the operating systems, but bear with me. we'll get there. ok. and then we have. like something like this? well, that's not the big let me move it up. ok, so we got like this adjoined thing here, right. ok. and so. if i've got a train heading this way now, this is not like the trolley problem from like ethics, whatever. but ok, so so they've got a train that's heading this way here. trying figure how do this and it's gon na go let me do the green train here. it's going go this way, right and. i've got another train that's heading this way down the track, ok? if this train is here. this red train, if it was a barrel through this area. what's gon na happen? hey each other. right. so that's not good. so what are the train people do? maybe you've seen it right? if you ride the train a lot, my dad's a really into train, so i was a kid."
"""OpSys_Threads_Transcript.txt""","it's going go this way, right and. i've got another train that's heading this way down the track, ok? if this train is here. this red train, if it was a barrel through this area. what's gon na happen? hey each other. right. so that's not good. so what are the train people do? maybe you've seen it right? if you ride the train a lot, my dad's a really into train, so i was a kid. all i really trains like constantly, so i just have this grain my head, but there's a little like bar that the train drop, it does n't go by the bar, but sitting next the train track. this is a little bar with this little like signal thing that goes up and down, kind of like your mailbox flag. right. and on the train track, there's a and so speak, that the train rolls across and went up hits that thing, the little like flag goes down. and on the other side, i do n't know why i'm doing this. you draw this on the picture, so there's a little indicator here, and so i'll do it in blue. and then there's a poll where little like flag thing on it. and when the train goes across it, it marks a thing and then sitting all the way down over here somewhere, there's a corresponding one with the flag that when the train rolls a clock across this, it connects. these are two connected together and it raises the flag and it raises the flag over here so that this train coming this way knows that there's a train inside here and it should say wait, i ca n't go in that part of the track because there's a train in there and so then in this particular case, there's probably another one over here that connects that they're all connected. there's my wag thing here that when this train here rolls across this side, it will mark and signal all the other ones that the train is gone from that particular set of track and that other trains can now roll on the track, ok. despite the fact that this focus in that great. this is in the train world called a semaphore. it's a signaling. it's a track signaling mechanism. ok, right. so we'll see that play factorial. you probably use these like crazy if you're getting into the training section. sorry, video games trains itself."
"""OpSys_Threads_Transcript.txt""","there's my wag thing here that when this train here rolls across this side, it will mark and signal all the other ones that the train is gone from that particular set of track and that other trains can now roll on the track, ok. despite the fact that this focus in that great. this is in the train world called a semaphore. it's a signaling. it's a track signaling mechanism. ok, right. so we'll see that play factorial. you probably use these like crazy if you're getting into the training section. sorry, video games trains itself. that's semaphore, so a train goes across here. we know that in this particular section of track, it is critical that no other train enter that section of track. so what i did there anyway, and as a result we wanna train comes across this. it signals all the other flags. raise your flag. any other train that could potentially come in here says hold on. i got ta wait because this guy's coming through. it's gon na go on this section of track. mark this line. it's gon na play the thing and signal all other trains. yeah, somebody can go in this section of track now because it's safe do so. ok, somewhat. this is kind of like a data structure object that the operating system creates. now, going back operating system world, right, so here's my caution. clear signal or some of our in trains, right? but relating it now code wise, the idea here is the operating system says you wanna have a signaling mechanism between your threats, right? you've got a critical section that you want only allow one, or maybe there's a situation where you wanna allow two in you wanna limit the number of threads that execute in a critical section. no. what you could do is create an object that the operating system is going manage for all of our threads. all of a sudden of them, and it has two things, a sum of four is a pretty cool thing. it's a variable that's managed by our by the operating system. it's like that's weird and we work with that before. and the the answer is yes, file descriptors are kind of like variables that are controlled by the operating system. the operating system controls the contents of the file, whether it be a pipe or whatever that's backing it, or an actual named file, and the file system, and it gives us a handle a way reference that object."
"""OpSys_Threads_Transcript.txt""","all of a sudden of them, and it has two things, a sum of four is a pretty cool thing. it's a variable that's managed by our by the operating system. it's like that's weird and we work with that before. and the the answer is yes, file descriptors are kind of like variables that are controlled by the operating system. the operating system controls the contents of the file, whether it be a pipe or whatever that's backing it, or an actual named file, and the file system, and it gives us a handle a way reference that object. but other than that, the operating system is managing that object for us. some of four is the same idea. we create a semaphore and the operating system is gon na hold on this object for us and give us a handle it. all of our threads will share access that handle, and then that object with inside the operating system world consists of two things, a number and a waiting queue. so what will happen is we give the number of the summer for an initial value 6/2. it's a number. ok. the operating system gives us two operations that we can perform against the sum of four. we can signal it or we can wait. the essentially the same as in my picture coming across this side or this side, we can signal a semaphore or wait. when we wait on a semaphore, the operating system will decrement the count by one. ok, this is just the way it works ok when the count becomes zero, the operating system says the count is 0. you as a thread need wait and it says i'm going hold you off of the ready list or and put you on a waiting queue. i will change your thread state inside your thread control block. remember now we're using thread control blocks for thread for state, not process control blocks. your set your state waiting and you wo n't be able run. if another thread signals a semaphore. what that's going do is it will increment the count by one check see if a thread is waiting and the wait queue, and if it is, it will take the thread off the waiting queue, change its state back ready and let it be added the list of of processes that are ready run. remember back our process state for thread state. makes sense? so if the semaphore has an initial value of 1. right. so if our summer four, we create a semaphore with an initial value of 1 and we have two threads."
"""OpSys_Threads_Transcript.txt""","what that's going do is it will increment the count by one check see if a thread is waiting and the wait queue, and if it is, it will take the thread off the waiting queue, change its state back ready and let it be added the list of of processes that are ready run. remember back our process state for thread state. makes sense? so if the semaphore has an initial value of 1. right. so if our summer four, we create a semaphore with an initial value of 1 and we have two threads. thread one and thread red 2. and we have a critical section of code. what's gon na happen is thread one and thread two will both be executing concurrently. ok. so we also have a waiting queue. thread one. at this point, we'll execute a weight and it will say i would like wait and get access this semaphore. that weight. well, send a signal. the operating system, it will change this value zero. the operating system will say great. you get keep going because the value was greater than zero when we called the weight, this thread gets go this thread here in the same code. issues await that weight. the operating system says ah, the value is 0. you tried do a wait. you're not allowed keep going. i'm gon na put you on the queue. so in this case thread 2 gets set in the waiting queue here for this summer form. thread one gets keep running. thread two is stuck there. it does not get go. finally, thread one when it's done with the critical section, can issue a signal. that signal. we'll say ha, i'm going increment this one and it will release this thread. this guy gets keep going and now this thread over here thread 2 because the value is now one, it's weight will allow be allowed continue and actually re execute. so it's almost like a signal handler. it will get continue executing where it left off. as a result, it's going thread two will change this value be 0, and it's gon na continue on. finally, it will signal the thread the signal the semaphore. this value will become one. and then both threads will continue on the result of doing that means only one thread does n't execute in between these lines and switched out at the same time. i had a time at the same time, no one will be allowed run at the same time. questions. yeah. what time is it?"
"""OpSys_Threads_Transcript.txt""","as a result, it's going thread two will change this value be 0, and it's gon na continue on. finally, it will signal the thread the signal the semaphore. this value will become one. and then both threads will continue on the result of doing that means only one thread does n't execute in between these lines and switched out at the same time. i had a time at the same time, no one will be allowed run at the same time. questions. yeah. what time is it? 146 so. let's see here. where am i at? let's look at this, ok? you know what? why do n't we stop there? i know it's weird. i know it's early, but the next step is go through an example and i think it's gon na take me longer than 3 minutes do that, so we'll stop here and then we will continue on with an example next time. lembke, james stopped transcription"
"""OpSys_Understanding_Pipes_Transcript.txt""","meeting in _ general_-20240226_130228 - meeting recording february 26, 2024, 7:02pm 48 m 17s lembke, james started transcription lembke, james 0:09 hello. hello. all right. so operating systems, so announcements for the week, week seven, we're gon na talk more about interprocess communication. i hope finish that this week and so this week is gon na be about message queues and shared memory and then next week we're going get into concurrency and threads is, is a wonderfully fun topic. so please friday on file descriptors and pipes stuff we talked about last week. so again, in paper in class, same as in the past and the other nodes that i want make is umm i i wo n't be able be at open forum on friday. for those of you that that like come, there is a faculty candidate that's coming on campus and he is giving his demo lecture. so that being said, please come the demo lecture. it's in total 110 from 11 noon on friday, so come and evaluate the the candidate that we'd love have everybody, whether they be students or faculty or whatever or, you know, bring your friends this as well. so one of computer science, our engineering or something else. now these are the potential people that might be teaching future students, so i'd like get a good evaluation of that. so that's fine. so i do n't have any new notes yet, because, well, we're gon na continue on the interprocess communication stuff. i do n't know more examples yet because we have written them yet and so we'll just dive into this. so what i want do today is i got one more example with pipes and then i wanna move on and talk about the next. or not dumb, but another interprocess communication mechanism has its advantages and disadvantages. and they'll just keep going through these so. pipes. let's go back the notes here. the work through file descriptors we work through pipes, pipes of these two sort of and like the operating system is creating the file descriptors for us, but we sort of beat this one death and the example that we got on friday was talking about this idea of exec and how we knew that file descriptors. and you guys said this on your quiz. i love it, man. i smiled every single time i saw this. a lot of you wrote that the you know, build descriptors are shared between parent and child, but nothing else is."
"""OpSys_Understanding_Pipes_Transcript.txt""","the work through file descriptors we work through pipes, pipes of these two sort of and like the operating system is creating the file descriptors for us, but we sort of beat this one death and the example that we got on friday was talking about this idea of exec and how we knew that file descriptors. and you guys said this on your quiz. i love it, man. i smiled every single time i saw this. a lot of you wrote that the you know, build descriptors are shared between parent and child, but nothing else is. i talked about right with fork and out the operating system does with fork and copies memory, yet they all that stuff, right? but then we talked about exact and we said that our i said that file descriptors remained open across an exec, just like file descriptors are shared with a fork, they are remain open across the big cross exec. so this allows us do something initially is kind of weird, but i refer it as a fd fake out what we can fake out a process make it think that standard in and standard out comes from where it expects it be, the keyboard or the terminal. but really it's from a file and i call it fd fake out the actual like technical documentation calls it file input and output redirection after you take out really. so in this example we created, i created a file descriptor for inputs and a file descriptor for output, and by utilizing the dupe system call when we forked, the child inherits the two input, the two file descriptors and. as a result, here we can use dupe the tape. one of the file descriptors and copy it over the top of another one. so we're essentially copying the input file descriptor over the top of standard input. so now when this child tries read from standard input expecting input from the keyboard from the user, it instead comes from the file single only with output instead of writing standard out or system dot out the terminal that gets redirected this output file descriptor. and once we do the do, we can close them because we've duplicated the billing script there and then we do an exec. that change remains after the exec and so the execute cat, just reads from standard input and then writes it standard output. we read it from the file and we write it another file, right? and then the parent just waits in returns. let me under this example, or at least the derivative of this example."
"""OpSys_Understanding_Pipes_Transcript.txt""","so now when this child tries read from standard input expecting input from the keyboard from the user, it instead comes from the file single only with output instead of writing standard out or system dot out the terminal that gets redirected this output file descriptor. and once we do the do, we can close them because we've duplicated the billing script there and then we do an exec. that change remains after the exec and so the execute cat, just reads from standard input and then writes it standard output. we read it from the file and we write it another file, right? and then the parent just waits in returns. let me under this example, or at least the derivative of this example. ok, so with this and my last example of pipes is useful utilize for the next programming project is these are just file descriptors and i said this a billion times. hopefully that file descriptors are a number. ah, i love it. great, right? it's a number. so whether it be something that we explicitly open or something that we pipe, this is just a number. and so when a child or another process leaves a file descriptor in place after indication of exec, that file descriptor is just a number and it can be a file numbers open explicitly with open or a pipe. so i want show you how we can do this file descriptor fake out or input redirection using a pipe and not using a named file. right. so let's do that and then we'll move on the next. ah ipc mechanism. let's call it this fork exec pipe. and because i want save a little bit of time, let's just do. copy all of my header files that we use have control for open you and id for a lot of system calls, sdo for printf, errno for the error number, string for doing str error, stdlib for exiting early and says wait for doing the wait system call. ok. so we're ultimately going fork. so let's set that up. and that's grab hold of our. code here for checking the return code from fork. we'll get rid of this could not fork, so this is the child. otherwise this is the parent ok and we got make sure we have a return statement in there. so what i'm going do here is i'm going have a child execute a command with the exact, but the child instead of getting its input from standard input, it's going get its input from the pipe."
"""OpSys_Understanding_Pipes_Transcript.txt""","so let's set that up. and that's grab hold of our. code here for checking the return code from fork. we'll get rid of this could not fork, so this is the child. otherwise this is the parent ok and we got make sure we have a return statement in there. so what i'm going do here is i'm going have a child execute a command with the exact, but the child instead of getting its input from standard input, it's going get its input from the pipe. so i'm gon na make a pipe that allows the parent send data the child's. ok, we've already done that. so do that, we need create our array, we'll call it two child is 2 integers for the file descriptors we're gon na pipe, and we're going check if that failed. pipe failed. why? we'll figure it out from the air. null. otherwise, we're going exit. if we fail, that's good. now that we have this pipe is open. do n't forget close if we have a failure like in fork, we're gon na have make sure we close both ends of the pipe where we got two ends. the read end and the right end because remember the read end is index. zero. the right index is index one, yeah. so we close those good. we also need make sure. that way, and the parent has done, it also closes those. the child will worry about in a second because we're going use dupe and do a bunch of other stuff so right? well, they so far creating a pipe. alright, so now the child is going do just like what it did in ft facon. it's gon na close, but not in, say close, but it's going do the read end of the pipe over the top or the other way around. it's going take standard input and duplicate the read end of the pipe over the top of standard input, so that instead of getting its input from the keyboard, it's gon na get its input from the read and of the pipe, right? so what we did over here with apd fake out was we duped it. and what's interesting about this is by looking at this line of code and isolation, this is just a number. it could be the end of a of a pipe. it could be a bio descriptor."
"""OpSys_Understanding_Pipes_Transcript.txt""","it's going take standard input and duplicate the read end of the pipe over the top of standard input, so that instead of getting its input from the keyboard, it's gon na get its input from the read and of the pipe, right? so what we did over here with apd fake out was we duped it. and what's interesting about this is by looking at this line of code and isolation, this is just a number. it could be the end of a of a pipe. it could be a bio descriptor. in this case, it happens be a file descriptor that we created with open, but it's just a file descriptor. duke does n't care if it's a pipe or not. so with this i can just copy this so. and just say child reads from the read end of the pipe. standard those ddn or system that in from the read end of the pipe. so in this case, we're gon na dupe 2 uh. what is the read end of the pipe we just talked about that is index zero over std in file node. ok, now we're going close this cause the child does n't need the pipe anymore because it's been duplicated over the top of standard input. and child does not right the pipe so it does n't need the right end. close it. it's not needed. right. parent so parent does not read from the pipe. stories are going close that immediately now in here do parent writes the pipe somewhere. we got ta figure that out. but now the child has set up everything it needs, right? we've got with the pipe. we've recently have two opens. we need two clothes. that's good. now the child can exactly. and i'll exec cap for example, just so that it's a nice. that's a nice command, but it just it's simple. it reads from standard input and writes standard output. so what this will do is now normally the cat will read from whatever the user types, but here it's gon na read from the read end of the pipe and that's gon na be the parents gon na write the pipe and the child should like that out. ok. thought you want write the child, so it's this is no longer a do because we're actually doing it, we write. we're gon na have the parent right the right end of the pipe, is two child. we want write hello child. 1234567891011 we'll do at 12."
"""OpSys_Understanding_Pipes_Transcript.txt""","so what this will do is now normally the cat will read from whatever the user types, but here it's gon na read from the read end of the pipe and that's gon na be the parents gon na write the pipe and the child should like that out. ok. thought you want write the child, so it's this is no longer a do because we're actually doing it, we write. we're gon na have the parent right the right end of the pipe, is two child. we want write hello child. 1234567891011 we'll do at 12. ok, 12 bytes will write the child. ok. so we're actually should probably check for. exact failed. right. and if exec succeeds well, we should n't get here because the child will be gone. so well, the child process will still exist, but it wo n't be executing this code. tomorrow the executing cat right? i'm good. i've been saying anything. i do n't think so. we'll see. we'll save it works. yep. i'll probably have a compile error. at least no wow. and so now let's run this old child. so why did it get printed out of there? it's tricky. oh, i know. why did n't print out down here and it looks like maybe something is sitting there waiting for forever and not running good. it's it's subtle, but the the reason is and i run into this problem all the time. is the parent bones 3 down in the pipe? wrote the child. close this and then kept going and return. the parent did n't wait for the child finish, so the parent immediately returned back the invoking process, was the shell, and so the shell printed out the shell prompt, and then the child brand and it printed out what it got from the parent. so there was these processes that were kind of like both running more or less at the same time and the operating system had decide who run and it chose run the parent 1st. and that's because they did n't wait. what i probably should have done is after the parent wrote the child wrote the child, it probably should have closed this and then done wait. that way, now the parent rights the child, it waits for the child and then after the child runs, are then calls it print, then it will return. that makes sense with the weight. now we get held child printed out separately. the boys are good."
"""OpSys_Understanding_Pipes_Transcript.txt""","so there was these processes that were kind of like both running more or less at the same time and the operating system had decide who run and it chose run the parent 1st. and that's because they did n't wait. what i probably should have done is after the parent wrote the child wrote the child, it probably should have closed this and then done wait. that way, now the parent rights the child, it waits for the child and then after the child runs, are then calls it print, then it will return. that makes sense with the weight. now we get held child printed out separately. the boys are good. ok, pipes, not a whole lot different than the fd fake out. it is really the same thing we're doing file input redirection from the pipe, and now we're explicitly writing something here. ok. so couple of things here. first off, really one big one. notice that i put the weight here. what does weight do? i remember what weight does. yeah, waits for the child determining. ok, so in this case the pair will wait, is nice because now i give this nice fancy output is formatted a little bit nicer like. what it's calls do. but think of like the pipes with flapper valves, right? that close closes the ends of the pipes right when that little flapper valve. if it was a a file descriptor that referred an actual file in the file system, that sort of releases the processes sort of control and the offsets operating system. i am no longer using this file. feel free delete it if somebody asks delete it, right? let's close here. says i'm not using this file anymore or this this file descriptor on the pipe pulls it close that flapper valve. so if everybody closes the right end of the pipe, there's no way that anybody could send anymore data down the pipe. so the operating system knows that there's no more data, right? what does that do? if i move the clothes after the wait. i'm gon na see any concern with us. there's a subtle concern that i otherwise i would n't have done it. but i want point it out. and that's the deal with the way cat works. and i know we have n't really looked at the man page or whatever for cat, but what what cat does is it reads from standard input we redirected come from the pipe, but it will keep reading until it sees the end of file."
"""OpSys_Understanding_Pipes_Transcript.txt""","if i move the clothes after the wait. i'm gon na see any concern with us. there's a subtle concern that i otherwise i would n't have done it. but i want point it out. and that's the deal with the way cat works. and i know we have n't really looked at the man page or whatever for cat, but what what cat does is it reads from standard input we redirected come from the pipe, but it will keep reading until it sees the end of file. and you might say, well, that's weird, because if it's reading from standard input, how does a user like? what is the end of file the users typing on the keyboard hitting a return character is n't the end of file, that's just a return character. if it's an actual real physical file. there's an end of file there because files are only so big text file. it's only so big it's not of infinite size. a pipe we can kind of consider be of infinite size. it's not really. it's limited by the memory on our machine, but we think about a hose and it's like well, when does the water gon na stop? well, that could just be more water now. there's not an infinite amount of water in the world, but we could keep piping a lot of water through them. had when it comes user input, we'll keep reading until it sees undo file. we can indicate end of file on the keyboard by hitting control v just a special key sequence where we can send the end of file character say operating system. i am done writing that will cost cat stop. but when it comes a pipe, the only way for the operating system tell. the pipe itself that there's no more data in the pipe is when everybody closes flapper valves on the end of the pipe. if there's any end of right end, open, the operating system says. i do n't know. there might be more data coming. i only know that there's more data coming when everybody that's holding a reference this pipe either dies, terminates, or closes pipe, they're in. so in this case, what will happen? what should happen, and i might have eat my words if this does n't happen? yes. we have this pipe. we have parent and we have child. so we have the right end. then we have the reader. we have parents and we have child, right, those two processes."
"""OpSys_Understanding_Pipes_Transcript.txt""","there might be more data coming. i only know that there's more data coming when everybody that's holding a reference this pipe either dies, terminates, or closes pipe, they're in. so in this case, what will happen? what should happen, and i might have eat my words if this does n't happen? yes. we have this pipe. we have parent and we have child. so we have the right end. then we have the reader. we have parents and we have child, right, those two processes. both parent and child have a reference the right end, and parent and child have a reference the reading. in the code, the parent closed the read end. it's like i'm not using the read end the child closed the right end right, and then the child ultimately did a dupe of the read end and then closed it. that says dupe. i thought the best handwriting, but it did n't do as we write it. ok, now that what happened here. now is the parent. rather, the child then went off and it invoked exec. child went and it did. an exec of cat. that's going read on standard input, is gon na be the read end of the pipe, and it's gon na sit there. keep reading until this end of file. the parent waited. but did n't close standard, did n't close the right end of the pipe, so the child's gon na say. i will. maybe there's still more data the operating systems like, yeah, there could be more data because there's this lagging, right and that's open, but the parent says i'm waiting for the child die and the child saying parent, i'm waiting for more data and the parent says i'm waiting for you finish. and the child says i'm waiting for more data. two are in this is what's referred as a state of deadlock, where one person is waiting for somebody else and the other person is waiting for that other person. and we're just sitting there, looking at each other going. are you gon na you gon na do something? but nobody's gon na do anything, ok? and by recompile this and rerun it. sure enough, the child got hello child, but the parents waiting and the child's waiting. and there's no data and i could enter as much as i want, and there's it's essentially stuck in deadlock."
"""OpSys_Understanding_Pipes_Transcript.txt""","two are in this is what's referred as a state of deadlock, where one person is waiting for somebody else and the other person is waiting for that other person. and we're just sitting there, looking at each other going. are you gon na you gon na do something? but nobody's gon na do anything, ok? and by recompile this and rerun it. sure enough, the child got hello child, but the parents waiting and the child's waiting. and there's no data and i could enter as much as i want, and there's it's essentially stuck in deadlock. so it's important i'm in control c terminate this that when we are done using our file descriptors, whether it be pipes or any other file descriptor that we close it so that we tell the operating system we are done, that there's no more data. ok. questions. ok, so i'm out. that's all i got left with pipes. i think we've done enough of that. so what's the next topic? well, no, i'm not quite done with pipes. let's go back over here. this is the last thing i wanna mention about parties, is what's gon na motivate the next interprocess communication mechanism. and it's this right here. pipes are file descriptors. file descriptors you read and write right, and when you write a file descriptor or you read from a file descriptor, you read bytes, right? that's what the man page says. that's what the actual operating system says. you wanna write data? give me bytes. it's unformatted, unstructured data. it's a stream. it's water. it's a there's water going down the pipe. can you indicate where? like there's a difference. there's not like here is 1 gallon now it is just a stream. do i know when i've reached the gallon? do i know how indicate what that is? it's just data, it's just water. so if we need format this data somehow, right? say i want send, not necessarily a stream of bytes or a whole bunch of characters. but what if i wanna send you a structure? a linked list node for example. we have agree essentially as what that structure is. it's kind of like a network protocol, right? we have a stream of data coming in off the network. once it's format, the network card does n't know just a bunch of bits and bytes."
"""OpSys_Understanding_Pipes_Transcript.txt""","it's just data, it's just water. so if we need format this data somehow, right? say i want send, not necessarily a stream of bytes or a whole bunch of characters. but what if i wanna send you a structure? a linked list node for example. we have agree essentially as what that structure is. it's kind of like a network protocol, right? we have a stream of data coming in off the network. once it's format, the network card does n't know just a bunch of bits and bytes. it's up the application know how that's formatted and so these applications with protocol have agreement. a protocol as what that data is formatted as had a nice and that makes pipes really simple, but it's also not nice because if i want get a message, i have know how much data there is and have an agreement on that. so i would in a way, kind of like have a mechanism where the data can be sort of more structured now. will i always want use that? you know, maybe, maybe not. umm, but it kind of nice, motivates maybe a lane motivation. the next enterprises communication mechanism, is message passing. let's draw a picture of message passing, and then we'll do an example and then will be done for the day. those message passing work. kind of like a pipe. but instead of a pipe. we have my finger, my mouse pointer, but you. what's a queue? they spell it right. i never spell queue. you right, q right? i've always felt like i add too many us&e or not enough. i write que sometimes, but that's like spanish. for what? ok, ok. so what's a queue? as what sorry priority list, ok. a first in first out. i like those words. it's kind of hard in a way define what that is. some people might say what's a queue? it's a line might line up at the door, queue up at the door, trying everything in british does say queue it making queue alright. what's a queue? well, in a message passing environment for q. is essentially a list. it's a bunch of places put stuff, but we put stuff on one end of the queue and we pull things off the other end of the queue, right? so you might say we nq things and we dq things. we have the central idea of a line, a line up."
"""OpSys_Understanding_Pipes_Transcript.txt""","it's a line might line up at the door, queue up at the door, trying everything in british does say queue it making queue alright. what's a queue? well, in a message passing environment for q. is essentially a list. it's a bunch of places put stuff, but we put stuff on one end of the queue and we pull things off the other end of the queue, right? so you might say we nq things and we dq things. we have the central idea of a line, a line up. it's a fifo, first in, first out. ok, you can look at that and see it and say, great, doctor lanky, we understand what queues are, but you know you just grow, draw that drew drew, it's not a whole lot different than a pipe. and i say yes, it is not a whole lot different than a pipe. the difference between a message queue and a pipe in linux is a couple of things. whether not say linux, but in posix hughes. are persistent. whereas hypes are anonymous and temporary. they are limited. incapacity. i'm only going be able put so many things on a queue. and the entries. are structured. when we create a queue, we're gon na tell the operating system how big each entry is and the operating system is gon na hold us that. so we will say operating system, i'd like you create a queue that can hold 100 elements and each of those elements are going be 10 bytes long every single time we send something on the queue, we have send something that's 10 bytes long and if we have more than 100 elements, the operating system is gon na do some stuff and it's gon na have make a decision. and you could say, ok, that seems like a weird, weird way say it. the happening system is gon na do some stuff. yeah. with the pipe we have sort of expected behavior or default behavior and that is would n't we read from a pipe and there's no data there? we block. we pretty much can always write a python. there is some restrictions that we ca n't write a pipe in that if we just run out of memory, but if we run out of memory, our system is at a whole lot of other problems. ah, but that's really the big one is that pipes are blocking. we try read from it and there's no data there."
"""OpSys_Understanding_Pipes_Transcript.txt""","with the pipe we have sort of expected behavior or default behavior and that is would n't we read from a pipe and there's no data there? we block. we pretty much can always write a python. there is some restrictions that we ca n't write a pipe in that if we just run out of memory, but if we run out of memory, our system is at a whole lot of other problems. ah, but that's really the big one is that pipes are blocking. we try read from it and there's no data there. we block if we try read from it and there is data there we get while mirror much data is there with a queue because now we have this idea of entries that are structured in a size and a queue that has so many we can create a queue that's like this. 1234567 spots ok and say 7 spots and each spot is maybe 10 bytes. every message here must be 10 bytes and we are always going read or write 10 bytes. message. you actually does n't call it read and write. it actually calls it send and receive because we're sending and receiving a message of a specific size. ok. so that's terminology. everybody with me so far on the terminology. ok, awesome. so now we have a couple of things think about. what if we receive? umm on an empty queue we can receive on a non empty queue where there's at least one message there we can send a full queue or we can send a non bulk queue. we have these sort of four possibilities, right? because the queue. can either be empty or fall or something in the middle, or it's neither empty nor fall, and we can read or or. or send or receive because we have this distinction of a limited capacity now and entries that are structured, our q can be full. like i said, i'm pipe could be fall also, but for all intensive purposes we can write as much data as we want it. it can be empty. in that case, we block. so now that we have these options here, read out an empty queue. do you want do? you want block and say, well, you want receive from an empty queue, so we're gon na follow the same behavior as a pipe, and you're just gon na wait. one other option is that. we got the operating system return an error saying you wanted receive a message and there's nothing there. so i got nothing for you."
"""OpSys_Understanding_Pipes_Transcript.txt""","it can be empty. in that case, we block. so now that we have these options here, read out an empty queue. do you want do? you want block and say, well, you want receive from an empty queue, so we're gon na follow the same behavior as a pipe, and you're just gon na wait. one other option is that. we got the operating system return an error saying you wanted receive a message and there's nothing there. so i got nothing for you. i'm just gon na return an error unless you keep going. so in all of these cases, we actually have an option. if we receive from an empty queue, maybe we block or maybe we do n't block. maybe we return have the operating system return an error. what is the best? use the corporate answer at the fence. depends on what you're doing, right? if i was for example implementing my message queue and using a message queue rather for something like an email system. if i want do a receive for all of my mail right, i want check my mail. how often do you check your email? ok, emails came in old. they maybe do n't check your email very often. i checked my email all the time constantly and hitting that refresh button right, the email used a blocking receive. my email program would sit there and spin until somebody sent me a message. does n't it make a whole lot of sense? does it now? maybe it does, but i do n't think it does. i like my email program check and see if there's mail there and if there is n't, i want it just say you have no new mail, right? and that case i wanted use a nonblocking receipt. i wanted say check see if there's any mail on my inbox queue. if there is, pull it off, put it in my inbox and let me see it. otherwise, just keep going and wait for me hit the refresh button, right? that's one reason reason. maybe i would wanna have a non blocking blocking well if i'm specifically waiting for somebody give me a notification or i just got, i got nothing else do except for wait, right? then maybe i want use barking. ok. receive anon. empty. well, i wanna get it. if it's there, give it me. there's no reason block if if there's a message there. when i do receive, sam got a full queue again."
"""OpSys_Understanding_Pipes_Transcript.txt""","otherwise, just keep going and wait for me hit the refresh button, right? that's one reason reason. maybe i would wanna have a non blocking blocking well if i'm specifically waiting for somebody give me a notification or i just got, i got nothing else do except for wait, right? then maybe i want use barking. ok. receive anon. empty. well, i wanna get it. if it's there, give it me. there's no reason block if if there's a message there. when i do receive, sam got a full queue again. we have this idea. do we block or do we return error? where are you? operate answer at the fence. depends on what your application is. there might be a situation where i wanna send a message and i really want that message. just wait till this room for it. it will only be there will be room for it. ultimately, when somebody does n't receive but kind of on the application is maybe i wanna say ohh just return immediately. ok, so we've got a couple of options when it comes sending and receiving iq and that's because of this idea that a queue can be full. ok with me. questions. yeah. what happens the data when you send? if you work like, return an error on a7 fold. where would it go? well, ultimately it gets down an implementation specific thing, right? when we look at posix cubes, is what we're learning in this class, the queue requires you pass a pointer the structure that contains the data that's being set, so that data needs be stored in the sending process. so that's going be either on the heap or stack or in global data. most likely right somewhere in that process is memory. if you have your queue set up in politics so that is a, suddenly they nonblocking 7. it's going return an error immediately that data will not go on the queue, but it will remain in memory on the processes and the process. that being said, even if it succeeds, what the operating system was gon na do, it's gon na copy the message from the processes memory into the queue. the queue is we'll find as actually going be an entity that will exist in the file system, and it's going persist. and now everything that there is going store that it's gon na copy that into the queue. so we'll now that exists in two places, one in the process and in the queue."
"""OpSys_Understanding_Pipes_Transcript.txt""","it's going return an error immediately that data will not go on the queue, but it will remain in memory on the processes and the process. that being said, even if it succeeds, what the operating system was gon na do, it's gon na copy the message from the processes memory into the queue. the queue is we'll find as actually going be an entity that will exist in the file system, and it's going persist. and now everything that there is going store that it's gon na copy that into the queue. so we'll now that exists in two places, one in the process and in the queue. then when the reader receives that message, it's gon na copy it out of the queue into the receiving process of memory, and so they'll have that there. and then when it receives it, it will pull it and just and remove it from the. that makes sense. ok. of the questions. alright, so let's go back the notes and then we'll do an example. also excuse. do n't i forget anything we can read? we can write. they have size, they have structure, limited in size, cues, queued message queues live beyond the life of the process. so that's kind of unique. they're persistent and there are a lot of options on how send and receive blocking, nonblocking and so on. ok, something i got over there. incidentally, i put this link on here. there's a message queue overview kind of talks about all of these things in a posix world, we can link it there. otherwise you can do man mq underscore overview and you can get that as well on your linux system. if you do that, it brings up a page like this talks about all the different functions that are available that you can create a queue you can send with an mq send. these are gon na look and kind of follow a theme. you've got empty receive mq clothes. there's an nq unlink. remember that queues are persistent and so if we want tell the operating system that we no longer need this queue, we have explicitly delete it. and there's a couple of attributes setting things. umm, the reason why i'm pulling up this page here is that because queues have a name, i'm sorry because he's a persistent they must have a name and i'm posix is kind of weird, but it's just you have get used it."
"""OpSys_Understanding_Pipes_Transcript.txt""","you've got empty receive mq clothes. there's an nq unlink. remember that queues are persistent and so if we want tell the operating system that we no longer need this queue, we have explicitly delete it. and there's a couple of attributes setting things. umm, the reason why i'm pulling up this page here is that because queues have a name, i'm sorry because he's a persistent they must have a name and i'm posix is kind of weird, but it's just you have get used it. that name must start with a slash and then have a single set of alphanumeric characters. and it can be up 255 characters long for the name. this is the name or the value that we're gon na refer the queue whenever we want use it. we open it with mq open, we send and receive with nq send and receive. we close it with mq close. the other sort of big thing i want mention here is that there's this sentence right here. i'll message you descriptor. so we'll find that when we open a queue, this returns a message queue descriptor. it's like a file descriptor, but it's not a file descriptor. remember, file descriptors work with streams of data, individual bytes. message queues work with messages, so we need a way refer the message queue and we use a message queue descriptor, not the file descriptor, because a message queue is a queue, not file. makes sense. ok, so we have a message here descriptor, not a file descriptor. but down here, a message you descriptor is a reference an open message you. ok, bring you back after a fork. a child inherits copies of its parents message queue descriptors. so the light was filed. descriptors, parenting, child sharefile, descriptors, parent and child also share message queue descriptors. but they so message your descriptors do n't have a file position pointer in it, so we do n't have worry about that. so that's kind of nice, but they do allow us have a parent open a queue fork and the child will inherit the reference that queue. it also inherits the responsibility close that queue when it's done, but because queues are persistent after we're done with parent and child, those cues still exist, so it's really cool about a queue is just like where the file in the file system."
"""OpSys_Understanding_Pipes_Transcript.txt""","but they so message your descriptors do n't have a file position pointer in it, so we do n't have worry about that. so that's kind of nice, but they do allow us have a parent open a queue fork and the child will inherit the reference that queue. it also inherits the responsibility close that queue when it's done, but because queues are persistent after we're done with parent and child, those cues still exist, so it's really cool about a queue is just like where the file in the file system. when we send a message a queue, if nobody receives it, the operating system holds on it for as long as we wanted until we explicitly remove it. so it's kind of like a file in the data persists, so it's something you can take advantage of. that's why i like use the example of an email system. if i send something on a queue, it sticks around for forever until it's deleted. ok, so let's take a look at mq open. and we'll find that mq open has a similar idea the regular file system open in that we open a name and we've got flags we specify. or how we are going what the purpose of this queue is if we're only gon na receive messages on this queue, we opened it for reading. if we wanna send and receive then we open it for reading and writing, and if we only are gon na send we can open it for writing. so the same idea with these flags, right? read only, write only or reading and writing. there's a couple of additional attributes this is given and required because mq open has the option create if it does n't exist. if we only want open a queue that exists, we use this first version. if we ever wanna open up a queue and have the operating system created, if it does n't exist, we have specify the queue attributes. specifically, how many slots are in the queue and how big each of those slots are, right? how big a message is going be and how many messages we want the key hold right as well as this mode, specifies permissions, who has the ability send and receive on this queue? we can limit it say only certain users have the ability receive or send for security reasons. ok. alright, let's do an example. and we might not finish it. we'll give it a good start. mq demo. so what do i need? i need a lot of stuff."
"""OpSys_Understanding_Pipes_Transcript.txt""","specifically, how many slots are in the queue and how big each of those slots are, right? how big a message is going be and how many messages we want the key hold right as well as this mode, specifies permissions, who has the ability send and receive on this queue? we can limit it say only certain users have the ability receive or send for security reasons. ok. alright, let's do an example. and we might not finish it. we'll give it a good start. mq demo. so what do i need? i need a lot of stuff. let's just do this. what else do i need? i need include mq dot h. get all the queue calls. so i need call i'm q open. i'm going use this flavor because i wanna create it. it does n't exist because the queue i'm creating is n't going exist, so i need do this so m shoot. what does the name of this mqd mqd descriptor? mike, you equals mq open and i'm gon na open ever got a good name going start with slash and this. you enough money and then we need flags. ohh we'll open it for reading and writing cause well, i'll have a parent send a message and a child. uh. read it. and we're gon na do permissions. i will create the with the permissions so that everybody can read and write it. let's uh. let's see. mode mode mode mode. uh, because i have go and look at open because i got ta find the mode bits. they are. we're going create it so that the user has read and write permissions. and right permissions. and then we got create the attributes. so let's go back mq open and figure out how these attributes are formatted. and it says alright, here's what the attribute struct looks like. so it's a structure that the binding this header file and it has four values right? thank you. flags ignored for open. there is a function out there called. i think it's called mq attributes or git attributes where we can ask the operating system for what the attributes of an existing mq message queue is are and these values are this same attribute structure is used for that. so some of these fields are n't used by open the operating system, just totally ignores them. so we have pay that attention down. so the flags are ignored by open. here we have the max number of messages right?"
"""OpSys_Understanding_Pipes_Transcript.txt""","flags ignored for open. there is a function out there called. i think it's called mq attributes or git attributes where we can ask the operating system for what the attributes of an existing mq message queue is are and these values are this same attribute structure is used for that. so some of these fields are n't used by open the operating system, just totally ignores them. so we have pay that attention down. so the flags are ignored by open. here we have the max number of messages right? we need that the max message size we need that and then the current number of messages in the queue. well, that's ignored. that's where the git attributes. so we do need create this, but these two are n't used these the two we need specify. so let's do that. and i've always forget the name of the thing mq attributes. just copy that over there. my attributes, let's just call it q attributes. ok, so q dot ohh we need specify the max messages. uh, i do n't know 10. we'll have it store 10 messages and then the message size, huh? how big is message? well, where the pipe it was just bites. so we did n't have a message. so now we're working with a message queue. we actually have have a message for these guys work with. so what's cool about this is that we can just create a structure, but we actually have define that. so where it probably better off actually make a message. let's make a message. what are you going send? let's send 2 integers. and maybe uh. maybe some text so there's a message it's structured, it has data associated with it. we have got some set size. so now when it comes the size of the message, i know this it's i do n't know. i mean, i do know how big that is, but i do n't wanna, like, pretend know how big that is. this is the size of this. except i'd like spend spout and spell struct right? so now. that's going be my attributes and i will past that open. it's what we got. we have a message that we're gon na send back and forth between her and child. we've got the attributes for the queue that's gon na be receiving these and sending these messages, and then we're gon na open the queue. you're not cute descriptor back."
"""OpSys_Understanding_Pipes_Transcript.txt""","i mean, i do know how big that is, but i do n't wanna, like, pretend know how big that is. this is the size of this. except i'd like spend spout and spell struct right? so now. that's going be my attributes and i will past that open. it's what we got. we have a message that we're gon na send back and forth between her and child. we've got the attributes for the queue that's gon na be receiving these and sending these messages, and then we're gon na open the queue. you're not cute descriptor back. it's going be called this queue. we're gon na open it for reading and writing. if it does n't exist, we're going have the operating system created with user read and write permissions. that's what this r and wr are and w and it's going use these attributes, is 10 messages, is the size of our message. the last thing i have do before i run out of time because i just did is add this says create the message queue if it does not exist. i have add that this. and then before i returned, let's just make sure i close it. ok, so i'm out of time. so we got ta keep working on this. we got ta work. we got ta send. we got ta receive, but for now it's good enough. is any place stop. so thanks for coming. have a good night. i will see you on thursday. ohp. long time. lembke, james stopped transcription"
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","meeting in _ general_-20240219_130305 - meeting recording february 19, 2024, 7:03pm 48 m 9s lembke, james started transcription lembke, james 0:08 hello. hello. alright, alright. so operating systems isolation and protection abstractions are cool. like i said, examples fork and exec. uh announcements for today. i got we're gon na talk about interprocess communication this week. so as far as announcements is concerned, for course material, we will look quiz on friday, several of you at sporting events has lots of things going on. let me know if you're not able take it on in class on friday. well ohh. and of find another time, we can either take you either take it early, or you can take it next week. using will be on fork and exec. i wo n't ask you, like, write if there's like, if i do ask you write syntax using parking exec, i will give you like a man's page of how write it. i'm not gon na ask you know the parameters, especially exec because exec is that family and so if i say write the call for exec l yeah, i would give you the the man page. so you know what all the parameters are, but i do want you know what goes on under the covers, what the operating system does. four fork and exec, so be prepared answer those types of stuff. i'll be ohh i'd friday. so today we're gon na go in the interprocess communication. these notes are out there. i'm gon na probably get them eventually, but before i get there, i want do some pictures. do some examples and we'll see how far we get so. let's go. a picture. you know what? it might just be better off show this picture. ok so. problem? well, not really a problem. it's only a problem if it's a problem. if i know it's weird, but it is, but we'll just put it this way, right, we'll just call it a situation whether or not it's a problem, we'll let you decide. parent and child processes. remember, we said do n't share anything. well, that's kind of a lie. i'll get that today. they do n't share address space. ok, you can kind of think of it in a way of apparent sharing, something with its child because it's more implicit."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","if i know it's weird, but it is, but we'll just put it this way, right, we'll just call it a situation whether or not it's a problem, we'll let you decide. parent and child processes. remember, we said do n't share anything. well, that's kind of a lie. i'll get that today. they do n't share address space. ok, you can kind of think of it in a way of apparent sharing, something with its child because it's more implicit. i'd like i need think of it that way, but it is kind of true in that the parent shares data with the child going one direction. so if a parent wants give some information its child, it can store it on the edu or in the stack or in some global data somewhere. and then because the child just by nature of fork is a copy of the parent, the child inherits all those values. so in that case the child can get something from the parent, but at the child wants send something the parent. it ca n't really do that, because if it modifies some variable, the parent does n't see it. and we did talk about this a little bit. i did n't show you an example, but i did n't kind of mention it that when the child process exits, it exits with some sort of exit code exit status and it can make an explicit call the exit system call with a number or just return, and that number gives part of its exit status, and then the parent process can. wait for that child finish passing in a pointer the operating system and the operating system will fill in the exit standard from the china. so in that case, the child can kind of send something back the parent, but in a way that's one thing. and it also has only transferred from the child the parent when the child finishes, right? so if the child wants actively communicate with the parent and the child. but sorry if the child wants actively communicate with the parent, they ca n't do that with weight. and the agent said, i think it's a one shot deal, right? so it's just so the thing that i'm trying get at here is. how can parent child communicate like parent can send data the child child ca n't really send anything back the parent except for exit status without an additional sort of mechanism or some additional help. and that's what the point of this week is."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","so if the child wants actively communicate with the parent and the child. but sorry if the child wants actively communicate with the parent, they ca n't do that with weight. and the agent said, i think it's a one shot deal, right? so it's just so the thing that i'm trying get at here is. how can parent child communicate like parent can send data the child child ca n't really send anything back the parent except for exit status without an additional sort of mechanism or some additional help. and that's what the point of this week is. now that we know how create process, we know how create a program or execute a program. creating a program we could run the compiler. we can execute a program with exec. now let's say now that we've got these guys run, how do they talk each other? and how do they work together? stop when it comes something like a chrome tab, i do n't really want them work together. i do n't want them pass my information back and forth, but in other situations. maybe i do. ok, so let's talk about that. so i want take a sidestep here and talk about the file system. ok. because on linux, when we're working with well as in linux but on posix, so speak, when we're working with process communication mechanisms, a lot of them stem around this idea of a file and the file system. and in reality, yes, it is a file in the file system, but ultimately it's actually more of a. we're gon na talk about things that are actually real files, but also things that are kind of like this entity that kind of like lives in the world of the operating system. but is n't actually a real file. it does n't have any backing storage on disk, seems kind of weird, but we'll certainly once we get home will become clearer. but ultimately, here's what i'm getting at here is what is a file, right? you could say what's a file doctor long key? what's a file? these are my notes that i've been driving all the pictures and stuff right and after this class is over, when i'm done with the semester, i will probably just because i like, i like save everything from the point of in a file folder sticking my file cabinet, right, right. ok. but that's a story."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","but ultimately, here's what i'm getting at here is what is a file, right? you could say what's a file doctor long key? what's a file? these are my notes that i've been driving all the pictures and stuff right and after this class is over, when i'm done with the semester, i will probably just because i like, i like save everything from the point of in a file folder sticking my file cabinet, right, right. ok. but that's a story. i mean, whether or not that's true or not, that's what i'm gon na do. you can say this piece of paper is a file, right? and as humans, we sort of adapted the fact that coming from a paper trail, my sister - in - law, she's an underwriter for blue cross blue shield of michigan. they used have all of customers documents in file canvas and when you have go get them, i just have get up out of her desk, walk over there and like, finger through them get stopped, right. all these files and so this idea of storing things on a piece of paper in a file cabinet, has kind of evolved into the world of computers where as a user of the computer i like think of a file as a thing. but i mentioned this before, there is no paper inside my computer. al, i lied. there might be paper inside my computer, but there's nothing i can really get. it's not like it's not like i could pull out a notepad out the side of my computer and write on it and then stick it in the side and have the computer understand what that means. right, files are an abstraction that the operating system creates for us. how that's actually formatted on this? well, we'll learn about that later on, but for now, i want just talk about how we access files and the system calls associated with that, because this theme of using a file descriptor and accessing a file will become important when we get the interprocess communication mechanisms. so in posix, this is what we have. we have an abstraction of a file i like think of it as a piece of paper, but it's just a file you've already looked at files on. on posix, there's six fundamental files. there's the regular file. there's a directory. there is a fifo. there is a socket is one. there is a link and then i'm missing 10."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","well, we'll learn about that later on, but for now, i want just talk about how we access files and the system calls associated with that, because this theme of using a file descriptor and accessing a file will become important when we get the interprocess communication mechanisms. so in posix, this is what we have. we have an abstraction of a file i like think of it as a piece of paper, but it's just a file you've already looked at files on. on posix, there's six fundamental files. there's the regular file. there's a directory. there is a fifo. there is a socket is one. there is a link and then i'm missing 10. there's like ohh devices, there's device specific. and character specific we why i've seven is there seven and this is my mic anyway, so there's so many files in here. most of the files that we work with are are, are, are going work with on this. in this class are just regular ordinary files files that store data, programs, regular files, text files, regular files, microsoft word documents, regular files, images. they're all just regular files directories. they're special files and that files that contain other files. so directories can contain directories, right? directories can contain regular files and so on. links are kind of like shortcuts in windows. then that's and then these typos and these device files are in a way, not really files. they're kind of like abstractions of things that are represented by the operating system. so all of the raw devices, whether it be the mouse, the keyboard, whatever, a represented as a file and the file system that as a system administrator i can go and manipulate those. it's not something you really would do on a regular basis, but we'll talk about how we access those devices as well as vehicles. but as far as regular files files are concerned, they all work on this idea of a file descriptor. we have open up a file requires us our application send a request the operating system, whether it be windows or linux or whatever. this operating system is going return us some identifier associated with that file. if we're allowed open this file, it's going say. here you go. if you want refer this file later on in the future, use this identifier. on windows it uses a file handle. on posix, it uses a file descriptor. it's just a hand. just have number."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","we have open up a file requires us our application send a request the operating system, whether it be windows or linux or whatever. this operating system is going return us some identifier associated with that file. if we're allowed open this file, it's going say. here you go. if you want refer this file later on in the future, use this identifier. on windows it uses a file handle. on posix, it uses a file descriptor. it's just a hand. just have number. there's some set of this script there. it's kind of like a process id as well. that's all we refer a process. then we can issue operations against that file descriptor every single time we want access anything with this file, it has be through a system call 1. what's the file system isolation and protection protection? what do i always say? distraction abstractions are cool. because there is no real files in our system, the operating system is making up what a file is. ultimately, a regular file is represented as a bunch of bits and bytes stored on some permanent storage. will there be a disk drive or a flash drive or an nvme drive or whatever? it's some sort of persistent storage and the operating system has manage that in turn, bites that storing on a disk drive into a bunch of files and directories. we do n't get direct access that as a process. we have ask the operating system for everything when it comes these abstractions. so we have ask the operating system and the only way for us ask the operating system for anything is v system call. so all this stuff is system called, so real media file we read it or what we get a file and script our back we read it, we write it, we can do operations against it. we can remove it, we can change permissions on it, we can rename it. there's a lot of these sort of meta type operations we can do against a file, but ultimately the big ones are reading and writing and mover done. we'll close it tell the operating system we do n't need this anymore. right. so this is kind of neat. why is this kind of neat? well, we well, let me go back over here. open and close. ok, we need these access the file initially. what happens on an open? a bunch of stuff and there's a couple of key things that i want you remember."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","there's a lot of these sort of meta type operations we can do against a file, but ultimately the big ones are reading and writing and mover done. we'll close it tell the operating system we do n't need this anymore. right. so this is kind of neat. why is this kind of neat? well, we well, let me go back over here. open and close. ok, we need these access the file initially. what happens on an open? a bunch of stuff and there's a couple of key things that i want you remember. do n't want forget? first off, the operating system checks make sure you have permission access that file. so when you open a file, you have ask the operating system. you know, i would like access this file, but i would like access it for this particular purpose and the operating system is going say ok, do you have permission do that? and you looked at permissions already in your first part of your project, where you're looking at the different user, group and world permissions. so one of the things you can do is i would like open this for reading or i would like open it for writing. i would like open it for both and so the operating system is going look and say, well first off, does that file exist and do you as a user have permission access it in the way you want? if you do n't have read access but you're not accessing the file for reading, the operating system might say, ok, go ahead. there are situations where somebody might make a file that you only have write access, right? leave me comments, but i do n't want you see what anybody else's comments are and all the comments are not written this file. ok, alright. so once a file is open, here is the thing that's really cool about open. open is kind of like a contract, almost like a lock. implicitly on file, if the operating system grants you the ability access this file, it's a contract you say user you want access this file. you are allowed access this file, but for the course of your access i as the operating system will guarantee that that file never goes away. maybe like a situation where if i wanna use a piece of paper file, i'm given the file i asked the operating system. can you will get that file for me? and it was like here. here is the piece of paper you can go now and write on that."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","implicitly on file, if the operating system grants you the ability access this file, it's a contract you say user you want access this file. you are allowed access this file, but for the course of your access i as the operating system will guarantee that that file never goes away. maybe like a situation where if i wanna use a piece of paper file, i'm given the file i asked the operating system. can you will get that file for me? and it was like here. here is the piece of paper you can go now and write on that. and i'm sitting there. i'm reading from the file that i'm writing the file, but there's also a guarantee that a mean coworker of mine is n't gon na come around and snag that paper away from me, while while i wanna write it, it will always exist once it's open. now with the computer gets shut off. ok, all bets are off right? but have you ever noticed this? i noticed this and sometimes i just get really annoyed by it because something accidentally happened. but i will be working on my computer and i'll look and i'll say, hey, you know, i do n't need that file anymore and i'll go the windows explorer and i'll hit the delete key and they'll say i'm sorry i hit delete this file because it's currently an application using that file, they may run into that problem. that's the open contract, right? microsoft office or something made a contract with the operating system say i would like access this file and as a result the operating system said i'll make sure that nobody deletes it. it just kind of cool, is all but also a little frustrating. what i really want delete something when like microsoft word crashes or something and i wanna delete that file and now i have like reboot my computer or something like that in order get the ability delete a file that's part of open the dual open on the other side of the coin of open is closed when you close the file. this tells the operating system i no longer get this file. i am done with it and if somebody else wants delete it, rename it something like that. it's ok. i'm open and talks. we need open. we need tools and so you might just think, well, do n't we just need read and write? and you can say, well, yeah, that's true."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","and now i have like reboot my computer or something like that in order get the ability delete a file that's part of open the dual open on the other side of the coin of open is closed when you close the file. this tells the operating system i no longer get this file. i am done with it and if somebody else wants delete it, rename it something like that. it's ok. i'm open and talks. we need open. we need tools and so you might just think, well, do n't we just need read and write? and you can say, well, yeah, that's true. you might just need read and write, but this open and close is kind of that nice little contract, so keep that in mind. it's really important. ok, questions. all right, so let's dive into this a little bit more now. user oh user space kernel space. now let's talk about this, though i like the draw this picture. that's all it better in that this is kind of like an abstraction of memory. it's different than that, like bar that it normally draw, but this is like user memory and this is kernel memory. so i mentioned and we've sort of dived into this before inside kernel memory for a process is it's process control block right? and the process control block consists of a lot of stuff. they've been important ones. i really wanted you remember where the process identifier there's the cpu context, the registers, the program counter, the process state, right? we have that five state model. i think those are the big ones that i wanted you remember. i remember correctly, there's also the owner. the parent process identifier and that kind of stuff in the process control block, but really remember a lot of that stuff is stuff about the process as well as what we need when we load this process on the cpu, ok. inside the process control block is something that's also referred as the file descriptor table. it's a reference, a pointer what that is. ok, inside the file descriptor table are entries for files. these are the files that are processed currently has opened and can access ok. so when you open a file, the operating system says ok, what do you wanna do? you wanna open this file? so in user space in the user's memory, it's gon na have and say i want open a name. i'm gon na do it."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","inside the process control block is something that's also referred as the file descriptor table. it's a reference, a pointer what that is. ok, inside the file descriptor table are entries for files. these are the files that are processed currently has opened and can access ok. so when you open a file, the operating system says ok, what do you wanna do? you wanna open this file? so in user space in the user's memory, it's gon na have and say i want open a name. i'm gon na do it. i'm gon na write this in another color. we'll do. we'll do red. i'm gon na do an open operation. i wanna open this file. for this. purpose, whether it's things like read or write. ok, there's other stuff associated with open. open is a relatively lengthy system call. you can also specify operations the operating system say, well, if the file that i wanna open does n't exist, i want you create it and i want you create it with these permissions because they are n't set by default the some other values you could set with open for whether or not you want the operating system like do buffering or things like that. but ultimately, these are two the two big ones. we make us this call that system call transfers us into robert colonel mode, loads the operating system operating system, gets the number for the system call it says i wanna do an open and then it creates an entry under the assumption that you have the ability and the permissions access this file. for that purpose, it makes an entry for this file. we will call it. file dot txt inside the file descriptor table. so here is an entry for file dot txt. this ultimately file dot txt has a reference the data on the disk drive. that's why i draw disk drives like a cylinder. they're not really look like that anymore, but that's sort of the historical reason way we drive disk drives. we, the historical way i have drawn describes. maybe you guys, maybe you guys tried this drives all the time, i do n't know maybe anyway. so. so what do we have in here? well, this entrance enter entry into the file descriptor table. establishes that contract is like this file is not going be deleted. the file itself has metadata associated with the file. the specific big ones that i want mention here is we got the file name and one thing called is the position pointer."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","we, the historical way i have drawn describes. maybe you guys, maybe you guys tried this drives all the time, i do n't know maybe anyway. so. so what do we have in here? well, this entrance enter entry into the file descriptor table. establishes that contract is like this file is not going be deleted. the file itself has metadata associated with the file. the specific big ones that i want mention here is we got the file name and one thing called is the position pointer. it's not a memory address for se, but the position pointer indicates where in a file we are currently doing operations too. by default, that's initially set at the beginning of the file, so if we wanna read or write a file, you'll notice that when we look at the at, the system calls for read and write. if it just says read and write, but what data are we gon na get out of the file? we're gon na get data out of the file out of read wherever the current file position pointer is when we write data a file, we write at the location of the current file position pointer. there are system calls that we can use manipulate where that is now. one big one called elsik, allows you move where that file position pointer is so you can move it forward. you can move it back and you move it essentially relative things. you can move it in absolute an absolute location. i would like you move the file position pointer location 22. you can move it relative the beginning of the file. you can move it relative where the current file position pointer is forward and backward, or you can move it relative the end of the file. i wanted you go the end of the file backwards 10 bytes and that's where i want the file position pointer be. it's weird, but you can also advance the file position pointer past the end of a file. play around with that if you'd like, but anyway, so with these so far i've file descriptor table and file position pointer. ok, so let's look at this. here is the man page for open. it also happens be the man page for the create system call, because they're very similar. you can open a file and also create it if it does n't exist or you can call create creates a file if it does n't exist. ok, these open apps are and create our against. it's open."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","play around with that if you'd like, but anyway, so with these so far i've file descriptor table and file position pointer. ok, so let's look at this. here is the man page for open. it also happens be the man page for the create system call, because they're very similar. you can open a file and also create it if it does n't exist or you can call create creates a file if it does n't exist. ok, these open apps are and create our against. it's open. app open app our they're kind of i was like kind of weird, but they're a little bit more if you wanna have a little bit more power, right. with great power comes great responsibility. it gives you a lot more parameters for little tweaks and things you can specify and ask the operating system for or creating an opening files. we're not gon na commit those. the big ones i wanna look at is open. and so we see open takes a bunch of parameters. and so here again you see those three dots, means optional parameters, right? we do n't have specify them if we do n't want. there are certain situations where we do need, but there are optional path. this is the file that we want open. notice with exact vp and exact lp. well, any of the exact flavors that end in p, we can specify a file name here and have the operating system search for the file in its path, right? and the system environment variable path, we open the file, we must specify the absolute path the file. we can not specify and have it look in the path variable. it's just going. open it only in a specified tab. ok. his wife these flags specify all the file is going be open right back intended purpose. ok. what are the flags that we can specify? well, they're all listed in the man page and they go on. ohh sorry they go on and on and on and on and on and on and on and there's a lot of flags we can specify. one of the big ones that i want look at. these first ones. right here, flags include must include one of the following the access modes, right? this is the intended purpose. i wanna open it for read only or write only or for reading and writing. i like the other one that i kind of think it's kind of cool get. mention, is this one called ohh underscore a pen?"
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","ohh sorry they go on and on and on and on and on and on and on and there's a lot of flags we can specify. one of the big ones that i want look at. these first ones. right here, flags include must include one of the following the access modes, right? this is the intended purpose. i wanna open it for read only or write only or for reading and writing. i like the other one that i kind of think it's kind of cool get. mention, is this one called ohh underscore a pen? these are all constants that are defined in a header file, so you do n't have know these correspond a number, but i'm not gon na ask you memorize what the numbers are. kind of like errno, right? we know that two is file not found, but i'm not gon na ask you memorize that. oh, append. what this does is it opens the file and immediately seeks the file position pointer the end of the file. so if you wanna append data a file, you can open it for either reading and writing or writing only with an appendix mode, and they'll shoot the pilot position pointer the end, and then as soon as you start writing it will add the end of the file. ok, tennis. all right, other stuff, you know, that's pretty much what i want mention here. there is some stuff if you specify all underscore create it will create the file if it does n't exist. if you do that, then you have specify an additional parameter is the mode parameter over here, and if we scroll down again in the man page, you can see what mode is. it's a bunch of variables that you org together specify what permissions you want on the brand new file. the operating system is n't really going know what permissions create if it's a brand new file. so you as a user need say operating system create this file for me. here are the permissions i'd like you put on those files. ok. yes, you give them the list of flags just like you would with the. the second was that before? yeah, good question. so do you give open with these flags and these mode? do you give it a list, right? so would it be something like? open and then you could say like my file dot txt and then it would ohe rdwr and then o underscore append. is it something like that, right? apparently it's not or."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","here are the permissions i'd like you put on those files. ok. yes, you give them the list of flags just like you would with the. the second was that before? yeah, good question. so do you give open with these flags and these mode? do you give it a list, right? so would it be something like? open and then you could say like my file dot txt and then it would ohe rdwr and then o underscore append. is it something like that, right? apparently it's not or. fortunately, it's not what these flags are, is you, actually they're they're values that correspond bits. and so you actually order them together. so that's how we would open a file for reading and writing and handle. and i'll show you an example about that. ok. so let's look at read. it says read from a file descriptor. ohh no wait. let's go back. sorry, i mentioned the operating system. posix sort of standard for system calls. if there was a success, it returns a 0. if there's a failure, it returns -, 1, and errno is set accordingly, right. except not for open. i feel like i said. here's how it works for most system calls, and then i introduced 3 system calls right away that do n't work that way. fork does n't work that way. exec does n't work that way and open does n't quite work that way either. sorry, but anyway if we scroll all the way past down all the flags there we go and the big one is return value those unsuccess open returns the new file descriptive on non negative integer on error negative ones returned an error one sec. ok, let's this still is a second and error. we get -, 1 return, and eronel said. but unsuccess we get back a non a non negative number and that number represents the file descriptor right? the identifier for the file that we will use. uh, that's the identifier that we will use later access this file. right. it's going be a number. this is cool, just a number. most likely it will start with 0. does not have, but we get a number back that number and i'll and i'll reality. i get this does n't tell you that, but in all reality, that number corresponds an index inside your file descriptor table inside kernel space. but we do n't need worry about that."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","the identifier for the file that we will use. uh, that's the identifier that we will use later access this file. right. it's going be a number. this is cool, just a number. most likely it will start with 0. does not have, but we get a number back that number and i'll and i'll reality. i get this does n't tell you that, but in all reality, that number corresponds an index inside your file descriptor table inside kernel space. but we do n't need worry about that. we're just giving a number, so if we want our read from that number, reopen a file, we get the number back and we just hold on that number in a variable we wanna read from it. we pass that as a parameter when going right, right? where am i going? back the main page. so low in now that we have that, let's just look at read. ok, read it says we're going read from a file descriptor. what do we have? that's kind of cool. we'll come back that in a second read from a file descriptor in dev. we already know that cause we got open returning that we have a buffer outside. this asks the operating system. we have this system call. i would like read from this file descriptor where wherever the current file position pointer is in that file descriptor, i would like you read this many bytes out of that file and store the result inside this buffer. so i'm gon na point create a pointer, a storage location and a pass an address that the operating system. so when it comes a read. how am i gon na remember that colors here? let's do blue. inside memory and user space, i'm going create. in a ring, a buffer. here's my array, my buffer. this is going be in, in, in memory somewhere. i'm going have the address of this. call it address with the ampersand and i'm going say i would like read. i've got the file descriptor that was returned from open, so here's my fd, my number, the address of the buffer, and then some amount of size. now it could be the entire buffer or some subset of that, but it's got ta be at least as big as how much buffer my buffer has be at least as big as how much data i wanna read. so i'll say something like 10 some number."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","call it address with the ampersand and i'm going say i would like read. i've got the file descriptor that was returned from open, so here's my fd, my number, the address of the buffer, and then some amount of size. now it could be the entire buffer or some subset of that, but it's got ta be at least as big as how much buffer my buffer has be at least as big as how much data i wanna read. so i'll say something like 10 some number. i'll take all of these pieces of information as long with the read thing read system call number, call syscall. it'll go into the operating system. the operating system will use that file descriptor. look up the entry and the file descriptor table. find the file position pointer and send the appropriate for requests needed read the data off of disk. and because i'm passing a pointer in here, the operating system has all access all of memory. it will take the data that was read and copy it directly into my buffer on my behalf. because i'm not running, the algorithm is running. i will. i'll have worry about my memory being changed or the operating system. was that the worry about my memory being changed? because me and you have n't system are the only people that can change that memory buffer. ok, ok, makes sense. here's what's also kind of cool. i am requesting data from a file that is on disk. this might take a while, right? i mean, ok, milliseconds, microseconds. ok, pretty quick from my perspective as a human, but from the cpu's perspective and eternity as a result, while business happening, the operating system is also going update my process control block and update my state say that i'm waiting and that i ca n't run. right, so here is something cool. it's an advantage of that other state, but waiting is that it can update that this this drive will ultimately return the information necessary. then the operating system will get invoked again, copy the data into my memory buffer and change my state back reading. right. that's a lot of hand waving, but it's true. all fits together. ok, alright anyway. that's right. so let's ultimately now look at right, ohb. sorry, i keep jumping around. i'm going too fast."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","it's an advantage of that other state, but waiting is that it can update that this this drive will ultimately return the information necessary. then the operating system will get invoked again, copy the data into my memory buffer and change my state back reading. right. that's a lot of hand waving, but it's true. all fits together. ok, alright anyway. that's right. so let's ultimately now look at right, ohb. sorry, i keep jumping around. i'm going too fast. i got ta slow down, right? return value the guys another system call where it does n't exactly follow the same behavior that we have. still i'm error -, 1 is returning errno asset indicate the error. ok, that's good. alright, we got that. but unsuccess it actually says the number of bytes red is returned ok, zero indicates that we are at the end of the file. ok, we're reading data right? if i want create a buffer that's i do n't know, 4 gigabytes, there's a lot of memory, but i could consume that much memory. i do n't want read a file that's only like a kb in size. i'm going pass the operating system a pointer this buffer and a size that's 4 gigabytes. the operating system is going read that file and say ohh the user wants 4 gigabytes. ohh but wait, the file is only 100 k, so i'm gon na just copy the size of the file in there and for me let the user know how much data was actually read they requested for game. the operating system will say i do n't have 4 gig give you, but i have 100 k, so that's the size that's returned. the actual amount of data that was actually read. ok, there could differ from what you request. and that's really right. not ri ght, but rw rit works again, the other head of the coin, the other side of the coin, the parameters look very similar or writing a file descriptor where wherever the current file position pointer is, we're going write data from a particular buffer. that's that many bytes. size. that's the return value here is going be the number of bytes actually written. what's different, so speak between read and write? other. the fact that write writes the file and read reads the file is that write will extend the size of the file."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","not ri ght, but rw rit works again, the other head of the coin, the other side of the coin, the parameters look very similar or writing a file descriptor where wherever the current file position pointer is, we're going write data from a particular buffer. that's that many bytes. size. that's the return value here is going be the number of bytes actually written. what's different, so speak between read and write? other. the fact that write writes the file and read reads the file is that write will extend the size of the file. if we keep writing past the end of the file, we ca n't read past the end of file because it's the end. there's nothing read like you've reached the end of the internet. go back and start over. no, i mean, you're not well with, right? if i'm creating something i can write when i reach down in the file and it will grow as i need right? questions alright. is it maybe you've experienced this? i know that if you in in the c++ class you worked with file streams or you did cnc out. this is in a similar idea only it takes a little bit, a couple more parameters. you ca n't. just like see out a variable and you ca n't just write a variable. we always have a write buffer. it's always a pointer, right? right. so let's do an example and then we'll see how far like it's gon na be done for the day. we'll just call it ohh read write. so for this. we need figure out all the header files that we need, and there's a lot o for open. we need include affect control is file control. umm. i'm gon na also include std io cause i wanna print something out. umm. right. is in. you know what? i'm not gon na do this. so you another trick wright is in you and i std dot h. and i think reed is also there. yes, alright. so do this, we need file. think of text file hello, csc 3010 good. and now let's work on this. we have a file that exists called myfile, and we want open it. open returns a value for a file descriptor, so i'm going say int fd equals open and the file i wanna open is myfile dot txt."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","i'm not gon na do this. so you another trick wright is in you and i std dot h. and i think reed is also there. yes, alright. so do this, we need file. think of text file hello, csc 3010 good. and now let's work on this. we have a file that exists called myfile, and we want open it. open returns a value for a file descriptor, so i'm going say int fd equals open and the file i wanna open is myfile dot txt. and if you look at that, you'll immediately jump and throw tomatoes and, say, doctor lembke. you told me we could n't specify a file name. you have specify a path name right and that i say yes. what the operating system will do is it will say you want this file. ohh you did n't specify an absolute path that file. what i'm gon na do is look for that file in your current working directory and it will sort of implicitly append the current working directory. i'm going compile this 88 out eight and that's gon na be here in my examples my file wherever it is or they put it right here is inside the same directory as that. so i do n't need the absolute path that if i wanted open a file somewhere else. sure enough, yes, i would have specify the absolute path. i'm gon na open this for ordr w for reading and writing, and that's all i need. now, as any good programmer i should check see if this returned -, 1. and i think i will do this. going then print off could not open my file dot txt and then the error is this is gon na be str error. there are no, means i need return and then i also need include. air noah, get the global definition of errno and string dot h get str error. should also have my main return and. i always do the his whenever i'm using open because just like with malik, got ta free the maliks. we have end this contract with the operating system and we're done with the file. we must close it and so close a file we just call it close. it's a separate system call, but i do n't ever want forget, so i always do that because if i open a file but not close it, then i run into the situation where we've got these like lagging contracts sitting around and so make sure we close the opens and now we can read."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","i always do the his whenever i'm using open because just like with malik, got ta free the maliks. we have end this contract with the operating system and we're done with the file. we must close it and so close a file we just call it close. it's a separate system call, but i do n't ever want forget, so i always do that because if i open a file but not close it, then i run into the situation where we've got these like lagging contracts sitting around and so make sure we close the opens and now we can read. so read i need a buffer put something in. read buffer. umm, let's just i do n't know, 100 bytes and now we can read so. bites red. read from our file descriptor we wanna pass in the read buffer and i'm passing an array and so are raised by default are passed by pointer so that read buffer will get translated by the compiler into an address. so i'm good. that's what the operating system wants, and i could specify 100 in here. i can also. specify the size of in this situation. works because the compiler knows how big this is. it's defined right here. it's 100 characters, so it will essentially pass in 100. what i like about doing it this way is i'm always know then how big the buffer is. what i really should do is if i specify 100 like this. this. that's me being extra smart in knowing that a character is 1 bite. what i really should do is i'm gon na do 100 here. i should say 100 times the size of a character, just be sure that makes sense. whatever we kind of, we did that in our c review, alright, so. all right, if by its red. then this is could not read well. i could n't. i read. well, we'll figure it out. now, you might be tempted just write return one here say, well, i had a failure. i do n't wanna continue on so i wanna return, but as soon as you do that, you should start something like wait. something does n't feel right. someone poking me, i got some sort of thing in my chair. and the the thing that bothers me about this is i want point that out is i'm like 8, we open online 22 we close. and then 18 or line 19 were returning."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","now, you might be tempted just write return one here say, well, i had a failure. i do n't wanna continue on so i wanna return, but as soon as you do that, you should start something like wait. something does n't feel right. someone poking me, i got some sort of thing in my chair. and the the thing that bothers me about this is i want point that out is i'm like 8, we open online 22 we close. and then 18 or line 19 were returning. we never close, so just like we opened, we got ta close. you might say, well, why do n't we close up here? well, we do n't need close up there because with that -, 1 returned open. that means we never opened, so if we never opened, you never have close. once you open, you got ta close. so what i could do is none of return here and let it drop through. but if this really was something i did n't want continue through, i really got ta make sure that i closed my update. makes sense. yeah. so close before you return. sometimes i'll also put like a comment up here say do n't forget close. right now we've got this. i read. ah, read buffer. good. uh, it's not a number. and there we go. close. so go ahead. so let's try this and see if it works. what did i call it? not my file read, write and what do i have the probably missing symposium icons? i got parentheses wrong. ok, that's that. also, am i doing? rd i always do this every single time. it's not rdr wrd wr. no, i think it's like a i wanna do like r and then a character and then another and then a character. that's not how you spell that. alright, we go. there i rad hello, cs c3210k. reading the roads are good, right? let's do right. right buffer right buffer equals. hello again. so i can write and for that it's just as easy do a copy of this and i'll accept like write this, but it's written. i'm going write the file descriptor on the right the right buffer. now comes a question. how many characters do i want write? here we said operating system. i'd like you read 100 characters, the operating system said no."
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","there i rad hello, cs c3210k. reading the roads are good, right? let's do right. right buffer right buffer equals. hello again. so i can write and for that it's just as easy do a copy of this and i'll accept like write this, but it's written. i'm going write the file descriptor on the right the right buffer. now comes a question. how many characters do i want write? here we said operating system. i'd like you read 100 characters, the operating system said no. ok, i i do n't have 100 bytes, but here are something i probably should read that out just just for fun. show you that it's not what is the problem there now it's that it'll work. it's time my format it's not right but anyway so, but when i write i have say exactly how many bytes i wanna write, how many bytes do you guys want write when we count 1234567891011? cool. do you wanna write the null terminator? if we if not right. well, certainly would work. it will also write the null terminator depending on what we're doing and what we wanna save our file, it might not make any sense put the null terminator in the text file, right? so in this case, i actually do n't want print the null terminator, but i also do n't necessarily wanna know that this is 11 or whatever bytes, so i'm gon na do is i'm gon na say. str len of wright buffer times the size of a character. this will use the string function tell me how big that is by standing across and adding up the number of characters in it. but i'm also then going multiply by the size of a character, so as i get that right. do n't forget close the file so could not write there you go close and we're done. ah, bytes written. good with me. so let's run this and hope that it compiles. fingers crossed. no, of course not. what do i have? i spell written wrong. ohh bytes written. ok, that's good. it's giving me some warnings about formats because these are not right. well, well, what? i worry about that cause those are just formatting errors, but let's print this out just because we're out of time. sure enough, there it is. i read 13 bytes even though i asked for 100. that's there. i wrote eleven bytes. where did i write them?"
"""OpSys_Unerstanding_Fork_and_Exec_Transcript.txt""","no, of course not. what do i have? i spell written wrong. ohh bytes written. ok, that's good. it's giving me some warnings about formats because these are not right. well, well, what? i worry about that cause those are just formatting errors, but let's print this out just because we're out of time. sure enough, there it is. i read 13 bytes even though i asked for 100. that's there. i wrote eleven bytes. where did i write them? i wrote them wherever the file position pointer is read and write both advance the file position pointer. so if i look at my file now, when i read those fights, i read one of them 13 bytes, but after reading the file position pointer was advanced the end of the file. so when i wrote hello again, it wrote wherever the file position pointer wants. so if i run this again, we'll see that i read 100, i read 24 bytes because i passed it a buffer that was 100 bytes long. but then when i wrote again, i wrote at the current position pointer. notice that i added bar at the end of the file. we if i wanted overwrite the old hello again with the new hello again, i would have had move the file position pointer around. ok. so we're on time. we'll start there. we'll see you on thursday. do n't forget programming project. also do thursday night. lembke, james stopped transcription"
