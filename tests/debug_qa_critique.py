"""Debug script for QA generation and critique process.

This script processes a small number of random chunks and prints detailed information
about each step of the process.
"""

import json
import pandas as pd
import random
from pathlib import Path
from llmqa import ROSIELlama, QAGenerator, CritiqueAgent, DatabricksModel

def print_separator(title: str = ""):
    """Print a separator line with optional title."""
    print("\n" + "="*80)
    if title:
        print(title)
        print("-"*80)

def main():
    # Configuration
    INPUT_FILE = "/home/drobeka/riley-team-14/LLMQA/tests/chunks/opsys_chunks.csv"  # Update this path as needed
    NUM_CHUNKS = 3  # Number of chunks to process
    
    print_separator("Configuration")
    print(f"Input file: {INPUT_FILE}")
    print(f"Number of chunks to process: {NUM_CHUNKS}")
    
    # Initialize models
    print_separator("Initializing Models")
    qa_model = ROSIELlama()
    critique_model = DatabricksModel(
        model_name="databricks-mixtral-8x7b-instruct",
        system_prompt="You are a critique agent that evaluates questions generated by another LLM from chunks of data.",
        base_url="https://dbc-e66ac7b6-520c.cloud.databricks.com/serving-endpoints"           
                                     )
    
    critique_agent = CritiqueAgent(critique_model)
    
    # Create generator with critique
    generator = QAGenerator(
        model=qa_model,
        critique_agent=critique_agent,
        min_critique_score=3.0,
        critique_criteria=['groundedness', 'relevance', 'standalone'],
        num_workers=1  # Force single process for debugging
    )
    
    # Read chunks
    print_separator("Reading Input File")
    try:
        df = pd.read_csv(INPUT_FILE)
        total_chunks = len(df)
        # Randomly select chunk indices
        selected_indices = random.sample(range(total_chunks), NUM_CHUNKS)
        chunks = [(idx, df['processed_text'].iloc[idx]) for idx in selected_indices]
        print(f"Successfully read {total_chunks} total chunks")
        print(f"Selected chunks at indices: {selected_indices}")
    except Exception as e:
        print(f"Error reading file: {e}")
        return
    
    # Process each chunk
    all_results = []
    for i, (chunk_idx, chunk) in enumerate(chunks, 1):
        print_separator(f"Processing Chunk {i}/{len(chunks)} (Index: {chunk_idx})")
        
        print("\nINPUT CHUNK:")
        print("-"*40)
        print(chunk)
        print("-"*40)
        
        try:
            # Generate QA pairs
            print("\nGENERATING QA PAIRS...")
            qa_pairs = generator.generate_from_chunk(chunk)
            
            print("\nGENERATED QA PAIRS:")
            print("-"*40)
            for j, pair in enumerate(qa_pairs, 1):
                print(f"\nPair {j}:")
                print(f"Question: {pair['question']}")
                print(f"Answer: {pair['answer']}")
                if 'critiques' in pair:
                    print("\nCritiques:")
                    for criterion, critique in pair['critiques'].items():
                        print(f"\n{criterion.capitalize()}:")
                        print(f"Rating: {critique['rating']}")
                        print(f"Evaluation: {critique['evaluation']}")
                if 'aggregate_score' in pair:
                    print(f"\nAggregate Score: {pair['aggregate_score']}")
                print("-"*40)
            
            # Add chunk index to results
            for pair in qa_pairs:
                pair['chunk_index'] = chunk_idx
            all_results.extend(qa_pairs)
            
        except Exception as e:
            print(f"Error processing chunk {chunk_idx}: {e}")
    
    # Save results
    print_separator("Saving Results")
    output_file = "debug_qa_output.json"
    try:
        with open(output_file, 'w') as f:
            json.dump(all_results, f, indent=2)
        print(f"Results saved to {output_file}")
    except Exception as e:
        print(f"Error saving results: {e}")
    
    # Print summary
    print_separator("Summary")
    print(f"Total chunks in dataset: {total_chunks}")
    print(f"Chunks processed: {len(chunks)} at indices {selected_indices}")
    print(f"Total QA pairs generated: {len(all_results)}")
    if all_results:
        scores = [pair.get('aggregate_score') for pair in all_results if 'aggregate_score' in pair]
        if scores:
            print(f"Average critique score: {sum(scores)/len(scores):.2f}")
            print(f"Score range: {min(scores):.2f} - {max(scores):.2f}")
        
        # Print QA pairs per chunk
        print("\nQA pairs per chunk:")
        for idx in selected_indices:
            pairs = [p for p in all_results if p['chunk_index'] == idx]
            print(f"Chunk {idx}: {len(pairs)} pairs")

if __name__ == "__main__":
    main() 